[
{"title": "Real-Time Calibration Model for Low-Cost Sensor in Fine-Grained Time Series", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Real-Time Calibration Model for Low-Cost Sensor in Fine-Grained Time Series\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Real-Time Calibration Model\", \"Low-Cost Sensor\", and \"Fine-Grained Time Series\". The mention of \"Time Series\" right there is a big clue. Time-series analysis involves data points indexed in time order, which is exactly what the title is referring to with \"Fine-Grained Time Series\". \n\nNow, checking the other options. Multimodal usually refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not that. RAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval. That doesn't seem relevant here either. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about knowledge graphs or structured data in that sense.\n\nThe focus is clearly on time series data, specifically for sensor calibration in real-time. So the correct topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/31974@AAAI"},
{"title": "AAAI.2025 - Application Domains", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"AAAI.2025 - Application Domains\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics entails. Time-series research typically involves data points indexed in time order, like stock prices or weather data. Multimodal refers to the use of multiple data types or modalities, such as combining text, images, and audio. RAG stands for Retrieval-Augmented Generation, which is a method in AI where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which involves structured representations of knowledge, often used for semantic search or reasoning.\n\nNow, looking at the title \"AAAI.2025 - Application Domains\". AAAI is the Association for the Advancement of Artificial Intelligence, so this is likely a conference paper. The title mentions \"Application Domains\", which suggests it's about where AI is applied, but it's pretty generic. The problem is that the title doesn't specify any particular technique or focus area. It's just stating the conference year and the general topic of application domains. \n\nApplication domains could cover a wide range of areas, like healthcare, finance, robotics, etc. Without more specific keywords in the title, it's hard to pin it down to one of the four topics. The title doesn't mention anything about time-series data, multimodal inputs, retrieval-augmented generation, or knowledge graphs. It's too broad. Therefore, it doesn't clearly belong to any of the specified topics. \n\nI should check if there's any possible overlap. For example, if the application domains discussed in the paper are related to multimodal data, but the title doesn't indicate that. Similarly, if it's about applying RAG or KG in certain domains, but again, the title doesn't specify. Since the title is just \"Application Domains\" without any modifiers, it's too vague. So the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/AAAI.2025?group=Application Domains"},
{"title": "BayesCNS: A Unified Bayesian Approach to Address Cold Start and Non-Stationarity in Search Systems at Scale", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BayesCNS: A Unified Bayesian Approach to Address Cold Start and Non-Stationarity in Search Systems at Scale.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are Bayesian approach, cold start, non-stationarity, and search systems. The problem being addressed is cold start and non-stationarity in search systems. The method is a Bayesian approach.\n\nCold start usually refers to the problem in recommendation systems where new items or users have no prior data. Non-stationarity means that the data distribution changes over time. Search systems at scale would involve handling large amounts of data and possibly dynamic environments.\n\nNow, looking at the four options:\n\n1. Time-series: This typically involves data points indexed in time order. The paper mentions non-stationarity, which is a concept in time-series analysis where statistical properties change over time. However, the main focus here is on search systems and cold start, which might not be strictly time-series. But non-stationarity could be a part of time-series challenges.\n\n2. Multimodal: This refers to systems that use multiple types of data (e.g., text, images, audio). The title doesn't mention different data modalities, so probably not this one.\n\n3. RAG (Retrieval-Augmented Generation): This is a method where a model retrieves relevant documents and uses them to generate answers. The title doesn't mention retrieval or generation, so maybe not RAG.\n\n4. KG (Knowledge Graph): Involves structured data representations. The paper doesn't mention knowledge graphs or structured data, so likely not KG.\n\nSo, the closest might be time-series because of non-stationarity. But wait, non-stationarity is a property of time-series data, but the paper is about search systems. Search systems can involve time-series data if they track user behavior over time. However, the cold start problem is more about initial data scarcity rather than time-series. The Bayesian approach is a method, but the topics are about the problem domain. \n\nAlternatively, maybe none of the four topics fit. The problem is cold start and non-stationarity in search systems, which might not neatly fit into time-series, multimodal, RAG, or KG. The paper is about a Bayesian method to handle these issues, but the topics listed are about the type of research area. Since the title doesn't mention time-series, multimodal, RAG, or KG, maybe the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31975@AAAI"},
{"title": "Scalable Surrogate Verification of Image-Based Neural Network Control Systems Using Composition and Unrolling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Scalable Surrogate Verification of Image-Based Neural Network Control Systems Using Composition and Unrolling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main subject is about verifying neural network control systems that are image-based. The methods mentioned are composition and unrolling. The goal is scalable surrogate verification. \n\nTime-series usually involves data over time, like sequences or temporal data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining images and text. The title says \"image-based,\" but it's about control systems. I'm not sure if it's combining different modalities. Maybe, but the focus seems more on verification techniques rather than multimodal data.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge representation. \n\nThe key terms here are \"surrogate verification,\" \"composition,\" and \"unrolling.\" Surrogate models are often used in verification to approximate complex systems. Composition and unrolling might refer to techniques for breaking down the system into parts for verification. This seems more related to formal verification methods in AI, which isn't one of the listed topics. Since none of the four topics (time-series, multimodal, RAG, KG) are clearly addressed here, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31976@AAAI"},
{"title": "External Reliable Information-enhanced Multimodal Contrastive Learning for Fake News Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"External Reliable Information-enhanced Multimodal Contrastive Learning for Fake News Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Multimodal Contrastive Learning\" and \"External Reliable Information-enhanced.\" The term \"Multimodal\" immediately stands out. Multimodal refers to using multiple types of data, like text, images, audio, etc. So that's one of the options. The other part is \"External Reliable Information-enhanced.\" That might relate to using external sources, which could be part of a knowledge graph (KG) or maybe Retrieval-Augmented Generation (RAG). But RAG is more about using retrieved information during the generation process, while KGs are structured knowledge bases. However, the main focus here seems to be on multimodal data. The title mentions \"Multimodal Contrastive Learning,\" which is a technique in multimodal learning. The enhancement with external information might be a method to improve the model, but the core topic is multimodal. Time-series isn't mentioned here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/31977@AAAI"},
{"title": "Holistic Semantic Representation for Navigational Trajectory Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Holistic Semantic Representation for Navigational Trajectory Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Holistic Semantic Representation\" suggests they're creating a comprehensive model that captures meaning. \"Navigational Trajectory Generation\" implies it's about creating paths or routes, probably in a spatial context like robotics or autonomous vehicles.\n\nTime-series usually involves data over time, like stock prices or sensor data. If the paper was about analyzing sequences of data points over time, it would fit here. But the title doesn't mention time explicitly. It's more about generating trajectories, which could involve time, but maybe not the focus.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not this one.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses retrieved information to generate responses. The title doesn't mention retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. If the paper is about building or using a knowledge graph for navigation, that could fit. The term \"semantic representation\" might relate to knowledge graphs, as they often encode semantic relationships. However, \"holistic\" might imply integrating various data sources or modalities, but the title doesn't specify using a graph structure.\n\nAlternatively, maybe it's about creating a semantic model for navigation, which could involve understanding the environment's semantics. But without explicit mention of knowledge graphs or retrieval, it's a bit unclear. The key here is whether \"semantic representation\" here is part of a knowledge graph. If the paper uses a knowledge graph to represent the semantic information for trajectory generation, then KG would be the answer. Otherwise, if it's just a semantic model without a graph structure, it might not fit any of the four.\n\nGiven the options, the closest might be KG if they're using a structured knowledge base. But the title doesn't explicitly state that. The other options don't seem to fit. Since the user wants only the topic name if it fits, and \"none\" otherwise, I might lean towards \"none\" if it's not clearly one of the four. However, \"semantic representation\" is often associated with knowledge graphs. Maybe the answer is KG. But I'm not entirely sure. Alternatively, maybe it's multimodal if they're combining different data types for the semantic model. But again, the title doesn't mention multiple modalities. Hmm. I think the safest answer here is \"none\" because the title doesn't clearly align with any of the four specified topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/31978@AAAI"},
{"title": "SQLFixAgent: Towards Semantic-Accurate Text-to-SQL Parsing via Consistency-Enhanced Multi-Agent Collaboration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SQLFixAgent: Towards Semantic-Accurate Text-to-SQL Parsing via Consistency-Enhanced Multi-Agent Collaboration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on Text-to-SQL parsing. That's converting natural language into SQL queries. The key terms here are \"Semantic-Accurate\" and \"Multi-Agent Collaboration.\" \n\nTime-series usually deals with data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like text and images. The paper here is about text-to-SQL, which is converting text into structured queries. Unless they're using other modalities besides text, but the title doesn't indicate that. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title mentions \"Multi-Agent Collaboration,\" which could involve different agents working together, but RAG specifically involves retrieval. The paper's focus is on improving the accuracy through consistency in agents, not necessarily retrieving external information. So maybe not RAG.\n\nKG is Knowledge Graphs. Those are structured representations of knowledge. If the paper is building or using a knowledge graph, that would be the case. However, the title is about parsing text into SQL, which is more about database queries. Unless the SQL is part of a knowledge graph, but the title doesn't mention that. So probably not KG.\n\nSo the options are none. Wait, but the user said if it doesn't belong to any of these, respond with \"none.\" But maybe I'm missing something. Let me check again. The paper is about Text-to-SQL parsing. None of the four topics (time-series, multimodal, RAG, KG) directly relate to that. Unless there's an overlap. For example, RAG could be used in generating SQL queries by retrieving relevant data, but the title doesn't mention retrieval. The \"Multi-Agent Collaboration\" part might be a method, but the main topic is the parsing itself. So I think the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31979@AAAI"},
{"title": "mmFAS: Multimodal Face Anti-Spoofing Using Multi-Level Alignment and Switch-Attention Fusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"mmFAS: Multimodal Face Anti-Spoofing Using Multi-Level Alignment and Switch-Attention Fusion.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Multimodal,\" which immediately makes me think the topic might be multimodal. But I should check the other parts to be sure. The paper is about face anti-spoofing, which is a security or biometric authentication problem. The methods used are multi-level alignment and switch-attention fusion. \n\nMultimodal typically refers to using multiple types of data or modalities, like combining images, text, audio, etc. In this case, face anti-spoofing might involve using different modalities such as RGB images, depth maps, infrared, etc. The \"Multi-Level Alignment\" could be aligning different modalities at various levels, and \"Switch-Attention Fusion\" might be a way to combine information from these modalities effectively. \n\nTime-series would involve data over time, like stock prices or sensor data over time. RAG (Retrieval-Augmented Generation) is more about using retrieval methods to augment generative models, often in NLP. KG (Knowledge Graph) involves structured data and relationships between entities. \n\nSince the title explicitly states \"Multimodal\" and the methods seem to focus on combining different data types for face anti-spoofing, this fits the multimodal category. There's no mention of time-series data, RAG, or knowledge graphs here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/31980@AAAI"},
{"title": "CLEP: A Novel Contrastive Learning Method for Evolutionary Reentrancy Vulnerability Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CLEP: A Novel Contrastive Learning Method for Evolutionary Reentrancy Vulnerability Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are \"Contrastive Learning Method\" and \"Evolutionary Reentrancy Vulnerability Detection.\" Contrastive learning is a type of machine learning technique where the model learns by comparing similar and dissimilar examples. That part doesn't immediately point to any of the four topics listed.\n\nNext, \"Evolutionary Reentrancy Vulnerability Detection.\" Reentrancy is a type of vulnerability in software, especially in smart contracts, where a function can be re-entered before the previous execution is completed, leading to potential exploits. So the paper is about detecting such vulnerabilities using an evolutionary approach. \n\nNow, looking at the four options: time-series, multimodal, RAG, KG. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about combining retrieval of information with generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on a contrastive learning method for a specific vulnerability detection. None of the four topics directly relate to vulnerability detection in software. The method uses contrastive learning, but that's a technique, not a research topic. The problem domain here is software security, which isn't one of the listed topics. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31981@AAAI"},
{"title": "GLCF: A Global-Local Multimodal Coherence Analysis Framework for Talking Face Generation Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GLCF: A Global-Local Multimodal Coherence Analysis Framework for Talking Face Generation Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Multimodal\" is right there in the title. That's one of the options. The framework is for analyzing coherence between different modalities, probably combining things like audio and video. The application is talking face generation detection, which might involve checking if the generated faces (like in videos) are coherent with the audio, so using multiple modalities makes sense.\n\nThe other parts of the title mention \"Global-Local,\" which might refer to analyzing both overall and detailed aspects, but that's more about the method rather than the topic. The key term here is \"Multimodal.\" The other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is about combining retrieval with generation models. KG is Knowledge Graphs, which are structured data representations. None of those terms are in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/31982@AAAI"}
{"title": "ReactGPT: Understanding of Chemical Reactions via In-Context Tuning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ReactGPT: Understanding of Chemical Reactions via In-Context Tuning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. ReactGPT sounds like a model name, possibly related to chemical reactions. The key part here is \"Understanding of Chemical Reactions via In-Context Tuning.\" In-context tuning is a term I've heard in the context of large language models where they adjust their behavior based on the context provided in the input. So maybe this is about using a model that's being fine-tuned or adapted for chemical reactions.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. Multimodal usually refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method where a model uses retrieved information to generate answers. KG is Knowledge Graph, which is a structured representation of knowledge.\n\nThe paper's focus is on understanding chemical reactions. If they're using in-context tuning, maybe they're using a model that's retrieving information about reactions to generate answers. That sounds like RAG because RAG involves retrieving relevant information from a database or knowledge base to assist in generating responses. Alternatively, if they're building a knowledge graph of chemical reactions, it could be KG. But the term \"in-context tuning\" makes me think more about RAG, where the model uses retrieved context to adjust its output. \n\nI don't think it's time-series because chemical reactions aren't inherently time-dependent data. Multimodal would require combining different data types, which isn't mentioned here. So between RAG and KG. Since the title mentions \"in-context tuning,\" which is a technique used in RAG, I'm leaning towards RAG. The model is probably retrieving information about chemical reactions to generate or understand them better. So the answer should be RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/31983@AAAI"},
{"title": "4D Diffusion for Dynamic Protein Structure Prediction with Reference and Motion Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"4D Diffusion for Dynamic Protein Structure Prediction with Reference and Motion Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"4D Diffusion\" probably refers to a method that models four-dimensional data, which might include time as a dimension. \"Dynamic Protein Structure Prediction\" suggests that the protein structures are changing over time, so there's a temporal aspect here. \"Reference and Motion Guidance\" could mean that the model uses some reference structures and motion information to guide the prediction.\n\nTime-series analysis deals with data points indexed in time order. Since the paper is about dynamic structures (which change over time), this might be a time-series topic. But wait, the other options are multimodal, RAG, and KG. Let's check those.\n\nMultimodal refers to using multiple types of data (like text and images). The title doesn't mention different data types, so maybe not multimodal. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title mentions \"Reference,\" which could be retrieval, but I'm not sure if it's RAG. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention graphs or structured knowledge, so probably not KG.\n\nSo, the main aspects are dynamic structures (time) and motion guidance. That points towards time-series. But wait, the 4D might include spatial dimensions as well. However, the key here is the dynamic aspect, which implies time. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/31984@AAAI"},
{"title": "G2LDetect: A Global-to-Local Approach for Hallucination Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"G2LDetect: A Global-to-Local Approach for Hallucination Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Global-to-Local\" suggests a method that looks at both the big picture and details. \"Hallucination Detection\" probably refers to identifying when a model makes up information, which is common in things like chatbots or language models. \n\nNow, the four options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method where a model uses retrieved information to generate answers. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on detecting hallucinations. RAG is a technique where a model retrieves information from a database and then generates a response. If the model is using RAG, it might hallucinate if the retrieved info is incorrect or if it combines it wrongly. So, a method to detect hallucinations in RAG systems would make sense. \n\nAlternatively, could it be multimodal? If the hallucination detection involves multiple modalities, but the title doesn't mention that. Time-series seems unrelated. KG might be involved if the knowledge graph is used for detection, but the title doesn't specify that. \n\nSo, the most likely is RAG. The paper is probably about detecting when a RAG-based model is hallucinating. Therefore, the topic is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/31985@AAAI"},
{"title": "3D Denoisers Are Good 2D Teachers: Molecular Pretraining via Denoising and Cross-Modal Distillation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"3D Denoisers Are Good 2D Teachers: Molecular Pretraining via Denoising and Cross-Modal Distillation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"3D Denoisers\" and \"2D Teachers\" suggest there's some kind of model or method that's working with different data representations. The mention of \"Cross-Modal Distillation\" is a big clue. Cross-modal usually refers to combining different types of data or modalities, like text and images, or in this case maybe 3D and 2D data. So \"cross-modal\" directly points to the multimodal topic. \n\nThe paper is about pretraining molecular models using denoising and cross-modal distillation. Denoising is a common technique in machine learning, especially in areas like autoencoders or diffusion models. But the key here is the cross-modal aspect. Since multimodal research involves integrating multiple data modalities, this seems to fit. \n\nLooking at the other options: time-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, often in NLP. KG (Knowledge Graphs) involves structured data and relationships. None of these seem to fit the cross-modal distillation part. \n\nSo the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/31986@AAAI"},
{"title": "CryoDomain: Sequence-free Protein Domain Identification from Low-resolution Cryo-EM Density Maps", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CryoDomain: Sequence-free Protein Domain Identification from Low-resolution Cryo-EM Density Maps.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on identifying protein domains using low-resolution Cryo-EM density maps. The key terms here are \"sequence-free,\" \"protein domain,\" and \"Cryo-EM density maps.\" \n\nTime-series usually involves data points indexed in time order, like stock prices over time or sensor data. This doesn't seem related to time-based data, so probably not time-series.\n\nMultimodal refers to combining multiple data types or modalities, such as text and images. The paper uses Cryo-EM density maps, which are a type of imaging data, but the title doesn't mention combining different data types. It's about using a specific type of data (density maps) without relying on sequence information. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This paper is about protein domain identification, which is more of a computational biology or bioinformatics problem. I don't see a direct link to RAG here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper were about building or using a knowledge graph for protein domains, that might fit. However, the title focuses on a method for identifying domains from density maps, not on constructing a graph or using existing knowledge structures.\n\nThe term \"sequence-free\" suggests that the method doesn't rely on the protein's amino acid sequence, which is a common approach in bioinformatics. Instead, it uses the 3D density maps from Cryo-EM. This seems like a novel approach in structural biology, but none of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The paper is about a specific computational method in structural biology, but the provided options don't cover that. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31987@AAAI"},
{"title": "Less Is More: Adaptive Program Repair with Bug Localization and Preference Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Less Is More: Adaptive Program Repair with Bug Localization and Preference Learning.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on program repair. Adaptive program repair suggests it's about automatically fixing bugs in software. Bug localization is part of that process, identifying where the bugs are. Preference learning might involve learning user preferences or certain patterns to guide the repair process.\n\nNow, the four options: time-series, multimodal, RAG, KG. Time-series usually involves data over time, like stock prices or sensor data. Multimodal deals with multiple data types, like combining text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time-based data, so time-series is probably out. There's no indication of combining different data modalities, so multimodal isn't it either. RAG and KG are both related to knowledge and information retrieval. However, the paper is about program repair, which is more about software engineering and automated fixing of code. The mention of preference learning might relate to learning from data, but it's not clear if it's using a knowledge graph or retrieval-augmented methods. Since the title doesn't explicitly reference knowledge graphs or retrieval-augmented generation, and the main focus is on program repair techniques, it doesn't fit into RAG or KG. Therefore, the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/31988@AAAI"},
{"title": "Improving Cancer Gene Prediction by Enhancing Common Information Between the PPI Network and Gene Functional Association", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Improving Cancer Gene Prediction by Enhancing Common Information Between the PPI Network and Gene Functional Association.\" I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main goal is improving cancer gene prediction. The method mentioned is enhancing common information between the PPI (Protein-Protein Interaction) network and gene functional association. \n\nPPI networks are about how proteins interact with each other, which is a type of biological network. Gene functional association refers to how genes are related in terms of their functions. So, the paper is combining two different data sources: the PPI network and gene functional data. \n\nNow, looking at the possible topics. Time-series usually involves data collected over time, like stock prices or weather data. This title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to using multiple types of data or modalities. Here, they are combining two different data types (PPI and gene function), so that might be multimodal. But wait, multimodal typically refers to different types of data like text, images, audio, etc. In this case, both are biological data, but they are different types of networks or associations. Maybe it's still multimodal? Or maybe it's knowledge graphs (KG)?\n\nKnowledge graphs are structured representations of knowledge, often integrating multiple sources. If they are combining PPI and gene functional associations into a structured graph, that could be a knowledge graph. The term \"common information\" might imply integrating these into a graph structure. \n\nRAG (Retrieval-Augmented Generation) is a method that combines retrieval of information with generation, often used in NLP. This doesn't seem to fit here. \n\nSo, the key is whether combining PPI and gene functional associations is a multimodal approach or a knowledge graph. Since both are structured data (networks and associations), integrating them into a unified structure sounds more like a knowledge graph. The paper is likely building a knowledge graph that combines these two sources to improve gene prediction. Therefore, the topic would be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/31989@AAAI"},
{"title": "AutoSciLab: A Self-Driving Laboratory for Interpretable Scientific Discovery", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AutoSciLab: A Self-Driving Laboratory for Interpretable Scientific Discovery.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Self-Driving Laboratory\" suggests automation in a lab setting, probably using AI or machine learning to conduct experiments. \"Interpretable Scientific Discovery\" implies that the system is designed to make the process of discovery understandable, maybe using models that are transparent or explainable.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to combining different types of data, such as text, images, and audio. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which structures information in a graph format to represent relationships between entities.\n\nThe paper's focus is on a self-driving lab for scientific discovery. That sounds more like an automated system for conducting experiments, possibly using AI to optimize or interpret results. None of the four topics directly relate to automation in a lab setting. Time-series might be involved if they're analyzing data over time, but the title doesn't mention that. Multimodal could be a stretch if they're using various data types, but again, the title doesn't specify. RAG and KG are more about information retrieval and knowledge representation, which don't seem central here. The key terms are \"self-driving\" and \"interpretable,\" which don't align with any of the listed topics. So, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31990@AAAI"},
{"title": "FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on stock returns prediction. The methods mentioned are a hypergraph-based factor model and temporal residual contrastive learning. \n\nTime-series analysis often deals with data points indexed in time order, which is common in stock market data. The term \"temporal\" in the title suggests that time is a component here. The model uses temporal residual contrastive learning, which implies that the model is considering time-based patterns or sequences. Stock returns are inherently time-series data because they're recorded over time. So, the temporal aspect points towards time-series.\n\nNow, checking the other options. Multimodal would involve combining different types of data (like text and images), but the title doesn't mention multiple data types. RAG (Retrieval-Augmented Generation) is typically about using retrieval mechanisms to enhance generation tasks, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data representations, but the title refers to a hypergraph-based model. Hypergraphs are a generalization of graphs, but unless it's explicitly about knowledge graphs, which are usually semantic networks, this might not fit. The hypergraph here is part of a factor model for stock prediction, so it's more about modeling relationships in the data rather than building a knowledge graph.\n\nSo, the key elements are temporal aspects and stock returns prediction, which are classic time-series problems. The model uses temporal learning, which aligns with time-series analysis. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/31993@AAAI"},
{"title": "How to Re-enable PDE Loss for Physical Systems Modeling Under Partial Observation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"How to Re-enable PDE Loss for Physical Systems Modeling Under Partial Observation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. PDE stands for Partial Differential Equations. The paper is about using PDE loss in modeling physical systems when there's partial observation. So, the focus is on physical systems and how to handle incomplete data using PDEs. \n\nTime-series analysis usually involves data points indexed in time order, often for forecasting or analyzing trends. This title doesn't mention time explicitly, so maybe not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different data modalities, so probably not multimodal.\n\nRAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, typically in NLP. The title doesn't seem related to retrieval or generation, so RAG is out.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on physical systems and PDEs, not on building or using knowledge graphs. \n\nSo, none of the four topics seem to fit. The paper is about physical systems modeling with PDEs under partial observations, which is more related to physics-based modeling or machine learning for physical systems, but not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31994@AAAI"}
{"title": "FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FactorGCL: A Hypergraph-Based Factor Model with Temporal Residual Contrastive Learning for Stock Returns Prediction.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on stock returns prediction. The methods mentioned are a hypergraph-based factor model and temporal residual contrastive learning. \n\nTime-series analysis often deals with data points indexed in time order, which is common in stock market data. The term \"temporal\" in the title suggests that time is a component here. The model uses temporal residual contrastive learning, which implies that the model is considering time-based patterns or sequences. Stock returns are inherently time-series data because they're recorded over time. So, the temporal aspect points towards time-series.\n\nNow, checking the other options. Multimodal would involve combining different types of data (like text and images), but the title doesn't mention multiple data types. RAG (Retrieval-Augmented Generation) is typically about using retrieval mechanisms to enhance generation tasks, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data representations, but the title refers to a hypergraph-based model. Hypergraphs are a generalization of graphs, but unless it's explicitly about knowledge graphs, which are usually semantic networks, this might not fit. The hypergraph here is part of a factor model for stock prediction, so it's more about modeling relationships in the data rather than building a knowledge graph.\n\nSo, the key elements are temporal aspects and stock returns prediction, which are classic time-series problems. The model uses temporal learning, which aligns with time-series analysis. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/31993@AAAI"},
{"title": "How to Re-enable PDE Loss for Physical Systems Modeling Under Partial Observation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"How to Re-enable PDE Loss for Physical Systems Modeling Under Partial Observation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. PDE stands for Partial Differential Equations. The paper is about using PDE loss in modeling physical systems when there's partial observation. So, the focus is on physical systems and how to handle incomplete data using PDEs. \n\nTime-series analysis usually involves data points indexed in time order, often for forecasting or analyzing trends. This title doesn't mention time explicitly, so maybe not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different data modalities, so probably not multimodal.\n\nRAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, typically in NLP. The title doesn't seem related to retrieval or generation, so RAG is out.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on physical systems and PDEs, not on building or using knowledge graphs. \n\nSo, none of the four topics seem to fit. The paper is about physical systems modeling with PDEs under partial observations, which is more related to physics-based modeling or machine learning for physical systems, but not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31994@AAAI"},
{"title": "APIRL: Deep Reinforcement Learning for REST API Fuzzing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"APIRL: Deep Reinforcement Learning for REST API Fuzzing.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Deep Reinforcement Learning\" is a machine learning technique where an agent learns by interacting with an environment to maximize some reward. \"REST API Fuzzing\" refers to testing APIs by sending them invalid or unexpected data to find vulnerabilities. So the paper is about using reinforcement learning to fuzz REST APIs.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or weather data. That doesn't seem related here. Multimodal refers to combining multiple data types, like text and images. The paper is about API testing, which might involve different data types, but the main focus is on the method (reinforcement learning) rather than combining modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The paper doesn't mention anything about retrieval or generation, so probably not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The paper isn't about building or using knowledge graphs either.\n\nSo none of the listed topics (time-series, multimodal, RAG, KG) directly apply here. The paper is about reinforcement learning applied to API fuzzing, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31995@AAAI"},
{"title": "A Theoretical Framework for an Efficient Normalizing Flow-Based Solution to the Electronic Schrödinger Equation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. The title is \"A Theoretical Framework for an Efficient Normalizing Flow-Based Solution to the Electronic Schrödinger Equation.\" \n\nFirst, I need to break down the title. The key terms here are \"Normalizing Flow,\" \"Electronic Schrödinger Equation,\" and \"Theoretical Framework.\" \n\nNormalizing flows are a type of probabilistic model used in machine learning for density estimation. They involve transforming a simple probability distribution into a more complex one through a series of invertible functions. This is often used in generative models, but I'm not sure if that directly ties into the four topics listed.\n\nThe Electronic Schrödinger Equation is a fundamental equation in quantum chemistry. Solving it is crucial for understanding molecular structures and reactions. The paper is proposing a method using normalizing flows to solve this equation efficiently. \n\nNow, looking at the four topics: time-series, multimodal, RAG, KG. \n\nTime-series analysis involves data points indexed in time order. This paper doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data modalities, like text and images. The title doesn't mention different data types, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The paper's focus is on solving a physics equation, not on information retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about a mathematical framework for a physics problem, not about building or using knowledge graphs. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) are directly related to the content of the title, the answer should be \"none.\" The paper is about applying normalizing flows to quantum chemistry, which is a different domain altogether.\n</think>\n\nnone", "url": "https://papers.cool/venue/31996@AAAI"},
{"title": "EWMoE: An Effective Model for Global Weather Forecasting with Mixture-of-Experts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EWMoE: An Effective Model for Global Weather Forecasting with Mixture-of-Experts.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series. Weather forecasting is definitely a time-series problem because it involves predicting future states based on past data. So that's a strong candidate. But wait, the question is whether the paper's topic is one of these four. The title mentions \"Mixture-of-Experts,\" which is a model architecture. But the main application here is weather forecasting, which is time-series. However, the options are the research topics, not the application area. So if the paper is about time-series modeling, then the answer would be time-series. But maybe the paper is about the Mixture-of-Experts (MoE) model itself. MoE is a type of model that can be used in various domains. But the options given don't include MoE. The four options are time-series, multimodal, RAG, KG. \n\nMultimodal would involve combining different types of data (like text and images), which doesn't seem to be the case here. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks, like in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or retrieval. \n\nSo the main topic here is time-series forecasting using a specific model (EWMoE). Since the application is weather forecasting, which is a classic time-series problem, the research topic would be time-series. The model itself (Mixture-of-Experts) is part of the methodology, but the broader category is time-series. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/31997@AAAI"},
{"title": "FoldToken: Learning Protein Language via Vector Quantization and Beyond", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FoldToken: Learning Protein Language via Vector Quantization and Beyond.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. This paper is about proteins, which are sequences of amino acids, but the focus here is on learning a language model for proteins using vector quantization. Not sure if that's time-series. Maybe not, since it's more about sequence modeling rather than temporal data.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities. It's about proteins and vector quantization, which might be a method for encoding the protein sequences. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate answers. The title doesn't mention retrieval or generation, so RAG might not be relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about building or using a knowledge graph. It's about learning a protein language model, which might involve some kind of knowledge, but not necessarily in the form of a graph.\n\nVector quantization is a technique used in machine learning for data compression or representation. In the context of protein language models, maybe they're using vector quantization to discretize the protein sequences into tokens. The term \"FoldToken\" suggests creating tokens for folding, which is part of protein structure prediction. So the main focus is on developing a language model for proteins using specific techniques like vector quantization. None of the four topics (time-series, multimodal, RAG, KG) seem to directly fit. The paper is about protein language modeling, which is more related to NLP or bioinformatics, but not the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/31998@AAAI"},
{"title": "Each Fake News Is Fake in Its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Each Fake News Is Fake in Its Own Way: An Attribution Multi-Granularity Benchmark for Multimodal Fake News Detection.\" I need to figure out which of the four topics this paper belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"Multimodal Fake News Detection.\" The word \"multimodal\" immediately stands out. Multimodal typically refers to the use of multiple data types or modalities, like text, images, audio, etc., in a machine learning model. So if the paper is about detecting fake news using multiple modalities, that would fall under the multimodal category.\n\nLooking at the other options: time-series would involve data that's sequential over time, like stock prices or weather data. RAG (Retrieval-Augmented Generation) is a method that combines retrieval of information with generation, often used in NLP tasks. KG (Knowledge Graph) involves structured data representations, like linking entities and their relationships. \n\nThe title doesn't mention anything about time-based data, so time-series is probably not it. There's no indication of retrieval or knowledge graphs either. The focus is on multimodal data for fake news detection. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/31999@AAAI"},
{"title": "HeMeNet: Heterogeneous Multichannel Equivariant Network for Protein Multi-task Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HeMeNet: Heterogeneous Multichannel Equivariant Network for Protein Multi-task Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Heterogeneous Multichannel Equivariant Network\" – the key terms here are \"heterogeneous\" and \"multichannel.\" Heterogeneous might refer to different types of data or features, and multichannel could imply multiple input channels, which is common in multimodal learning where different modalities (like text, images, etc.) are combined. But wait, the application here is for protein multi-task learning. So maybe it's about combining different types of data related to proteins.\n\nMultimodal typically involves integrating different data types, like combining text and images. But in this case, the paper is about a network architecture for proteins. The term \"multichannel\" might be more about the network's structure rather than different modalities. Also, \"equivariant\" suggests that the model is designed to handle transformations, which is common in certain neural networks, like those used in computer vision or for structured data.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, which doesn't seem to fit here. KG (Knowledge Graphs) involve structured data representations, but the title doesn't mention anything about graphs or knowledge bases. Time-series would involve sequential data over time, but the title doesn't indicate that either.\n\nThe term \"multimodal\" is about combining different data types, but the paper's focus is on a specific network architecture for proteins. The \"heterogeneous\" part might suggest different types of data, but without explicit mention of modalities like text, image, etc., it's unclear. The main application is in multi-task learning for proteins, which could involve different tasks but not necessarily different modalities. So maybe it's not multimodal. The other options don't fit either. So perhaps the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32000@AAAI"},
{"title": "CoPRA: Bridging Cross-domain Pretrained Sequence Models with Complex Structures for Protein-RNA Binding Affinity Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CoPRA: Bridging Cross-domain Pretrained Sequence Models with Complex Structures for Protein-RNA Binding Affinity Prediction.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Cross-domain Pretrained Sequence Models\" suggests they're using models trained on different domains, maybe using transfer learning. \"Complex Structures\" might refer to the structural aspects of proteins and RNA. The task is predicting binding affinity between proteins and RNA. \n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't seem to fit here. Multimodal would involve combining different data types, like text and images. The paper mentions sequence models and complex structures, which could be different modalities (sequence data and structural data). So maybe multimodal?\n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. KG (Knowledge Graphs) involve structured data and relationships. The paper is about predicting binding affinity, which is more of a prediction task rather than building or using a knowledge graph. \n\nSo the most likely is multimodal because they're combining sequence models (text/sequence data) with complex structures (maybe 3D structures or other data types), making it a multimodal approach. The answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32001@AAAI"},
{"title": "GARLIC: GPT-Augmented Reinforcement Learning with Intelligent Control for Vehicle Dispatching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GARLIC: GPT-Augmented Reinforcement Learning with Intelligent Control for Vehicle Dispatching.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. GPT-Augmented suggests using GPT, which is a large language model. Reinforcement Learning (RL) is a type of machine learning where an agent learns by interacting with an environment. The term \"RAG\" stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in LLMs to enhance responses with external data. \n\nThe paper's focus is on vehicle dispatching, which is a problem in operations research or logistics. The key part here is \"GPT-Augmented Reinforcement Learning.\" Since RAG involves using retrieval to augment generation, but here it's about augmenting RL with GPT. Wait, RAG is specifically about retrieval and generation, not necessarily about using a model like GPT in another context. So maybe this isn't RAG. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so probably not multimodal. Time-series is about data over time, which might be relevant in vehicle dispatching if they're tracking over time, but the title doesn't specify time-series analysis. \n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs. \n\nSo the main components here are GPT (a language model) and Reinforcement Learning. The term \"RAG\" is a specific technique, but the paper is using GPT to augment RL, which is different from RAG's retrieval and generation approach. Therefore, it doesn't fit into RAG, multimodal, time-series, or KG. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32002@AAAI"}
{"title": "Open-world Radio Frequency Fingerprint Identification via Augmented Semi-supervised Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Open-world Radio Frequency Fingerprint Identification via Augmented Semi-supervised Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Radio Frequency Fingerprint Identification\" sounds like it's about identifying unique signals or patterns in radio frequencies. That might involve time-series data because radio signals are often time-dependent. But I'm not sure yet. \n\nThen \"Augmented Semi-supervised Learning\" refers to a machine learning approach. The term \"semi-supervised\" is a type of learning method, but the question is about the research topic, not the methodology. The key part here is \"Radio Frequency Fingerprint,\" which is a specific application area. \n\nLooking at the four options: time-series deals with data over time, multimodal involves multiple data types (like combining text and images), RAG is Retrieval-Augmented Generation, and KG is Knowledge Graphs. \n\nThe paper's focus is on identifying RF fingerprints, which are unique identifiers for devices based on their radio emissions. This could involve analyzing time-series data from the radio signals. However, the main topic here isn't the time-series aspect itself but the application of semi-supervised learning in an open-world scenario for RF fingerprinting. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) directly relate to RF fingerprint identification or the specific methods mentioned (augmented semi-supervised learning), the paper doesn't fit into any of the listed categories. The core research topic is more about machine learning applications in RF identification, which isn't covered by the given options. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32003@AAAI"},
{"title": "Limitations in Employing Natural Language Supervision for Sensor-Based Human Activity Recognition - And Ways to Overcome Them", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Limitations in Employing Natural Language Supervision for Sensor-Based Human Activity Recognition - And Ways to Overcome Them.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Sensor-Based Human Activity Recognition\" probably involves data from sensors, which are often time-series data because they collect information over time. So maybe time-series is a candidate. But the main focus here is on using natural language supervision. That part makes me think about how the model is trained using natural language, which could relate to multimodal learning if it's combining text (language) with sensor data. But wait, multimodal usually refers to combining different types of data like text, images, audio, etc. Here, the sensor data might be numerical time-series, and natural language is another modality. So combining them would be multimodal.\n\nBut the title is about the limitations of using natural language supervision. So the research is about how using natural language (text) to supervise the model for sensor data (which is time-series) has certain issues and how to fix them. So the core is the integration of text (natural language) with sensor data. That sounds like a multimodal approach because it's combining different data types. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval systems to augment model responses, which doesn't seem directly related here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. The paper isn't about building a knowledge graph or using retrieval-augmented methods. \n\nSo the main topic here is multimodal because it's combining natural language (text) with sensor data (which could be time-series, but the key is the combination of different modalities). Even though sensor data is time-series, the focus is on the integration with natural language, making it multimodal. The time-series aspect is part of the sensor data but the main research topic is the multimodal approach.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32004@AAAI"},
{"title": "Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. Hypergraph attacks... Hmm, hypergraphs are a type of graph structure where edges can connect more than two nodes. So this is about attacking hypergraphs. The method mentioned is injecting homogeneous nodes into elite hyperedges. \n\nNow, the possible topics are time-series, multimodal, RAG, or KG. Time-series usually involves data over time, like stock prices or weather data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model uses retrieved information to generate responses. KG is Knowledge Graphs, which are structured representations of knowledge, often using graphs.\n\nThe paper's focus is on hypergraphs and attacks on them. Hypergraphs are a generalization of graphs, so maybe related to Knowledge Graphs (KG)? But KGs are more about representing entities and their relationships, often using triples. Hypergraphs can be a way to model complex relationships, which might be part of a KG. However, the paper is about attacking hypergraphs, which could be a security or robustness issue in hypergraph structures. \n\nRAG is about retrieval and generation, which doesn't seem related. Multimodal is about combining different data types, which also doesn't fit. Time-series is about temporal data, which isn't mentioned here. So the closest might be KG, but I'm not entirely sure. However, the paper is specifically about hypergraphs and attacks, which might not directly fall under any of the four categories. If none of the topics fit, the answer would be \"none.\" \n\nWait, maybe the hypergraph is part of a Knowledge Graph structure? If the hyperedges represent complex relationships in a KG, then maybe it's related to KG. But the title doesn't explicitly mention knowledge graphs. It's possible that the research is in the context of KGs, but the title is more about hypergraph attacks. Since the options are time-series, multimodal, RAG, or KG, and the paper's title doesn't clearly align with any of these, the answer might be \"none.\" But I need to be careful. If hypergraphs are considered part of KG research, then maybe it's KG. However, I'm not certain. The term \"elite hyperedges\" might refer to important edges in the hypergraph, but without more context, it's hard to say. Given the options, I think the answer is \"none\" because the paper's focus is on hypergraph attacks, which isn't one of the listed topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32005@AAAI"},
{"title": "HHAN: Comprehensive Infectious Disease Source Tracing via Heterogeneous Hypergraph Neural Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HHAN: Comprehensive Infectious Disease Source Tracing via Heterogeneous Hypergraph Neural Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on tracing the source of infectious diseases using a Heterogeneous Hypergraph Neural Network. The term \"Heterogeneous Hypergraph\" stands out. Hypergraphs are a type of graph structure where edges can connect more than two nodes, which is different from traditional graphs. Heterogeneous implies that the nodes and edges have different types. So this is about using a specific kind of neural network that works with hypergraphs to model the data.\n\nNow, looking at the four options. Time-series would involve data points indexed in time order, like stock prices over time. Multimodal refers to combining multiple types of data, like text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP that uses external information during the generation process. KG stands for Knowledge Graph, which is a structured representation of knowledge, often using graphs to represent entities and their relationships.\n\nThe paper's title mentions a hypergraph neural network. Hypergraphs are a type of graph structure, so this might relate to Knowledge Graphs (KG), which are also graph-based. However, hypergraphs are more complex than standard graphs used in KGs. But the key here is that the paper is using a hypergraph structure to model the data for disease source tracing. Since hypergraphs are a type of graph, and the problem is about modeling relationships (which is what KGs do), maybe it's related to KG. However, the term \"Knowledge Graph\" typically refers to a specific application of graph structures for knowledge representation, often involving ontologies and semantic relationships. The paper's focus is on using a hypergraph neural network for a specific task, which might be more about the graph structure itself rather than a traditional KG. \n\nAlternatively, could it be multimodal? The title doesn't mention combining different data types like text, images, or sensor data. It's about tracing sources using a hypergraph, which is a structural approach. RAG and time-series don't seem relevant here. So the most plausible is either KG or none. But since hypergraphs are a type of graph structure, and the problem involves modeling relationships (like in a KG), maybe it's considered under KG. However, the paper's main contribution is the hypergraph neural network, which is a specific model, not necessarily a knowledge graph application. But the options are limited to the four given. Since the paper uses a graph-based approach (hypergraph) for modeling, and KG is one of the options, perhaps it's categorized under KG. Alternatively, if the hypergraph is just a different structure and not a knowledge graph, then maybe it's none. But given the options, I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32006@AAAI"},
{"title": "VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Verilog is a hardware description language, so this is about coding in Verilog. The key parts here are \"Graph-based Planning\" and \"Abstract Syntax Tree (AST)-based Waveform Tracing Tool\". \n\nGraph-based planning might relate to knowledge graphs (KG) since graphs are a key component there. AST is part of code analysis, which could be part of a knowledge graph structure. The waveform tracing tool might involve some kind of data processing, but the main focus here seems to be on the structure of the code and planning using graphs. \n\nTime-series usually involves data over time, like stock prices or sensor data. Multimodal would involve combining different data types like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models. KG (Knowledge Graph) involves structured data representations using graphs. \n\nThe paper mentions graph-based planning and AST, which are structural elements. ASTs are tree structures representing code, which could be part of a knowledge graph. So, the use of graphs here might point to KG. The other parts about autonomous agents and coding don't directly relate to the four topics listed. So, the most likely topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32007@AAAI"},
{"title": "ViFactCheck: A New Benchmark Dataset and Methods for Multi-Domain News Fact-Checking In Vietnamese", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ViFactCheck: A New Benchmark Dataset and Methods for Multi-Domain News Fact-Checking In Vietnamese.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key parts are \"benchmark dataset,\" \"multi-domain,\" \"news fact-checking,\" and \"Vietnamese.\" The main focus here is on creating a dataset and methods for fact-checking news in Vietnamese. \n\nTime-series usually involves data over time, like stock prices or weather data. This doesn't seem related to that. Multimodal refers to using multiple types of data, like text and images. The title doesn't mention anything about combining different data types, just news fact-checking. \n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generating responses. The paper might use RAG if they're retrieving information to check facts, but the title doesn't explicitly mention RAG. It just says \"methods,\" which could be any approach. \n\nKG is Knowledge Graphs, which are structured representations of information. If the paper uses a knowledge graph for fact-checking, that would fit. However, the title doesn't mention knowledge graphs either. \n\nThe main focus here is on creating a dataset for fact-checking in Vietnamese news. Fact-checking often involves verifying claims against existing knowledge sources, which could involve retrieval (like RAG) or knowledge graphs. But without explicit mention, it's hard to say. The term \"multi-domain\" might suggest using different types of information, but again, not necessarily multimodal. \n\nSince the title doesn't clearly align with time-series, multimodal, RAG, or KG, the answer might be \"none.\" But wait, fact-checking can sometimes involve retrieving information from external sources, which is part of RAG. However, the title doesn't specify the method used. The dataset itself is for fact-checking, which is a task, not necessarily tied to any of the four topics listed. So I think the correct answer here is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32008@AAAI"},
{"title": "MOL-Mamba: Enhancing Molecular Representation with Structural & Electronic Insights", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MOL-Mamba: Enhancing Molecular Representation with Structural & Electronic Insights.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title doesn't mention anything about time or sequences over time, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title talks about molecular representation using structural and electronic insights. Structural could be 3D structure, and electronic might relate to properties like charge distribution. So combining different aspects of molecular data. That sounds like multimodal because it's integrating different modalities (structural and electronic) to enhance representation. \n\nRAG is Retrieval-Augmented Generation, which is about using retrieval systems to augment generative models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about molecular representations, but unless it's explicitly building or using a knowledge graph, it's less likely. The title mentions enhancing representation, which could be a model or embedding, not necessarily a graph structure.\n\nSo the most likely answer is multimodal since it's combining different data types (structural and electronic) for molecular representation.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32009@AAAI"},
{"title": "PRAGA: Prototype-aware Graph Adaptive Aggregation for Spatial Multi-modal Omics Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's tackle this. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. The title is \"PRAGA: Prototype-aware Graph Adaptive Aggregation for Spatial Multi-modal Omics Analysis.\" \n\nFirst, I'll break down the title. The key parts here are \"Graph Adaptive Aggregation\" and \"Spatial Multi-modal Omics Analysis.\" The term \"multi-modal\" immediately stands out. The user's options include \"multimodal,\" which is a direct match. But I need to make sure there's no other possible fit.\n\nLooking at the other options: time-series usually involves data over time, which isn't mentioned here. RAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, which doesn't seem to fit. KG (Knowledge Graph) involves structured data and relationships, but the title mentions \"Graph\" in the method name, but the context is about aggregation for multi-modal data. The main focus here is on handling multiple data modalities (multi-modal) in the context of omics analysis. The \"Graph\" part might refer to a graph-based method, but the primary topic is the multi-modal aspect. So the correct answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32010@AAAI"},
{"title": "Social Recommendation via Graph-Level Counterfactual Augmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Social Recommendation via Graph-Level Counterfactual Augmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Social Recommendation\" suggests it's about recommending items or connections in a social context. \"Graph-Level\" makes me think of graphs, which are structures used in knowledge graphs (KG) or social networks. \"Counterfactual Augmentation\" might refer to generating alternative scenarios or data points, which could be a method used in various machine learning contexts.\n\nLooking at the options: time-series deals with data over time, which doesn't seem to fit here. Multimodal involves combining different data types like text and images, which isn't mentioned. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which also doesn't directly relate. KG (Knowledge Graphs) are structured representations of information, often using graphs. The mention of \"Graph-Level\" in the title points towards graph-based methods, which are commonly associated with knowledge graphs. So, the paper is likely about using graph structures (KG) for social recommendations through counterfactual augmentation. Therefore, the topic should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32011@AAAI"},
{"title": "DF-MIA: A Distribution-Free Membership Inference Attack on Fine-Tuned Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DF-MIA: A Distribution-Free Membership Inference Attack on Fine-Tuned Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Membership Inference Attack\" is a type of privacy attack where an adversary tries to determine if a specific data point was part of the training set of a model. The term \"Distribution-Free\" suggests that the attack doesn't rely on assumptions about the data distribution. \"Fine-Tuned Large Language Models\" refers to models like GPT or BERT that have been fine-tuned on specific tasks.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather. Multimodal deals with multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which combines retrieval of information with generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on an attack method against fine-tuned LLMs. None of the topics directly relate to privacy attacks or membership inference. The attack is about model security, not the model's data type (time-series, multimodal) or its architecture (RAG, KG). So it doesn't fit into any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32012@AAAI"}
{"title": "Bi-level Contrastive Learning for Knowledge-Enhanced Molecule Representations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bi-level Contrastive Learning for Knowledge-Enhanced Molecule Representations.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Bi-level Contrastive Learning\" sounds like a machine learning method, maybe involving two levels of contrastive learning. Then \"Knowledge-Enhanced Molecule Representations.\" The key term here is \"Knowledge-Enhanced.\" That makes me think of Knowledge Graphs (KG), since knowledge graphs are structures that represent entities and their relationships, often used to enhance models with external knowledge. \n\nMolecule representations could be about how molecules are modeled in computational chemistry or drug discovery. If they're using knowledge to enhance these representations, it's likely leveraging some form of structured knowledge, which points towards Knowledge Graphs. \n\nTime-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. Multimodal usually refers to combining different data types like text and images. The title is about molecules, which might involve data types, but the key here is the enhancement through knowledge. RAG (Retrieval-Augmented Generation) is more about using retrieval to augment generation in models, like in NLP tasks. The title doesn't mention retrieval or generation, so RAG is probably out. \n\nSo the most likely answer is KG (Knowledge Graphs).\n</think>\n\nKG", "url": "https://papers.cool/venue/32013@AAAI"},
{"title": "Learning Generalized Residual Exchange-Correlation-Uncertain Functional for Density Functional Theory", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning Generalized Residual Exchange-Correlation-Uncertain Functional for Density Functional Theory.\" Hmm. I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. The main subject here is \"Density Functional Theory,\" which I know is a computational quantum mechanical modeling method used in physics and chemistry. The paper is about learning a generalized residual functional related to exchange, correlation, and uncertainty. \n\nNow, the four options. Time-series usually involves data over time, like stock prices or weather. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where models retrieve information from a database to enhance their responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used in semantic web and AI applications.\n\nThe title doesn't mention anything about time, so time-series is probably out. There's no indication of combining multiple data modalities either, so multimodal might not fit. RAG and KG are both related to information retrieval and knowledge representation, but the paper seems focused on a functional in DFT, which is a physics/chemistry computational method. The terms \"residual,\" \"exchange-correlation,\" and \"uncertain\" suggest it's about improving or modeling a specific part of the DFT calculations, possibly using machine learning techniques. However, none of the four topics directly relate to DFT or the specific aspects mentioned here. \n\nSince the paper is about a functional in DFT and doesn't align with time-series, multimodal, RAG, or KG, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32014@AAAI"},
{"title": "IWRN:A Robust Blind Watermarking Method for Artwork Image Copyright Protection Against Noise Attack", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"IWRN: A Robust Blind Watermarking Method for Artwork Image Copyright Protection Against Noise Attack.\" I need to figure out which of the given topics this paper belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"blind watermarking,\" \"artwork image,\" \"copyright protection,\" and \"noise attack.\" Blind watermarking usually refers to embedding information into a digital image without needing the original to detect it. The focus is on protecting copyright, so it's about digital rights management or image security.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or sensor data. This paper is about images, so time-series doesn't seem relevant. Multimodal refers to combining multiple data types, like text and images. The paper is focused solely on images for watermarking, so maybe not multimodal. RAG stands for Retrieval-Augmented Generation, which is a method in NLP for enhancing models with external information. That's more about text generation with retrieval. KG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data. \n\nThe paper's main contribution is a robust watermarking technique for images, specifically against noise attacks. None of the listed topics (time-series, multimodal, RAG, KG) directly relate to watermarking or image copyright protection. The methods involved here are likely in the field of digital image processing or information hiding, which aren't among the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32015@AAAI"},
{"title": "AnalogCoder: Analog Circuit Design via Training-Free Code Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AnalogCoder: Analog Circuit Design via Training-Free Code Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Analog Circuit Design\" suggests it's about designing circuits, specifically analog ones. The method mentioned is \"Training-Free Code Generation.\" So they're generating code without training, probably using some kind of pre-trained model or another approach that doesn't require training on specific data.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This doesn't seem related to time-based data. Multimodal would involve combining different types of data, like text and images. The title doesn't mention multiple data types. RAG stands for Retrieval-Augmented Generation, which is a method where a model uses retrieved information to generate responses. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe key part here is \"Training-Free Code Generation.\" If it's using a retrieval-based method, maybe they're retrieving existing code or knowledge to generate the circuit design code without training. That would align with RAG. Alternatively, if they're using a knowledge graph to structure the information for code generation, it might be KG. But the term \"Training-Free\" makes me think of RAG because RAG models can generate outputs using retrieved information without needing to be trained on new data. \n\nAnalog circuit design is a specific domain, so maybe they're using a pre-trained model that can generate code by retrieving relevant information from a database or existing knowledge. Since the paper is about code generation without training, it's likely leveraging retrieval methods, which points to RAG. I don't see a direct mention of knowledge graphs here. So the answer is probably RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32016@AAAI"},
{"title": "Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction with Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Political Actor Agent: Simulating Legislative System for Roll Call Votes Prediction with Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather. The paper is about predicting roll call votes, which might involve historical data, but the main focus here seems to be on simulating a legislative system using agents and LLMs. Not sure if time-series is the main topic here.\n\nMultimodal refers to using multiple data types, like text and images. The title doesn't mention different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which combines retrieval of information with generation. The paper uses large language models, but the title doesn't specify retrieval or augmentation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title mentions simulating a legislative system, which might involve structured data, but the key term here is \"agent\" and \"large language models.\" Knowledge graphs could be part of the system, but the title doesn't explicitly mention them.\n\nThe main elements here are using agents and LLMs for prediction. None of the four topics directly relate to agent-based simulations or legislative systems. So maybe the answer is \"none.\" But wait, could it be multimodal if they use different data types? The title doesn't specify, so probably not. RAG and KG also don't seem to fit. So the answer should be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32017@AAAI"},
{"title": "Simulate and Eliminate: Revoke Backdoors for Generative Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Simulate and Eliminate: Revoke Backdoors for Generative Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper here is about generative large language models, which are text-based, but the title doesn't mention other modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text based on that. The title talks about revoking backdoors in generative models. Backdoors could be a security issue, maybe related to how the model is trained or how it retrieves information. But RAG specifically involves retrieval during generation. The paper's focus seems more on security and backdoors rather than retrieval methods. Not sure yet.\n\nKG is Knowledge Graphs. Those are structured representations of knowledge, often used for linking entities and relationships. The title doesn't mention anything about knowledge graphs or structured data. \n\nThe paper's title mentions \"Generative Large Language Models\" and \"revoke backdoors.\" Backdoors in this context might relate to security vulnerabilities or unintended behaviors in the model. RAG involves retrieval, but if the paper is about eliminating backdoors, maybe it's about how the model's training or generation process is secured. However, none of the four topics directly relate to security or backdoors. The options are time-series, multimodal, RAG, KG. Since the paper is about generative models but the focus is on backdoors and revoking them, which isn't covered by any of the four topics, the answer might be \"none.\" But wait, maybe RAG? If the backdoor is related to retrieval, but the title doesn't specify that. The main topic here is security in LLMs, which isn't one of the four. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32018@AAAI"},
{"title": "Vox-UDA: Voxel-wise Unsupervised Domain Adaptation for Cryo-Electron Subtomogram Segmentation with Denoised Pseudo-Labeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Vox-UDA: Voxel-wise Unsupervised Domain Adaptation for Cryo-Electron Subtomogram Segmentation with Denoised Pseudo-Labeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Voxel-wise\" suggests working with 3D data, like voxels, which are 3D pixels. \"Unsupervised Domain Adaptation\" (UDA) is a machine learning technique where a model trained on a source domain is adapted to a target domain without labeled data in the target. The application here is \"Cryo-Electron Subtomogram Segmentation,\" which is a specific imaging technique in biology, probably for electron microscopy. \"Denoised Pseudo-Labeling\" implies using pseudo-labels (generated labels) that are denoised, maybe to improve segmentation accuracy.\n\nNow, the four options: time-series, multimodal, RAG, KG. Time-series would involve data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using external knowledge in generation tasks. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on domain adaptation for image segmentation in a specific imaging modality. The key terms here are domain adaptation and segmentation. None of the four topics directly relate to domain adaptation. Time-series is about temporal data, which isn't mentioned. Multimodal would involve combining different data types, but the title doesn't mention that. RAG and KG are about knowledge retrieval and structured data, which also don't fit. The paper is about adapting models between domains in a specific imaging context, which doesn't align with any of the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32019@AAAI"},
{"title": "ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ChemVLM: Exploring the Power of Multimodal Large Language Models in Chemistry Area.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Large Language Models\" is right there. The term \"multimodal\" is one of the options. The other parts mention chemistry, but the key part here is \"multimodal.\" The other options are time-series, which deals with data over time; RAG is Retrieval-Augmented Generation; KG is Knowledge Graphs. None of those terms are in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32020@AAAI"},
{"title": "Learning Complex Heterogeneous Multimodal Fake News via Social Latent Network Inference", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning Complex Heterogeneous Multimodal Fake News via Social Latent Network Inference.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Multimodal\" and \"Fake News.\" The word \"Multimodal\" is right there in the title, which immediately makes me think that this might be a multimodal research topic. But I should check the other parts to be sure.\n\nThe paper is about fake news detection, which often involves analyzing different types of data like text, images, and maybe social network information. The term \"heterogeneous\" suggests that multiple data types are involved, which aligns with multimodal approaches. Also, \"Social Latent Network Inference\" might refer to using social network structures, but that could relate to knowledge graphs (KG) if they're modeling relationships. However, the presence of \"Multimodal\" in the title is a strong indicator. \n\nRAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, which doesn't seem to be mentioned here. Time-series would involve temporal data analysis, which isn't indicated in the title. KG (Knowledge Graphs) might be a possibility if they're building a graph of social networks, but the primary focus here seems to be on combining different modalities (text, images, etc.) for fake news detection. \n\nSo, the most fitting category here is \"multimodal\" because the title explicitly mentions it and the problem involves integrating multiple data types.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32022@AAAI"},
{"title": "AI-Powered Algorithm-Centric Quantum Processor Topology Design", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AI-Powered Algorithm-Centric Quantum Processor Topology Design.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"AI-Powered\" suggests that artificial intelligence is involved. \"Algorithm-Centric\" might mean the design is focused around specific algorithms. \"Quantum Processor Topology Design\" refers to the structure or layout of a quantum processor. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or weather. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about designing the topology of a quantum processor using AI. None of the topics directly relate to time-series data. It's not combining multiple data modalities, so not multimodal. RAG and KG are more about information retrieval and knowledge representation, which don't seem to connect here. The focus is on quantum computing architecture, which is a different area. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32023@AAAI"}
{"title": "AI-Powered Algorithm-Centric Quantum Processor Topology Design", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AI-Powered Algorithm-Centric Quantum Processor Topology Design.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"AI-Powered\" suggests that artificial intelligence is involved. \"Algorithm-Centric\" might mean the design is focused around specific algorithms. \"Quantum Processor Topology Design\" refers to the structure or layout of a quantum processor. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or weather. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about designing the topology of a quantum processor using AI. None of the topics directly relate to time-series data. It's not combining multiple data modalities, so not multimodal. RAG and KG are more about information retrieval and knowledge representation, which don't seem to connect here. The focus is on quantum computing architecture, which is a different area. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32023@AAAI"},
{"title": "Enhancing the Adversarial Robustness via Manifold Projection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing the Adversarial Robustness via Manifold Projection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Adversarial robustness\" usually refers to making machine learning models more resistant to adversarial attacks, which are inputs designed to fool the model. \"Manifold projection\" sounds like a technique in machine learning where data is projected onto a lower-dimensional manifold to preserve structure or improve performance.\n\nNow, the four options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on adversarial robustness through manifold projection. None of the four topics directly relate to adversarial robustness or manifold learning. Time-series is about temporal data, which isn't mentioned here. Multimodal deals with multiple data modalities, which isn't the case here. RAG and KG are about retrieval and knowledge graphs, which also don't seem related to the methods described in the title. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32024@AAAI"},
{"title": "Whole Genome Transformer for Gene Interaction Effects in Microbiome Habitat Specificity", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Whole Genome Transformer for Gene Interaction Effects in Microbiome Habitat Specificity.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or weather data. The title doesn't mention anything about time or temporal data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title talks about gene interactions in microbiomes, but I don't see any indication of multiple data modalities being used together. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title mentions a Transformer model, which is common in NLP, but the focus here is on gene interactions and microbiome habitats. I don't see any mention of retrieval or augmentation, so RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of information, often used to model relationships between entities. The paper's title mentions gene interaction effects, which could involve modeling relationships between genes. If the research is about creating a graph structure to represent these interactions, then it might be a Knowledge Graph. However, the term \"Transformer\" suggests a deep learning model, which is different from traditional KG approaches. But maybe they're using a Transformer to model interactions in a knowledge graph context. Alternatively, if the focus is on the interactions themselves as a graph, that could be a KG. However, the title doesn't explicitly mention a knowledge graph. \n\nWait, the title says \"Whole Genome Transformer for Gene Interaction Effects.\" Gene interactions are often represented as networks or graphs, so maybe they're using a Transformer to model these interactions, which could be part of a knowledge graph. But the key here is whether the research is specifically about constructing or utilizing a knowledge graph. If the paper is about building a model (Transformer) to analyze gene interactions, it might not be a KG topic unless the interactions are explicitly structured as a graph. Since the options are between the four, and the other three don't fit, maybe it's none? But the user wants to check if it's one of the four. Alternatively, maybe the gene interactions are part of a knowledge graph. Hmm. I'm a bit torn here. The term \"KG\" is usually about structured knowledge representation. If the paper is about modeling gene interactions as a graph, then it's a KG. But if it's just using a Transformer to analyze interactions without structuring them as a graph, then it's not. The title doesn't specify, but \"gene interaction effects\" could imply a network or graph structure. So maybe it's a Knowledge Graph (KG) topic. Alternatively, maybe it's none. But given the options, I think the best fit is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32025@AAAI"},
{"title": "SCALM: Detecting Bad Practices in Smart Contracts Through LLMs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SCALM: Detecting Bad Practices in Smart Contracts Through LLMs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Detecting Bad Practices in Smart Contracts\" suggests it's about analyzing smart contracts for issues. The method mentioned is \"Through LLMs,\" which stands for Large Language Models. So the main approach here is using LLMs to detect problems in smart contracts.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is a method where a model uses retrieved information to generate answers. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper uses LLMs, but does it fit into any of these categories? The key here is the method. If they're using a retrieval system to augment the LLM's knowledge, that would be RAG. If they're building a knowledge graph to represent smart contract practices, that would be KG. If they're combining different data types (like code and natural language), that's multimodal. Time-series doesn't seem relevant here.\n\nThe title doesn't mention anything about time-based data, so time-series is out. The focus is on using LLMs, but the question is whether it's specifically RAG or KG. Since the title doesn't mention retrieval or knowledge graphs, maybe it's just using the LLM directly. However, the problem is detecting bad practices, which might involve some kind of knowledge base. But without explicit mention of RAG or KG in the title, it's hard to say. The term \"LLMs\" alone doesn't specify RAG or KG. So perhaps it's none of the listed topics. Wait, but the user wants to know if it's one of the four. If the paper uses RAG, then it's RAG. If it's building a knowledge graph, then KG. If it's using multimodal data, then multimodal. Otherwise, none.\n\nThe title doesn't mention retrieval, so RAG is unlikely. It doesn't mention knowledge graphs either. The problem is about smart contracts, which are code, but the method is LLMs. Unless the LLM is being used in a way that's part of a multimodal approach, but the title doesn't indicate that. So maybe it's none. But wait, maybe the LLM is part of a RAG system? The title says \"Through LLMs,\" which could imply that the LLM is the main tool, but RAG is a specific technique. Without more info, it's safer to say none. So the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32026@AAAI"},
{"title": "An Evaluation Framework for Product Images Background Inpainting Based on Human Feedback and Product Consistency", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"An Evaluation Framework for Product Images Background Inpainting Based on Human Feedback and Product Consistency.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus is on evaluating product image background inpainting. Inpainting is a technique in image processing where missing or damaged parts of an image are filled in. The evaluation is based on human feedback and product consistency. \n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices over time. This paper is about images, so time-series doesn't seem relevant here. \n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image processing, but the evaluation uses human feedback, which is text-based. However, the primary task is image inpainting, which is a single modality (images). The use of human feedback might be part of the evaluation method, but the core task isn't multimodal. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. This paper doesn't mention anything about retrieval or generation, so RAG is probably not the right fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't discuss building or using a knowledge graph, so that's out.\n\nSo the paper is about image inpainting evaluation using human feedback and product consistency. None of the four topics (time-series, multimodal, RAG, KG) directly apply here. The closest might be multimodal if the evaluation involved combining different data types, but since the main task is image processing without combining modalities, it's not a fit. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32027@AAAI"},
{"title": "A Thorough Comparison Between Independent Cascade and Susceptible-Infected-Recovered Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Thorough Comparison Between Independent Cascade and Susceptible-Infected-Recovered Models.\" I need to figure out which of the given topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I should recall what each of these terms means. Time-series analysis involves data points indexed in time order, often used for forecasting or understanding trends. Multimodal refers to combining multiple types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used for linking entities and relationships.\n\nNow, the title mentions two models: Independent Cascade and Susceptible-Infected-Recovered. I remember that these are models used in the study of information or disease spread over networks. The Independent Cascade Model (ICM) is a model for how information spreads through a network, where each node can influence its neighbors with a certain probability. The Susceptible-Infected-Recovered (SIR) model is an epidemiological model that divides the population into three compartments: Susceptible, Infected, and Recovered. Both models are used to simulate the spread of something through a network over time.\n\nSo, the paper is comparing these two models. The key here is to see if this falls under any of the listed topics. Time-series might be a possibility because both models involve processes that evolve over time. However, the primary focus here is on the models themselves and their comparison, not necessarily on analyzing time-series data. The SIR model is more about differential equations and compartmental modeling, while ICM is a probabilistic model for network diffusion. Neither of these are directly related to time-series analysis in the context of data analysis techniques. They are more about network dynamics and spread processes.\n\nMultimodal doesn't seem relevant here since the paper isn't combining different data types. RAG and KG are related to information retrieval and knowledge representation, which also don't fit. The paper is about comparing two network diffusion models, which is more in the realm of network science or epidemiology modeling. Since none of the given topics (time-series, multimodal, RAG, KG) directly align with the subject of the paper, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32028@AAAI"},
{"title": "IDseq: Decoupled and Sequentially Detecting and Grounding Multi-Modal Media Manipulation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"IDseq: Decoupled and Sequentially Detecting and Grounding Multi-Modal Media Manipulation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That immediately makes me think of the multimodal topic. But I should check the other parts to be sure. The paper is about detecting and grounding media manipulation, which involves multiple modalities. So multimodal seems like a strong candidate.\n\nNow, time-series usually involves data over time, like sequences or time-based analysis. The title mentions \"Sequentially,\" which might hint at time-series, but the main focus here is on multi-modal data. The term \"decoupled\" might refer to separating different components, but not necessarily time-based.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't reference knowledge graphs or structured data, so that's out.\n\nPutting it all together, the key term is \"Multi-Modal,\" so the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32029@AAAI"},
{"title": "Controllable Protein Sequence Generation with LLM Preference Optimization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Controllable Protein Sequence Generation with LLM Preference Optimization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. This title is about protein sequences, which are sequences of amino acids. But the key here is \"controllable generation\" using LLM (Large Language Model) preference optimization. So maybe it's about generating sequences with some control, but does that relate to time-series? Not sure. Time-series models often use RNNs or LSTMs, but LLMs can handle sequences too. However, the term \"time-series\" might not be the best fit here unless the sequences are explicitly in time order, which protein sequences are in terms of structure but not necessarily time-based.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch information and then generates text based on that. The title mentions \"LLM Preference Optimization,\" which sounds like training or fine-tuning the model's preferences, but not necessarily retrieving external information. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about generating protein sequences, which might involve some biological knowledge, but unless they're explicitly using a knowledge graph structure, this might not fit.\n\nSo, the options left are time-series or none. Protein sequences are sequences, but they're more about spatial structure or functional relationships rather than time. Since the title doesn't mention time-based data, maybe it's not time-series. The other options don't fit either. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32030@AAAI"},
{"title": "Recoverable Facial Identity Protection via Adaptive Makeup Transfer Adversarial Attacks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Recoverable Facial Identity Protection via Adaptive Makeup Transfer Adversarial Attacks.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on facial identity protection using adversarial attacks that involve adaptive makeup transfer. So, the key elements here are facial identity, adversarial attacks, and makeup transfer. \n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't seem related to time-based data. Multimodal would involve combining different data types, like text and images. The paper mentions makeup transfer, which is about modifying images (facial features), but I'm not sure if it's combining multiple modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about knowledge graphs or retrieval-augmented generation. \n\nAdversarial attacks are a concept in machine learning, particularly in deep learning, where inputs are perturbed to fool models. The paper is about protecting facial identity through adversarial methods, which might fall under computer vision or security. However, the given options don't include computer vision or security. The four options are time-series, multimodal, RAG, or KG. \n\nSince the paper is about modifying facial images (a modality) using adversarial techniques, maybe it's multimodal? But multimodal typically refers to combining different types of data, like text and images. If the paper is only dealing with images (facial data) and adversarial attacks, it might not be multimodal. \n\nAlternatively, RAG and KG are more about data retrieval and knowledge representation. The title doesn't mention anything about retrieving information or using a knowledge graph. \n\nSo, none of the four topics seem to fit perfectly. The paper is about adversarial attacks in facial recognition, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32031@AAAI"},
{"title": "Knowledge-Guided Domain Adaptation Model for Transferring Drug Response Prediction from Cell Lines to Patients", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Knowledge-Guided Domain Adaptation Model for Transferring Drug Response Prediction from Cell Lines to Patients.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge-Guided\" seems important. The term \"Knowledge-Guided\" might relate to Knowledge Graphs (KG) since that's a common term in that area. Then \"Domain Adaptation\" is a machine learning technique where you transfer knowledge from one domain to another. The application here is transferring drug response prediction from cell lines to patients. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. The title doesn't mention anything about time, so probably not that. Multimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation models, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG. \n\nThe key part here is \"Knowledge-Guided.\" Since KG stands for Knowledge Graph, and the model is guided by knowledge, this seems to fit under the Knowledge Graph (KG) topic. The use of domain adaptation with knowledge guidance suggests leveraging structured knowledge to improve the model's transferability. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32032@AAAI"}
{"title": "TrojanDec: Data-free Detection of Trojan Inputs in Self-supervised Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TrojanDec: Data-free Detection of Trojan Inputs in Self-supervised Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"TrojanDec\" probably refers to detecting trojan inputs. \"Data-free\" suggests that the method doesn't require additional data for detection. \"Self-supervised learning\" is a type of machine learning where the model learns from the data's structure without explicit labels. \n\nNow, the topics given are time-series, multimodal, RAG, and KG. Time-series would involve data over time, like stock prices or sensor data. Multimodal deals with multiple data types, like combining text and images. RAG is Retrieval-Augmented Generation, which uses external data retrieval to enhance model responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper is about detecting trojan inputs in self-supervised learning. Trojans in this context might be malicious inputs that cause the model to behave incorrectly. The detection method is data-free, meaning it doesn't rely on additional datasets. Self-supervised learning is a training method, but the core issue here is security or robustness against adversarial attacks. \n\nNone of the four topics directly relate to security, adversarial attacks, or trojan detection. Time-series is about temporal data, which isn't mentioned. Multimodal involves multiple data types, which isn't the focus here. RAG and KG are about retrieval and knowledge representation, which also don't fit. The paper's focus is on a specific problem in model security, which isn't covered by the given topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32033@AAAI"},
{"title": "BiDeV: Bilateral Defusing Verification for Complex Claim Fact-Checking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BiDeV: Bilateral Defusing Verification for Complex Claim Fact-Checking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Bilateral Defusing Verification\" sounds like a method for checking facts in claims. The term \"Complex Claim Fact-Checking\" suggests it's about verifying the truth of complex statements. \n\nNow, the four options. Time-series usually involves data over time, like stock prices or weather. Multimodal refers to using multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which combines retrieval of information with generating answers. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on verifying complex claims. Fact-checking often involves retrieving information from various sources to verify claims. RAG is a method where a model retrieves relevant information from a database and then generates an answer. So if BiDeV uses retrieval of information to check facts, it might be RAG. \n\nAlternatively, if it's using a knowledge graph to verify claims by checking against structured data, it could be KG. But the title doesn't mention knowledge graphs explicitly. \"Bilateral Defusing Verification\" might refer to a process that checks claims from two sides or uses some bilateral approach, but that's not clear. \n\nMultimodal would require the use of different data types, which isn't indicated here. Time-series is unrelated. So between RAG and KG. Since RAG is about retrieving information to augment generation, and fact-checking often involves retrieving evidence, I think RAG is more likely. The paper might be using retrieval methods to gather evidence for fact-checking, hence RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32034@AAAI"},
{"title": "WiFi CSI Based Temporal Activity Detection via Dual Pyramid Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"WiFi CSI Based Temporal Activity Detection via Dual Pyramid Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"WiFi CSI\" refers to Channel State Information from WiFi, which is used for things like activity detection. \"Temporal Activity Detection\" suggests that the focus is on activities over time, so time-based data. \"Dual Pyramid Network\" sounds like a neural network architecture, maybe for processing sequences or spatial data.\n\nTime-series analysis deals with data points indexed in time order. Since the paper mentions \"temporal,\" which directly relates to time, this seems like a strong candidate. The use of WiFi CSI data over time would likely involve time-series methods to detect activities as they occur.\n\nMultimodal would involve combining different types of data (like text and images), but the title only mentions WiFi CSI, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about enhancing models with external knowledge retrieval, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data representations, which also doesn't fit the context of activity detection via WiFi signals.\n\nSo the most likely topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32035@AAAI"},
{"title": "DAMMFND: Domain-Aware Multimodal Multi-view Fake News Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DAMMFND: Domain-Aware Multimodal Multi-view Fake News Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal\" is right there in the title. That suggests it's about using multiple types of data, like text, images, maybe audio or video. The other parts mention \"Multi-view,\" which could mean different perspectives or data sources. Fake news detection is the main goal here.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. RAG is Retrieval-Augmented Generation, which is a method for models to retrieve information and generate responses. KG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about time, retrieval, or knowledge graphs. The key term here is \"Multimodal,\" which directly matches one of the options. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32036@AAAI"},
{"title": "Graph-Based Cross-Domain Knowledge Distillation for Cross-Dataset Text-to-Image Person Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Graph-Based Cross-Domain Knowledge Distillation for Cross-Dataset Text-to-Image Person Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph-Based\" might hint at Knowledge Graphs (KG), but I need to check the context. \"Cross-Domain Knowledge Distillation\" – knowledge distillation is a technique where a smaller model is trained using a larger model's outputs. But the mention of \"graph-based\" could be about using graph structures in the process. However, RAG (Retrieval-Augmented Generation) is more about using external knowledge during generation, which might not be the case here.\n\n\"Cross-Dataset Text-to-Image Person Retrieval\" suggests that the task involves both text and images, which is multimodal. Multimodal research deals with integrating different data types like text, images, audio, etc. So if the paper is about retrieving images based on text across different datasets, that's a multimodal problem. \n\nBut wait, the first part mentions \"Graph-Based.\" Could that be Knowledge Graph (KG)? Knowledge Graphs are structured data representations, often used for semantic relationships. However, the main focus here seems to be on the retrieval task combining text and images, which is multimodal. The graph-based approach might be a method used within the multimodal framework, but the core topic is the integration of different modalities. \n\nRAG is about retrieval-augmented generation, which is more about using retrieved information to enhance model outputs, typically in NLP. This doesn't seem to fit. Time-series is about sequential data over time, which isn't mentioned here. \n\nSo the most likely answer is multimodal because the task involves text and image data. The graph-based method is part of the approach but the primary research area is multimodal retrieval.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32037@AAAI"},
{"title": "GenAL: Generative Agent for Adaptive Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GenAL: Generative Agent for Adaptive Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Generative Agent\" makes me think of something that generates content or models, maybe like generative AI. \"Adaptive Learning\" suggests it's about systems that adjust or learn over time. \n\nTime-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so maybe not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't specify using different modalities, so probably not that either.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to pull information and then generates a response. The term \"Generative Agent\" could be related, but the title doesn't mention retrieval or augmentation. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper was about building or using a knowledge graph, that would fit. But the title doesn't mention graphs or knowledge structures.\n\nSo, the title is about a generative agent focused on adaptive learning. None of the four topics (time-series, multimodal, RAG, KG) seem to directly match. The closest might be RAG if it's about generating with retrieval, but the title doesn't specify that. Since it doesn't clearly fit any of the given categories, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32038@AAAI"},
{"title": "Number Theoretic Accelerated Learning of Physics-Informed Neural Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Number Theoretic Accelerated Learning of Physics-Informed Neural Networks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Number Theoretic Accelerated Learning\" probably refers to using mathematical number theory to speed up the learning process. \"Physics-Informed Neural Networks\" suggests that the neural networks are incorporating physical laws or equations into their training, which is a common approach in scientific machine learning to ensure the models adhere to known physical principles.\n\nNow, looking at the four options. Time-series analysis involves data points indexed in time order, often used in forecasting or signal processing. Multimodal refers to combining multiple types of data (like text, images, audio) in a model. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where models retrieve information from a database to enhance their responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used for semantic reasoning.\n\nThe paper's title doesn't mention anything about time-dependent data, so time-series is probably not it. There's no indication of combining different data modalities, so multimodal is out. RAG and KG are both related to knowledge and information retrieval, but the title here is about accelerating learning using number theory in physics-informed neural networks. Physics-informed models are more about integrating domain-specific knowledge (like physics equations) into the neural network's loss function or architecture. However, the options given are RAG and KG. RAG is about retrieving external information during generation, and KG is about structured knowledge graphs. The paper's focus seems to be on the mathematical acceleration and physics integration, not on retrieving information or building a knowledge graph. Therefore, it doesn't fit into any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32040@AAAI"},
{"title": "Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Defense Against Model Stealing Based on Account-Aware Distribution Discrepancy.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on defending against model stealing. Model stealing is a type of attack where an adversary tries to replicate a machine learning model by querying it. The defense method here is based on \"Account-Aware Distribution Discrepancy.\" \n\nNow, the four options. Time-series would involve data over time, like stock prices or weather. Multimodal refers to using multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about combining retrieval with generation in models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's defense mechanism seems to involve analyzing distribution discrepancies, possibly in the data or model outputs. The term \"Account-Aware\" might refer to user accounts or some form of tracking, but that's not directly related to the four topics. The key here is whether the defense method ties into any of the four. \n\nSince the defense is about distribution discrepancy, which is a statistical concept, but none of the four topics (time-series, multimodal, RAG, KG) directly relate to distribution discrepancies in the context of model stealing. Time-series is about temporal data, multimodal about multiple data types, RAG about retrieval and generation, and KG about structured knowledge. The paper's focus is on a security defense mechanism, which doesn't fit into any of these categories. \n\nTherefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32041@AAAI"},
{"title": "Multi-modal Deepfake Detection via Multi-task Audio-Visual Prompt Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-modal Deepfake Detection via Multi-task Audio-Visual Prompt Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the title. That suggests it's about combining multiple data types, like audio and visual. The paper is about deepfake detection using both audio and visual information. So multimodal seems like a strong candidate. \n\nThe other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe title mentions \"audio-visual,\" which are different modalities, so multimodal fits. The other terms like \"multi-task\" and \"prompt learning\" might relate to the methodology, but the key here is the \"multi-modal\" part. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32042@AAAI"},
{"title": "GoBERT: Gene Ontology Graph Informed BERT for Universal Gene Function Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GoBERT: Gene Ontology Graph Informed BERT for Universal Gene Function Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"GoBERT\" probably refers to a model that uses BERT, which is a transformer-based model for natural language processing. Then \"Gene Ontology Graph Informed\" suggests that the model incorporates some kind of graph structure related to gene ontology. Gene Ontology (GO) is a system for categorizing gene functions, and it's structured as a graph where terms are connected hierarchically. So \"Graph Informed\" here likely means that the model uses the Gene Ontology graph as part of its architecture or training.\n\nThe term \"KG\" stands for Knowledge Graph, which is a structured representation of knowledge, often in the form of a graph. Since Gene Ontology is a type of knowledge graph, using it in the model would fall under the KG topic. \n\nLooking at the other options: time-series would involve data over time, which isn't mentioned here. Multimodal refers to combining different types of data (like text and images), but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) involves using a retrieval system to augment a generative model, which also doesn't seem to be the case here. \n\nTherefore, the paper is using a knowledge graph (Gene Ontology) to inform the BERT model, so the correct topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32043@AAAI"}
{"title": "GoBERT: Gene Ontology Graph Informed BERT for Universal Gene Function Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GoBERT: Gene Ontology Graph Informed BERT for Universal Gene Function Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"GoBERT\" probably refers to a model that uses BERT, which is a transformer-based model for natural language processing. Then \"Gene Ontology Graph Informed\" suggests that the model incorporates some kind of graph structure related to gene ontology. Gene Ontology (GO) is a system for categorizing gene functions, and it's structured as a graph where terms are connected hierarchically. So \"Graph Informed\" here likely means that the model uses the Gene Ontology graph as part of its architecture or training.\n\nThe term \"KG\" stands for Knowledge Graph, which is a structured representation of knowledge, often in the form of a graph. Since Gene Ontology is a type of knowledge graph, using it in the model would fall under the KG topic. \n\nLooking at the other options: time-series would involve data over time, which isn't mentioned here. Multimodal refers to combining different types of data (like text and images), but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) involves using a retrieval system to augment a generative model, which also doesn't seem to be the case here. \n\nTherefore, the paper is using a knowledge graph (Gene Ontology) to inform the BERT model, so the correct topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32043@AAAI"},
{"title": "SLRL: Semi-Supervised Local Community Detection Based on Reinforcement Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SLRL: Semi-Supervised Local Community Detection Based on Reinforcement Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Semi-Supervised\" refers to a machine learning approach that uses both labeled and unlabeled data. \"Local Community Detection\" sounds like it's about finding communities or groups within a network or graph. \"Reinforcement Learning\" is a type of machine learning where an agent learns by interacting with an environment to maximize some reward.\n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like some chatbots. KG is Knowledge Graphs, which are structured representations of knowledge, often using graphs to represent entities and their relationships.\n\nThe paper's focus is on community detection in a graph using reinforcement learning. Community detection is typically a graph-based problem, which relates to Knowledge Graphs (KG) since KGs are structured as graphs. However, the paper itself is about the method (reinforcement learning) applied to community detection. But the question is about the research topic the paper belongs to. Since the main application here is community detection in a graph, which is a graph-based problem, it might be related to Knowledge Graphs. However, RAG is more about combining retrieval and generation, which doesn't seem to fit here. The paper isn't about time-series data or multimodal data. So the closest would be KG, but I need to be careful. Alternatively, maybe it's none of them. Wait, the problem is community detection in a graph, which is a graph mining task. Knowledge Graphs are a type of graph, but the paper's title doesn't mention knowledge graphs specifically. It's just about local community detection using reinforcement learning. So maybe it's not directly related to KG. Then, none of the options might fit. But the options are time-series, multimodal, RAG, KG. Since the paper is about graph-based community detection, which is a graph problem, but the options don't include graph mining or network analysis. The closest is KG, but unless the paper specifically deals with knowledge graphs, which it doesn't mention, then it's not KG. Therefore, the answer might be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32044@AAAI"},
{"title": "Robust Heterogeneous Graph Classification for Molecular Property Prediction with Information Bottleneck", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Robust Heterogeneous Graph Classification for Molecular Property Prediction with Information Bottleneck.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Heterogeneous Graph Classification\" stands out. Heterogeneous graphs are a type of graph where nodes and edges can have different types. That makes me think of Knowledge Graphs (KG), which are structured representations of information with entities and relationships. But wait, the term \"graph\" here might refer to graph structures in machine learning, like in graph neural networks. However, the mention of \"heterogeneous\" could align with KGs, which often have multiple types of nodes and edges.\n\nThen there's \"Molecular Property Prediction.\" That's about predicting properties of molecules, which is common in chemistry or drug discovery. In such contexts, molecules are often represented as graphs, where atoms are nodes and bonds are edges. So maybe this is using graph-based models for molecular data. But again, the key term here is \"heterogeneous graph,\" which is a concept in graph theory and could be part of Knowledge Graphs.\n\nLooking at the options: KG (Knowledge Graph) is one of the choices. The other options are time-series, multimodal, RAG. Time-series is about data over time, which doesn't seem to fit. Multimodal would involve multiple data types like text and images. RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. \n\nThe paper's focus on graph classification and molecular properties suggests it's using graph structures. Since the graph is heterogeneous, and the application is in molecular data, this seems more like a graph-based approach, possibly within the realm of Knowledge Graphs. However, sometimes in machine learning, \"graph\" can refer to graph neural networks (GNNs) rather than Knowledge Graphs. But the term \"heterogeneous graph\" is more commonly associated with Knowledge Graphs, which are inherently heterogeneous. \n\nSo, the answer is likely KG. The other options don't fit. Time-series is out. Multimodal isn't mentioned. RAG isn't related here. So the topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32045@AAAI"},
{"title": "Counterexample Guided Program Repair Using Zero-Shot Learning and MaxSAT-based Fault Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Counterexample Guided Program Repair Using Zero-Shot Learning and MaxSAT-based Fault Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Counterexample Guided Program Repair\" sounds like it's about fixing programs using counterexamples. \"Zero-Shot Learning\" is a machine learning concept where the model can recognize classes not seen during training. \"MaxSAT-based Fault Localization\" refers to using MaxSAT (Maximum Satisfiability) algorithms to find faults in the program.\n\nNow, the four topics: time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is a method that combines retrieval of information with generation, often used in NLP. KG (Knowledge Graph) is about structured data representing entities and their relationships.\n\nThe paper's focus is on program repair using specific techniques. Zero-Shot Learning is a machine learning approach, but none of the four topics directly relate to program repair. RAG and KG are more about information retrieval and knowledge representation. MaxSAT is a logical reasoning method, but again, not one of the listed topics. Since the paper is about software engineering techniques and doesn't fit into time-series, multimodal, RAG, or KG, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32046@AAAI"},
{"title": "MalCL: Leveraging GAN-Based Generative Replay to Combat Catastrophic Forgetting in Malware Classification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MalCL: Leveraging GAN-Based Generative Replay to Combat Catastrophic Forgetting in Malware Classification.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on malware classification using a method called GAN-Based Generative Replay to address catastrophic forgetting. Catastrophic forgetting is a problem in machine learning where a model forgets previously learned tasks when learning new ones. GANs, or Generative Adversarial Networks, are used here for generative replay, which probably involves generating synthetic data to help the model retain old knowledge.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or sensor data. The title doesn't mention anything about time-based data, so maybe not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images. The paper's title doesn't mention different data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database to enhance its responses. This is common in NLP tasks, but the title here is about generative replay using GANs, which is different. So RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper doesn't mention anything about building or using knowledge graphs, so that's probably not it either.\n\nSo, the paper is about using GANs to prevent catastrophic forgetting in malware classification. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The methods used here are more about generative models and continual learning, which aren't covered by the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32047@AAAI"},
{"title": "Exploring Query Efficient Data Generation Towards Data-Free Model Stealing in Hard Label Setting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring Query Efficient Data Generation Towards Data-Free Model Stealing in Hard Label Setting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on data generation that's query-efficient, aimed at data-free model stealing. The \"hard label setting\" part might refer to using only class labels without additional information. \n\nTime-series would involve data points indexed in time order, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal typically involves combining multiple data types, like text and images. The title doesn't mention different modalities, so maybe not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The paper here is about generating data efficiently for model stealing, which might involve generating synthetic data to attack a model. But RAG is more about using retrieved information to aid in generation, not about data generation for attacks. Not sure yet.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nSo, the remaining options are RAG or none. The paper is about generating data in a query-efficient way to steal models without access to the original data. This seems more related to adversarial machine learning or data generation techniques, but not specifically RAG. RAG is about using retrieval to augment generation, not about generating data for attacks. Since none of the four topics (time-series, multimodal, RAG, KG) directly fit, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32048@AAAI"},
{"title": "A Simple and Comprehensive Benchmark for Single-Cell Transcriptomics", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"A Simple and Comprehensive Benchmark for Single-Cell Transcriptomics\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics refers to. \n\nTime-series research typically involves data collected over time, looking at trends, patterns, or changes. Examples include stock market data, weather data, or any sequential data where time is a key factor.\n\nMultimodal research involves combining multiple types of data or modalities, like text, images, audio, etc. For example, a study that uses both images and text to analyze something would be multimodal.\n\nRAG stands for Retrieval-Augmented Generation. This is a technique in natural language processing where a model retrieves relevant information from a database and uses it to generate responses. It's often used in question-answering systems or chatbots.\n\nKG stands for Knowledge Graph, which is a structured representation of knowledge, often in the form of a graph with nodes and edges representing entities and their relationships. Knowledge graphs are used for organizing and querying complex data.\n\nNow, looking at the title: \"A Simple and Comprehensive Benchmark for Single-Cell Transcriptomics\". Single-cell transcriptomics is a field in biology that studies the RNA transcripts in individual cells. Benchmarks in this context would be standardized tests or datasets used to evaluate methods or algorithms in this field.\n\nThe question is whether this benchmark relates to any of the four topics. Let's break it down:\n\n- Time-series: Single-cell transcriptomics might involve time-series data if they're looking at gene expression over time, but the title doesn't specify that. The focus here is on a benchmark, not necessarily on temporal data.\n\n- Multimodal: This would require the use of multiple data types. Single-cell transcriptomics typically deals with gene expression data, which is a single modality. Unless the benchmark combines other data types like imaging or proteomics, it's not multimodal.\n\n- RAG: Retrieval-Augmented Generation is about using retrieved information to generate responses. This seems unrelated to creating a benchmark for transcriptomics data unless the benchmark is for a RAG system, which isn't indicated here.\n\n- KG: Knowledge Graphs are about structuring knowledge. If the benchmark involves creating or evaluating a knowledge graph related to single-cell data, that might fit. However, the title doesn't mention anything about a graph structure or knowledge representation.\n\nThe title mentions a benchmark, which is more about evaluation metrics or datasets rather than the specific techniques listed. Since none of the four topics (time-series, multimodal, RAG, KG) are explicitly mentioned or implied in the title, the answer would be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32049@AAAI"},
{"title": "Dual-Channel Interactive Graph Transformer for Traffic Classification with Message-Aware Flow Representation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dual-Channel Interactive Graph Transformer for Traffic Classification with Message-Aware Flow Representation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dual-Channel\" might suggest using two different types of data or features. \"Interactive Graph Transformer\" points to using graph structures and transformers. \"Traffic Classification\" is the task, probably network traffic. \"Message-Aware Flow Representation\" implies considering message data in the flow.\n\nTime-series usually involves data over time, like stock prices or sensor data. The title doesn't mention time explicitly, but traffic data can be time-series. However, the focus here seems more on graph structures and message-aware features.\n\nMultimodal would involve combining different data types, like text and images. The dual-channel might hint at that, but the main components are graph and message data. Maybe it's using two modalities, but I'm not sure.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships. The graph in the title could be a knowledge graph, but \"Interactive Graph Transformer\" might refer to a graph neural network (GNN) rather than a knowledge graph. Knowledge graphs are more about semantic relationships, while GNNs process graph-structured data for tasks like node classification.\n\nSo, the paper uses a graph-based model for traffic classification, focusing on message-aware flow. Since it's using a graph structure (Interactive Graph Transformer), maybe it's related to Knowledge Graphs (KG). But wait, KG typically refers to the use of pre-existing knowledge graphs, whereas here it's a model that processes graph data. However, the options given are time-series, multimodal, RAG, KG. Since the model uses a graph structure, perhaps it's under KG? Or maybe not. Alternatively, if the graph is part of the model architecture (like a GNN), it might not be classified under KG. The term \"KG\" in the options might refer to knowledge graphs, not graph neural networks. So maybe it's none of the four. But the user wants to check if it fits any. Alternatively, maybe the graph here is a knowledge graph. The title doesn't specify, but \"message-aware flow\" could be part of a knowledge graph structure. Hmm. Alternatively, since the model is a graph transformer, maybe it's using a knowledge graph. But without explicit mention, it's unclear. The options are limited, so perhaps the best fit is KG. Alternatively, maybe it's none. But I need to decide. The other options: time-series? The traffic data could be time-series, but the model is a graph transformer. Multimodal? Dual-channel might imply two modalities, but the title doesn't specify different data types. So maybe the answer is KG. Or none. Hmm. The user might expect that if it's a graph-based model, it's under KG. But I'm not entirely sure. Let me think again. Knowledge Graphs are structured data repositories, while graph neural networks are models. The paper is about a model using graph structures for traffic classification. So maybe it's not KG. Then, none? But the options are time-series, multimodal, RAG, KG. If none of these fit, then answer \"none\". But maybe the graph is part of the model, so it's not KG. So the answer would be none. Wait, but the user might consider graph-based models under KG. But I think that's a stretch. So the correct answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32050@AAAI"},
{"title": "Revisiting Tampered Scene Text Detection in the Era of Generative AI", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Revisiting Tampered Scene Text Detection in the Era of Generative AI.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Tampered Scene Text Detection\" sounds like it's about detecting altered text in images, maybe like detecting if someone has changed text in a photo. \"Generative AI\" probably refers to models like GANs or diffusion models that can generate realistic images or text. \n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. That doesn't seem related here. Multimodal usually involves combining different data types, like text and images. Since the paper is about detecting tampered text in scenes (which are images), that might involve both image and text data, so multimodal could be a fit. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate responses. That's more about combining retrieval with generation, like in question-answering systems. KG is Knowledge Graphs, which are structured representations of information, often used for linking entities. \n\nThe paper's focus is on detecting tampered text in scene images, which is a computer vision problem. If they're using both image data and text analysis, that's multimodal. But if they're using a model that retrieves information to help detect tampering, maybe RAG? However, RAG is more about augmenting generation with retrieval, not detection. \n\nAlternatively, if the paper is about using generative AI (like GANs) to create or detect tampered text, but the main task is detection. Since the detection involves analyzing both the image and the text within it, that's combining two modalities. So multimodal seems likely. \n\nI don't see a direct link to time-series, RAG, or KG here. The key terms are scene text and detection, which are image and text related. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32051@AAAI"},
{"title": "Towards Better Robustness Against Natural Corruptions in Document Tampering Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Better Robustness Against Natural Corruptions in Document Tampering Localization.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on improving robustness against natural corruptions in the context of document tampering localization. So, the task is about detecting tampered documents, especially when there are natural corruptions involved. \n\nNow, the four options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to using multiple types of data, like combining text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time or sequential data, so time-series is probably out. It's about document tampering, which might involve images or text, but the title doesn't specify using multiple modalities. The key terms here are \"robustness\" and \"natural corruptions.\" Natural corruptions could refer to things like noise, blurring, or other distortions in images. If the paper is about making a model more robust to these corruptions in document images, it might be related to computer vision or image processing. \n\nRAG and KG are more about information retrieval and structured knowledge. The title doesn't mention anything about retrieving information or using a knowledge base. So RAG and KG are less likely. \n\nMultimodal could be a possibility if the paper uses both text and images, but the title doesn't specify that. The focus is on robustness against corruptions in document tampering, which is more about image processing or machine learning models handling noisy data. Since none of the four topics directly relate to image robustness or document tampering, the answer might be \"none.\" \n\nWait, but maybe I'm missing something. If the paper uses multiple modalities (like text and images) to detect tampering, then it would be multimodal. However, the title doesn't mention multiple data types. It just talks about natural corruptions in document tampering. So unless the corruptions involve multiple modalities, which isn't stated, multimodal might not fit. \n\nTherefore, the correct answer is probably \"none\" because the topic doesn't clearly align with any of the four listed categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32052@AAAI"}
{"title": "StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly?\" Hmm. The user wants to categorize this into one of the four topics: time-series, multimodal, RAG, or KG.\n\nFirst, I need to understand what each of these topics entails. Time-series research usually involves data points indexed in time order, like stock prices over time. Multimodal refers to combining multiple types of data, such as text and images. RAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which involves structured data representing entities and their relationships.\n\nNow, looking at the paper's title. The key terms here are \"StressPrompt\" and the question about stress impacting LLMs and human performance. The study seems to be comparing how stress affects both large language models and humans. StressPrompt might be a method or a framework they're using to induce stress in the models. \n\nDoes this relate to any of the four topics? Time-series? Probably not, unless they're analyzing data over time, but the title doesn't suggest that. Multimodal? The paper might be using different data types, but the title doesn't mention combining modalities. RAG? If they're using retrieval to augment generation, maybe, but the title doesn't specify that. KG? If they're using a knowledge graph structure, but again, the title doesn't indicate that. \n\nThe main focus here is on the effect of stress on performance, comparing humans and models. It's more about model behavior under stress rather than the specific techniques like RAG or KG. So it doesn't fit into any of the four categories. Therefore, the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32053@AAAI"},
{"title": "SUMI-IFL: An Information-Theoretic Framework for Image Forgery Localization with Sufficiency and Minimality Constraints", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SUMI-IFL: An Information-Theoretic Framework for Image Forgery Localization with Sufficiency and Minimality Constraints.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on image forgery localization. The method is called SUMI-IFL, which uses an information-theoretic approach. The constraints mentioned are sufficiency and minimality. \n\nTime-series usually involves data over time, like stock prices or weather data. This paper is about images, so probably not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The title only mentions image forgery, so maybe not multimodal unless it's using other modalities, but the title doesn't specify that. \n\nRAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image analysis, not building or using knowledge graphs. \n\nSo, none of the four topics seem to fit. The paper is about image forgery detection using information theory, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32054@AAAI"},
{"title": "SpeHeaTal: A Cluster-Enhanced Segmentation Method for Sperm Morphology Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SpeHeaTal: A Cluster-Enhanced Segmentation Method for Sperm Morphology Analysis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cluster-Enhanced Segmentation Method\" suggests that the method uses clustering techniques to improve segmentation. Segmentation is often used in image processing to separate objects from the background or to identify different parts of an image. The application here is \"Sperm Morphology Analysis,\" which is about analyzing the shape and structure of sperm cells. \n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order, like stock prices over time. This paper seems to be about image analysis, not time-based data, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention anything about combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model retrieves information from a database to enhance its responses. This doesn't seem related to image segmentation for sperm analysis.\n\nKG is Knowledge Graph, which involves structured data representation and relationships between entities. Again, the paper is about a segmentation method using clustering, not about building or using a knowledge graph.\n\nSo, none of the four topics (time-series, multimodal, RAG, KG) seem to fit. The paper is focused on a specific image processing technique for a biological application, which doesn't align with any of the listed research areas. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32055@AAAI"},
{"title": "Autonomous Goal Detection and Cessation in Reinforcement Learning: A Case Study on Source Term Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Autonomous Goal Detection and Cessation in Reinforcement Learning: A Case Study on Source Term Estimation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on reinforcement learning (RL), specifically autonomous goal detection and cessation. The case study is about source term estimation. Now, the four options are time-series, multimodal, RAG, or KG. \n\nTime-series usually involves data over time, like stock prices or weather data. Multimodal refers to using multiple types of data, like text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP that combines retrieval with generation. KG stands for Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time-series data or analysis. It's about reinforcement learning, which is a type of machine learning where an agent learns by interacting with an environment. The case study on source term estimation might involve some specific application, but the core topic here is RL. None of the four options (time-series, multimodal, RAG, KG) directly relate to reinforcement learning. The paper isn't about combining different data modalities, using retrieval-augmented generation, or building knowledge graphs. So it doesn't fit any of the given topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32056@AAAI"},
{"title": "HDT: Hierarchical Discrete Transformer for Multivariate Time Series Forecasting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HDT: Hierarchical Discrete Transformer for Multivariate Time Series Forecasting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multivariate Time Series Forecasting\" clearly mentions time series. The term \"multivariate\" here refers to multiple variables in the time series data. The model is called a Hierarchical Discrete Transformer, which is a type of neural network architecture. \n\nNow, looking at the options. Time-series is one of the options, so that's a strong candidate. The other options are multimodal, RAG, and KG. Multimodal usually refers to combining different types of data like text, images, audio, etc. The title doesn't mention anything about combining different data modalities, so probably not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention retrieval or generation, so RAG is unlikely. \n\nKG is Knowledge Graphs, which involve structured data representations. The paper's focus is on forecasting time series, not on building or using knowledge graphs. \n\nSo, the key part here is \"Multivariate Time Series Forecasting,\" which directly points to the time-series topic. The model's name and structure (Hierarchical Discrete Transformer) are specific to how they approach the time series problem. Therefore, the correct category should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32057@AAAI"},
{"title": "Enhancing Generalizability in Molecular Conformation Generation with METRIZATION-Informed Geometric Diffusion Pretraining", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Generalizability in Molecular Conformation Generation with METRIZATION-Informed Geometric Diffusion Pretraining.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on molecular conformation generation. Molecular conformations relate to the 3D structure of molecules, which is important in chemistry and drug discovery. The term \"geometric diffusion pretraining\" suggests that they're using some kind of geometric modeling, maybe involving spatial relationships or structures. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. This doesn't seem to fit because the paper is about molecular structures, not temporal data. \n\nMultimodal typically refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention retrieval or generation in that context, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of information. If the paper were about building or using a knowledge graph for molecules, that might fit. However, the title focuses on geometric diffusion and pretraining for conformation generation, which sounds more like a machine learning model trained on molecular geometry rather than a knowledge graph. \n\nWait, \"METRIZATION-Informed\" might be a typo or a specific term. Maybe it's \"Metricization-Informed\"? If they're using metric learning or geometric metrics in their diffusion process, that's more about the model's architecture or training method. Since none of the four topics directly relate to geometric diffusion or molecular conformation generation, the answer might be \"none.\" \n\nBut let me double-check. The four options are time-series, multimodal, RAG, KG. The paper's topic is about improving generalizability in generating molecular conformations using a specific geometric approach. None of the listed topics seem to directly cover this. So the correct answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32058@AAAI"},
{"title": "Predicting User Behavior in Smart Spaces with LLM-Enhanced Logs and Personalized Prompts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Predicting User Behavior in Smart Spaces with LLM-Enhanced Logs and Personalized Prompts.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or weather data. The title mentions predicting user behavior, which could involve time-based data, but the key terms here are \"LLM-Enhanced Logs\" and \"Personalized Prompts.\" LLMs are large language models, so maybe they're using logs enhanced by LLMs. \n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention different data types, so maybe not multimodal. RAG is Retrieval-Augmented Generation, which uses retrieval of documents to enhance generation. The title says \"LLM-Enhanced Logs,\" which might involve using retrieved logs to improve predictions. That sounds like RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention graphs or structured data, so probably not KG. So the most likely is RAG. Let me double-check. If they're using logs (which could be retrieved data) and enhancing them with LLMs, that fits RAG's approach of combining retrieval with generation. Yeah, I think RAG is the right answer here.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32059@AAAI"},
{"title": "END^2: Robust Dual-Decoder Watermarking Framework Against Non-Differentiable Distortions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"END^2: Robust Dual-Decoder Watermarking Framework Against Non-Differentiable Distortions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on a watermarking framework. Watermarking is typically about embedding information into data, like images or text, to prove ownership or track usage. The term \"Dual-Decoder\" suggests there are two decoders involved in the process. \"Robust\" implies it's designed to handle certain types of attacks or distortions. The specific mention of \"Non-Differentiable Distortions\" points to challenges in machine learning where the model might not be able to compute gradients for certain types of attacks, which are common in adversarial scenarios.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequential data, so probably not time-series. \n\nMultimodal refers to combining multiple types of data, like text and images. The paper's title doesn't mention multiple data types, so maybe not multimodal either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus on watermarking doesn't seem related to building or using knowledge graphs.\n\nSo, none of the four topics seem to fit. The paper is about a specific watermarking technique against certain distortions, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32060@AAAI"},
{"title": "dyAb: Flow Matching for Flexible Antibody Design with AlphaFold-driven Pre-binding Antigen", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"dyAb: Flow Matching for Flexible Antibody Design with AlphaFold-driven Pre-binding Antigen.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"dyAb\" probably stands for dynamic antibody. \"Flow Matching\" might refer to a method in machine learning, maybe something like normalizing flows or flow-based models. \"Flexible Antibody Design\" suggests it's about creating antibodies, which are proteins used in the immune system. \"AlphaFold-driven\" indicates they're using AlphaFold, which is a protein structure prediction tool. \"Pre-binding Antigen\" implies they're working on how antibodies bind to antigens before the binding occurs.\n\nNow, the four topics: time-series, multimodal, RAG, KG. \n\nTime-series usually involves data over time, like stock prices or weather. This paper seems to be about protein design, not time-based data. So probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks. The paper's focus is on antibody design using AlphaFold, which is a structure prediction tool. I don't see retrieval mentioned here, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper doesn't mention anything about building or using a knowledge graph. It's more about protein structure and design.\n\nSo, none of the four topics seem to fit. The paper is about using flow matching for antibody design with AlphaFold, which is in the field of computational biology or bioinformatics. The topics provided don't cover that area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32061@AAAI"},
{"title": "Embedding Robust Watermarking into Pattern to Protect the Copyright of Ceramic Artifacts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Embedding Robust Watermarking into Pattern to Protect the Copyright of Ceramic Artifacts.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about watermarking in ceramic artifacts, which might involve images or patterns, but the title doesn't explicitly mention combining different modalities. Maybe, but not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about protecting copyright through watermarking, which doesn't seem related to building or using knowledge graphs.\n\nSo, the main focus here is on watermarking techniques for ceramic artifacts. Watermarking is a method to embed information into media to protect copyright. The term \"embedding\" is used, which is common in watermarking. However, none of the four topics (time-series, multimodal, RAG, KG) directly relate to watermarking or copyright protection in this context. The closest might be multimodal if it involves different data types, but the title doesn't specify that. Since none of the listed topics fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32062@AAAI"}
{"title": "ODDN: Addressing Unpaired Data Challenges in Open-World Deepfake Detection on Online Social Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ODDN: Addressing Unpaired Data Challenges in Open-World Deepfake Detection on Online Social Networks.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The paper is about deepfake detection, which often uses different modalities (e.g., video and audio), but the title specifically mentions \"unpaired data challenges.\" Unpaired data could mean that the data isn't aligned across modalities, which is a common issue in multimodal learning. So maybe multimodal is a possibility.\n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generation models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nSo the most likely answer is multimodal because deepfake detection often involves multiple data types, and the unpaired data issue is a challenge in multimodal settings where data from different modalities aren't aligned. The open-world aspect might involve handling various modalities not seen during training, which is a multimodal problem. So I'll go with multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32063@AAAI"},
{"title": "NEST: A Neuromodulated Small-world Hypergraph Trajectory Prediction Model for Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"NEST: A Neuromodulated Small-world Hypergraph Trajectory Prediction Model for Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Trajectory Prediction\" and \"Autonomous Driving.\" Trajectory prediction is about predicting the future path of an object, which is a time-dependent problem. So that makes me think of time-series analysis because it involves sequences over time. \n\nNow, the model is called a \"Neuromodulated Small-world Hypergraph.\" Hypergraphs are a type of graph structure, but they can represent more complex relationships than regular graphs. However, the term \"KG\" here refers to Knowledge Graphs, which are a specific type of graph used to represent structured knowledge. Hypergraphs might be related but aren't exactly the same as KGs. \n\nThe other options are multimodal, which involves combining different types of data (like text, images, audio), and RAG (Retrieval-Augmented Generation), which is a method that combines retrieval of information with generation models. The title doesn't mention anything about combining different data modalities or using retrieval mechanisms. \n\nSo, the main focus here is on predicting trajectories over time, which is a time-series problem. Even though the model uses a hypergraph structure, the primary application and problem type here aligns with time-series analysis. Therefore, the correct topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32064@AAAI"},
{"title": "PScalpel: A Machine Learning-based Guider for Protein Phase-Separating Behaviour Alteration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PScalpel: A Machine Learning-based Guider for Protein Phase-Separating Behaviour Alteration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on using machine learning to guide or alter the phase-separating behavior of proteins. Phase separation in proteins is a biological process where proteins form liquid-like droplets, which is important in cellular functions. The term \"Machine Learning-based Guider\" suggests they're using some ML model to predict or influence this behavior.\n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices or sensor data over time. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention different data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, the title doesn't mention anything about building or using a knowledge graph.\n\nSo, the paper is about using machine learning for a specific biological application. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The core of the research is in applying ML to protein phase separation, which is more of a computational biology or bioinformatics problem. Since the given options don't cover this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32065@AAAI"},
{"title": "Hybrid-Driving: An Autonomous Driving Decision Framework Integrating Large Language Models, Knowledge Graphs and Driving Rules", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hybrid-Driving: An Autonomous Driving Decision Framework Integrating Large Language Models, Knowledge Graphs and Driving Rules.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components mentioned are Large Language Models (LLMs), Knowledge Graphs (KGs), and Driving Rules. The framework is called Hybrid-Driving, which suggests combining different elements. The key here is to see which of the listed topics are directly referenced.\n\nLooking at the options: time-series usually involves data over time, like stock prices or weather. Multimodal refers to using multiple types of data (text, images, audio, etc.). RAG is Retrieval-Augmented Generation, which combines retrieval of information with generation models. KG stands for Knowledge Graph, which is explicitly mentioned in the title.\n\nThe title specifically mentions \"Knowledge Graphs\" as part of the integration. So that's a direct hit on the KG topic. The other elements like LLMs and driving rules don't fall under the other categories. RAG isn't mentioned here. The paper isn't about time-series data or multimodal data types. Therefore, the correct topic should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32066@AAAI"},
{"title": "GTG: Generalizable Trajectory Generation Model for Urban Mobility", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GTG: Generalizable Trajectory Generation Model for Urban Mobility.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Trajectory Generation\" suggests creating paths or sequences of movement, which is often related to time-series data because trajectories are sequences over time. Urban mobility could involve movement data like vehicle paths, pedestrian movement, etc., which are typically time-dependent.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention different data types, so maybe not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation, often in NLP. The title doesn't mention retrieval or augmentation, so probably not RAG. KG (Knowledge Graph) involves structured data and relationships. The title doesn't mention knowledge graphs either.\n\nSo, trajectory generation for urban mobility likely involves modeling sequences over time, which fits the time-series category. The model is generating trajectories, which are time-ordered data points. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32067@AAAI"},
{"title": "Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather. This title doesn't mention anything about time-based data, so probably not time-series.\n\nMultimodal refers to combining different data types, like text and images. The title is about unlearning in language models, which are text-based, but there's no mention of combining modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when models use external information retrieval to enhance their responses. The paper here is about unlearning, which is about removing or forgetting certain data. Doesn't seem directly related to RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's focus is on unlearning techniques in language models, not on building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about machine unlearning, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32068@AAAI"},
{"title": "VisRec: A Semi-Supervised Approach to Visibility Data Reconstruction in Radio Astronomy", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VisRec: A Semi-Supervised Approach to Visibility Data Reconstruction in Radio Astronomy.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Visibility Data Reconstruction\" in \"Radio Astronomy\" using a \"Semi-Supervised Approach.\" The key terms here are visibility data, radio astronomy, and semi-supervised learning. \n\nTime-series analysis deals with data points indexed in time order. Radio astronomy might involve time-series data, like signals over time. But the title mentions reconstruction of visibility data, which could be more about processing and reconstructing data rather than analyzing time-based patterns. Not sure yet.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention multiple modalities, so maybe not this one.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. This seems unrelated to radio astronomy data reconstruction.\n\nKG is Knowledge Graph, which involves structured data representation. The paper's focus is on reconstructing visibility data, which might not involve building or using a knowledge graph.\n\nSo, the options are time-series or none. The paper is about reconstructing visibility data in radio astronomy. Visibility data in radio astronomy is typically complex numbers representing the Fourier transform of the sky brightness, collected over time. However, the reconstruction here might not be about time-series analysis but rather about filling in missing data points or enhancing the data. The semi-supervised approach suggests using both labeled and unlabeled data, which is a machine learning technique but not necessarily tied to time-series. Since the primary focus is on data reconstruction in a specific domain without clear indication of time-series analysis, multimodal, RAG, or KG, maybe it doesn't fit any of the given topics. But wait, visibility data could be time-series if it's collected over time. However, the reconstruction might not be about the time aspect. The problem is whether the research topic is about time-series analysis. If the method is for reconstructing time-series data, then it's time-series. But the title doesn't explicitly state that. The term \"visibility data\" in radio astronomy is more about spatial or spectral data. So maybe it's not time-series. Therefore, the answer might be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32069@AAAI"},
{"title": "FMPM-DNet: Hyperspectral Pansharpening Dynamic Network Based on Feature Modulation and Probability Mask", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FMPM-DNet: Hyperspectral Pansharpening Dynamic Network Based on Feature Modulation and Probability Mask\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Hyperspectral pansharpening refers to combining hyperspectral images with higher resolution panchromatic images to get a high-resolution hyperspectral image. So that's an image processing task. The dynamic network part suggests it's a neural network model. The methods mentioned are feature modulation and probability mask. \n\nNow, the four options. Time-series would involve data over time, like stock prices or weather data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using external information in generative models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on a dynamic network for image processing (hyperspectral pansharpening). There's no mention of time-based data, so time-series is out. It's combining different image data (hyperspectral and panchromatic), which could be considered multimodal since they're different data types. But wait, pansharpening is a specific image fusion technique, not necessarily combining multiple modalities like text and images. However, hyperspectral and panchromatic are different types of images, so maybe multimodal. \n\nRAG and KG don't seem relevant here. The paper isn't about retrieval or knowledge graphs. So the most likely answer is multimodal. But I need to be careful. Let me check again. If multimodal is about integrating different data sources, then yes, combining two different image types (hyperspectral and panchromatic) would be multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32070@AAAI"},
{"title": "Aerodynamic Coefficients Prediction via Cross-Attention Fusion and Physical-Informed Training", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Aerodynamic Coefficients Prediction via Cross-Attention Fusion and Physical-Informed Training.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main goal is predicting aerodynamic coefficients. The methods mentioned are cross-attention fusion and physical-informed training. \n\nCross-attention fusion sounds like it's combining different data sources or modalities using attention mechanisms. That might point towards multimodal, since multimodal research often involves integrating multiple types of data. But wait, cross-attention is also used in time-series models, like in transformers for sequence data. However, the term \"fusion\" here might imply combining different modalities, like data from different sensors or types.\n\nPhysical-informed training probably refers to incorporating physical laws or equations into the training process, which is common in physics-informed machine learning. But that's more about the training methodology rather than the data type or model structure. \n\nLooking at the four options: time-series usually deals with sequential data over time. The title doesn't explicitly mention time or sequences, but aerodynamic coefficients could be time-dependent. However, the key terms here are cross-attention fusion and physical-informed training. \n\nMultimodal would involve multiple data types (e.g., text, images, sensor data). If the model is fusing different data sources (like sensor data and simulations), that's multimodal. But the title doesn't specify different modalities, just cross-attention. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to augment generation, typically in NLP. That doesn't seem relevant here. \n\nKG (Knowledge Graphs) involve structured data and relationships. The title doesn't mention knowledge graphs or structured data. \n\nSo, cross-attention fusion might be part of a multimodal approach if it's combining different data types. But if it's just using cross-attention within a single modality (like time-series data), then it's not multimodal. However, the term \"fusion\" often implies combining different sources. \n\nAlternatively, if the model is using cross-attention between different features or time steps, it could be part of a time-series model. But the presence of \"fusion\" might lean towards multimodal. \n\nI'm a bit torn here. The physical-informed training is a method, not a topic. The main question is whether the paper is about time-series, multimodal, RAG, or KG. \n\nSince the title mentions \"cross-attention fusion,\" which is a technique used in multimodal models to combine different modalities, I think it's more likely to be multimodal. Unless the fusion is within the same modality's features, but the term \"fusion\" usually implies different sources. \n\nTherefore, the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32071@AAAI"},
{"title": "Generalized Implicit Neural Representations for Dynamic Molecular Surface Modeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generalized Implicit Neural Representations for Dynamic Molecular Surface Modeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Implicit Neural Representations\" sounds like a machine learning technique, maybe using neural networks to represent data in a certain way. \"Dynamic Molecular Surface Modeling\" suggests that the focus is on modeling surfaces of molecules that change over time or in different states. \n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices over days. Multimodal refers to combining multiple types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about combining different data modalities, so probably not multimodal. It's about molecular surfaces, which might involve 3D structures or dynamic changes. Time-series could be a possibility if the model is tracking changes over time. However, \"dynamic\" here might refer to the surface's properties changing in response to different conditions rather than a sequence over time. \n\nRAG and KG are more about information retrieval and structured knowledge, which don't seem directly related to molecular surface modeling. The term \"implicit neural representations\" might relate to how the model represents the data, but it's not clear if it's using a knowledge graph or retrieval methods. \n\nSo, the closest might be time-series if the dynamic aspect implies temporal changes. But I'm not entirely sure. Alternatively, maybe none of the options fit. The paper could be about neural networks for molecular modeling, which isn't one of the listed topics. The key here is whether \"dynamic\" implies a time-series aspect. If the model is capturing how the surface changes over time, then time-series. If it's about different states or configurations without a time component, maybe not. Since the title doesn't explicitly mention time-series, but \"dynamic\" could imply it, I'm a bit torn. However, given the options, maybe none is the right answer here because the main focus is on neural representations for molecular surfaces, which doesn't clearly align with any of the four topics listed.\n</think>\n\nnone", "url": "https://papers.cool/venue/32072@AAAI"}
{"title": "Vision Transformers Beat WideResNets on Small Scale Datasets Adversarial Robustness", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Vision Transformers Beat WideResNets on Small Scale Datasets Adversarial Robustness.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions Vision Transformers and WideResNets, which are types of neural networks used in computer vision. So probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title is about comparing two models for adversarial robustness on small datasets. It doesn't mention multiple modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like some NLP models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge bases, so that's out.\n\nSo the answer should be none. The paper is about comparing Vision Transformers and WideResNets in terms of adversarial robustness on small datasets, which doesn't fit any of the given topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32073@AAAI"},
{"title": "Relation-Aware Equivariant Graph Networks for Epitope-Unknown Antibody Design and Specificity Optimization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Relation-Aware Equivariant Graph Networks for Epitope-Unknown Antibody Design and Specificity Optimization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Relation-Aware Equivariant Graph Networks\" – the term \"Graph Networks\" makes me think of Graph Neural Networks (GNNs). Then \"Relation-Aware\" and \"Equivariant\" might be specific techniques or properties of the model. The application is in \"Epitope-Unknown Antibody Design and Specificity Optimization,\" which is related to bioinformatics or computational biology, specifically in antibody design.\n\nNow, the four options: time-series, multimodal, RAG, KG. \n\nTime-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge, often using graphs. The paper's title mentions \"Graph Networks,\" which could be related to knowledge graphs. However, the term \"Equivariant Graph Networks\" might refer to a specific type of GNN, like those that maintain certain symmetries. But the key here is whether it's about knowledge graphs. Knowledge Graphs are more about representing entities and their relationships, often in a structured format. If the paper is using graph networks to model relationships in a knowledge graph context, then KG would be the topic. However, the application here is in antibody design, which is more about molecular structures and interactions. In that case, it might be using graph networks to model molecular structures, which is a different application. But the term \"Relation-Aware\" might imply modeling relationships between entities, which is a key aspect of knowledge graphs. However, in the context of antibody design, the graph could represent the molecular structure (atoms and bonds), which is a different use case. So maybe it's not a knowledge graph but a graph neural network for molecular modeling. \n\nWait, the options are RAG, KG, time-series, multimodal. The paper's title mentions \"Graph Networks,\" which could be related to Knowledge Graphs (KG), but I'm not sure. Alternatively, if the paper is about using graph networks in a way that's specific to knowledge graphs, then KG. But if it's just using graph networks for a different purpose, like molecular design, then maybe it's not KG. However, the term \"Relation-Aware\" might be a hint towards modeling relationships, which is central to knowledge graphs. But in molecular structures, relationships (like bonds) are also modeled as graphs. So it's a bit ambiguous. \n\nAlternatively, RAG is Retrieval-Augmented Generation, which is a specific method. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nMultimodal is combining different data types, which isn't indicated here. \n\nTime-series is out. \n\nSo between KG and none. But the paper is using graph networks, which could be part of knowledge graph research. However, in many cases, graph networks are used in various domains, not just knowledge graphs. For example, in chemistry, graph networks model molecules. So maybe the paper is using graph networks for a different purpose, not specifically knowledge graphs. Therefore, it might not belong to any of the four topics. But the options are to choose between the four or none. \n\nWait, the four topics are time-series, multimodal, RAG, KG. The paper's title mentions \"Graph Networks,\" which could be part of Knowledge Graphs (KG) if it's about modeling relationships in a knowledge base. However, in this case, the application is in antibody design, which is more about molecular structures. So perhaps the graph here is a molecular graph, not a knowledge graph. Therefore, the paper might not belong to any of the four topics. But the user is asking to choose between the four or none. \n\nAlternatively, maybe \"Relation-Aware Equivariant Graph Networks\" is a type of Knowledge Graph method. But I'm not sure. The term \"Equivariant\" refers to properties in machine learning where the model's output transforms predictably with the input. This is more of a technical aspect of the model, not necessarily related to knowledge graphs. \n\nGiven that, the paper is about using graph networks in a specific application (antibody design) with certain properties (relation-aware, equivariant). Since the four topics don't include general graph neural networks, and the options are RAG, KG, time-series, multimodal, none of which directly fit, the answer would be \"none.\" But wait, the user might consider \"KG\" as any graph-related work. However, in academic terms, Knowledge Graphs (KG) are a specific area. If the paper is about using graph networks for knowledge representation, then KG. But if it's for molecular modeling, then it's not. \n\nGiven the title's focus on antibody design, which is a molecular biology application, the graph is likely representing molecular structures (atoms and bonds), not a knowledge graph. Therefore, the paper doesn't belong to any of the four topics. So the answer is \"none.\"\n</think>\n\nKG", "url": "https://papers.cool/venue/32074@AAAI"},
{"title": "MYOPIA: Protecting Face Privacy from Malicious Personalized Text-to-Image Synthesis via Unlearnable Examples", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MYOPIA: Protecting Face Privacy from Malicious Personalized Text-to-Image Synthesis via Unlearnable Examples.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like text and images. The paper talks about text-to-image synthesis, which combines text and images. That seems like multimodal. But wait, the main focus here is on protecting privacy by making examples unlearnable. So maybe the multimodal aspect is part of the problem, but the core research might be about privacy or adversarial methods. However, the question is about the topic the paper belongs to. Since the synthesis is text-to-image, which is multimodal, maybe it's under multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate text. The title doesn't mention retrieval or generation in that context. It's about preventing malicious synthesis, not augmenting with retrieved data. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using knowledge graphs. So not KG.\n\nSo the most likely is multimodal because it's dealing with text and image synthesis. Even though the main goal is privacy, the method involves multimodal data. The answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32075@AAAI"},
{"title": "MultiSFL: Towards Accurate Split Federated Learning via Multi-Model Aggregation and Knowledge Replay", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MultiSFL: Towards Accurate Split Federated Learning via Multi-Model Aggregation and Knowledge Replay.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Split Federated Learning (SFL) is a type of federated learning where the model is split across clients and a server. The paper mentions \"Multi-Model Aggregation and Knowledge Replay.\" \n\nLooking at the options: time-series usually involves data over time, like stock prices or weather. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge for generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title doesn't mention anything about time-based data, so time-series is probably out. The term \"multimodal\" isn't in the title, but \"Multi-Model\" might be a red herring. However, multimodal typically refers to different data modalities, not just multiple models. The paper is about federated learning with model splitting and aggregation, which is more about distributed machine learning techniques. \n\nRAG and KG are about knowledge retrieval and structured data, which don't seem related here. The focus is on improving federated learning accuracy through aggregation and knowledge replay, which is a method in machine learning but doesn't fit into the four categories listed. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32076@AAAI"},
{"title": "Generalizable Sensor-Based Activity Recognition via Categorical Concept Invariant Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generalizable Sensor-Based Activity Recognition via Categorical Concept Invariant Learning.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, activity recognition using sensors usually involves time-series data because sensors like accelerometers or gyroscopes collect data over time. So maybe time-series is a candidate. But wait, the title mentions \"Categorical Concept Invariant Learning.\" That part might be about making the model invariant to certain categories, which could relate to generalization. But does that tie into any of the listed topics?\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention multiple modalities, just sensor data. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, typically in NLP tasks. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't reference knowledge graphs or structured data, so that's probably not it either.\n\nSo the main clue is \"sensor-based activity recognition,\" which is typically time-series data. Even though the method mentioned is about invariant learning, the core data type is time-series. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32077@AAAI"},
{"title": "Improving Multimodal Social Media Popularity Prediction via Selective Retrieval Knowledge Augmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Improving Multimodal Social Media Popularity Prediction via Selective Retrieval Knowledge Augmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the word \"Multimodal\" is right there in the title. That suggests it's about combining different types of data, like text and images. So maybe the topic is multimodal. But wait, the paper also mentions \"Selective Retrieval Knowledge Augmentation.\" RAG stands for Retrieval-Augmented Generation, which is a technique where a model uses retrieved information to enhance its outputs. So \"Retrieval Knowledge Augmentation\" sounds like RAG. \n\nBut the title says \"Multimodal Social Media Popularity Prediction,\" which is the main task. The method they're using is \"Selective Retrieval Knowledge Augmentation.\" So the primary focus is on multimodal data, but the method involves RAG. However, the question is about which topic the paper belongs to. The options are time-series, multimodal, RAG, or KG. \n\nThe main topic here is the prediction task, which is multimodal. The RAG is the method used. So the paper is about improving a multimodal task using RAG. But the question is asking which of the four topics the paper belongs to. Since the title includes \"Multimodal,\" and the task is multimodal, the answer might be multimodal. However, if the main contribution is the RAG approach, maybe it's RAG. But the title structure is \"Improving [X] via [Y].\" So [X] is the main topic, and [Y] is the method. So the paper is about improving multimodal prediction using RAG. Therefore, the primary topic is multimodal. But I need to check if RAG is a separate category here. The options are time-series, multimodal, RAG, KG. So if the paper is about using RAG as a method, then maybe it's RAG. But the title's main focus is on the multimodal prediction. Hmm. \n\nAlternatively, maybe the paper is about both multimodal and RAG. But the question says to choose one. The options are exclusive. The title mentions both, but the task is multimodal prediction, and the method is RAG. So the primary topic would be multimodal, as that's the main problem being addressed. The RAG is the technique used. So the answer should be multimodal. But wait, the title says \"via Selective Retrieval Knowledge Augmentation,\" which is RAG. So maybe the paper is about RAG. But the main problem is multimodal. The question is which topic the paper belongs to. If the paper is about applying RAG to a multimodal problem, then the primary topic is multimodal, and RAG is the method. So the answer is multimodal. Alternatively, if the paper's main contribution is the RAG approach, then it's RAG. But the title structure suggests that the main topic is the multimodal prediction, and RAG is the method. Therefore, the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32078@AAAI"},
{"title": "DearLLM: Enhancing Personalized Healthcare via Large Language Models-Deduced Feature Correlations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DearLLM: Enhancing Personalized Healthcare via Large Language Models-Deduced Feature Correlations.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on using Large Language Models (LLMs) to deduce feature correlations for personalized healthcare. The key terms here are \"Large Language Models,\" \"feature correlations,\" and \"personalized healthcare.\" \n\nTime-series analysis usually involves data points indexed in time order, like stock prices over time. The title doesn't mention anything about time-based data, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text, images, audio. The paper's title doesn't specify using different data types, just mentions LLMs and feature correlations. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to pull information and then generates a response. The title doesn't mention retrieval or augmentation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper was about building or using a knowledge graph, that would fit. But the title talks about feature correlations deduced by LLMs, not about structuring knowledge into a graph. \n\nSo none of the four topics seem to fit. The paper is about using LLMs to find correlations in features for healthcare, which is more about machine learning applications in healthcare rather than the specific topics listed. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32079@AAAI"},
{"title": "PriFold: Biological Priors Improve RNA Secondary Structure Predictions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PriFold: Biological Priors Improve RNA Secondary Structure Predictions.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. This paper is about RNA structure prediction, which is more about biological sequences and their structures, not time-based data. So probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title mentions \"biological priors,\" which might be prior knowledge or data, but I don't see mention of multiple modalities here. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The paper's focus is on improving predictions using biological priors, which could be a form of prior knowledge, but RAG specifically involves retrieval during generation. Not sure if that's the case here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses a knowledge graph to incorporate biological information, then it might be KG. However, the term \"biological priors\" sounds more like integrating prior knowledge (maybe as constraints or features) rather than building or using a knowledge graph structure.\n\nSo, the paper is about using prior biological knowledge (priors) to enhance RNA structure prediction. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to using prior knowledge in this context, the answer might be \"none.\" But wait, maybe RAG? If \"biological priors\" are retrieved information used during the prediction process, could that be RAG? But RAG typically involves retrieving external information at inference time. The title doesn't specify retrieval, just using priors. So maybe it's not RAG. Similarly, if the priors are part of a knowledge graph, then KG. But the title doesn't mention a graph structure. So I think the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32080@AAAI"},
{"title": "Graph Structure Learning for Spatial-Temporal Imputation: Adapting to Node and Feature Scales", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Graph Structure Learning for Spatial-Temporal Imputation: Adapting to Node and Feature Scales.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph Structure Learning\" suggests that the paper is about learning the structure of a graph. Then \"Spatial-Temporal Imputation\" refers to filling in missing data in spatial and temporal data. The subtitle mentions adapting to node and feature scales, which might relate to how the graph handles different scales of nodes and features.\n\nLooking at the options: time-series deals with data over time, multimodal involves multiple data types (like text and images), RAG is Retrieval-Augmented Generation, and KG is Knowledge Graphs. \n\nGraph Structure Learning is part of Knowledge Graphs (KG) because KGs often involve constructing and learning the relationships (edges) between entities (nodes). The spatial-temporal aspect might involve time-series elements, but the main focus here is on learning the graph structure for imputation. Since the paper is about learning the graph's structure, which is a key aspect of Knowledge Graphs, I think it belongs to the KG topic. Time-series could be a component, but the primary research area here is graph learning, which aligns with KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32081@AAAI"},
{"title": "Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data analysis, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper here is about code detection, which is text-based, but there's no mention of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The paper's focus is on detecting code generated by LLMs using code rewriting. I don't see retrieval or augmentation mentioned here. The method is about code rewriting and zero-shot detection, which might be more about model analysis or detection techniques rather than RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using knowledge graphs. It's about detecting synthetic code, which is a different area.\n\nSo, none of the topics seem to fit. The paper is about detecting code generated by large language models, which relates to model behavior analysis or code generation detection, but none of the given categories (time-series, multimodal, RAG, KG) directly apply here. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32082@AAAI"}
{"title": "Disentangled Table-Graph Representation for Interpretable Transmission Line Fault Location", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Disentangled Table-Graph Representation for Interpretable Transmission Line Fault Location.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Disentangled Table-Graph Representation\" suggests they're combining tabular data with graph structures. \"Interpretable Transmission Line Fault Location\" is about finding faults in power lines, which is an application area. \n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper mentions \"Table-Graph Representation,\" which combines tabular (structured data) and graph (network structure) data. That sounds like multimodal because it's integrating different data types. But wait, sometimes graph data is considered a separate modality. However, multimodal typically refers to things like text, images, audio. Maybe in this context, combining tables and graphs could be seen as multimodal. Alternatively, if the graph is part of a knowledge graph, maybe it's KG. But the title doesn't mention knowledge explicitly. The key term is \"Table-Graph,\" which is a combination of two data types. So I think it's multimodal. The other options don't fit. Time-series isn't mentioned. RAG and KG are not directly referenced. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32083@AAAI"},
{"title": "RaCMC: Residual-Aware Compensation Network with Multi-Granularity Constraints for Fake News Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RaCMC: Residual-Aware Compensation Network with Multi-Granularity Constraints for Fake News Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on fake news detection. The method mentioned is a Residual-Aware Compensation Network with Multi-Granularity Constraints. The key terms here are \"Residual-Aware,\" \"Compensation Network,\" and \"Multi-Granularity Constraints.\" \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like text and images. The title doesn't specify combining different data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention retrieval or generation, so RAG might not fit.\n\nKG is Knowledge Graph, which involves structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nThe paper seems to be about a neural network architecture (Residual-Aware Compensation Network) with specific constraints for fake news detection. Since none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32084@AAAI"},
{"title": "Reinforced Multi-teacher Knowledge Distillation for Efficient General Image Forgery Detection and Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Reinforced Multi-teacher Knowledge Distillation for Efficient General Image Forgery Detection and Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Reinforced Multi-teacher Knowledge Distillation\" – knowledge distillation is a method where a smaller model (student) learns from a larger one (teacher). The \"multi-teacher\" part suggests using multiple teachers. \"Reinforced\" might refer to reinforcement learning, but I'm not sure. The application is for image forgery detection and localization, which is about computer vision, specifically image analysis.\n\nNow, the topics. Time-series is about data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. Multimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities, just image forgery. RAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on knowledge distillation, which is a model compression technique. None of the four topics directly relate to knowledge distillation. RAG and KG are different concepts. Since the title doesn't mention time-series data, multimodal inputs, RAG, or knowledge graphs, it doesn't fit any of the given categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32085@AAAI"},
{"title": "Accurate Nucleic Acid-Binding Residue Identification Based Domain-Adaptive Protein Language Model and Explainable Geometric Deep Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Accurate Nucleic Acid-Binding Residue Identification Based Domain-Adaptive Protein Language Model and Explainable Geometric Deep Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main goal is identifying nucleic acid-binding residues in proteins. The methods mentioned are a domain-adaptive protein language model and explainable geometric deep learning. \n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't seem to fit here. The paper is about protein structures and residues, which are more about spatial data rather than temporal sequences.\n\nMultimodal typically refers to combining different types of data, like text and images. The title mentions a language model and geometric deep learning. A language model could be considered a modality (text), and geometric deep learning might handle 3D structures. So maybe multimodal? But I'm not sure if combining a language model with geometric models is standard enough to classify as multimodal. It might be more about the specific application in bioinformatics.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate answers. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper doesn't mention building or using a knowledge graph, so that's probably not it either.\n\nSo, the closest might be multimodal if the combination of different models (language and geometric) is considered multimodal. But I'm a bit uncertain. Alternatively, maybe none of the options fit perfectly. The paper is about protein structure prediction using specific models, which might not align with the given categories. However, since the options are limited, and the use of a language model (text) and geometric deep learning (spatial) could be seen as different modalities, I'll go with multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32086@AAAI"},
{"title": "SWAMamba: A Sliding Window Attention Mamba Framework for Predicting Translation Elongation Rates", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SWAMamba: A Sliding Window Attention Mamba Framework for Predicting Translation Elongation Rates.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key parts here are \"Sliding Window Attention Mamba\" and \"Predicting Translation Elongation Rates.\" The term \"Mamba\" might refer to a specific model or framework. I remember that Mamba is a type of model designed for sequence modeling, similar to transformers but with some differences in how they handle sequences. It's often used in time-series data because it can process sequences efficiently with state space models.\n\nThe \"Sliding Window Attention\" part suggests that the model uses a sliding window approach, which is common in time-series analysis to capture temporal dependencies. The application here is predicting translation elongation rates, which sounds like a biological process, maybe related to protein synthesis. In such cases, time-series data is often involved because the elongation rates could be measured over time.\n\nNow, checking the possible topics. Time-series is a strong candidate here because the model is likely processing sequential data over time. Multimodal would involve combining different types of data (like text and images), which doesn't seem to be the case here. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, which isn't mentioned. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo, the most likely topic is time-series. The paper is about a model (Mamba) using attention mechanisms in a sliding window for a prediction task that's likely time-dependent. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32087@AAAI"},
{"title": "Portcullis: A Scalable and Verifiable Privacy Gateway for Third-Party LLM Inference", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Portcullis: A Scalable and Verifiable Privacy Gateway for Third-Party LLM Inference.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are \"Privacy Gateway,\" \"Third-Party LLM Inference,\" and the adjectives \"Scalable\" and \"Verifiable.\" The term \"LLM\" stands for Large Language Model. The paper is about a system called Portcullis that acts as a privacy gateway for using third-party LLMs. \n\nNow, looking at the four options. Time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time-based data, so probably not time-series. \n\nMultimodal refers to models that handle multiple types of data, like text and images. The title is about privacy in LLM inference, not about combining different data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method where models retrieve information from a database to augment their responses. The title doesn't mention retrieval or generation processes, so RAG might not be the right fit here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on privacy and a gateway for LLMs, not on building or using knowledge graphs. \n\nSo none of the four topics seem to directly relate to the paper's title. The paper is about privacy mechanisms for LLMs, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32088@AAAI"},
{"title": "Is LLMs Hallucination Usable? LLM-based Negative Reasoning for Fake News Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Is LLMs Hallucination Usable? LLM-based Negative Reasoning for Fake News Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on using Large Language Models (LLMs) for fake news detection, specifically looking at their hallucination aspect. The term \"Negative Reasoning\" might refer to how the model handles incorrect or false information. \n\nNow, the four options: time-series deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data retrieval to enhance model responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's title doesn't mention anything about time-based data, so time-series is probably out. There's no indication of combining multiple data modalities, so multimodal might not fit. RAG involves retrieval, but the title doesn't talk about retrieving external information. The focus is on the model's own reasoning and hallucinations, which are more about the model's internal processes rather than retrieval. Knowledge Graphs (KG) are about structured knowledge, but again, the title doesn't mention using or building a knowledge graph. \n\nSo, none of the four topics seem to directly apply here. The research is about LLMs and their reasoning in detecting fake news, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32089@AAAI"},
{"title": "BERT-Based Code Learning for Exception Localization and Type Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BERT-Based Code Learning for Exception Localization and Type Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about code learning and exceptions, so probably not time-series.\n\nMultimodal refers to using multiple data types, like text and images. The title mentions code, which is text, but there's no indication of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate a response. The title doesn't mention anything about retrieval or generation, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on using BERT for code analysis, which is more about natural language processing in code rather than building or using a knowledge graph.\n\nSo, the paper is about applying BERT (a language model) to code for exception handling tasks. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The closest might be multimodal if code is considered a modality, but code is text, and multimodal typically involves combining different types like text and images. Since the options don't include NLP or code analysis specifically, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32090@AAAI"},
{"title": "Revolutionizing Encrypted Traffic Classification with MH-Net: A Multi-View Heterogeneous Graph Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Revolutionizing Encrypted Traffic Classification with MH-Net: A Multi-View Heterogeneous Graph Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on encrypted traffic classification. The model mentioned is MH-Net, which stands for Multi-View Heterogeneous Graph Model. The key terms here are \"Multi-View\" and \"Heterogeneous Graph.\" \n\nHeterogeneous Graphs (KG) are a type of knowledge graph where different types of nodes and edges exist. So, if the model is using a heterogeneous graph, that might point towards Knowledge Graphs (KG). \n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention different data modalities, so maybe not multimodal. \n\nRAG (Retrieval-Augmented Generation) is more about using retrieval to augment generation in models, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nTime-series would involve data over time, like sequences. The title doesn't mention time-series data, so that's probably not it either. \n\nSo the key part here is \"Heterogeneous Graph Model,\" which aligns with Knowledge Graphs (KG). The multi-view aspect might be part of how the graph is structured, but the primary category here is likely KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32091@AAAI"},
{"title": "mRNA2vec: mRNA Embedding with Language Model in the 5'UTR-CDS for mRNA Design", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"mRNA2vec: mRNA Embedding with Language Model in the 5'UTR-CDS for mRNA Design\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. mRNA2vec sounds like a model name, similar to word2vec. The key parts here are \"mRNA Embedding\" and \"Language Model\". The 5'UTR-CDS refers to parts of the mRNA structure. The purpose is for mRNA design, which is about creating or optimizing mRNA sequences, maybe for vaccines or therapies.\n\nNow, the four options. Time-series usually involves data over time, like stock prices or weather. Multimodal combines different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper uses a language model to create embeddings for mRNA sequences. Language models are typically used in NLP, but here it's applied to biological sequences. The focus is on embedding mRNA parts (5'UTR and CDS) using a language model. This seems more like a representation learning task for biological data. \n\nNone of the four topics directly relate to this. Time-series is about temporal data, which isn't the case here. Multimodal would involve combining different modalities, but the paper is about a single modality (mRNA sequences). RAG and KG are about retrieval and knowledge graphs, which don't seem relevant here. The paper is about creating embeddings using a language model for a specific biological application, which doesn't fit into any of the given categories. So the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32092@AAAI"}
{"title": "Phoneme-Level Feature Discrepancies: A Key to Detecting Sophisticated Speech Deepfakes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Phoneme-Level Feature Discrepancies: A Key to Detecting Sophisticated Speech Deepfakes.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. Phoneme-level features refer to the smallest units of sound in speech. The paper is about discrepancies in these features to detect deepfakes. Deepfake detection in speech could involve analyzing audio data over time, which might relate to time-series analysis. Time-series typically deals with data points indexed in time order, so if the research is looking at how phonemes change over time or their temporal patterns, that could fit.\n\nMultimodal usually involves combining different types of data, like text and images or audio and video. The title here is specifically about speech (phonemes), so unless they're combining speech with another modality, it might not be multimodal. The title doesn't mention other data types, so maybe not.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This seems more related to text generation and retrieval, not directly to analyzing speech features for deepfakes. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses or builds a knowledge graph to detect deepfakes, that would fit. But the title doesn't mention anything about knowledge graphs or structured data, so that's unlikely.\n\nSo the most plausible is time-series. The analysis of phoneme features over time in speech signals would be a time-series problem. Detecting discrepancies in these time-based features aligns with time-series analysis techniques. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32093@AAAI"},
{"title": "Multi-View Collaborative Learning Network for Speech Deepfake Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-View Collaborative Learning Network for Speech Deepfake Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-View\" suggests that the model uses multiple perspectives or data sources. \"Collaborative Learning Network\" implies that different components or models work together. The application is \"Speech Deepfake Detection,\" which is about identifying fake speech.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Speech is a time-series, but the title doesn't explicitly mention time-series. However, the main focus here is on detecting deepfakes in speech, which might involve time-series analysis. But the key term here is \"Multi-View,\" which could relate to multimodal if it's combining different types of data (like audio and text). But the title specifically mentions \"Speech,\" so maybe it's using different features of the speech signal as multiple views. \n\nMultimodal typically refers to combining different modalities like text, image, audio, etc. If the paper uses multiple modalities, it would be multimodal. But the title says \"Speech Deepfake Detection,\" so maybe it's using different features within the speech data (like spectral features, prosody, etc.) as different views. That might still be considered multimodal if the views are different data types. However, if all the views are from the same modality (speech), it's not exactly multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to augment generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention knowledge graphs, so that's out.\n\nSo, the main question is whether \"Multi-View\" here refers to multimodal. If the different views are different data modalities (like audio and text), then it's multimodal. But if it's different features within the same modality (speech), then it's not. The title doesn't specify, but since the application is speech deepfake detection, it's possible that the multi-view approach is using different aspects of the speech signal. However, in machine learning, \"multi-view\" can sometimes be used interchangeably with multimodal when combining different data sources. But without more context, it's a bit ambiguous. However, given the options, the closest fit would be multimodal if the different views are different data types. But if it's just different features of the same modality, then it's none. Since the title doesn't specify other modalities, maybe it's not multimodal. Alternatively, maybe the \"multi-view\" here is a technique, not necessarily multimodal. So perhaps the answer is none. Wait, but the user is asking if it belongs to one of the four topics. If the paper uses multiple data sources (modalities), then it's multimodal. If it's using different features of the same modality, it's not. Since the title doesn't mention other modalities, maybe it's not multimodal. Therefore, the answer might be none. But I'm not entirely sure. Alternatively, maybe the multi-view collaborative learning is a multimodal approach. Hmm. I think the safest answer here is multimodal, assuming that multi-view refers to combining different data sources. But without more info, it's a bit of a guess. Alternatively, maybe it's time-series since speech is a time-series. But the main focus is on detection using multiple views, which might not be time-series. So perhaps the answer is multimodal. Wait, but the problem is speech deepfake detection. If the model uses different features (like audio and text), then it's multimodal. But if it's just different features of the audio, then it's not. The title doesn't specify, but the term \"multi-view\" in machine learning can sometimes refer to different feature representations. So maybe it's not multimodal. Therefore, the answer would be none. But I'm not 100% sure. Alternatively, maybe the answer is multimodal. I'm a bit torn here. Given the options, I'll go with multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32094@AAAI"},
{"title": "Multi-Edge Reinforced Collaborative Data Acquisition for Continuous Video Analytics by Prioritizing Quality over Quantity", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Edge Reinforced Collaborative Data Acquisition for Continuous Video Analytics by Prioritizing Quality over Quantity.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Edge\" might refer to multiple edges in a network, maybe edge computing? \"Reinforced Collaborative Data Acquisition\" suggests some kind of reinforcement learning or collaborative methods for gathering data. \"Continuous Video Analytics\" implies processing video data over time. \"Prioritizing Quality over Quantity\" means they're focusing on better data rather than just more data.\n\nLooking at the options: time-series deals with data over time, which video analytics might involve since video is a sequence of frames. Multimodal would involve combining different data types like text, images, audio. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to generate responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about data acquisition for video analytics. Video is a time-series because each frame is a time step. The focus on continuous analytics and quality over quantity might relate to how they handle the temporal aspects. There's no mention of combining different modalities (like text and video), so multimodal might not fit. RAG and KG don't seem relevant here. So the most likely topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32095@AAAI"},
{"title": "Efficient Traffic Prediction Through Spatio-Temporal Distillation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Efficient Traffic Prediction Through Spatio-Temporal Distillation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, traffic prediction usually involves time-series data because it's about predicting future traffic conditions based on past data. So time-series is a possibility. The term \"Spatio-Temporal\" in the title suggests that both spatial (like different locations) and temporal (time) aspects are considered. That's common in time-series analysis, especially for things like traffic where you have data across different locations over time.\n\nMultimodal would involve combining different types of data, like text and images, but the title doesn't mention different data modalities. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem related here. KG (Knowledge Graph) involves structured data and relationships, which also isn't mentioned. \n\nSo the most likely topic here is time-series. The spatio-temporal aspect is a key part of time-series analysis in traffic prediction. The other options don't fit. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32096@AAAI"},
{"title": "Motif-Oriented Representation Learning with Topology Refinement for Drug-Drug Interaction Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Motif-Oriented Representation Learning with Topology Refinement for Drug-Drug Interaction Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Motif-Oriented Representation Learning\" suggests they're using some kind of motifs, which are recurring patterns. \"Topology Refinement\" might relate to the structure of data. Drug-Drug Interaction Prediction is about predicting how drugs interact, which is a common problem in bioinformatics or cheminformatics.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal usually involves combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate answers. The title doesn't seem to involve retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of entities and their relationships. Drug interactions could be modeled as a graph where drugs are nodes and interactions are edges. The mention of \"topology refinement\" might refer to refining the structure of such a graph. Also, \"motif-oriented\" could relate to subgraph patterns in a knowledge graph. So this seems like it could be related to KG.\n\nBut wait, the paper is about representation learning. Knowledge Graphs often use representation learning techniques to embed entities and relations into vector spaces. So combining motif-based learning with topology refinement for drug interactions fits into the KG domain. \n\nI don't see any mention of time-series data, multimodal inputs, or RAG components. So the most likely answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32097@AAAI"},
{"title": "Exploit Your Latents: Coarse-Grained Protein Backmapping with Latent Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploit Your Latents: Coarse-Grained Protein Backmapping with Latent Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Latent Diffusion Models\" sounds like a machine learning technique, maybe related to generative models. The term \"latent\" here probably refers to latent variables or latent space, which are common in models like VAEs or GANs. \"Coarse-Grained Protein Backmapping\" suggests that the research is about proteins, possibly in computational biology or bioinformatics. Backmapping might involve converting a simplified (coarse-grained) model back to a more detailed one.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus seems to be on using latent diffusion models for protein structure, which is a specific application in biology. None of the four topics directly relate to proteins or backmapping. The mention of \"latent\" might be a red herring, as latent variables are common in many models. Since the other topics (time-series, multimodal, RAG, KG) don't align with the content described, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32098@AAAI"},
{"title": "TC-Diffuser: Bi-Condition Multi-Modal Diffusion for Tropical Cyclone Forecasting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TC-Diffuser: Bi-Condition Multi-Modal Diffusion for Tropical Cyclone Forecasting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That immediately makes me think of the \"multimodal\" topic. But I should check the other parts to be sure. The paper is about tropical cyclone forecasting, which is a time-dependent problem, so maybe time-series is also a possibility. However, the key term here is \"Multi-Modal Diffusion,\" which suggests combining different types of data modalities. \n\nMultimodal research typically involves integrating data from different sources or types, like combining satellite images with sensor data or other environmental data. The term \"Bi-Condition\" might refer to using two different conditions or data types in the diffusion process. Since the title explicitly mentions \"Multi-Modal,\" and the other options like RAG (Retrieval-Augmented Generation) or KG (Knowledge Graph) don't seem to be directly referenced here, the most fitting category is multimodal. Time-series could be a component, but the primary focus here is on the multimodal aspect. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32099@AAAI"},
{"title": "Zero-Shot Learning for Materials Science Texts: Leveraging Duck Typing Principles", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Zero-Shot Learning for Materials Science Texts: Leveraging Duck Typing Principles.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, zero-shot learning is a concept in machine learning where a model can recognize or predict something it hasn't been trained on. But how does that relate to the given topics? Let's break down each option.\n\nTime-series usually involves data points indexed in time order, like stock prices over time. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title mentions \"Materials Science Texts,\" which is text data, but there's no indication of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to pull information and then generates a response. The title talks about zero-shot learning and duck typing principles. Duck typing is a programming concept where an object's suitability is determined by its behavior rather than its type. Not sure how that connects to RAG. Maybe the paper is using some retrieval method, but the title doesn't explicitly mention retrieval or generation.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper is about building or using a knowledge graph for materials science, that might fit. But the title mentions \"Leveraging Duck Typing Principles,\" which sounds more like a programming or data modeling approach rather than constructing a knowledge graph.\n\nWait, zero-shot learning in materials science texts could involve using some kind of knowledge base or graph to infer information not seen during training. But the title doesn't specify a knowledge graph. Duck typing is more about how data is structured or inferred based on properties rather than explicit types. Maybe the paper is using a knowledge graph to enable zero-shot learning by structuring the data in a way that allows for such inferences. But the title doesn't mention KG explicitly. Alternatively, maybe it's using RAG by retrieving relevant information to generate answers. However, the term \"Duck Typing\" is a bit confusing here. Duck typing in programming is about \"if it looks like a duck and quacks like a duck, it's a duck.\" In the context of the paper, maybe they're using a similar principle to infer properties of materials based on their textual descriptions without explicit training. That could be a form of knowledge graph reasoning, where the structure allows for such inferences. But without more details, it's hard to say. The title doesn't clearly mention RAG, KG, or multimodal aspects. So maybe it's none of the given topics. But I need to check again. The four options are time-series, multimodal, RAG, KG. The paper is about zero-shot learning in materials science texts using duck typing. None of the four topics seem to directly fit. So the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32100@AAAI"},
{"title": "Formal Synthesis of Barrier Certificates Using Fourier Kolmogorov-Arnold Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Formal Synthesis of Barrier Certificates Using Fourier Kolmogorov-Arnold Network.\" Hmm, I need to figure out which of the given topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Formal Synthesis of Barrier Certificates\" sounds like it's related to formal methods in computer science, maybe verification or safety analysis. Barrier certificates are used in control theory and hybrid systems to prove safety properties. Then there's \"Fourier Kolmogorov-Arnold Network.\" Kolmogorov-Arnold Networks (KANs) are a type of neural network that uses the Kolmogorov-Arnold representation theorem, which allows multivariate functions to be represented as sums of univariate functions. The Fourier part might refer to using Fourier series or transforms in the network's structure.\n\nNow, looking at the possible topics. Time-series would involve data over time, like forecasting or analysis of temporal data. Multimodal would involve combining different types of data (e.g., text, images). RAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper seems to be about using a specific neural network architecture (Fourier KAN) for synthesizing barrier certificates. Barrier certificates are mathematical constructs used in system verification. None of the topics listed (time-series, multimodal, RAG, KG) directly relate to formal methods, barrier certificates, or the specific neural network type mentioned. The Fourier KAN is a novel network structure, but the application here is in formal synthesis, which doesn't fit into the given categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32101@AAAI"},
{"title": "Drawing Informative Gradients from Sources: A One-stage Transfer Learning Framework for Cross-city Spatiotemporal Forecasting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Drawing Informative Gradients from Sources: A One-stage Transfer Learning Framework for Cross-city Spatiotemporal Forecasting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts are \"Spatiotemporal Forecasting\" and \"Cross-city.\" Spatiotemporal usually refers to data that has both spatial and temporal components, which is common in time-series analysis, especially when dealing with data that changes over time and space, like traffic or weather. So that might point towards time-series. \n\nThe paper mentions a transfer learning framework. Transfer learning is a technique where a model trained on one task is adapted to another related task. In this case, it's cross-city, meaning the model is trained on data from one city and applied to another. Transfer learning is often used in time-series forecasting when there's a need to adapt models to different contexts or domains.\n\nNow, looking at the options. Time-series is a strong candidate here because spatiotemporal forecasting is a type of time-series problem that includes spatial data. Multimodal would involve combining different types of data (like text, images, audio), but the title doesn't mention different data modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also isn't mentioned.\n\nSo, the main focus is on forecasting over time and space, using transfer learning across different cities. That fits under time-series. The other topics don't align with the keywords in the title. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32102@AAAI"}
{"title": "A Gaussian Filter-Based 3D Registration Method for Series Section Electron Microscopy", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Gaussian Filter-Based 3D Registration Method for Series Section Electron Microscopy.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"3D Registration Method\" suggests it's about aligning 3D data. \"Series Section Electron Microscopy\" probably refers to a technique where multiple sections of a sample are imaged, and then they need to be registered (aligned) to form a 3D model. The Gaussian filter part is a method used in the registration process.\n\nNow, looking at the topics. Time-series usually involves data collected over time, like stock prices or sensor data over time. Multimodal refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is more about using external data in generating responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper here is about a method for 3D registration in electron microscopy. The key here is whether this falls under any of the four categories. Time-series might be a stretch unless the registration is over time, but the title doesn't mention time. Multimodal would require combining different data types, but the title mentions a single modality (electron microscopy). RAG and KG are more about data retrieval and knowledge representation, which don't seem relevant here. The Gaussian filter is a technique, but the main topic is 3D registration for microscopy. Since none of the four topics directly relate to 3D registration or microscopy, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32103@AAAI"},
{"title": "E4: Energy-Efficient DNN Inference for Edge Video Analytics via Early Exiting and DVFS", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"E4: Energy-Efficient DNN Inference for Edge Video Analytics via Early Exiting and DVFS.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus is on energy-efficient deep neural network (DNN) inference for edge video analytics. The methods mentioned are early exiting and DVFS (Dynamic Voltage and Frequency Scaling). \n\nTime-series usually involves data points indexed in time order, like stock prices over time. This paper is about video analytics, which could involve sequences, but the key here is energy efficiency in DNNs for edge devices. Not sure if time-series is the right fit.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about video analytics, which is a single modality (video), so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like some NLP models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention knowledge graphs or structured data, so that's out.\n\nSo the paper is about optimizing DNNs for edge devices using specific techniques. None of the four topics (time-series, multimodal, RAG, KG) seem to directly apply here. The focus is on energy efficiency and hardware optimization, which doesn't fit into any of the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32104@AAAI"},
{"title": "Multi-Perspective Consolidation Enhanced Cognitive Diagnosis via Conditional Diffusion Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Perspective Consolidation Enhanced Cognitive Diagnosis via Conditional Diffusion Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-Perspective Consolidation\" suggests combining information from different perspectives or sources. \"Cognitive Diagnosis\" is about assessing cognitive abilities or conditions. The method used is a \"Conditional Diffusion Model,\" which is a type of machine learning model, but I'm not sure if that directly relates to any of the four topics.\n\nLooking at the four options:\n\n1. Time-series: This usually involves data points indexed in time order. The title doesn't mention anything about time or sequential data, so maybe not.\n\n2. Multimodal: This refers to using multiple types of data (like text, images, audio) together. The \"Multi-Perspective Consolidation\" might imply combining different data modalities, but the term \"multimodal\" isn't explicitly used. However, \"multi-perspective\" could be a synonym for multimodal in some contexts. But I'm not certain.\n\n3. RAG (Retrieval-Augmented Generation): This is about combining retrieval of information with generation models, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\n4. KG (Knowledge Graph): These are structured representations of knowledge. The title doesn't mention graphs or knowledge structures, so likely not KG.\n\nSo, the closest might be multimodal if \"multi-perspective\" refers to combining different data types. But the main focus here is on cognitive diagnosis using a diffusion model. The term \"multimodal\" isn't explicitly in the title, and without more context, it's a bit of a stretch. The other options don't fit. Maybe the answer is \"none\" because it doesn't clearly fit any of the four categories. The paper might be about a specific application in cognitive diagnosis using a diffusion model, which isn't one of the listed topics. So I think the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32105@AAAI"},
{"title": "From Words to Worth: Newborn Article Impact Prediction with LLM", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"From Words to Worth: Newborn Article Impact Prediction with LLM\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Newborn Article Impact Prediction\" suggests they're trying to predict the impact of new articles. Using LLM (Large Language Model) probably means they're analyzing the text of the articles. The phrase \"From Words to Worth\" implies converting textual content into some measure of value or impact.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about predicting impact based on the text of articles. Since they're using LLM, which is a language model, it's text-based. There's no mention of combining different data types (so not multimodal), no indication of using retrieval (RAG), or building a knowledge graph (KG). Time-series also doesn't fit because the focus is on the content of the articles rather than temporal data. So the answer might be none. Wait, but maybe I'm missing something. Let me check again. The prediction is about the impact, which could be over time, but the method is using LLM on the text. Since none of the four topics directly relate to text analysis for prediction without being one of the listed categories, the answer is probably none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32106@AAAI"},
{"title": "DeNC: Unleash Neural Codecs in Video Streaming with Diffusion Enhancement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DeNC: Unleash Neural Codecs in Video Streaming with Diffusion Enhancement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Neural Codecs\" probably refers to using neural networks for encoding/decoding video. \"Video Streaming\" suggests it's about transmitting video data over a network. \"Diffusion Enhancement\" might be a technique to improve the quality or efficiency of the streaming. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about video streaming using neural codecs. Video is a time-series in a way because it's a sequence of frames over time. However, the main focus here seems to be on the codec technology and diffusion methods, which might not directly relate to time-series analysis. It's more about compression and transmission. Multimodal could be a stretch unless they're combining different modalities, but the title doesn't mention that. RAG and KG don't seem relevant here. So maybe none of the topics fit. But wait, video is a time-series, but the paper's primary focus isn't on analyzing time-series data. It's about enhancing video streaming with neural codecs. So perhaps it doesn't fit any of the given categories. The answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32107@AAAI"},
{"title": "NumbOD: A Spatial-Frequency Fusion Attack Against Object Detectors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"NumbOD: A Spatial-Frequency Fusion Attack Against Object Detectors.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"NumbOD\" is probably the name of the method or attack. \"Spatial-Frequency Fusion\" suggests combining spatial and frequency domain information. \"Attack Against Object Detectors\" implies it's an adversarial attack targeting object detection models.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation in models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on an attack that uses spatial and frequency domains. Spatial here relates to image data (like pixels), and frequency could be Fourier transforms or similar. This seems more about image processing and adversarial attacks in computer vision. None of the four topics directly relate to adversarial attacks or object detection. Time-series is about temporal data, which isn't the case here. Multimodal would require combining different modalities, but the attack is within a single modality (images). RAG and KG are unrelated to adversarial attacks. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32108@AAAI"},
{"title": "Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Collaborative Evolution: Multi-Round Learning Between Large and Small Language Models for Emergent Fake News Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not that. \n\nMultimodal would involve combining different types of data, like text and images. The title talks about language models, which are text-based, but there's no mention of other modalities like images or audio. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title mentions collaboration between large and small models, but I'm not sure if retrieval is involved here. The focus seems more on learning between models rather than retrieval.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nThe paper is about collaborative learning between different language models for fake news detection. The key terms here are \"multi-round learning\" and \"collaborative evolution.\" This sounds like a method where models work together iteratively. RAG involves retrieval, which isn't mentioned here. The collaboration aspect might be more about model interaction rather than retrieval. Since none of the four topics (time-series, multimodal, RAG, KG) seem to fit perfectly, maybe the answer is \"none.\" But wait, could it be RAG? If the small model is retrieving information from the large model, maybe? But RAG typically involves external knowledge retrieval, not just model collaboration. I think it's more about model collaboration, which isn't one of the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32109@AAAI"},
{"title": "DUSTED: Dual-Attention Enhanced Spatial Transcriptomics Denoiser", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DUSTED: Dual-Attention Enhanced Spatial Transcriptomics Denoiser.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatial Transcriptomics\" refers to the study of gene expression in specific locations within tissues, right? So it's about spatial data. The \"Denoiser\" part suggests that the paper is about removing noise from such data. The \"Dual-Attention Enhanced\" part probably refers to using a dual attention mechanism in their model.\n\nNow, looking at the possible topics. Time-series would involve data over time, like sequences. Multimodal usually involves combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on spatial transcriptomics, which is a type of spatial data. The denoising aspect might involve machine learning models, perhaps using attention mechanisms. But does this relate to any of the four topics? The dual attention could be part of a model architecture, but the main application here is in spatial data denoising. None of the four topics directly relate to spatial transcriptomics or denoising in this context. Time-series is about temporal data, which isn't the case here. Multimodal would require combining different data types, which isn't mentioned. RAG and KG are more about retrieval and knowledge graphs, which don't seem relevant here. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32110@AAAI"},
{"title": "Multi-Modal Latent Variables for Cross-Individual Primary Visual Cortex Modeling and Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Modal Latent Variables for Cross-Individual Primary Visual Cortex Modeling and Analysis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That immediately makes me think of the multimodal category. But I should check the rest to be sure. The paper is about using latent variables for modeling the primary visual cortex across individuals. \n\nMultimodal typically refers to combining data from multiple modalities, like text and images, or different types of data sources. The term \"multi-modal\" in the title suggests that the research involves integrating different types of data or modalities. So that's a strong indicator for the multimodal topic.\n\nThe other options: time-series would involve data points indexed in time order, which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about enhancing models with retrieval, which doesn't seem related to visual cortex modeling. KG (Knowledge Graphs) involve structured data representations, which also doesn't fit here. \n\nSo the most likely answer is multimodal. The title explicitly uses \"multi-modal,\" and the context of combining different data types for modeling supports that. I don't see any mention of time-series data, RAG techniques, or knowledge graphs in the title. Therefore, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32111@AAAI"},
{"title": "Text-Guided Fine-grained Counterfactual Inference for Short Video Fake News Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Text-Guided Fine-grained Counterfactual Inference for Short Video Fake News Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-Guided\" suggests that text is involved, maybe as a modality. \"Fine-grained Counterfactual Inference\" sounds like it's about analyzing details and hypothetical scenarios. \"Short Video Fake News Detection\" implies working with videos, which are a combination of visual and auditory elements, possibly text as well if there are captions or subtitles.\n\nMultimodal research typically involves combining multiple data types, like text, images, audio, etc. Since the paper is about detecting fake news in short videos, which are inherently multimodal (video includes both visual and audio components, and maybe text), this seems like a strong candidate for the multimodal topic. \n\nTime-series usually deals with data points indexed in time order, like stock prices over time. While videos do have a time component, the key here is the combination of different modalities (text, video) rather than just the temporal aspect. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, which doesn't seem directly mentioned here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't appear to be the focus. \n\nSo the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32112@AAAI"}
{"title": "Enhancing Identity-Deformation Disentanglement in StyleGAN for One-Shot Face Video Re-Enactment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Identity-Deformation Disentanglement in StyleGAN for One-Shot Face Video Re-Enactment.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main components are StyleGAN, identity-deformation disentanglement, and one-shot face video re-enactment. StyleGAN is a type of generative adversarial network used for generating images, particularly faces. The focus here is on disentangling identity (the person's identity) from deformation (like expressions or poses) in the generated images. The application is one-shot face video re-enactment, which probably means creating a video of a person's face performing certain actions based on a single example.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like sequences or temporal data. This paper is about video, which is a time-series, but the core of the research isn't about the temporal aspect itself but rather about disentangling features in the model. So maybe time-series isn't the main topic here.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is focused on video (which is a sequence of images) but doesn't mention combining different modalities. It's more about the structure within the video data, not integrating different types of data.\n\nRAG stands for Retrieval-Augmented Generation, which involves using retrieval mechanisms to enhance generation tasks. The title doesn't mention anything about retrieval or augmenting generation with external data, so RAG might not be relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't seem to involve building or using knowledge graphs, so that's probably not it either.\n\nSo, the paper is about improving a GAN model (StyleGAN) for a specific video generation task. The key terms are disentanglement and video re-enactment. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to the core focus of the research, which is on generative models and disentanglement in the context of video, the answer might be \"none.\" However, I should double-check if any of the topics could be a stretch. Time-series could be a possible fit because video is a time-series, but the research isn't about time-series analysis per se. The main contribution is about the model's architecture and disentanglement, which isn't covered by the given topics. Therefore, the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32113@AAAI"},
{"title": "AAAI.2025 - Cognitive Modeling and Cognitive Systems", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"AAAI.2025 - Cognitive Modeling and Cognitive Systems\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics entails. \n\nTime-series research typically involves data that is collected over time, analyzing trends, patterns, and making predictions based on temporal sequences. Examples include stock market analysis, weather forecasting, etc.\n\nMultimodal research deals with integrating multiple types of data or modalities, such as text, images, audio, and video. It's common in areas like AI that require processing different data types together, like in virtual assistants or medical diagnostics combining imaging and lab results.\n\nRAG stands for Retrieval-Augmented Generation. This is a method where a model retrieves relevant information from a database or knowledge source and then uses that to generate responses. It's often used in question-answering systems to enhance the accuracy by incorporating up-to-date or specific data.\n\nKG refers to Knowledge Graphs, which are structured representations of knowledge, often in the form of entities and their relationships. They are used for organizing information in a way that machines can understand and query, common in semantic web technologies and recommendation systems.\n\nNow, looking at the title: \"Cognitive Modeling and Cognitive Systems\". Cognitive modeling involves creating models that simulate human thought processes, which can be related to AI, psychology, or neuroscience. Cognitive systems are systems that mimic human cognition, often integrating various AI techniques. \n\nThe AAAI conference is a major AI conference, so the paper is likely in the AI domain. However, the specific topics listed (time-series, multimodal, RAG, KG) don't directly align with cognitive modeling or cognitive systems. Cognitive systems might use multimodal data if they process multiple input types, but the title doesn't specify that. Similarly, cognitive modeling could involve knowledge graphs if they're using structured knowledge, but again, the title doesn't mention that. RAG and time-series are more specific techniques that aren't indicated here. \n\nSince the title is about cognitive modeling and systems, which is a broader area and doesn't specifically mention any of the four listed topics, the answer would be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/AAAI.2025?group=Cognitive Modeling and Cognitive Systems"},
{"title": "Dynamic Interactive Bimodal Hypergraph Networks for Emotion Recognition in Conversations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dynamic Interactive Bimodal Hypergraph Networks for Emotion Recognition in Conversations.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dynamic Interactive Bimodal Hypergraph Networks\" – the key terms here are \"Bimodal\" and \"Hypergraph.\" \"Bimodal\" suggests that there are two modes or types of data being used. In the context of emotion recognition in conversations, that could mean combining different data types like text and audio, or text and video. So \"Bimodal\" points towards multimodal processing, which is one of the options.\n\nThen there's \"Hypergraph Networks.\" Hypergraphs are a type of graph structure where edges can connect more than two nodes, which is different from a regular graph. This might relate to Knowledge Graphs (KG), but hypergraphs are more about complex relationships. However, the term \"Hypergraph\" isn't exactly the same as \"Knowledge Graph,\" which typically refers to a structured representation of knowledge. So maybe not KG here.\n\nThe other options are time-series and RAG. Time-series would involve data points indexed in time order, which might be relevant for conversations since they are sequential. But the title doesn't explicitly mention time-series analysis. RAG stands for Retrieval-Augmented Generation, which is a method combining retrieval and generation models, often used in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is probably not it.\n\nPutting it all together: \"Bimodal\" indicates the use of multiple modalities (like text and audio), which fits the multimodal category. The hypergraph part is about the network structure, but the main research focus here seems to be on combining different data modalities for emotion recognition. So the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32114@AAAI"},
{"title": "Multi-View Incremental Learning with Structured Hebbian Plasticity for Enhanced Fusion Efficiency", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-View Incremental Learning with Structured Hebbian Plasticity for Enhanced Fusion Efficiency.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View\" might suggest multiple perspectives or data sources, which could relate to multimodal learning, where different types of data (like text and images) are used. But \"multi-view\" can also mean different views of the same data, not necessarily different modalities. \n\n\"Incremental Learning\" refers to learning in a sequential manner, updating models as new data comes in. That's a bit different from time-series, which is about data over time, but incremental learning could be applied to time-series data. However, the title doesn't explicitly mention time or sequences.\n\n\"Structured Hebbian Plasticity\" sounds like a method related to neural plasticity, maybe in neural networks. Hebbian theory is about synaptic plasticity, so structured might mean some organized form of this. Not sure how that connects to the four topics.\n\n\"Enhanced Fusion Efficiency\" – fusion usually refers to combining information from different sources. If it's multi-view, maybe they're fusing different views. But again, multimodal is about different modalities, not just different views. \n\nLooking at the options: time-series is about temporal data. The title doesn't mention time or sequences, so probably not. Multimodal is about combining different data types (like text, image, audio). The title says \"multi-view,\" which could be similar but not exactly the same. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which doesn't seem related here. KG (Knowledge Graphs) involve structured data and relationships, but the title doesn't mention graphs or knowledge bases.\n\nSo, the closest might be multimodal if \"multi-view\" is considered as different modalities. But I'm not entirely sure. Alternatively, maybe it's none of them. The paper could be about a new learning method with structured plasticity for fusion, which doesn't fit into the four categories. Since the options are time-series, multimodal, RAG, KG, and the title doesn't clearly align with any, maybe the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32115@AAAI"},
{"title": "SocialSim: Towards Socialized Simulation of Emotional Support Conversation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SocialSim: Towards Socialized Simulation of Emotional Support Conversation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not that.\n\nMultimodal refers to using multiple types of data, like text and images. The paper is about emotional support conversations, which might involve text, but the title doesn't specify combining different modalities. Not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs either.\n\nThe term \"Socialized Simulation\" might imply modeling social interactions, but none of the given topics directly relate to that. Emotional support conversations could be part of dialogue systems, but the options given don't include that. So maybe it's none of the listed topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32116@AAAI"},
{"title": "Symbolic Functional Decomposition: A Reconfiguration Approach", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Symbolic Functional Decomposition: A Reconfiguration Approach\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should say \"none\".\n\nFirst, I need to understand what each of these topics entails. \n\nTime-series research typically involves data points indexed in chronological order, like stock prices over time or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, such as text, images, and audio. The title here is about functional decomposition and reconfiguration, which doesn't immediately suggest multimodal data integration.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model retrieves information from a database to enhance its responses. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The title talks about symbolic functional decomposition and reconfiguration. Symbolic methods might relate to knowledge representation, but the term \"reconfiguration approach\" isn't a standard term in KGs. However, functional decomposition could be part of building or modifying a knowledge graph's structure. But I'm not sure if that's a direct fit.\n\nAlternatively, maybe the paper is about decomposing functions symbolically, which could be a method in knowledge representation or system design. However, none of the four topics (time-series, multimodal, RAG, KG) seem to directly align with the title. The title is more about a methodological approach to decomposition and reconfiguration, which might be a general systems or software engineering topic. Since none of the specified topics are clearly indicated, the answer might be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32117@AAAI"},
{"title": "EventZoom: A Progressive Approach to Event-Based Data Augmentation for Enhanced Neuromorphic Vision", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EventZoom: A Progressive Approach to Event-Based Data Augmentation for Enhanced Neuromorphic Vision.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Event-Based Data Augmentation\" suggests that the data being worked with is event-based. Neuromorphic vision is related to neuromorphic computing, which often deals with event-based sensors like dynamic vision sensors (DVS) that capture changes in light intensity over time. These sensors output a stream of events, which are timestamped and represent changes in the visual scene. So, event-based data is inherently time-series data because each event has a timestamp and the data is sequential over time.\n\nThe term \"Progressive Approach\" might refer to a method that builds up or processes data incrementally, which could be relevant in time-series analysis where data is processed in a sequence. Data augmentation here is about generating more training data from existing data, which in the context of event-based data would involve techniques that simulate or transform events over time.\n\nNow, checking the possible topics. Time-series analysis deals with data that is ordered in time, which fits event-based data. Multimodal would involve combining different types of data (like text and images), but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, which doesn't seem directly related. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit here.\n\nSo, the paper is about augmenting event-based data for neuromorphic vision, which is a type of time-series data. Therefore, the correct topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32118@AAAI"},
{"title": "SS-GEN: A Social Story Generation Framework with Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SS-GEN: A Social Story Generation Framework with Large Language Models.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Social Story Generation\" suggests creating stories related to social contexts. The framework uses Large Language Models (LLMs), which are typically used for text generation. Now, the options are time-series, multimodal, RAG, or KG. \n\nTime-series usually involves data over time, like stock prices or weather. This doesn't seem related to story generation. Multimodal would involve multiple data types like text, images, audio. The title doesn't mention other modalities, just a framework using LLMs. \n\nRAG stands for Retrieval-Augmented Generation, which combines retrieval of information with generation. If the paper uses a retrieval system to augment the story generation, that might fit. But the title doesn't explicitly mention retrieval. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the framework uses a knowledge graph to generate stories, that could be it. However, the title doesn't mention knowledge graphs either. \n\nThe key here is that the paper is about generating social stories using LLMs. None of the listed topics (time-series, multimodal, RAG, KG) are directly indicated in the title. The framework's name is SS-GEN, which doesn't hint at any of these. So unless there's an implicit connection I'm missing, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32119@AAAI"},
{"title": "MSAmba: Exploring Multimodal Sentiment Analysis with State Space Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MSAmba: Exploring Multimodal Sentiment Analysis with State Space Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Sentiment Analysis\" immediately makes me think of the \"multimodal\" topic. Multimodal usually refers to combining different types of data, like text, audio, and video. So that's a strong indicator. Then, \"State Space Models\" – those are often used in time-series analysis because they model systems that evolve over time. But the main focus here seems to be on the multimodal aspect. The paper is about using state space models for multimodal sentiment analysis. \n\nNow, checking the other options. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which doesn't seem to be mentioned here. KG (Knowledge Graphs) involve structured data and relationships, which also isn't in the title. Time-series is a possible angle because of the state space models, but the primary topic here is multimodal. The title explicitly mentions \"Multimodal,\" so that's the key term. Even though state space models are used in time-series, the main research area here is multimodal sentiment analysis. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32120@AAAI"},
{"title": "CraftFactory: A Conditioned Control Policy Benchmark for Compositional Generalization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CraftFactory: A Conditioned Control Policy Benchmark for Compositional Generalization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"CraftFactory\" sounds like a system or framework. \"Conditioned Control Policy\" suggests it's about control policies that are conditioned on certain factors. \"Benchmark for Compositional Generalization\" implies it's a benchmark designed to test how well models can generalize across different combinations of tasks or elements.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather. Multimodal refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time, so time-series is probably out. There's no indication of combining different data modalities, so multimodal might not fit. RAG and KG are about retrieval and knowledge graphs, which also don't seem directly related to control policies or compositional generalization. \n\nCompositional generalization is more about the model's ability to handle new combinations of known elements, which is a concept in machine learning, particularly in areas like reinforcement learning or control systems. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to control policies or compositional generalization benchmarks, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32121@AAAI"}
{"title": "Compose with Me: Collaborative Music Inpainter for Symbolic Music Infilling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Compose with Me: Collaborative Music Inpainter for Symbolic Music Infilling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Collaborative Music Inpainter\" suggests that the system is working with music, specifically filling in missing parts (inpainting). \"Symbolic Music Infilling\" probably refers to working with music notation or symbolic representations, like sheet music, rather than audio. \n\nNow, the possible topics. Time-series usually involves data that changes over time, like stock prices or sensor data. Music can be time-series, but the key here is the method. If the paper is about modeling temporal sequences, maybe. But the term \"inpainting\" might be more about filling gaps in the data, which could be time-series, but I'm not sure yet.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention combining different modalities, just symbolic music. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate responses. The title doesn't mention retrieval or using external data sources, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus seems to be on generating music, not on building or using a knowledge graph. So likely not KG.\n\nSo, the remaining options are time-series or none. The task is about infilling symbolic music, which is a sequence of notes over time. Inpainting in this context would involve predicting missing parts of the sequence. That sounds like a time-series problem because the music is a sequence with temporal structure. However, sometimes symbolic music can be represented as a graph or other structures, but the term \"inpainting\" here is more about filling in missing parts of a sequence. So I think it's a time-series topic. But wait, maybe the model isn't specifically using time-series methods. For example, if it's using a transformer model, which is common in NLP and can handle sequences, but transformers are often used for time-series as well. However, the key is whether the research is explicitly about time-series analysis. The title doesn't mention time-series, but the nature of music as a sequence might imply it. Alternatively, maybe it's a different approach, like using a graph or something else. But given the options, time-series seems the closest. So I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32122@AAAI"},
{"title": "AFFAKT: A Hierarchical Optimal Transport Based Method for Affective Facial Knowledge Transfer in Video Deception Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AFFAKT: A Hierarchical Optimal Transport Based Method for Affective Facial Knowledge Transfer in Video Deception Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Affective Facial Knowledge Transfer\" suggests that they're dealing with knowledge related to facial expressions and emotions. \"Video Deception Detection\" implies that they're analyzing videos to detect lies or deceptive behavior. \n\nNow, the method mentioned is \"Hierarchical Optimal Transport Based.\" Optimal transport is a mathematical concept used in various machine learning applications, but how does that relate to the given topics? \n\nLooking at the options: time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generative models. KG (Knowledge Graph) involves structured data representations.\n\nThe paper's focus is on transferring knowledge about affective (emotional) facial expressions in videos. Since videos are a sequence of frames over time, maybe time-series is a possibility. However, the key term here is \"knowledge transfer,\" which might relate to knowledge graphs if they're structuring the knowledge. But the title mentions \"knowledge transfer\" in the context of facial expressions and deception detection. \n\nWait, \"Affective Facial Knowledge Transfer\" could imply building a knowledge base about facial expressions, which might be structured as a knowledge graph. However, the method uses optimal transport, which is more of a mathematical approach for aligning distributions. \n\nAlternatively, multimodal could be a fit if they're combining different modalities like facial expressions with other data (e.g., voice). But the title doesn't explicitly mention multiple modalities. It's focused on facial knowledge in videos. \n\nRAG and KG are less likely here. The paper doesn't mention retrieval or generation, so RAG is probably out. Knowledge Graph (KG) might be a stretch unless they're explicitly building a graph structure. The term \"knowledge transfer\" could be part of a knowledge graph's application, but the method described is hierarchical optimal transport, which is more about aligning data distributions. \n\nGiven that the paper is about transferring knowledge in the context of video analysis for deception detection, and the method is based on optimal transport, which is a mathematical technique, it doesn't clearly fit into time-series, multimodal, RAG, or KG. The closest might be time-series if the video is treated as a time series, but the main focus is on knowledge transfer and affective facial analysis. Since none of the four topics are clearly indicated, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32123@AAAI"},
{"title": "Deep Reinforcement Learning with Time-Scale Invariant Memory", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Deep Reinforcement Learning with Time-Scale Invariant Memory.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Deep Reinforcement Learning\" is the main approach. Then \"Time-Scale Invariant Memory\" is the key part here. Time-scale invariant suggests that the memory mechanism is designed to handle different time scales, which is a concept related to time-series data. Time-series analysis often deals with data points indexed in time order, and handling varying time scales is a common challenge. \n\nMultimodal would involve combining different types of data, like text and images, which doesn't seem to be the case here. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation models, typically in NLP tasks. KG (Knowledge Graph) involves structured data representations, which also doesn't fit. \n\nThe focus on time-scale invariance in memory for reinforcement learning points towards handling temporal data effectively. So the topic here is likely time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32124@AAAI"},
{"title": "Open Models, Closed Minds? On Agents Capabilities in Mimicking Human Personalities through Open Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Open Models, Closed Minds? On Agents Capabilities in Mimicking Human Personalities through Open Large Language Models.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not that. \n\nMultimodal refers to using multiple data types, like text and images. The title talks about mimicking human personalities using large language models, which are text-based. There's no mention of combining different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to pull information and then generates text. The title doesn't mention retrieval or combining retrieval with generation, so RAG might not be it.\n\nKG is Knowledge Graphs, which are structured data representations. The paper's focus is on agents mimicking personalities through open models, not on building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about using open LLMs for personality mimicry, which relates more to AI agents and language models rather than the specified categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32125@AAAI"},
{"title": "Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spike2Former: Efficient Spiking Transformer for High-performance Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spiking Transformer\" suggests it's related to neural networks, maybe using spiking neurons, which are common in neuromorphic computing. The term \"Transformer\" usually refers to the architecture, like in NLP. But the application here is \"Image Segmentation,\" which is a computer vision task. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. Multimodal typically involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data representations, like ontologies or semantic networks.\n\nThe paper's focus is on image segmentation using a spiking transformer. There's no mention of time-series data, so that's probably out. It's a single modality (images), so multimodal might not fit unless it's combining different modalities, but the title doesn't indicate that. RAG and KG are more about data retrieval or structured knowledge, which doesn't seem to be the case here. The key terms are \"spiking\" and \"Transformer,\" which relate to neural network architecture efficiency for image tasks. Since none of the four topics directly relate to spiking neural networks or image segmentation, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32126@AAAI"},
{"title": "DARR: A Dual-Branch Arithmetic Regression Reasoning Framework for Solving Machine Number Reasoning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DARR: A Dual-Branch Arithmetic Regression Reasoning Framework for Solving Machine Number Reasoning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dual-Branch Arithmetic Regression Reasoning\" suggests some kind of model with two branches using regression for arithmetic reasoning. The application is in \"Machine Number Reasoning,\" which might involve solving math problems or numerical tasks.\n\nLooking at the options:\n\n- Time-series: Typically involves data over time, like stock prices or weather. The title doesn't mention anything about sequences over time, so probably not this one.\n\n- Multimodal: Involves combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not.\n\n- RAG (Retrieval-Augmented Generation): This is about using retrieval to enhance generation, often in NLP tasks. The title doesn't mention retrieval or generation, so probably not RAG.\n\n- KG (Knowledge Graph): Involves structured data, relationships between entities. The title doesn't mention knowledge graphs or structured data.\n\nThe paper seems to focus on arithmetic reasoning with a dual-branch regression model. None of the four topics directly relate to arithmetic reasoning frameworks. The key terms here are \"arithmetic regression reasoning,\" which doesn't align with time-series analysis, multimodal data, retrieval-augmented generation, or knowledge graphs. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32127@AAAI"},
{"title": "MI-CAPTCHA: Enhance the Security of CAPTCHA Using Mooney Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MI-CAPTCHA: Enhance the Security of CAPTCHA Using Mooney Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. CAPTCHA is a security measure used to distinguish humans from bots. The paper is about enhancing its security using Mooney images. Mooney images are probably some kind of image processing technique. The term \"MI\" in the title might stand for Mooney Images. \n\nNow, the research topics given are time-series, multimodal, RAG, and KG. Time-series usually involves data over time, like stock prices or weather data. Multimodal refers to using multiple types of data, like combining text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. KG stands for Knowledge Graph, which is a structured representation of knowledge.\n\nThe paper is about CAPTCHA security using images. CAPTCHA typically involves visual challenges, so maybe it's related to image processing. But does that make it multimodal? Multimodal would require combining different modalities like text, image, and audio. If the paper is only using images (Mooney images) to enhance CAPTCHA, it's not combining multiple data types. So maybe it's not multimodal. \n\nRAG and KG are more about information retrieval and knowledge representation. The paper doesn't mention anything about retrieving information or using a knowledge graph. Time-series is about sequential data over time, which doesn't seem relevant here either. \n\nSo, the paper is focused on improving CAPTCHA security through a specific image technique. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to image-based security enhancements or CAPTCHA specifically, the answer might be \"none.\" The paper doesn't fit into any of the provided categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32128@AAAI"},
{"title": "Asymmetric Cross-Modal Hashing Based on Formal Concept Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Asymmetric Cross-Modal Hashing Based on Formal Concept Analysis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-modal\" immediately makes me think of multimodal. Because cross-modal usually refers to different types of data modalities, like text and images. So that's a hint towards the multimodal category. Then there's \"hashing,\" which is a technique used for efficient data retrieval, often in multimodal contexts where you want to map different modalities into a common hash space. \n\nThe method mentioned is \"Asymmetric Cross-Modal Hashing,\" which I've heard before in the context of multimodal learning. Asymmetric here might mean that the hashing functions for different modalities are different, which is common when dealing with heterogeneous data. \n\nFormal Concept Analysis (FCA) is the basis here. FCA is a mathematical framework for analyzing data by finding concepts and their relationships. While FCA itself isn't directly one of the four topics, its application in cross-modal hashing would still fall under multimodal because the core issue is handling multiple data modalities. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation models, often in NLP. The paper here is about hashing for cross-modal data, which is more about retrieval efficiency than generation. KG (Knowledge Graphs) involve structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so that's out. \n\nSo the most fitting category here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32129@AAAI"},
{"title": "Towards Accurate Binary Spiking Neural Networks: Learning with Adaptive Gradient Modulation Mechanism", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Accurate Binary Spiking Neural Networks: Learning with Adaptive Gradient Modulation Mechanism.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Binary Spiking Neural Networks (SNNs) are a type of neural network that uses binary weights and spikes to process information. They're often used in neuromorphic computing and can be efficient for certain tasks. The key part here is \"Learning with Adaptive Gradient Modulation Mechanism.\" Gradient modulation relates to how gradients are adjusted during training, which is part of the optimization process. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, common in NLP. KG (Knowledge Graph) involves structured data representations, like relationships between entities.\n\nThe paper's focus is on improving the learning mechanism in binary SNNs through gradient modulation. None of the topics directly relate to time-series data, multimodal inputs, retrieval-augmented generation, or knowledge graphs. The adaptive gradient modulation is more about the training algorithm and network architecture rather than the data types or external knowledge integration. So, it doesn't fit into any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32130@AAAI"},
{"title": "Semi-IIN: Semi-Supervised Intra-Inter Modal Interaction Learning Network for Multimodal Sentiment Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Semi-IIN: Semi-Supervised Intra-Inter Modal Interaction Learning Network for Multimodal Sentiment Analysis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Multimodal Sentiment Analysis\" and \"Intra-Inter Modal Interaction.\" The term \"multimodal\" directly refers to using multiple modalities, like text, audio, and video in sentiment analysis. The network is designed to handle interactions between these different modalities, both within (intra) and between (inter) them. \n\nThe other parts of the title mention \"Semi-Supervised,\" which is a learning approach, but that's more about the training method rather than the core topic. The acronym Semi-IIN probably stands for the network's name, but the main focus here is on multimodal interaction. \n\nLooking at the options: time-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships. None of these seem to fit the title's focus on multimodal interactions. \n\nSo the answer should be \"multimodal\" since the paper is about combining multiple data modalities for sentiment analysis.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32131@AAAI"}
{"title": "Towards More Discriminative Feature Learning in SNNs with Temporal-Self-Erasing Supervision", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards More Discriminative Feature Learning in SNNs with Temporal-Self-Erasing Supervision.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, SNNs stand for Spiking Neural Networks. They are a type of neural network that processes information in a way that's similar to how biological neurons work, using spikes over time. So, the mention of \"Temporal-Self-Erasing Supervision\" makes me think about time because \"temporal\" relates to time. The paper is about feature learning in SNNs, which are inherently temporal models since they process sequences of spikes over time. \n\nTime-series analysis involves data points indexed in time order, and SNNs are often used for time-series data because they handle temporal dynamics well. The term \"temporal\" in the title directly points to time-series. \n\nMultimodal would involve combining different types of data, like text and images, but the title doesn't mention anything about multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generative models, which isn't indicated here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem relevant. \n\nSo, the key terms here are \"temporal\" and \"SNNs,\" which are related to time-series data processing. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32132@AAAI"},
{"title": "EyEar: Learning Audio Synchronized Human Gaze Trajectory Based on Physics-Informed Dynamics", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EyEar: Learning Audio Synchronized Human Gaze Trajectory Based on Physics-Informed Dynamics.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"EyEar\" probably refers to combining eye and ear, so maybe audio and visual data. \"Audio Synchronized Human Gaze Trajectory\" suggests that the research is about tracking where a person is looking, synchronized with audio. That sounds like using multiple modalities—audio and visual (gaze). So multimodal might be a candidate here.\n\nThen, \"Physics-Informed Dynamics\" could imply that they're using some physical models or principles to inform the dynamics of the gaze trajectory. But I'm not sure if that's related to any of the four topics. Time-series usually involves data over time, which this might be, since gaze trajectories are sequences over time. But the key here is whether the main focus is on time-series analysis. The title mentions \"Learning\" which could be a model, but the main aspect seems to be combining audio and gaze data, which are different modalities. \n\nMultimodal research typically involves integrating data from different sources or modalities, like combining text, images, audio, etc. Since this paper is about audio and gaze (which is visual), that fits multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, usually in NLP. KG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval-augmented generation. \n\nTime-series could be a part of it because gaze trajectories are time-dependent, but the primary focus here seems to be the synchronization of different modalities (audio and gaze), making multimodal the more likely category. The physics-informed part might relate to the model's structure but doesn't point to any of the four topics listed. \n\nSo the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32133@AAAI"},
{"title": "Multi-to-Single: Reducing Multimodal Dependency in Emotion Recognition Through Contrastive Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-to-Single: Reducing Multimodal Dependency in Emotion Recognition Through Contrastive Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Multimodal Dependency,\" which immediately makes me think the topic is related to multimodal. But wait, the paper is about reducing that dependency. So maybe it's still in the multimodal category because it's addressing an issue within multimodal systems. \n\nTime-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP tasks. The title doesn't mention retrieval or generation, so RAG is probably not it. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge bases, so KG is out. \n\nSo the main keywords here are \"Multimodal\" and \"Emotion Recognition.\" The paper is about emotion recognition using multimodal data but trying to reduce dependency on multiple modalities. Even though they're reducing dependency, the problem is still within the realm of multimodal learning. So the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32134@AAAI"},
{"title": "Understanding Emotional Body Expressions via Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Understanding Emotional Body Expressions via Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or sensor data. The title doesn't mention anything about time-based data, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about body expressions, which could involve visual data (like videos or images) and maybe text. If they're using both modalities, then it's multimodal. But the title says \"via Large Language Models,\" which are text-based. However, body expressions might involve visual data, so maybe they're combining text and visual inputs. That would make it multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to pull information and then generates a response. The title doesn't mention anything about retrieval or augmenting generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention building or using a knowledge graph, so likely not KG.\n\nSo the most plausible is multimodal because it's about understanding body expressions (which could be visual) using language models (text), combining different modalities. Unless the body expressions are analyzed through text only, but that seems less likely. The key here is \"body expressions,\" which are typically visual, so combining that with LLMs would be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32135@AAAI"},
{"title": "Multimodal Fine-Grained Apparent Personality Trait Recognition: Joint Modeling of Big Five and Questionnaire Item-level Scores", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multimodal Fine-Grained Apparent Personality Trait Recognition: Joint Modeling of Big Five and Questionnaire Item-level Scores.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, the word \"Multimodal\" is right there in the title. That's one of the options. Let me check if that's the main focus. The paper is about recognizing personality traits using multimodal data, which typically means combining different types of data like text, audio, video, etc. The \"Joint Modeling\" part suggests integrating multiple data sources, which aligns with multimodal research. \n\nNow, the other options. Time-series would involve data over time, like sequences or temporal patterns. The title doesn't mention anything about time or sequences, so probably not time-series. RAG (Retrieval-Augmented Generation) is a method that combines retrieval with generation models, often used in NLP. The title doesn't mention retrieval or generation, so RAG is unlikely. KG (Knowledge Graph) involves structured data and relationships between entities. Again, the title doesn't refer to knowledge graphs or structured data modeling. \n\nSo the key term here is \"Multimodal,\" which is one of the specified topics. The rest of the title supports that by talking about combining different data types for personality recognition. Therefore, the correct answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32136@AAAI"},
{"title": "SpikingYOLOX: Improved YOLOX Object Detection with Fast Fourier Convolution and Spiking Neural Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SpikingYOLOX: Improved YOLOX Object Detection with Fast Fourier Convolution and Spiking Neural Networks.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. YOLOX is an object detection model, right? So the paper is about improving object detection. The methods mentioned are Fast Fourier Convolution and Spiking Neural Networks. \n\nTime-series usually deals with data over time, like stock prices or sensor data. This paper is about object detection in images, so maybe not time-series. \n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like in some NLP tasks. The paper here is about object detection, not text generation or retrieval, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSpiking Neural Networks are a type of neural network that processes information in spikes, which is more related to neuromorphic computing or bio-inspired models. The Fast Fourier Convolution might be a technique to process data more efficiently. Since the main focus is on improving object detection using specific neural network techniques, none of the four topics (time-series, multimodal, RAG, KG) seem to fit. The paper is about computer vision and neural network architecture improvements, which isn't covered by the given options. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32137@AAAI"},
{"title": "MIDI-GPT: A Controllable Generative Model for Computer-Assisted Multitrack Music Composition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MIDI-GPT: A Controllable Generative Model for Computer-Assisted Multitrack Music Composition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. MIDI-GPT uses GPT, which is a transformer model, so maybe it's related to generative models. The term \"Multitrack Music Composition\" suggests that it's dealing with multiple tracks in music. Music composition can involve sequences, so maybe time-series? But wait, time-series usually refers to data that's ordered over time, like stock prices or sensor data. MIDI files do have a time component since they represent musical notes over time, so that's a possibility.\n\nMultimodal refers to combining different types of data, like text and images or audio and video. The title mentions \"Multitrack,\" which could mean multiple tracks (like different instruments or voices), but does that count as multimodal? Maybe, but I'm not sure. If the model is generating multiple tracks, it might be handling multiple sequences or different data types, but the term \"multimodal\" usually implies different modalities like text, image, audio, etc. Here, it's all about music tracks, which are sequences, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch information and then generates text based on that. The title doesn't mention anything about retrieval, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, the main contenders are time-series and multimodal. Since the model is generating music, which is a sequence of notes over time, it's likely dealing with time-series data. MIDI files are essentially time-series data where each event (note on/off) happens at specific times. The model is generating these sequences, so time-series makes sense. The \"Multitrack\" part might refer to multiple sequences (each track being a separate sequence), but that's still within the realm of time-series. Multimodal would require different data types, which isn't the case here. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32138@AAAI"},
{"title": "GRSN: Gated Recurrent Spiking Neurons for POMDPs and MARL", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GRSN: Gated Recurrent Spiking Neurons for POMDPs and MARL\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. GRSN stands for Gated Recurrent Spiking Neurons. The keywords here are \"Gated Recurrent\" which makes me think of recurrent neural networks (RNNs), specifically like LSTMs or GRUs. Those are often used for time-series data because they handle sequences over time. Then \"Spiking Neurons\" might relate to spiking neural networks, which are a type of neural network that processes information in spikes over time, so that's definitely time-dependent.\n\nThe applications mentioned are POMDPs (Partially Observable Markov Decision Processes) and MARL (Multi-Agent Reinforcement Learning). POMDPs are used in scenarios where the environment is only partially observable, and they often involve sequential decision-making, which again ties into time-series processing. MARL involves multiple agents learning in an environment, which could involve sequences of actions and observations over time.\n\nNow, looking at the four options: time-series, multimodal, RAG, KG. \n\nTime-series is about data over time, which seems to fit because of the recurrent and spiking aspects. Multimodal would involve combining different types of data (like text and images), but the title doesn't mention that. RAG (Retrieval-Augmented Generation) is about using retrieval methods in generation tasks, which doesn't seem related here. KG (Knowledge Graphs) involve structured data representations, which also don't appear in the title.\n\nSo, the paper is about a neural network architecture (GRSN) for POMDPs and MARL, which are time-dependent problems. Therefore, it's likely related to time-series research. The other topics don't fit. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32139@AAAI"},
{"title": "Does GPT Really Get It? A Hierarchical Scale to Quantify Human and AI’s Understanding of Algorithms", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Does GPT Really Get It? A Hierarchical Scale to Quantify Human and AI’s Understanding of Algorithms.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not that. \n\nMultimodal refers to using multiple data types, like text and images. The title talks about understanding algorithms, but there's no indication of combining different modalities. \n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses external information retrieval to enhance its responses. The paper here is about evaluating understanding of algorithms, not about retrieval methods. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about building or using knowledge graphs. \n\nThe paper seems to focus on assessing how well GPT and humans understand algorithms using a hierarchical scale. None of the four topics directly relate to this. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32140@AAAI"},
{"title": "MuMA-ToM: Multi-modal Multi-Agent Theory of Mind", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MuMA-ToM: Multi-modal Multi-Agent Theory of Mind.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the name. That suggests it's about combining different types of data, like text, images, audio, etc. So that points towards the multimodal category. \n\nThen there's \"Multi-Agent Theory of Mind.\" Theory of Mind in AI usually refers to understanding others' mental states, which is more about cognitive modeling or social AI. But the question is about the research topic. The key part here is \"Multi-modal,\" which directly corresponds to the multimodal option. \n\nThe other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge. None of those terms are in the title. \n\nSo the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32142@AAAI"}
{"title": "MuMA-ToM: Multi-modal Multi-Agent Theory of Mind", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MuMA-ToM: Multi-modal Multi-Agent Theory of Mind.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the name. That suggests it's about combining different types of data, like text, images, audio, etc. So that points towards the multimodal category. \n\nThen there's \"Multi-Agent Theory of Mind.\" Theory of Mind in AI usually refers to understanding others' mental states, which is more about cognitive modeling or social AI. But the question is about the research topic. The key part here is \"Multi-modal,\" which directly corresponds to the multimodal option. \n\nThe other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge. None of those terms are in the title. \n\nSo the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32142@AAAI"},
{"title": "ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Verbalizing the Mental States\" suggests they're trying to express or articulate the internal states of a model. \"Role-Playing LLMs\" means the large language models are being used in role-playing scenarios. \"Benchmarking Theory of Mind\" refers to evaluating the model's ability to understand others' mental states, which is a concept from psychology.\n\nNow, the four options. Time-series would involve data over time, like sequences or temporal analysis. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data retrieval to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper seems focused on understanding and benchmarking the theory of mind in LLMs through role-playing. This involves assessing how well the model can simulate or understand mental states, which is more about model behavior and evaluation rather than time-series data, multimodal inputs, retrieval, or knowledge graphs. None of the four topics directly relate to theory of mind or the specific methods mentioned here. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32143@AAAI"},
{"title": "Knowledge-Enhanced Hierarchical Heterogeneous Graph for Personality Identification with Limited Training Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Knowledge-Enhanced Hierarchical Heterogeneous Graph for Personality Identification with Limited Training Data.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge-Enhanced\" suggests that some form of knowledge is being incorporated into the model. \"Hierarchical Heterogeneous Graph\" points towards a graph structure that's both hierarchical and has different types of nodes or edges. \"Personality Identification\" is the task, and \"Limited Training Data\" indicates that the model is designed to work with not much data.\n\nNow, looking at the options. Time-series would involve data over time, like sequences. The title doesn't mention anything about time or sequences, so probably not time-series. Multimodal usually refers to combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation models. The title doesn't mention anything about retrieval or generation, so RAG might not be the right fit here.\n\nKG stands for Knowledge Graphs. The term \"Knowledge-Enhanced\" in the title could be related to integrating knowledge graphs into the model. Also, the mention of a \"Hierarchical Heterogeneous Graph\" aligns with the structure of knowledge graphs, which can be complex and hierarchical. Personality identification using such a graph structure with limited data might leverage external knowledge to compensate for the lack of training data. So, this seems like it fits under the KG topic.\n</think>\n\nKG", "url": "https://papers.cool/venue/32144@AAAI"},
{"title": "Pose as a Modality: A Psychology-Inspired Network for Personality Recognition with a New Multimodal Dataset", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Pose as a Modality: A Psychology-Inspired Network for Personality Recognition with a New Multimodal Dataset.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, the title mentions \"Pose as a Modality.\" Modality usually refers to different types of data inputs, like text, image, audio, etc. Then it says \"Multimodal Dataset,\" which directly uses the term \"multimodal.\" That seems like a strong indicator. The paper is about combining multiple modalities (like pose, maybe with other data types) for personality recognition. \n\nThe other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about time-based data, retrieval, or knowledge graphs. So the most fitting topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32145@AAAI"},
{"title": "A Multi-Focus-Driven Multi-Branch Network for Robust Multimodal Sentiment Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Multi-Focus-Driven Multi-Branch Network for Robust Multimodal Sentiment Analysis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Sentiment Analysis\" is right there. Multimodal usually refers to using multiple types of data, like text, audio, and video together. So that's a strong hint. The other parts mention a network structure with multiple branches and focus-driven, which might relate to how different modalities are processed. \n\nTime-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nSince the title explicitly mentions \"Multimodal,\" and the task is sentiment analysis using multiple modalities, this fits under the multimodal category. The other terms in the title don't point to time-series, RAG, or KG. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32146@AAAI"},
{"title": "Alignment of CNN and Human Judgments of Geometric and Topological Concepts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Alignment of CNN and Human Judgments of Geometric and Topological Concepts.\" Hmm. The user wants to know if this paper fits into one of the four categories: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal research deals with combining different types of data, like text and images. The title here is about CNNs (which are image-related) and human judgments, but it's about aligning their understanding of geometric and topological concepts. Not sure if it's multimodal, but maybe not the main focus.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper seems to be about aligning CNNs with human judgments in geometry and topology, which might relate to how knowledge is structured, but the title doesn't explicitly mention knowledge graphs. It's more about the alignment between a model and human concepts rather than building or using a knowledge graph.\n\nSo, none of the four categories seem to fit perfectly. The paper is about aligning CNNs with human judgments in specific concepts, which might be more about model interpretability or human-AI alignment, but not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32147@AAAI"},
{"title": "DDJND: Dual Domain Just Noticeable Difference in Multi-Source Content Images with Structural Discrepancy", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DDJND: Dual Domain Just Noticeable Difference in Multi-Source Content Images with Structural Discrepancy.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dual Domain\" might refer to two different domains or types of data. \"Just Noticeable Difference\" sounds like it's about perceptual differences, maybe in images. \"Multi-Source Content Images\" suggests that the images come from different sources. \"Structural Discrepancy\" implies there's some structural difference between them.\n\nLooking at the options: time-series is about data over time, which doesn't seem to fit here. Multimodal usually involves combining different types of data like text, images, audio. The title mentions multi-source images, which could be a form of multimodal if they're combining different data types. But wait, the term \"multi-source\" here might just mean images from different origins, not necessarily different modalities. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which doesn't seem related. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo, the key part is \"Multi-Source Content Images.\" If \"multi-source\" refers to different modalities (like combining images with text or other data types), then it's multimodal. But if it's just images from different sources but same modality (all images), then it's not multimodal. The term \"structural discrepancy\" might relate to how different the structures are between these images, which could be part of multimodal analysis if they're integrating different data types. However, without more context, it's a bit ambiguous. \n\nBut given the options, the closest might be multimodal because it's dealing with multiple sources, which could imply different modalities. However, the title doesn't explicitly mention combining different data types. It's possible that the paper is about image processing techniques for images from different sources, which might not be multimodal. \n\nAlternatively, maybe the \"dual domain\" refers to two different domains (like spatial and frequency domains in image processing), which is a technical aspect but not necessarily one of the listed topics. \n\nSince the options are time-series, multimodal, RAG, or KG, and the paper seems to focus on image processing with multiple sources and structural differences, but not combining different data modalities, it might not fit any of the listed topics. So the answer could be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32148@AAAI"},
{"title": "BIG-FUSION: Brain-Inspired Global-Local Context Fusion Framework for Multimodal Emotion Recognition in Conversations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BIG-FUSION: Brain-Inspired Global-Local Context Fusion Framework for Multimodal Emotion Recognition in Conversations.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The key parts here are \"Multimodal Emotion Recognition.\" The word \"multimodal\" is right there, which makes me think it's related to the multimodal topic. But I should check the other parts to be sure. \n\nThe framework is called BIG-FUSION, which is about fusing global and local context. The term \"fusion\" in multimodal contexts often refers to combining different modalities like text, audio, and video. Since the paper is about emotion recognition in conversations, it's likely using multiple data types (e.g., speech, facial expressions, text) to recognize emotions. That definitely sounds like multimodal research.\n\nNow, checking the other options. Time-series would involve data points indexed in time order, like stock prices or sensor data over time. While conversations do have a temporal aspect, the main focus here is on combining different modalities, not the time aspect. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, typically in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graphs) involve structured data representations, often using graphs to model relationships. The title doesn't mention knowledge graphs or structured data, so that's out.\n\nSo, the most fitting topic here is multimodal. The paper is about integrating multiple modalities for emotion recognition, which aligns with the multimodal category.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32149@AAAI"},
{"title": "Adaptive Calibration: A Unified Conversion Framework of Spiking Neural Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adaptive Calibration: A Unified Conversion Framework of Spiking Neural Networks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Adaptive Calibration\" sounds like a method or process. \"Unified Conversion Framework\" suggests it's about converting something into another form. \"Spiking Neural Networks\" (SNNs) are a type of neural network that processes information in spikes, which are time-dependent. So SNNs are inherently related to time-series data because they deal with temporal information.\n\nNow, looking at the options. Time-series research deals with data that is sequential over time. Since SNNs are based on spikes over time, this seems like a fit. Multimodal would involve combining different types of data (like text and images), which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem related. KG (Knowledge Graphs) involve structured data representations, which also isn't the focus here.\n\nThe paper is about converting SNNs, which are time-based, so the topic is likely time-series. The other options don't align with the content described in the title. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32150@AAAI"},
{"title": "Undermining Mental Proof: How AI Can Make Cooperation Harder by Making Thinking Easier", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Undermining Mental Proof: How AI Can Make Cooperation Harder by Making Thinking Easier.\" Hmm. I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title is about AI affecting cooperation and thinking, but there's no mention of multiple data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in AI where models retrieve information from a database to generate responses. The title talks about AI making thinking easier, but RAG is more about enhancing generation with retrieval. Not sure if that's the connection here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about structured data or knowledge representation. \n\nThe paper seems to be about the social or psychological impact of AI, specifically how it affects human cooperation by making thinking easier. None of the four topics directly relate to this kind of research. The focus is on the societal implications rather than the technical aspects of time-series analysis, multimodal data, RAG, or knowledge graphs. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32151@AAAI"}
{"title": "Enriching Multimodal Sentiment Analysis Through Textual Emotional Descriptions of Visual-Audio Content", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enriching Multimodal Sentiment Analysis Through Textual Emotional Descriptions of Visual-Audio Content.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Sentiment Analysis\" is right there. Multimodal usually refers to using multiple types of data, like combining text, audio, and visual information. The paper is about enhancing this analysis by using textual descriptions of visual and audio content. So the key term here is \"multimodal.\" \n\nTime-series would involve data points indexed in time order, like stock prices over time. RAG is Retrieval-Augmented Generation, which is about using retrieval methods to enhance generative models. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about time, retrieval, or knowledge graphs. The focus is clearly on combining different modalities (text, visual, audio) for sentiment analysis. So the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32152@AAAI"},
{"title": "DepMGNN: Matrixial Graph Neural Network for Video-based Automatic Depression Assessment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DepMGNN: Matrixial Graph Neural Network for Video-based Automatic Depression Assessment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The model is called DepMGNN, which stands for something. The key parts here are \"Matrixial Graph Neural Network\" and \"Video-based Automatic Depression Assessment.\" \n\nGraph Neural Networks (GNNs) are typically used for data that can be represented as graphs, like social networks or knowledge graphs. The term \"Matrixial\" might refer to using matrices in the GNN structure. The application is video-based depression assessment. \n\nNow, the topics to consider: time-series, multimodal, RAG, KG. \n\nTime-series usually involves data points indexed in time order, like stock prices over time. Multimodal refers to using multiple types of data (e.g., text, images, audio) together. RAG is Retrieval-Augmented Generation, which combines retrieval of information with generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper uses a video-based approach. Videos are a combination of visual and auditory data, so that's multimodal. However, the title doesn't explicitly mention using multiple modalities. The key part here is the model itself. The GNN part might be related to knowledge graphs (KG) if they're modeling relationships in a graph structure. But the application is depression assessment from video, which could involve analyzing facial expressions, speech, etc., which are multimodal. \n\nWait, but the question is about the research topic the paper belongs to. The model is a GNN, which is often used in knowledge graphs. However, the application here is video-based, which is more about processing video data. But the problem is depression assessment, which might involve analyzing different modalities from the video (like visual and audio). So maybe multimodal? But the title doesn't mention multimodal explicitly. The model is a GNN, which could be used in KG, but the application is video-based. \n\nAlternatively, maybe the model is using a graph structure to represent the video data, which could be a time-series aspect. But the term \"Matrixial\" might be a specific type of GNN. \n\nHmm. The options are time-series, multimodal, RAG, KG. The paper is about using a GNN for video-based depression assessment. If the video is processed as a time-series (since videos are sequences over time), but the model is a GNN, which is more about graph structures. However, the key here is the application. Since the input is video, which is a time-series of frames, but the model is a GNN. However, the main research topic might be multimodal if they are combining different modalities (like facial expressions, speech, etc.) from the video. But the title doesn't mention multimodal. \n\nWait, the title says \"video-based,\" which is a single modality (video), but video itself contains multiple modalities (visual and audio). However, the paper's title doesn't specify that they are combining multiple modalities. So maybe it's not multimodal. \n\nRAG is about retrieval and generation, which doesn't seem relevant here. KG is knowledge graphs, which might be if they're using a graph structure to represent knowledge, but the model is a GNN applied to video data. \n\nSo, perhaps the answer is none? But wait, maybe the model is a GNN, which is related to knowledge graphs. But the application is depression assessment from video. So the research topic could be KG if the GNN is used to model a knowledge graph. However, the title doesn't mention knowledge graphs. \n\nAlternatively, maybe the model is a GNN that's structured as a matrix, which is a different approach. Since the options are time-series, multimodal, RAG, KG, and the paper is using a GNN for video data, which is a time-series of frames. But the model is a GNN, which is more about graph structures. \n\nI'm a bit confused. Let me think again. The four options are the possible topics. The paper's title is about a GNN for video-based depression assessment. The GNN part could be related to knowledge graphs (KG) if they're using a graph to represent knowledge. But the application is video-based, which is more about processing video data. Since the title doesn't mention knowledge graphs, maybe it's not KG. \n\nMultimodal would require using multiple data types. If the video is processed as a time-series, maybe time-series. But the model is a GNN, which is not typically a time-series model. \n\nAlternatively, maybe the video is being processed as a time-series of frames, but the model is a GNN. However, the main research topic here is the model (GNN) applied to a specific task. Since the options are the topics, and the model is a GNN, which is related to knowledge graphs (KG), but the application is video-based. \n\nHmm. I'm not sure. The answer might be none, but maybe it's multimodal if the video is considered as combining different modalities. But the title doesn't specify that. Alternatively, maybe it's time-series because video is a sequence. But the model is a GNN, which is not a typical time-series model. \n\nI think the correct answer here is none. Because the paper is about a GNN model for video-based depression assessment, which doesn't clearly fit into time-series, multimodal, RAG, or KG. Unless the GNN is part of a knowledge graph, but the title doesn't mention that. So the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32153@AAAI"},
{"title": "Leveraging Asynchronous Spiking Neural Networks for Ultra Efficient Event-Based Visual Processing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Leveraging Asynchronous Spiking Neural Networks for Ultra Efficient Event-Based Visual Processing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Asynchronous Spiking Neural Networks\" – spiking neural networks are a type of neural network that processes information in spikes, which are events over time. So that's time-dependent. \"Event-Based Visual Processing\" suggests that the input is events, which are time-stamped and asynchronous. So the data here is event-based, which is a form of time-series data because each event has a time component. \n\nTime-series analysis deals with data points indexed in time order. Since the processing is event-based and asynchronous, it's handling data that arrives at irregular intervals, which is typical in time-series contexts. \n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention multiple modalities, so probably not that. RAG (Retrieval-Augmented Generation) is about using retrieval systems to augment model outputs, which isn't mentioned here. KG (Knowledge Graphs) involve structured data representations, which also doesn't seem relevant. \n\nSo the key here is the event-based processing and spiking networks, which are time-dependent. Therefore, the topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32154@AAAI"},
{"title": "Personalized Dynamic Music Emotion Recognition with Dual-Scale Attention-Based Meta-Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Personalized Dynamic Music Emotion Recognition with Dual-Scale Attention-Based Meta-Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on music emotion recognition. The term \"dynamic\" might suggest that the data is sequential, which could relate to time-series. But I need to check if that's the case here. Time-series analysis typically involves data points indexed in time order, like stock prices over time. In music, if they're analyzing the emotion over time, maybe that's time-series. But the key here is \"Personalized Dynamic Music Emotion Recognition.\" So they're trying to recognize emotions in music, and it's dynamic, meaning it changes over time. That could imply time-series data, but I'm not sure yet.\n\nNext, \"Dual-Scale Attention-Based Meta-Learning.\" Attention mechanisms are common in various models, but dual-scale might refer to different time scales or different features. Meta-learning is about learning to learn, which is a method for adapting to new tasks quickly. But how does that tie into the topics? The four options are time-series, multimodal, RAG, KG.\n\nMultimodal would involve combining different types of data, like text and images. The paper is about music emotion, which is a single modality (audio), unless they're combining other data types. The title doesn't mention other modalities, so maybe not multimodal.\n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to generate responses. That's more common in NLP tasks, like question-answering. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nSo, the remaining options are time-series or none. The dynamic aspect might imply time-series, but the main focus is on emotion recognition in music. However, music is inherently a time-series (audio signals over time), but the paper's title doesn't explicitly mention time-series analysis techniques. The use of \"dynamic\" could be about the changing emotions over time, which would be a time-series aspect. But the key methods here are dual-scale attention and meta-learning. The attention mechanism could be applied to time-series data, but it's also used in other contexts. The meta-learning part is about personalization, adapting to individual users. \n\nWait, the problem is to determine which of the four topics the paper belongs to. The four are time-series, multimodal, RAG, KG. The paper's title doesn't mention anything about combining multiple modalities (so not multimodal), retrieval (RAG), or knowledge graphs (KG). The dynamic aspect might relate to time-series, but the primary focus is on emotion recognition in music using meta-learning and attention. However, music emotion recognition could involve time-series data (audio signals), but the paper's title doesn't explicitly state that it's a time-series analysis. The term \"dynamic\" might refer to the changing emotions over time, which is a time-series aspect. But the main contribution is the method (dual-scale attention and meta-learning) rather than the data type. \n\nHmm. Maybe the answer is time-series because the data is inherently time-based (music is a time-series), but the paper's title doesn't explicitly mention time-series analysis techniques. Alternatively, maybe it's none of the four. But the options are time-series, multimodal, RAG, KG. Since the paper is about music emotion recognition, which is a single modality, and doesn't mention retrieval or knowledge graphs, the closest might be time-series. But I'm not entirely sure. Alternatively, maybe it's none. Wait, the user says if it doesn't belong to any of these, respond with \"none\". \n\nBut the title does mention \"dynamic\", which could imply time-series. However, the primary focus is on the method (meta-learning with attention) for personalized emotion recognition. The data type (music) is a time-series, but the research topic might not be classified under time-series unless the paper is specifically about time-series analysis techniques. Since the title doesn't mention time-series analysis methods, maybe it's not categorized under time-series. Therefore, the answer might be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32155@AAAI"},
{"title": "Learning Concept Prerequisite Relation via Global Knowledge Relation Optimization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning Concept Prerequisite Relation via Global Knowledge Relation Optimization.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Learning Concept Prerequisite Relation\" sounds like it's about understanding relationships between concepts, maybe in an educational context where one concept is a prerequisite for another. Then \"Global Knowledge Relation Optimization\" – \"Knowledge Relation\" makes me think of Knowledge Graphs (KG), which are structured representations of information. Optimization here might refer to improving the structure or relationships within the knowledge graph.\n\nTime-series would involve data over time, like stock prices or weather. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge sources for generating responses. KG is Knowledge Graphs, which are about structured knowledge and relationships between entities.\n\nThe paper's focus seems to be on optimizing knowledge relations, which aligns with Knowledge Graphs. The mention of \"Global Knowledge Relation\" specifically points towards KG. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32156@AAAI"},
{"title": "SalM²: An Extremely Lightweight Saliency Mamba Model for Real-Time Cognitive Awareness of Driver Attention", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SalM²: An Extremely Lightweight Saliency Mamba Model for Real-Time Cognitive Awareness of Driver Attention.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Saliency Mamba Model\" – Mamba is a type of model, right? I remember that Mamba is a state-space model designed for processing sequences, which is often used in time-series data. So maybe it's related to time-series. The term \"Real-Time\" also suggests that the model is handling data as it comes in, which is typical in time-series analysis. \n\nThe application here is \"Cognitive Awareness of Driver Attention,\" which might involve processing data from sensors or cameras in real-time to monitor the driver's attention. That could be time-series data from sensors, like eye movement or head position over time. \n\nNow, checking the other options. Multimodal would involve combining different types of data, like text and images. The title doesn't mention multiple modalities, so maybe not. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't appear relevant. \n\nSo the most likely topic here is time-series, given the use of Mamba (a time-series model) and the real-time processing aspect.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32157@AAAI"},
{"title": "Look Around Before Locating: Considering Content and Structure Information for Visual Grounding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Look Around Before Locating: Considering Content and Structure Information for Visual Grounding.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, I'll break down the title. \"Visual grounding\" refers to the task of connecting language to visual elements, like identifying where a described object is in an image. The paper mentions considering both content and structure information. Content would be the actual visual data, and structure might refer to the layout or spatial relationships in the image.\n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is a method for enhancing models with external information retrieval, but the title doesn't mention retrieval or generation. KG (Knowledge Graphs) involves structured data and relationships, but again, the title is about visual and structural info, not knowledge graphs.\n\nMultimodal refers to combining multiple data types, like text and images. Since visual grounding involves both visual (image) and textual (language) information, this seems like a fit. The paper is about integrating content (visual) and structure (spatial layout) for a task that's inherently multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32158@AAAI"},
{"title": "PerReactor: Offline Personalised Multiple Appropriate Facial Reaction Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PerReactor: Offline Personalised Multiple Appropriate Facial Reaction Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Offline Personalised Multiple Appropriate Facial Reaction Generation.\" So, it's about generating facial reactions, which are probably expressions or responses. The key terms here are \"facial reaction generation,\" \"personalised,\" and \"offline.\" \n\nTime-series usually involves data over time, like stock prices or weather. This doesn't seem to fit because the focus is on generating reactions, not analyzing sequences over time. \n\nMultimodal refers to using multiple data types, like combining text, images, audio. If the paper uses different modalities (e.g., text input and generates facial expressions), it might be multimodal. But the title doesn't explicitly mention multiple modalities. It's about generating facial reactions, which could be a single modality (visual), unless the input is something else. However, the title doesn't specify, so maybe not.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information before generating a response. The title doesn't mention anything about retrieval or using external data for generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses a knowledge graph to inform the facial reactions, it would fit here. But again, the title doesn't mention knowledge graphs or structured data.\n\nThe main focus here is generating facial reactions, which is a type of generation task. The options given don't include general generation tasks. The closest might be multimodal if it's combining different inputs (like text to generate a facial reaction), but the title doesn't specify. Since none of the four topics (time-series, multimodal, RAG, KG) are clearly indicated, the answer might be \"none.\" But wait, maybe \"multimodal\" if it's using multiple modalities. For example, if the input is text and the output is a facial reaction (image), that's multimodal. However, the title doesn't state that. The term \"facial reaction generation\" could be a single modality. Without more info, it's safer to say \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32159@AAAI"},
{"title": "Bridge Then Begin Anew: Generating Target-Relevant Intermediate Model for Source-Free Visual Emotion Adaptation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bridge Then Begin Anew: Generating Target-Relevant Intermediate Model for Source-Free Visual Emotion Adaptation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Visual Emotion Adaptation.\" Visual implies something related to images or video, which is a modality. Emotion could be another modality, like text or audio. So combining visual and emotion might suggest multimodal, since it's using multiple data types. \n\nThen there's \"Source-Free,\" which might refer to not using the source domain data during adaptation. That's a common term in domain adaptation, which is a part of transfer learning. But how does that relate to the given topics? The other part is \"Intermediate Model,\" which could be a model that bridges different domains or modalities. \n\nLooking at the options: time-series is about sequential data over time. The title doesn't mention anything about time or sequences, so probably not that. Multimodal involves combining different data types, like vision and text, which seems to fit here with visual and emotion. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval to augment generation models, often in NLP. The title doesn't mention retrieval or generation in that context. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem to be the case here. \n\nSo the most likely answer is multimodal. The paper is about adapting a model for visual emotion, which combines different modalities (visual and emotional data), and creating an intermediate model to bridge domains without source data. That fits under multimodal research.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32160@AAAI"},
{"title": "Progressive Self-Learning for Domain Adaptation on Symbolic Regression of Integer Sequences", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Progressive Self-Learning for Domain Adaptation on Symbolic Regression of Integer Sequences.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Symbolic Regression\" usually refers to finding mathematical expressions that fit data, often using genetic programming or similar methods. \"Integer Sequences\" suggests sequences of numbers, which could be time-series data if they're ordered over time. But the key part here is \"Domain Adaptation.\" That's about making a model work in a new domain after being trained on a different one. \n\nNow, looking at the options. Time-series is about data over time, which could fit if the sequences are time-based. But the title doesn't explicitly mention time. Multimodal would involve multiple data types like text and images, which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which doesn't seem related. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't fit. \n\nThe main focus here is on adapting models for symbolic regression on integer sequences. Since integer sequences can be considered a type of time-series data (if they're ordered), but the paper's emphasis is on domain adaptation and self-learning rather than the temporal aspect. However, time-series is the closest match among the given options. The other topics don't align. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32162@AAAI"}
{"title": "Progressive Self-Learning for Domain Adaptation on Symbolic Regression of Integer Sequences", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Progressive Self-Learning for Domain Adaptation on Symbolic Regression of Integer Sequences.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Symbolic Regression\" usually refers to finding mathematical expressions that fit data, often using genetic programming or similar methods. \"Integer Sequences\" suggests sequences of numbers, which could be time-series data if they're ordered over time. But the key part here is \"Domain Adaptation.\" That's about making a model work in a new domain after being trained on a different one. \n\nNow, looking at the options. Time-series is about data over time, which could fit if the sequences are time-based. But the title doesn't explicitly mention time. Multimodal would involve multiple data types like text and images, which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which doesn't seem related. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't fit. \n\nThe main focus here is on adapting models for symbolic regression on integer sequences. Since integer sequences can be considered a type of time-series data (if they're ordered), but the paper's emphasis is on domain adaptation and self-learning rather than the temporal aspect. However, time-series is the closest match among the given options. The other topics don't align. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32162@AAAI"},
{"title": "HSRDiff: A Hierarchical Self-Regulation Diffusion Model for Stochastic Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HSRDiff: A Hierarchical Self-Regulation Diffusion Model for Stochastic Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Diffusion Model\" makes me think of generative models, maybe like those used in image generation. \"Stochastic Semantic Segmentation\" suggests it's about segmenting images into parts with some randomness involved. The \"Hierarchical Self-Regulation\" part might refer to the model's structure or how it manages different levels of processing.\n\nNow, the options. Time-series would involve data over time, like stock prices or sensor data. Multimodal would combine different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge for generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus seems to be on a specific type of model for semantic segmentation, which is an image processing task. There's no mention of time-based data, so time-series is out. It doesn't talk about combining different modalities, so multimodal isn't it. RAG and KG are more about knowledge retrieval and structured data, which doesn't seem to fit here. The model is a diffusion model, which is a type of generative model, but none of the given topics directly relate to diffusion models or semantic segmentation. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32163@AAAI"},
{"title": "AAAI.2025 - Computer Vision", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"AAAI.2025 - Computer Vision\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics entails. Time-series research typically deals with data points indexed in time order, like stock prices or weather data. Multimodal refers to the integration of multiple data types, such as text, images, and audio. RAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generative models. KG is Knowledge Graphs, which are structured representations of knowledge, often used in semantic web and AI applications.\n\nThe title given is \"AAAI.2025 - Computer Vision\". AAAI is the Association for the Advancement of Artificial Intelligence, so this is a conference paper. The main topic here is Computer Vision. Now, I need to see if Computer Vision falls under any of the four categories listed.\n\nComputer Vision is a broad field that involves processing and analyzing visual data, like images and videos. It's a subfield of AI. Now, does it relate to time-series? Well, some computer vision applications might involve video (which is a time-series of images), but the field itself isn't primarily about time-series data. So maybe not the best fit.\n\nMultimodal? Computer Vision could be part of a multimodal system if it's combined with other data types, but the title doesn't specify that. The title just mentions Computer Vision, so it's possible the paper is focused solely on that, not combining multiple modalities.\n\nRAG? That's more about combining retrieval and generation, which is common in NLP tasks like question-answering. Computer Vision papers might use RAG techniques, but again, the title doesn't indicate that. The main focus here is on Computer Vision, not on retrieval or generation.\n\nKG? Knowledge Graphs are about structured data and relationships. While some computer vision systems might use knowledge graphs for context, the title doesn't suggest that. The primary focus is on Computer Vision, not on building or using knowledge graphs.\n\nSince the title only mentions Computer Vision and none of the specific topics (time-series, multimodal, RAG, KG) are explicitly indicated, the paper likely doesn't belong to any of these four categories. Therefore, the correct response should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/AAAI.2025?group=Computer Vision"},
{"title": "GRICP: Granular-Ball Iterative Closest Point with Multikernel Correntropy for Point Cloud Fine Registration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GRICP: Granular-Ball Iterative Closest Point with Multikernel Correntropy for Point Cloud Fine Registration.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. GRICP is the method's name. Granular-Ball and Iterative Closest Point (ICP) are parts of it. ICP is a common algorithm for aligning point clouds, so that's about 3D data registration. The mention of \"Multikernel Correntropy\" suggests some statistical or machine learning approach for handling noise or similarity measures. The application is \"Point Cloud Fine Registration,\" which is about precisely aligning 3D point clouds, often used in robotics, computer vision, or mapping.\n\nNow, the four topics: time-series, multimodal, RAG, KG. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is in NLP for enhancing models with external knowledge. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on a specific algorithm for point cloud registration. Point clouds are a type of spatial data, not time-series. It's not combining multiple data modalities, so not multimodal. RAG and KG are more about knowledge integration in NLP or structured data, which doesn't seem related here. The paper is about a technical method in computer vision or robotics, not fitting any of the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32164@AAAI"},
{"title": "AQUAFace: Age-Invariant Quality Adaptive Face Recognition for Unconstrained Selfie vs ID Verification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AQUAFace: Age-Invariant Quality Adaptive Face Recognition for Unconstrained Selfie vs ID Verification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. This paper is about face recognition, which is image-based, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The title mentions face recognition and ID verification, but it doesn't explicitly say they're combining different modalities. It's about adapting to selfie quality and age invariance, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. This paper is about face recognition, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on improving face recognition accuracy, not on building or using a knowledge graph.\n\nSo, the paper is about face recognition techniques, specifically making them age-invariant and adaptive to selfie quality. None of the given topics (time-series, multimodal, RAG, KG) directly apply here. The main focus is on improving the model's performance in specific scenarios, which doesn't fall under the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32165@AAAI"},
{"title": "ISR-DPO: Aligning Large Multimodal Models for Videos by Iterative Self-Retrospective DPO", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ISR-DPO: Aligning Large Multimodal Models for Videos by Iterative Self-Retrospective DPO.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Large Multimodal Models\" is mentioned right there. Multimodal usually refers to models that handle multiple types of data, like text and images or video. So that's a strong hint towards the multimodal category. \n\nThen, the method is called \"Iterative Self-Retrospective DPO.\" DPO might stand for Direct Preference Optimization, which I've heard in the context of aligning models with human preferences. But the key part here is \"Multimodal Models for Videos.\" Videos are a combination of visual and auditory data, so that's definitely multimodal. \n\nThe other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which uses external knowledge sources. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about time-series data, retrieval, or knowledge graphs. \n\nSo the main focus here is on multimodal models, specifically for videos. The alignment part is about training the model, but the core topic is multimodal. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32166@AAAI"},
{"title": "EMPLACE: Self-Supervised Urban Scene Change Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EMPLACE: Self-Supervised Urban Scene Change Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Self-Supervised\" suggests it's a machine learning approach where the model learns without explicit labels. \"Urban Scene Change Detection\" implies the task is about identifying changes in urban environments over time. So, they're probably looking at images or videos of cities and detecting when things change, like new buildings, removed structures, etc.\n\nNow, the possible topics. Time-series usually involves data points indexed in time order, like stock prices over days. Multimodal refers to using multiple types of data, like combining text and images. RAG is Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on change detection in urban scenes. That sounds like it's about analyzing images or videos over time to detect changes. So, if they're comparing different time points, that would be time-series. But wait, sometimes change detection can be done with before-and-after images without a continuous time series. However, the term \"self-supervised\" might imply that they're using temporal data to train the model without labels. For example, using pairs of images from different times to learn the changes. \n\nMultimodal would require using different data types, like combining satellite images with sensor data. The title doesn't mention multiple modalities, so maybe not. RAG and KG are less likely here. RAG is about retrieval and generation, which doesn't fit. KG is about structured knowledge, which also doesn't seem relevant. \n\nSo the most likely topic is time-series. Even if it's just two images, the change detection over time would still fall under time-series analysis. The key is the temporal aspect of detecting changes, which is a time-based analysis. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32167@AAAI"},
{"title": "AGFSync: Leveraging AI-Generated Feedback for Preference Optimization in Text-to-Image Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AGFSync: Leveraging AI-Generated Feedback for Preference Optimization in Text-to-Image Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about text-to-image generation, which definitely uses both text and images. So that's a possibility. But let me check the other options.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text. The title mentions AI-generated feedback, but I'm not sure if it's using retrieval. The focus here is on optimizing preferences using feedback, which might be more about the generation process rather than retrieving information.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nSo, the main elements here are text and image generation. Since it's combining text and images, that's multimodal. The other aspects like feedback and optimization might be part of the methodology, but the core topic is multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32168@AAAI"},
{"title": "Pre-training a Density-Aware Pose Transformer for Robust LiDAR-based 3D Human Pose Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Pre-training a Density-Aware Pose Transformer for Robust LiDAR-based 3D Human Pose Estimation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on 3D human pose estimation using LiDAR data. The method mentioned is a \"Density-Aware Pose Transformer,\" which is pre-trained. Now, the key here is to see if any of the four topics are relevant.\n\nTime-series usually involves data over time, like sequences. This paper is about pose estimation, which could involve sequences if it's tracking over time, but the title doesn't explicitly mention time-series data. It's more about a single LiDAR-based estimation.\n\nMultimodal refers to using multiple data types, like combining images with text or LiDAR with other sensors. The title mentions LiDAR, but does it combine with another modality? The paper is about LiDAR-based, so maybe it's using LiDAR data alone. Unless the Transformer is multimodal in some way, but the title doesn't specify combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. This paper is about pose estimation, which is computer vision, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data in the title. It's about a neural network model for pose estimation.\n\nSo, none of the four topics seem to fit. The paper is about a Transformer model for 3D pose estimation using LiDAR, which is more in the realm of computer vision and robotics, not time-series, multimodal (as in combining different data types), RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32169@AAAI"},
{"title": "CA-MLIF: Cross-Attention and Multimodal Low-Rank Interaction Fusion Framework for Tumor Prognostic Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CA-MLIF: Cross-Attention and Multimodal Low-Rank Interaction Fusion Framework for Tumor Prognostic Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts are \"Cross-Attention,\" \"Multimodal,\" \"Low-Rank Interaction Fusion,\" and the application is \"Tumor Prognostic Prediction.\" \n\n\"Multimodal\" is right there in the title. That suggests the research involves combining different types of data modalities, like images, text, or other data sources. The term \"Multimodal Low-Rank Interaction Fusion\" implies that they're fusing multiple modalities using some low-rank methods. So that points towards the multimodal topic.\n\nThe other parts: Cross-Attention is a technique often used in multimodal tasks to help different modalities attend to each other's features. So that's a method within multimodal research. The application is in tumor prognosis, which is a medical domain, but the question is about the research topic category.\n\nTime-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, which is more common in NLP tasks. KG (Knowledge Graph) involves structured data and relationships, which isn't mentioned here. \n\nSo the main keyword here is \"Multimodal,\" which is one of the options. The framework is designed for fusing multiple modalities, so the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32170@AAAI"}
{"title": "HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language Models\" immediately makes me think of multimodal because they combine visual and textual data. Multimodal models typically handle multiple types of data, like images and text. The other parts of the title mention token dropping and attention mechanisms, which are common in transformer-based models. But the key here is the combination of vision and language, which is a classic example of multimodal processing. \n\nTime-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation tasks, often in NLP. KG (Knowledge Graphs) involve structured data representations. The paper's focus on vision and language integration points to multimodal. I don't see any mention of time-based data, retrieval, or knowledge graphs here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32171@AAAI"},
{"title": "Multi-View Pedestrian Occupancy Prediction with a Novel Synthetic Dataset", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-View Pedestrian Occupancy Prediction with a Novel Synthetic Dataset.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View\" suggests that the research uses data from multiple perspectives or sources. \"Pedestrian Occupancy Prediction\" is about predicting where pedestrians are or will be, which is common in computer vision or robotics. The \"Novel Synthetic Dataset\" part means they created a new dataset, probably for training or testing their model.\n\nNow, the possible topics. Time-series would involve data over time, like sequences. Multimodal refers to using multiple types of data (e.g., images and text). RAG is Retrieval-Augmented Generation, which combines retrieval and generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe key term here is \"Multi-View.\" That usually refers to combining data from different viewpoints or modalities. For example, in computer vision, multi-view could mean using images from different angles. If the dataset includes different modalities (like images and LiDAR), it would be multimodal. However, the title doesn't explicitly mention different modalities, just multiple views. But \"multi-view\" in the context of pedestrian prediction might involve different sensor inputs or camera angles, which could be considered multimodal. \n\nAlternatively, if it's just multiple camera angles of the same modality (e.g., all images), it might not be multimodal. But the term \"multi-view\" is often associated with multimodal when different data types are involved. Since the paper introduces a synthetic dataset, it's possible they combined different data sources. \n\nTime-series could be a factor if the prediction is over time, but the title doesn't mention time explicitly. RAG and KG don't seem relevant here. So the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32172@AAAI"},
{"title": "ProtoArgNet: Interpretable Image Classification with Super-Prototypes and Argumentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ProtoArgNet: Interpretable Image Classification with Super-Prototypes and Argumentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image classification, so time-series probably isn't it. \n\nMultimodal would involve combining different data types, like text and images. The paper is about image classification, but the title doesn't mention combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance their responses. The title doesn't mention anything about retrieval or generation, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title talks about prototypes and argumentation, which might relate to how the model makes decisions, but I don't see a direct link to knowledge graphs here.\n\nThe key terms are \"interpretable image classification,\" \"super-prototypes,\" and \"argumentation.\" Super-prototypes could be a method for creating interpretable models by using representative examples. Argumentation might refer to reasoning or justifying the classification decisions. This seems more about model interpretability rather than the specific topics listed. Since none of the four topics (time-series, multimodal, RAG, KG) are clearly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32173@AAAI"},
{"title": "Can Generative Models Improve Self-Supervised Representation Learning?", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Can Generative Models Improve Self-Supervised Representation Learning?\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. The main components are \"Generative Models\" and \"Self-Supervised Representation Learning.\" Generative models are a type of machine learning model that can generate new data instances, like GANs or VAEs. Self-supervised learning is a method where the model learns representations from unlabeled data by solving pretext tasks. So the question is whether using generative models can enhance this kind of learning.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series. Multimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities either. \n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in models like those that fetch documents to answer questions. The title is about generative models improving self-supervised learning, not about retrieval. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data. \n\nSo none of the four topics seem to fit. The paper is about generative models in the context of self-supervised learning, which is a broader area. Since the options given don't include a category for generative models or self-supervised learning, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32174@AAAI"},
{"title": "The Master Key Filters Hypothesis: Deep Filters Are General", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"The Master Key Filters Hypothesis: Deep Filters Are General\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should say \"none\".\n\nFirst, I need to understand what each of these topics entails. Time-series research typically deals with data points indexed in time order, like stock prices or weather data. Multimodal refers to combining multiple types of data, such as text, images, and audio. RAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which involves structured data representing entities and their relationships.\n\nNow, looking at the title: \"The Master Key Filters Hypothesis: Deep Filters Are General\". The term \"filters\" here might refer to neural network layers or components that process data. \"Deep Filters\" could imply deep learning models with multiple layers. The hypothesis suggests that these filters are general, meaning they might be applicable across different tasks or data types. \n\nBut none of the keywords in the title directly point to time-series data, multimodal integration, RAG, or knowledge graphs. The title seems more about the theoretical aspect of deep learning models, possibly their architecture or generalization capabilities. Since the topics provided don't include general deep learning or neural network theory, and the title doesn't mention any of the four specific areas, I should conclude that it doesn't belong to any of these topics. Therefore, the answer is \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32175@AAAI"},
{"title": "Frozen Language Models Are Gradient Coherence Rectifiers in Vision Transformers", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Frozen Language Models Are Gradient Coherence Rectifiers in Vision Transformers.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Frozen Language Models\" – that sounds like they're using a pre-trained language model that's not being fine-tuned, maybe as part of a larger system. \"Gradient Coherence Rectifiers\" – I'm not exactly sure what that means, but it might relate to how gradients are handled during training. \"Vision Transformers\" – so this is about vision models, specifically using transformers. \n\nNow, the main question is whether this paper fits into one of the four categories. Let's consider each option:\n\nTime-series: That's about data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not this one.\n\nMultimodal: This involves combining different types of data, like text and images. The title mentions both language models (text) and vision transformers (images), so this could be a candidate. The idea of using a frozen language model in a vision model might be part of a multimodal approach where text and vision are combined.\n\nRAG (Retrieval-Augmented Generation): That's about using retrieval methods to augment the generation process in models, often in NLP. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG (Knowledge Graphs): These are structured representations of knowledge. The title doesn't seem to relate to building or using knowledge graphs, so probably not KG.\n\nSo the most likely is multimodal. The paper is about integrating a language model (text) with a vision transformer (images), which are different modalities. The fact that the language model is frozen suggests it's being used as a pre-trained component, possibly to provide textual context or features to the vision model. That fits the multimodal research area where different data types are combined. The other terms in the title might be specific techniques, but the overarching topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32176@AAAI"},
{"title": "Plug-and-Play Tri-Branch Invertible Block for Image Rescaling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Plug-and-Play Tri-Branch Invertible Block for Image Rescaling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Image Rescaling\" suggests that the paper is about resizing images, maybe upscaling or downscaling. The \"Tri-Branch Invertible Block\" part sounds like a neural network architecture with three branches that can be inverted, which might be used for tasks like image processing. The \"Plug-and-Play\" part implies that this block can be integrated into different models easily.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on image rescaling, which is a computer vision task. The tri-branch invertible block is likely a component for image processing. None of the four topics directly relate to image rescaling or invertible neural networks. Time-series is about temporal data, which doesn't fit. Multimodal would involve combining different modalities, but the title doesn't mention that. RAG and KG are about retrieval and knowledge graphs, which aren't related here. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32177@AAAI"},
{"title": "BEE: Metric-Adapted Explanations via Baseline Exploration-Exploitation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BEE: Metric-Adapted Explanations via Baseline Exploration-Exploitation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"BEE\" is probably an acronym. The main parts are \"Metric-Adapted Explanations\" and \"Baseline Exploration-Exploitation.\" The term \"explanations\" makes me think of interpretability or explainable AI. \"Baseline Exploration-Exploitation\" sounds like it's about balancing exploration and exploitation in some algorithm, maybe in reinforcement learning or optimization. \n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or weather. Multimodal deals with multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about combining retrieval with generative models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time, so time-series is probably out. There's no indication of multiple modalities either. RAG and KG are both related to knowledge and retrieval. The term \"Baseline Exploration-Exploitation\" might relate to how the model explores different baselines or strategies, but I'm not sure. \"Metric-Adapted Explanations\" could be about adjusting explanations based on certain metrics, which might be part of RAG if it's about generating explanations using retrieved information. However, RAG is more about augmenting generation with retrieval, not necessarily explanations. KGs are about structured knowledge, but the title doesn't mention graphs or knowledge structures. \n\nHmm. Maybe it's about creating explanations that adapt to different metrics, which could be part of model interpretability. But none of the four topics directly relate to model explanations or interpretability. The options given are time-series, multimodal, RAG, KG. Since the title doesn't clearly fit any of these, the answer might be \"none.\" But wait, maybe \"Baseline Exploration-Exploitation\" is a method used in RAG? Not sure. Alternatively, if it's about generating explanations using some retrieval method, maybe RAG. But the title doesn't mention retrieval. I think it's more likely that it doesn't fit any of the four, so the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32178@AAAI"},
{"title": "Dual Manifold Regularization Steered Robust Representation Learning for Point Cloud Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dual Manifold Regularization Steered Robust Representation Learning for Point Cloud Analysis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Dual Manifold Regularization\" sounds like a technique involving manifolds, which are often used in machine learning for dimensionality reduction or data representation. \"Robust Representation Learning\" suggests they're trying to learn features that are resilient to noise or variations. \"Point Cloud Analysis\" refers to processing 3D data points, which is common in computer vision or robotics.\n\nNow, looking at the options. Time-series deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. Multimodal would involve combining different data types, like text and images. The paper is about point clouds, which are a single data modality, so maybe not multimodal. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like some NLP models. The title doesn't mention retrieval or generation, so probably not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on representation learning for point clouds, not on building or using knowledge graphs. \n\nSo, none of the four topics seem to fit. The paper is about a specific regularization method for point cloud data, which isn't covered by the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32179@AAAI"},
{"title": "Learning Fine-grained Domain Generalization via Hyperbolic State Space Hallucination", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning Fine-grained Domain Generalization via Hyperbolic State Space Hallucination.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Domain Generalization\" refers to making models work well on unseen domains, which is a common problem in machine learning. The method mentioned here is \"Hyperbolic State Space Hallucination.\" Hyperbolic geometry is often used in knowledge graphs (KG) because it can represent hierarchical data efficiently. State space models are typically used in time-series analysis, but the term \"hallucination\" here might be a red herring. \n\nWait, \"hallucination\" in this context might refer to generating or imagining states, which could be part of a model's training process. But hyperbolic space is more associated with knowledge graphs. Also, the paper is about domain generalization, which isn't directly one of the four topics. \n\nLooking at the options: time-series usually involves sequential data over time. Multimodal deals with multiple data types like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models. KG (Knowledge Graphs) involves structured data and relationships. \n\nThe use of hyperbolic space suggests a connection to knowledge graphs, as hyperbolic embeddings are used there. So even though the main focus is domain generalization, the method might be related to knowledge graphs. Therefore, the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32180@AAAI"}
{"title": "DGFamba: Learning Flow Factorized State Space for Visual Domain Generalization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DGFamba: Learning Flow Factorized State Space for Visual Domain Generalization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual Domain Generalization\" suggests that the research is about making models work well across different visual domains. That's about generalization, so maybe transfer learning or domain adaptation. But the question is about the topic category. \n\nThe term \"Flow Factorized State Space\" might be a model or method they're using. \"Flow\" could refer to something like normalizing flows in machine learning, which are used for density estimation. \"Factorized\" might mean they're decomposing the state space into components. \n\nNow, looking at the options. Time-series would involve sequences over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on visual domain generalization. The method mentioned doesn't seem to directly relate to time-series data. It's about visual data, so maybe multimodal if they're combining different modalities, but the title doesn't mention that. The term \"Flow Factorized State Space\" doesn't immediately connect to RAG or KG. RAG is more about retrieval and generation, and KG is about structured knowledge. \n\nSo, none of the four topics seem to fit. The paper is about domain generalization in visual data using a specific state space model, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32181@AAAI"},
{"title": "CustomTTT: Motion and Appearance Customized Video Generation via Test-Time Training", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CustomTTT: Motion and Appearance Customized Video Generation via Test-Time Training.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on video generation. The key terms here are \"Motion and Appearance Customized\" and \"Test-Time Training.\" \n\nTime-series usually involves data that is sequential over time, like stock prices or sensor data. Video is a form of time-series data because it's a sequence of frames over time. So maybe this could be related to time-series. But the other topics might also be relevant.\n\nMultimodal refers to combining multiple types of data, like text and images, or audio and video. The paper mentions both motion and appearance, which are different aspects of video. However, multimodal typically involves different modalities (e.g., text, image, audio), not just different aspects of the same modality. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information during generation. The title doesn't mention anything about retrieval or augmenting generation with external data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, the main contenders are time-series and multimodal. Since the paper is about video generation, which is inherently a time-series problem (sequence of frames), and the customization of motion (which is temporal) and appearance (spatial), it's likely related to time-series. The test-time training part might refer to adapting the model during inference, but the core data being handled is a time-series. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32182@AAAI"},
{"title": "MotionCraft: Crafting Whole-Body Motion with Plug-and-Play Multimodal Controls", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MotionCraft: Crafting Whole-Body Motion with Plug-and-Play Multimodal Controls.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Crafting Whole-Body Motion\" suggests it's about generating or controlling motion, maybe in robotics or animation. The key part here is \"Plug-and-Play Multimodal Controls.\" The word \"multimodal\" is right there. Multimodal typically refers to using multiple types of data or modalities, like combining text, images, audio, etc. So if the paper is about integrating different modalities for control, that would fall under the multimodal category.\n\nLet me check the other options. Time-series usually involves data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generative models. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about time-based data, retrieval, or knowledge graphs. The focus is on multimodal controls for motion, so the most fitting topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32183@AAAI"},
{"title": "FAMNet: Frequency-aware Matching Network for Cross-domain Few-shot Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FAMNet: Frequency-aware Matching Network for Cross-domain Few-shot Medical Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key parts here are \"Cross-domain Few-shot Medical Image Segmentation.\" So, the main focus is on medical image segmentation, which is a computer vision task. The term \"cross-domain\" suggests that the model is trained on one domain and applied to another, which is common in few-shot learning scenarios. Few-shot learning typically deals with learning from very few examples, which is a challenge in machine learning.\n\nNow, looking at the four options. Time-series analysis involves data points indexed in time order, like stock prices or sensor data over time. The paper here is about image segmentation, which is more spatial than temporal, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images, or audio and video. The title doesn't mention anything about combining different data modalities. It's focused on medical images, which is a single modality. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method used in natural language processing where a model retrieves relevant information from a database to enhance its responses. This seems more related to text generation and retrieval systems. The paper here is about image segmentation, so RAG doesn't seem to fit.\n\nKG is Knowledge Graph, which involves structured data representations, often used for semantic relationships between entities. The paper's title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nThe paper introduces a \"Frequency-aware Matching Network,\" which might involve analyzing the frequency components of images, perhaps using Fourier transforms or similar techniques. However, the core research topic here is about improving few-shot learning in cross-domain medical image segmentation. None of the four listed topics (time-series, multimodal, RAG, KG) directly relate to this. The paper is about a specific application in computer vision, particularly in medical imaging, using a novel network architecture. Since none of the provided options match this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32184@AAAI"},
{"title": "Dynamic Adapter with Semantics Disentangling for Cross-lingual Cross-modal Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dynamic Adapter with Semantics Disentangling for Cross-lingual Cross-modal Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-lingual\" means it deals with multiple languages. \"Cross-modal\" suggests it's about different types of data, like text and images. So cross-modal retrieval is about retrieving information across different modalities. That makes me think of multimodal, since multimodal research often involves combining different data types. \n\nThe other parts of the title mention a dynamic adapter and semantics disentangling. The dynamic adapter might be a component that adjusts during processing, and semantics disentangling could be about separating different aspects of meaning. But the key terms here are cross-modal and cross-lingual. \n\nTime-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is a specific method combining retrieval and generation, but the title doesn't mention generation. KG (Knowledge Graph) involves structured data, which isn't directly mentioned either. \n\nSo the main focus is cross-modal retrieval, which falls under multimodal. The cross-lingual aspect is an additional feature but the core is multimodal. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32186@AAAI"},
{"title": "Divide-and-Conquer: Tree-structured Strategy with Answer Distribution Estimator for Goal-Oriented Visual Dialogue", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Divide-and-Conquer: Tree-structured Strategy with Answer Distribution Estimator for Goal-Oriented Visual Dialogue.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Goal-Oriented Visual Dialogue\" suggests that the research is about conversations where the goal is to achieve something, and it involves visual elements. So, visual dialogue usually combines text and images, which makes me think of multimodal data. Multimodal refers to using multiple types of data, like text and images together. \n\nThe \"Tree-structured Strategy\" part might be about the method they use, maybe a hierarchical approach. The \"Answer Distribution Estimator\" could be part of the model's architecture. But the key here is the application area. Since it's a visual dialogue, combining visual (images) and textual (dialogue) inputs, that's a classic multimodal scenario. \n\nTime-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which uses external knowledge retrieval. KG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about time, retrieval, or knowledge graphs. So the most likely topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32187@AAAI"},
{"title": "Object-level Geometric Structure Preserving for Natural Image Stitching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Object-level Geometric Structure Preserving for Natural Image Stitching.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title here is about image stitching, which is more about combining images, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions natural image stitching, which is about images, but there's no mention of other data types. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The title doesn't seem related to retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The title talks about geometric structure in images, but not in the context of a knowledge graph. It's more about preserving the structure during image stitching.\n\nSo, none of the four topics seem to fit. The paper is about image processing, specifically preserving geometric structures when stitching images. The given options don't cover this area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32188@AAAI"},
{"title": "Zero-shot Video Restoration and Enhancement Using Pre-Trained Image Diffusion Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Zero-shot Video Restoration and Enhancement Using Pre-Trained Image Diffusion Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or sensor data. Video is a time-series because it's a sequence of frames over time. So video restoration and enhancement would involve processing that sequence. But the title mentions using a pre-trained image diffusion model. Image models are typically for single images, not sequences. However, applying an image model to video might involve some time-series aspects, but maybe not the main focus here.\n\nMultimodal refers to combining multiple types of data, like text and images, or audio and video. The title is about video, which is a single modality (visual), unless they're combining with another modality. The title doesn't mention other modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate text based on that. The title doesn't mention anything about retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo the main question is whether it's time-series or not. The task is video restoration and enhancement. Video is a time-series of images, so processing video could be considered time-series analysis. However, the method used here is a pre-trained image diffusion model. If they're applying an image model to each frame without considering the temporal aspect, maybe it's not a traditional time-series approach. But the problem itself (video) is inherently time-series. However, the research topic might be more about the application (video processing) rather than the time-series methodology. The title doesn't mention time-series explicitly, so maybe the answer is none. Wait, but the options are time-series, multimodal, RAG, KG. If the paper is about video processing using image models, maybe it's not time-series. Alternatively, if the focus is on the temporal aspects of video, then time-series. But the title says \"using pre-trained image diffusion model,\" which suggests they're using a model trained on images for video, which might not involve time-series techniques. So perhaps it's not time-series. Then, none of the options fit. So the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32189@AAAI"},
{"title": "ObjVariantEnsemble: Advancing Point Cloud LLM Evaluation in Challenging Scenes with Subtly Distinguished Objects", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ObjVariantEnsemble: Advancing Point Cloud LLM Evaluation in Challenging Scenes with Subtly Distinguished Objects.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Point Cloud LLM Evaluation\" suggests they're working with large language models (LLMs) in the context of point clouds, which are 3D data points. The term \"ObjVariantEnsemble\" might refer to an ensemble method for object variants. The focus is on challenging scenes where objects are subtly different.\n\nNow, the four options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper is about evaluating LLMs with point cloud data. Point clouds are a type of data modality, so if they're combining point clouds with text (since LLMs process text), that would be multimodal. The challenge here is handling subtle differences in objects, which might require integrating different data types. So, multimodal seems likely. The other options don't fit: it's not about time-series data, RAG, or knowledge graphs. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32190@AAAI"},
{"title": "Adaptive Guidance: Training-free Acceleration of Conditional Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adaptive Guidance: Training-free Acceleration of Conditional Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Conditional Diffusion Models\" are a type of generative model, right? They're used for generating data by gradually denoising it. The term \"training-free\" suggests that the method doesn't require retraining the model, which is interesting. \"Acceleration\" implies making the model run faster or more efficiently. \"Adaptive Guidance\" might refer to adjusting the guidance during the diffusion process to speed things up without training.\n\nNow, the possible topics. Time-series would involve data over time, like stock prices or weather. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external information retrieval to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on accelerating diffusion models without training. Diffusion models are typically used in image or audio generation, which are unimodal. There's no mention of combining different modalities, so probably not multimodal. It's not about time-series data either. RAG and KG are more about integrating external knowledge or retrieval systems. The paper seems to be about optimizing the model's inference process, not about retrieval or knowledge graphs. So, none of the four topics seem to fit. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32192@AAAI"}
{"title": "Deep Graph Online Hashing for Multi-Label Image Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Deep Graph Online Hashing for Multi-Label Image Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Deep Graph\" suggests something related to graphs, maybe knowledge graphs (KG) since they often use graph structures. \"Online Hashing\" might be about hashing techniques for efficient retrieval. \"Multi-Label Image Retrieval\" indicates that the work is about retrieving images with multiple labels, which could be a multimodal task if it combines different data types like images and text. But wait, multimodal usually refers to combining multiple modalities (e.g., text, image, audio). Here, the focus is on image retrieval with multiple labels, which might not necessarily involve multiple modalities. \n\nRAG (Retrieval-Augmented Generation) is more about using retrieval to augment generation models, like in question-answering systems. The title doesn't mention generation, so probably not RAG. Time-series is about sequential data over time, which doesn't seem relevant here. \n\nThe \"Deep Graph\" part makes me think of Knowledge Graphs (KG), which are structured representations of knowledge. If the method uses graph structures for hashing in image retrieval, maybe it's leveraging a knowledge graph. However, the term \"Deep Graph\" could also refer to graph neural networks. But the key here is the application in image retrieval with multi-labels. If the graph is part of the model architecture rather than a knowledge base, maybe it's not KG. \n\nAlternatively, multimodal could be a fit if the image retrieval involves combining different data types. But the title only mentions image retrieval with multi-labels, which are just labels (maybe text labels) for the images. So it's possible that the model uses both image data and their labels, making it multimodal. But I'm not entirely sure. \n\nWait, the problem is multi-label image retrieval. So each image has multiple labels, but the retrieval is based on those labels. If the method uses a graph to model relationships between labels or images, that's more about the structure of the data rather than combining different modalities. So maybe it's not multimodal. \n\nGiven that, the most likely candidate is Knowledge Graph (KG) if the graph is representing a knowledge base. However, the term \"Deep Graph\" might refer to a graph neural network approach, which is different from a knowledge graph. But the title doesn't explicitly mention knowledge graphs. \n\nHmm. The options are time-series, multimodal, RAG, KG. Since the paper is about image retrieval with multi-labels using a deep graph model, and none of the other topics fit, maybe it's none. But I need to check again. \n\nMultimodal requires combining different data types. If the image and its labels are considered different modalities, then it's multimodal. But typically, multimodal refers to combining data like text and images, not just multiple labels for the same image. So maybe it's not multimodal. \n\nRAG is about retrieval-augmented generation, which isn't mentioned here. Time-series is unrelated. So the answer might be none. But wait, the user's options include KG. If the graph is part of a knowledge graph, then it's KG. But the title doesn't specify that. The term \"Deep Graph\" could be a graph neural network, which is a different area. \n\nI think the correct answer here is none because the paper's focus is on image retrieval with a graph-based hashing method, which doesn't clearly fit into the four categories provided. The topics given are time-series, multimodal, RAG, or KG. Since the paper isn't about time-series data, doesn't combine multiple modalities, isn't RAG, and doesn't explicitly mention knowledge graphs, the answer should be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32191@AAAI"},
{"title": "Adaptive Guidance: Training-free Acceleration of Conditional Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adaptive Guidance: Training-free Acceleration of Conditional Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Conditional Diffusion Models\" are a type of generative model, right? They're used for generating data by gradually denoising it. The term \"training-free\" suggests that the method doesn't require retraining the model, which is interesting. \"Acceleration\" implies making the model run faster or more efficiently. \"Adaptive Guidance\" might refer to adjusting the guidance during the diffusion process to speed things up without training.\n\nNow, the possible topics. Time-series would involve data over time, like stock prices or weather. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external information retrieval to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on accelerating diffusion models without training. Diffusion models are typically used in image or audio generation, which are unimodal. There's no mention of combining different modalities, so probably not multimodal. It's not about time-series data either. RAG and KG are more about integrating external knowledge or retrieval systems. The paper seems to be about optimizing the model's inference process, not about retrieval or knowledge graphs. So, none of the four topics seem to fit. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32192@AAAI"},
{"title": "Segment Any 3D Gaussians", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Segment Any 3D Gaussians.\" Hmm. I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. This title mentions 3D Gaussians, which sounds more like a spatial or geometric problem, not time-based. So probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities. It's about segmenting 3D Gaussians, which might be a specific technical task in computer vision or graphics. Not sure if multimodal here.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't seem related to retrieval or generation. It's about segmentation, which is more of a computer vision task. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge or graphs in that sense. It's about 3D Gaussians, which could be related to 3D modeling or point clouds. So probably not KG.\n\nSo the options are none of the above. The paper seems to be about 3D Gaussian segmentation, which might fall under computer vision or machine learning techniques for 3D data. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32193@AAAI"},
{"title": "Text2Relight: Creative Portrait Relighting with Text Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Text2Relight: Creative Portrait Relighting with Text Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nNext, multimodal. That refers to using multiple types of data, like text and images together. The title mentions \"Text Guidance,\" which suggests using text as input. If the paper uses text to guide a process that involves images (like relighting a portrait), that's combining text and visual data. So multimodal might be a fit here.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to pull information from a database and then generates a response. The title doesn't mention anything about retrieval or augmenting generation with external data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem to involve building or using a knowledge graph, so probably not KG.\n\nSo the most likely answer is multimodal because it's using text (a modality) to guide an image processing task (another modality). The combination of text and image processing points to multimodal research.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32194@AAAI"},
{"title": "KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image Sequences", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image Sequences.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Keyframe-Centric\" suggests that the method focuses on keyframes, which are important frames in a sequence. \"Gaussian Splatting\" is a technique used in 3D reconstruction, where points are rendered as Gaussian distributions. \"Monocular Image Sequences\" means it's using a single camera's images over time, so it's dealing with sequences of images taken one after another.\n\nTime-series analysis involves data points indexed in time order. Since the method is for image sequences, which are inherently time-ordered, this might be a candidate. But I need to check the other options.\n\nMultimodal refers to combining multiple data types, like text and images. The title mentions monocular image sequences, which is a single modality (images), so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't indicate anything related to knowledge graphs either.\n\nSo, the main contenders are time-series and none. The method processes image sequences, which are time-ordered. Gaussian splatting in this context is applied to sequences, so it's handling data over time. Therefore, it might fall under time-series. However, sometimes image sequences in computer vision are considered as sequences but not necessarily time-series in the traditional sense (like stock prices or sensor data). But since the question includes time-series as a possible category, and the method is for monocular image sequences, which are time-based, I think time-series is the right choice here.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32195@AAAI"},
{"title": "WaterDiffusion: Learning a Prior-involved Unrolling Diffusion for Joint Underwater Saliency Detection and Visual Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"WaterDiffusion: Learning a Prior-involved Unrolling Diffusion for Joint Underwater Saliency Detection and Visual Restoration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about underwater saliency detection and visual restoration. Saliency detection is about identifying important regions in images, and visual restoration could involve tasks like deblurring or denoising. These are image processing tasks, but does it use multiple modalities? The title doesn't mention combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus seems to be on a diffusion model for image processing, not on building or using a knowledge graph. So KG is unlikely.\n\nThe paper is about a diffusion model applied to underwater image tasks. Diffusion models are a type of generative model, but the given options don't include generative models. The four topics are time-series, multimodal, RAG, KG. None of these seem to fit. The paper is about a specific application of a diffusion model in computer vision, which isn't covered by the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32196@AAAI"},
{"title": "RFL: Simplifying Chemical Structure Recognition with Ring-Free Language", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RFL: Simplifying Chemical Structure Recognition with Ring-Free Language.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"RFL\" is probably the acronym for the method or framework. \"Simplifying Chemical Structure Recognition\" suggests that the paper is about making it easier to recognize chemical structures. \"Ring-Free Language\" might refer to a way of representing chemical structures without rings, which are common in molecules. \n\nNow, the possible topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. KG is Knowledge Graphs, which are structured representations of information, often used to link entities and their relationships.\n\nThe paper's focus is on chemical structure recognition. That's more about processing molecular structures, which are typically represented as graphs (like SMILES strings or molecular graphs). The mention of \"Ring-Free Language\" might be a novel way to represent these structures without considering ring structures, which could simplify the recognition process. \n\nLooking at the topics, none of them directly relate to chemical structure recognition. Time-series is unrelated. Multimodal could be if they're combining different data types, but the title doesn't mention that. RAG and KG are about information retrieval and knowledge representation, which might be tangentially related if the paper uses a knowledge graph for chemical structures, but the title doesn't specify that. The main focus here is on a new language or representation for chemical structures, which doesn't fit into the given categories. \n\nSo, the answer should be \"none\" because the paper's topic isn't covered by the provided options.\n</think>\n\nnone", "url": "https://papers.cool/venue/32197@AAAI"},
{"title": "Motion-Zero: A Zero-Shot Trajectory Control Framework of Moving Object for Diffusion-Based Video Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Motion-Zero: A Zero-Shot Trajectory Control Framework of Moving Object for Diffusion-Based Video Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Motion-Zero\" probably refers to a framework. The key parts here are \"trajectory control,\" \"moving object,\" and \"diffusion-based video generation.\" \n\nTime-series analysis usually involves data points indexed in time order, like stock prices over time or sensor data. This paper is about controlling the trajectory of moving objects in video generation. Video data is inherently time-series because it's a sequence of frames over time. So maybe it's related to time-series. But the main focus here is on trajectory control, which is about how objects move through space over time. That does sound like time-series data processing.\n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention anything about combining different data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or augmenting generation with external data, so RAG is unlikely.\n\nKG is Knowledge Graph, which involves structured data representations. Again, the title doesn't mention knowledge graphs or structured data, so that's probably not it.\n\nSo the most likely topic here is time-series. The framework deals with controlling trajectories over time in video generation, which is a time-dependent process. Even though the paper might use other techniques, the core aspect of trajectory control in a video (a sequence of frames) aligns with time-series analysis.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32198@AAAI"},
{"title": "Sharpening Neural Implicit Functions with Frequency Consolidation Priors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sharpening Neural Implicit Functions with Frequency Consolidation Priors.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Neural Implicit Functions\" probably refers to using neural networks to model implicit functions, which are mathematical functions defined implicitly rather than explicitly. \"Sharpening\" might mean making these functions more precise or accurate. \"Frequency Consolidation Priors\" sounds like a method involving frequency domain techniques, maybe using Fourier transforms or something similar to consolidate or refine the function's parameters.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or sensor data. Multimodal refers to combining different types of data, like text and images. RAG (Retrieval-Augmented Generation) is about enhancing models with external information retrieval. KG (Knowledge Graphs) involves structured data representations, like relationships between entities.\n\nThe paper's title doesn't mention anything about time-based data, so time-series is probably out. There's no indication of combining multiple data modalities, so multimodal isn't it. RAG and KG are more about data retrieval or structured knowledge, which doesn't seem to align with the title's focus on neural implicit functions and frequency-based methods. The paper seems to be about improving neural network models through a specific mathematical approach, which doesn't fit any of the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32199@AAAI"},
{"title": "Skeleton-based Action Recognition with Non-linear Dependency Modeling and Hilbert-Schmidt Independence Criterion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Skeleton-based Action Recognition with Non-linear Dependency Modeling and Hilbert-Schmidt Independence Criterion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, skeleton-based action recognition. That usually involves analyzing sequences of movements over time, right? So maybe time-series? Because actions are performed over time, and the data is sequential. But wait, the other parts of the title mention non-linear dependency modeling and Hilbert-Schmidt Independence Criterion. Those terms sound like they might be about capturing dependencies between different parts of the skeleton data. \n\nMultimodal would involve combining different types of data, like text and images, but here it's just skeleton data, which is a single modality. So probably not multimodal. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, typically in NLP. That doesn't seem related here. KG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs, so that's out.\n\nSo the main question is whether it's time-series or not. Since action recognition using skeleton data is inherently temporal, as actions unfold over time, the data is a time series. The non-linear dependency modeling might be about how different joints or parts of the skeleton interact over time. The Hilbert-Schmidt Independence Criterion is a statistical method for measuring independence between variables, which could be used to model dependencies in the time series data. So I think the topic here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32201@AAAI"}
{"title": "Skeleton-based Action Recognition with Non-linear Dependency Modeling and Hilbert-Schmidt Independence Criterion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Skeleton-based Action Recognition with Non-linear Dependency Modeling and Hilbert-Schmidt Independence Criterion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, skeleton-based action recognition. That usually involves analyzing sequences of movements over time, right? So maybe time-series? Because actions are performed over time, and the data is sequential. But wait, the other parts of the title mention non-linear dependency modeling and Hilbert-Schmidt Independence Criterion. Those terms sound like they might be about capturing dependencies between different parts of the skeleton data. \n\nMultimodal would involve combining different types of data, like text and images, but here it's just skeleton data, which is a single modality. So probably not multimodal. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, typically in NLP. That doesn't seem related here. KG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs, so that's out.\n\nSo the main question is whether it's time-series or not. Since action recognition using skeleton data is inherently temporal, as actions unfold over time, the data is a time series. The non-linear dependency modeling might be about how different joints or parts of the skeleton interact over time. The Hilbert-Schmidt Independence Criterion is a statistical method for measuring independence between variables, which could be used to model dependencies in the time series data. So I think the topic here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32201@AAAI"},
{"title": "Causal-Inspired Multitask Learning for Video-Based Human Pose Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Causal-Inspired Multitask Learning for Video-Based Human Pose Estimation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Causal-Inspired\" probably refers to using causal reasoning in the model. \"Multitask Learning\" means the model is trained to perform multiple tasks simultaneously. \"Video-Based Human Pose Estimation\" suggests that the input is video data, and the task is estimating human poses.\n\nNow, the four options. Time-series usually involves data points indexed in time order, like stock prices over time. Since the input is video, which is a sequence of frames over time, that could be time-series. But the main focus here is on pose estimation, which is a computer vision task. However, video data inherently has a temporal component, so maybe time-series is a candidate.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about video, which is a single modality (visual), so maybe not multimodal unless they're combining other modalities too. The title doesn't mention other modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, common in NLP tasks. The paper is about pose estimation, which is a vision task, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which involve structured data and relationships. The title doesn't mention anything about knowledge graphs or structured data, so probably not KG.\n\nSo the main contenders are time-series and multimodal. Since the input is video (a time series of images), but the primary task is pose estimation, which is a computer vision problem. However, the temporal aspect of video does make it a time-series. But sometimes, in computer vision, video processing is considered a separate domain. However, the question is about the research topic. If the paper's focus is on the temporal aspect of the video data, then time-series. But if it's just using video as input without focusing on the time-series aspect, maybe not. The title mentions \"video-based,\" which implies sequential frames, so time-series could be applicable. But I'm a bit unsure because in some contexts, video processing is considered multimodal if combining different modalities, but here it's just video. So the answer might be time-series. Alternatively, if the paper is about combining different tasks (multitask learning) but not necessarily different modalities, then multimodal isn't the right term. So the best fit here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32202@AAAI"},
{"title": "Enhancing Adversarial Transferability with Adversarial Weight Tuning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Adversarial Transferability with Adversarial Weight Tuning.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Adversarial transferability\" sounds like it's related to adversarial attacks in machine learning, where an attack is designed to be effective across different models or systems. \"Adversarial weight tuning\" probably refers to adjusting the weights in a model to improve how well these adversarial examples transfer between different models. \n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on adversarial attacks and improving their transferability. None of the four topics directly relate to adversarial machine learning. Time-series is about temporal data, multimodal is about multiple data types, RAG is about retrieval and generation, and KG is about structured knowledge. The paper's subject is about making adversarial examples more transferable, which is a security or robustness issue in ML, not directly related to any of the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32203@AAAI"},
{"title": "Adversarial Learning Under Hybrid Perturbations for Robust Acute Lymphoblastic Leukemia Classification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adversarial Learning Under Hybrid Perturbations for Robust Acute Lymphoblastic Leukemia Classification.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. Adversarial learning is a method used to make models more robust by introducing adversarial examples. Hybrid perturbations probably refer to combining different types of perturbations in the adversarial training. The application here is for classifying Acute Lymphoblastic Leukemia, which is a medical condition. \n\nNow, the four options. Time-series would involve data that's sequential over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like some chatbots. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on adversarial learning for robust classification in a medical context. There's no mention of time-series data, so that's probably not it. It's about making a classifier robust, not combining different data modalities, so multimodal might not fit. RAG and KG are more about information retrieval and knowledge representation, which don't seem directly related to adversarial training for leukemia classification. \n\nSo, none of the four topics seem to fit. The paper is about adversarial learning in a medical classification task, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32204@AAAI"},
{"title": "Ouroboros-Diffusion: Exploring Consistent Content Generation in Tuning-free Long Video Diffusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Ouroboros-Diffusion: Exploring Consistent Content Generation in Tuning-free Long Video Diffusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Long Video Diffusion\" suggests that the paper is about generating long videos using diffusion models. Diffusion models are a type of generative model, often used in image and video generation. The term \"tuning-free\" might mean that they don't require fine-tuning or parameter adjustments, which is a methodological aspect. \"Consistent Content Generation\" implies maintaining coherence or consistency in the generated content over time, which is a common challenge in video generation.\n\nNow, looking at the possible topics. Time-series research deals with data that is sequential over time, like stock prices or sensor data. Video data is inherently time-series because it's a sequence of frames. So, if the paper is about generating long videos, it's likely dealing with time-series data. \n\nMultimodal refers to combining multiple types of data, like text and images, or audio and video. The title doesn't mention combining different modalities, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model uses retrieved information to enhance its generation. The title doesn't mention retrieval or augmenting with external data, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't indicate the use of knowledge graphs, so that's probably out. \n\nSo, the key here is the \"Long Video Diffusion\" part. Since video is a time-series of frames, and the paper is about generating long videos, it's dealing with time-series data. The focus on consistent content generation over time also aligns with time-series challenges. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32205@AAAI"},
{"title": "GigaGS: 3D Gaussian Based Planar Representation for Large-Scene Surface Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GigaGS: 3D Gaussian Based Planar Representation for Large-Scene Surface Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title mentions 3D Gaussian and surface reconstruction, which sounds more like computer vision or graphics. So probably not time-series.\n\nMultimodal refers to combining different data types, like text and images. The title doesn't mention anything about combining different modalities. It's focused on a specific representation method for 3D scenes. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's title is about a 3D planar representation for surface reconstruction. That's more about geometric modeling rather than structured knowledge. \n\nSo none of the four topics seem to fit. The paper is about 3D reconstruction using Gaussian-based methods, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32206@AAAI"},
{"title": "Rethinking High-speed Image Reconstruction Framework with Spike Camera", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Rethinking High-speed Image Reconstruction Framework with Spike Camera.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"High-speed Image Reconstruction\" suggests they're working on reconstructing images quickly. \"Spike Camera\" might refer to a type of camera that captures data in spikes, maybe like neuromorphic sensors which capture events asynchronously. That's often used in time-series data because the spikes are temporal events. \n\nTime-series analysis deals with data points indexed in time order. If the camera is capturing spikes over time, then the data would be time-series. The reconstruction process might involve processing these time-based signals. \n\nMultimodal would involve combining different types of data, like text and images, but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generative models, which doesn't seem related here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo the most likely topic here is time-series because the spike camera's data is inherently temporal, and the reconstruction would involve time-series processing techniques.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32207@AAAI"},
{"title": "Dual-Level Precision Edges Guided Multi-View Stereo with Accurate Planarization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dual-Level Precision Edges Guided Multi-View Stereo with Accurate Planarization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View Stereo\" sounds like computer vision, maybe 3D reconstruction from multiple images. \"Dual-Level Precision Edges\" might refer to edge detection at different levels of detail. \"Accurate Planarization\" could be about making surfaces flat or accurate in the 3D model.\n\nNow, the options. Time-series is about data over time, like stock prices or weather. This title doesn't mention time, so probably not that. Multimodal usually involves combining different data types, like text and images. The paper here seems focused on stereo vision, which is about using multiple images (views) to create a 3D model. So maybe multimodal? But wait, multimodal is more about different modalities (e.g., text, audio, video), whereas multi-view stereo is about multiple camera views of the same scene. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is in NLP, using external data for generating responses. Doesn't seem related here. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data.\n\nSo, the paper is about 3D reconstruction using multiple views, which is a computer vision technique. The options given don't include computer vision or 3D reconstruction. The closest might be multimodal if \"multi-view\" is considered multiple modalities, but I think multimodal is more about different data types. Since none of the four topics fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32208@AAAI"},
{"title": "Contrasting Adversarial Perturbations: The Space of Harmless Perturbations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Contrasting Adversarial Perturbations: The Space of Harmless Perturbations.\" I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Adversarial perturbations are small changes made to input data that can cause machine learning models to make mistakes. The paper is contrasting these adversarial perturbations with harmless ones. So, it's about understanding the difference between perturbations that are harmful (adversarial) and those that aren't. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generative models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title doesn't mention anything about time-based data, so time-series is probably not it. There's no indication of combining multiple data types, so multimodal is out. RAG and KG are more about specific techniques or structures. The paper seems focused on adversarial examples and perturbations, which is a topic in machine learning security or robustness. None of the four topics listed (time-series, multimodal, RAG, KG) directly relate to adversarial perturbations. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32209@AAAI"},
{"title": "CustomContrast: A Multilevel Contrastive Perspective for Subject-Driven Text-to-Image Customization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CustomContrast: A Multilevel Contrastive Perspective for Subject-Driven Text-to-Image Customization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-to-Image Customization\" suggests that the paper is about generating images based on text, which is a common task in multimodal learning because it involves both text (language) and images (vision). So multimodal is a possibility. \n\nThe term \"Multilevel Contrastive Perspective\" might refer to using contrastive learning techniques, which are often used in multimodal models to align different modalities. But contrastive learning itself isn't one of the listed topics. The key here is the combination of text and image, which points to multimodal. \n\nLooking at the other options: time-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in text. KG (Knowledge Graphs) involves structured data and relationships. The title doesn't mention anything about time, retrieval, or knowledge graphs. \n\nSo the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32210@AAAI"}
{"title": "IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Image-enhanced\" suggests that images are involved. \"Prompt Decoding Network\" might relate to using prompts, which could be part of something like RAG (Retrieval-Augmented Generation), but I'm not sure yet. The task is \"3D Referring Expression Segmentation,\" which sounds like a computer vision task where you segment parts of a 3D model based on a referring expression, like a natural language instruction.\n\nNow, the options. Time-series would involve data over time, like stock prices or sensor data. This doesn't seem to fit. Multimodal usually involves combining different data types, like text and images. The title mentions \"image-enhanced\" and \"referring expression,\" which is text. So combining image and text inputs, which is multimodal. \n\nRAG is about using retrieval to augment generation, often in NLP tasks. The paper's focus is on segmentation using a prompt, but I'm not sure if it's using retrieval. KG (Knowledge Graphs) involve structured data and relationships, which doesn't seem to be the case here. \n\nSo, the key here is the combination of image and text (referring expressions) for segmentation. That's a classic multimodal setup. The \"image-enhanced\" part suggests integrating visual data with another modality, likely text. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32211@AAAI"},
{"title": "CP-DETR: Concept Prompt Guide DETR Toward Stronger Universal Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CP-DETR: Concept Prompt Guide DETR Toward Stronger Universal Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. CP-DETR probably refers to a model or method. DETR is a known object detection model, right? So the paper is about improving DETR using concept prompts. The key part here is \"Concept Prompt Guide.\" \n\nNow, the four options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper's focus is on object detection, which is a computer vision task. The term \"Concept Prompt\" might relate to prompting techniques, which are common in multimodal models where you combine different modalities (like text and images). For example, using text prompts to guide image models. So if they're using concept prompts to guide the DETR model, that might be a multimodal approach, integrating textual concepts with visual data. \n\nRAG is more about retrieval during generation, which doesn't seem to fit here. KG involves structured knowledge, but the title doesn't mention graphs or structured data. Time-series is unrelated to object detection. So the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32212@AAAI"},
{"title": "Infinite-Canvas: Higher-Resolution Video Outpainting with Extensive Content Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Infinite-Canvas: Higher-Resolution Video Outpainting with Extensive Content Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Video Outpainting\" suggests generating content beyond the original video's frame, maybe extending it. \"Higher-Resolution\" implies working with detailed images or videos. \"Extensive Content Generation\" points to creating a lot of new content. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about video, which is a sequence of frames over time. However, the main focus here is on generating content beyond the existing video frames, which might involve spatial extension rather than temporal. But video inherently has a time component. However, the key terms are \"outpainting\" and \"content generation.\" Outpainting is similar to image generation beyond the existing borders, but for video. This could involve generating new frames or extending existing ones. \n\nMultimodal might be a stretch unless they're combining different modalities like text and video. The title doesn't mention that. RAG and KG are more about using external knowledge or retrieval. The title doesn't mention retrieval or knowledge graphs. \n\nSo, the closest might be time-series since video is a time-series of images. But outpainting is more about spatial extension. Wait, maybe not. Video outpainting could involve generating frames in time as well. But the term \"outpainting\" usually refers to spatial extension, like expanding the canvas of an image. For video, it might be extending the frame size in spatial dimensions, not adding more frames over time. So maybe it's not time-series. \n\nIf it's about generating content in the spatial domain for each frame, then it's more of a computer vision task. But the four options given don't include computer vision. The options are time-series, multimodal, RAG, KG. Since the paper is about video content generation, perhaps it's not fitting into any of these. But wait, maybe multimodal? If they're using multiple modalities, but the title doesn't indicate that. \n\nAlternatively, maybe it's a time-series because video is a sequence over time. But the main task is outpainting, which is spatial. Hmm. I'm a bit confused. Let me think again. The four options: time-series, multimodal, RAG, KG. The paper's title doesn't mention anything about combining different data types (multimodal), retrieval (RAG), or knowledge graphs (KG). The core is video generation, which is a type of time-series data. However, the specific task of outpainting might not be a time-series analysis. Time-series research usually involves forecasting, anomaly detection, etc. Outpainting is more about image or video generation, which might fall under computer vision or generative models. Since the options don't include those, maybe the answer is none. But I need to check if any of the four topics could fit. \n\nWait, maybe it's multimodal if they're using text or other modalities to guide the generation. The title doesn't mention that. The title is about video outpainting with extensive content generation. So, unless they're combining video with another modality, it's not multimodal. \n\nTherefore, the answer might be none. But I'm not entirely sure. Let me check again. The four options are time-series, multimodal, RAG, KG. The paper's topic is video outpainting. If video is considered a time-series, then maybe time-series. But outpainting is more about spatial generation. However, video is a time-series of images. So, if the research is about generating time-series data (video frames) in a higher resolution, maybe it's time-series. But the key term is \"outpainting,\" which is spatial. \n\nAlternatively, maybe the answer is none because the main focus isn't on time-series analysis, multimodal integration, RAG, or KG. The paper is about a specific video generation technique, which doesn't fit into the given categories. So, the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32213@AAAI"},
{"title": "Grounded Multi-Hop VideoQA in Long-Form Egocentric Videos", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Grounded Multi-Hop VideoQA in Long-Form Egocentric Videos.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Grounded\" might refer to grounding in the context of video understanding, which often involves linking visual elements to language. \"Multi-Hop VideoQA\" suggests that the research is about answering questions that require multiple steps or reasoning in videos. \"Long-Form Egocentric Videos\" are videos recorded from a first-person perspective, like those from a wearable camera, and they're long in duration.\n\nNow, the possible topics. Time-series usually deals with data points indexed in time order, common in forecasting or analysis over time. Multimodal refers to combining multiple data types, like text and video. RAG (Retrieval-Augmented Generation) is a method that uses retrieval of documents to aid in generating answers. KG (Knowledge Graph) involves structured data representations, often linking entities and their relationships.\n\nThe paper's focus is on video question answering, which is a multimodal task because it involves processing both video (visual) and text (questions/answers). The \"grounded\" part might imply that the model needs to connect the video content with the textual questions, which is a multimodal aspect. Multi-hop suggests that the model needs to perform multiple reasoning steps, but that's more about the complexity of the task rather than the modality. Since the input is video and text, and the task is to answer questions using both, this seems like a multimodal research topic. It doesn't seem to be about time-series data specifically, nor does it mention knowledge graphs or retrieval-augmented generation. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32214@AAAI"},
{"title": "Attribution Analysis Meets Model Editing: Advancing Knowledge Correction in Vision Language Models with VisEdit", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Attribution Analysis Meets Model Editing: Advancing Knowledge Correction in Vision Language Models with VisEdit.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Vision Language Models\" immediately makes me think of multimodal because they combine vision (images) and language (text). Multimodal models are all about integrating different types of data, like images and text. The paper is about knowledge correction in these models, which involves editing the model's knowledge. The method mentioned is VisEdit, which probably stands for Vision Editing. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not that. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance model outputs, often in text generation. The title doesn't mention retrieval or generation in that context. KG (Knowledge Graphs) are structured representations of knowledge, but the title is about editing models, not building or querying knowledge graphs. \n\nSo, the key terms here are \"Vision Language Models,\" which are definitely multimodal. The paper is about improving these models through knowledge correction, which is a part of multimodal research. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32215@AAAI"},
{"title": "Unsupervised Degradation Representation Aware Transform for Real-World Blind Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unsupervised Degradation Representation Aware Transform for Real-World Blind Image Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Unsupervised\" suggests it's a machine learning approach without labeled data. \"Degradation Representation Aware Transform\" might refer to a method that's aware of how images are degraded. \"Real-World Blind Image Super-Resolution\" is about enhancing low-resolution images without knowing the exact degradation process. So, the main focus here is image super-resolution, which is a computer vision task.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. Multimodal involves combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not that either. RAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents. KG is Knowledge Graphs, which are structured representations of information. The paper's focus is on image processing, specifically super-resolution, which doesn't seem to involve retrieval or knowledge graphs. \n\nSince the paper is about image super-resolution using an unsupervised method that's aware of degradation, it doesn't fit into any of the listed topics. The key areas here are computer vision and unsupervised learning, which aren't among the options provided. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32216@AAAI"},
{"title": "Motion Prior Knowledge Learning with Homogeneous Language Descriptions for Moving Infrared Small Target Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Motion Prior Knowledge Learning with Homogeneous Language Descriptions for Moving Infrared Small Target Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Motion Prior Knowledge Learning\" suggests they're using some kind of prior knowledge related to motion. \"Homogeneous Language Descriptions\" might mean they're using language or textual data that's consistent or uniform. The application is \"Moving Infrared Small Target Detection,\" which is about detecting small targets in infrared images that are moving.\n\nNow, the four options. Time-series usually involves data over time, like sequences. Multimodal refers to using multiple types of data, like combining text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP that uses external knowledge during generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper mentions \"Language Descriptions,\" which could be a modality, but the main focus here is on using language to inform the detection in infrared images. So maybe multimodal? But wait, multimodal typically involves combining different data types (like text and images). If they're using language descriptions to enhance the model's understanding of motion for detection, that could be multimodal. However, the title doesn't explicitly mention combining different modalities like images and text. It's more about using language to learn motion priors. \n\nAlternatively, if they're using a knowledge graph to structure the prior knowledge, that would be KG. But the term \"Knowledge Graph\" isn't in the title. \"Prior Knowledge Learning\" might imply using some structured knowledge, but without explicit mention of a graph structure, it's a stretch. \n\nRAG is about retrieval during generation, which doesn't seem to fit here. Time-series would involve temporal data, but the title doesn't mention sequences or time-based analysis. \n\nSo, the closest might be multimodal if they're integrating language (text) with infrared images (visual data). But the title doesn't clearly state that they're combining modalities. It's more about using language descriptions to learn motion priors for detection. Maybe it's not strictly multimodal. If the language is just a source of prior knowledge and not combined with another modality, then it might not fit into the four categories. \n\nHmm. The options are time-series, multimodal, RAG, KG. Since the paper is about using language (a modality) to inform another modality (infrared images), maybe it's multimodal. But I'm not entirely sure. Alternatively, if the language is part of the knowledge graph, but again, the title doesn't mention a graph. \n\nI think the best fit here is multimodal because they're using language (text) to enhance the model's performance in a visual task. So the answer would be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32217@AAAI"},
{"title": "Mixture-of-Attack-Experts with Class Regularization for Unified Physical-Digital Face Attack Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Mixture-of-Attack-Experts with Class Regularization for Unified Physical-Digital Face Attack Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Mixture-of-Attack-Experts\" sounds like a model that combines different experts, maybe for different types of attacks. \"Class Regularization\" might be a technique to prevent overfitting or improve generalization. The main goal is \"Unified Physical-Digital Face Attack Detection,\" which refers to detecting attacks in face recognition systems, both physical (like printed photos) and digital (like screen-based attacks).\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. Multimodal usually refers to combining different data types, like text and images. The paper is about face attack detection, which might involve different modalities (e.g., RGB and depth images), but the title doesn't explicitly state that. However, \"unified\" could imply combining different attack types, but not necessarily different data modalities.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to generate responses. This seems unrelated to face attack detection. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data.\n\nSo, the paper is about a method for detecting face attacks using a mixture of experts and class regularization. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The closest might be multimodal if the model uses different data types, but the title doesn't specify that. Since the problem is about face attack detection, which is more about computer vision and security, and none of the given topics directly apply, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32218@AAAI"},
{"title": "Cross-View Referring Multi-Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cross-View Referring Multi-Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-View\" probably means that the tracking is happening across different viewpoints or perspectives, maybe from different cameras or sensors. \"Referring\" might relate to referring expressions, like using language to point to specific objects. \"Multi-Object Tracking\" is about tracking multiple objects over time, which is common in computer vision tasks like surveillance or autonomous driving.\n\nNow, looking at the possible topics. Time-series usually involves data over time, which is part of tracking, but the question is whether the paper's main focus is on time-series analysis. However, multi-object tracking is a common application in time-series, but the title doesn't explicitly mention time-series methods. \n\nMultimodal refers to using multiple types of data, like combining visual and textual information. The \"Referring\" part might involve language (text) and visual data, so that's a possibility. For example, if the paper uses both images and text to track objects, that's multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval of information with generation, often in NLP tasks. I don't see a direct link here unless the paper uses retrieval methods for tracking, but the title doesn't suggest that.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. Unless the paper is building or using a knowledge graph for tracking, which isn't indicated in the title.\n\nPutting it together: \"Cross-View Referring\" suggests using different modalities (like different camera views and possibly language) to track objects. So multimodal seems likely. The \"referring\" part might involve natural language, making it a combination of vision and language, hence multimodal. Time-series is part of tracking, but the key differentiator here is the use of multiple modalities. So the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32219@AAAI"},
{"title": "H-MBA: Hierarchical MamBa Adaptation for Multi-Modal Video Understanding in Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"H-MBA: Hierarchical MamBa Adaptation for Multi-Modal Video Understanding in Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal Video Understanding\" immediately makes me think of multimodal, since that term is right there. The paper is about using multiple modalities, like combining different types of data (e.g., video, audio, sensor data) for understanding in autonomous driving. So that's a strong indicator for the multimodal category.\n\nThe other parts of the title mention \"Hierarchical MamBa Adaptation.\" MamBa might be a model or a technique, but the key part here is \"Multi-Modal,\" which is part of the title. The other options are time-series, RAG (Retrieval-Augmented Generation), and KG (Knowledge Graphs). None of those terms seem to be directly mentioned. Time-series would involve data over time, but the focus here is on multiple modalities. RAG and KG are more about integrating external knowledge or retrieval, which doesn't seem to be the case here. The paper is about adapting a model for multi-modal data, so the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32220@AAAI"}
{"title": "DiffDVC: Accurate Event Detection for Dense Video Captioning via Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffDVC: Accurate Event Detection for Dense Video Captioning via Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dense Video Captioning\" suggests that the paper is about generating captions for videos, which involves both visual and textual data. So that's a hint towards multimodal, since it's combining different data types—video (visual) and captions (text). \n\nThen, \"Event Detection\" is part of the process, which in video context would involve identifying specific events or actions in the video. But the key part here is \"via Diffusion Models.\" Diffusion models are a type of generative model, often used in image and video generation. However, the main focus here is on using diffusion models for event detection in video captioning. \n\nNow, looking at the four options. Time-series usually refers to data over time, like stock prices or sensor data. While video is a time-series of frames, the primary application here isn't about time-series analysis per se but about video content understanding. \n\nMultimodal would involve combining multiple modalities, like text and video. Since the paper is about video captioning, which combines visual and textual information, that's a strong candidate. \n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to augment its generation. The title doesn't mention anything about retrieval or augmenting with external data, so probably not RAG. \n\nKG (Knowledge Graphs) involve structured data and relationships. The title doesn't mention knowledge graphs or structured data, so that's out. \n\nSo, the most likely answer is multimodal. The paper deals with video (visual) and captions (text), making it a multimodal task. Even though diffusion models are used, the core research topic here is the multimodal aspect of video captioning.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32221@AAAI"},
{"title": "FIRM: Flexible Interactive Reflection ReMoval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FIRM: Flexible Interactive Reflection ReMoval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Reflection ReMoval\" suggests it's about removing reflections from something, maybe images or videos. The term \"Flexible Interactive\" might imply that the method allows for user interaction or adaptability. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus on removing reflections sounds like an image processing or computer vision task. None of the listed topics directly relate to image processing. Time-series is about sequential data over time, which doesn't fit. Multimodal could be if it uses multiple data types, but the title doesn't mention that. RAG and KG are more about information retrieval and knowledge representation, which also don't seem relevant here. \n\nSince the paper is about a specific image processing technique and none of the given topics cover that, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32222@AAAI"},
{"title": "SUTrack: Towards Simple and Unified Single Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SUTrack: Towards Simple and Unified Single Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Single Object Tracking\" is the main part. Tracking usually involves following an object over time, which might relate to time-series data. Time-series analysis deals with data points indexed in time order, so tracking an object's movement over time could fit here. But I should check the other options too.\n\nMultimodal refers to using multiple types of data (like text, images, audio) together. The title doesn't mention anything about combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't seem related to retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The title doesn't mention knowledge graphs or structured data, so that's probably out.\n\nSo the most likely candidate is time-series. Single object tracking involves analyzing data over time, which is a key aspect of time-series analysis. The \"unified\" part might refer to integrating different tracking methods or data sources, but the core is tracking over time. I don't see any mention of multiple modalities, RAG, or knowledge graphs here. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32223@AAAI"},
{"title": "Ultra-High-Definition Dynamic Multi-Exposure Image Fusion via Infinite Pixel Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Ultra-High-Definition Dynamic Multi-Exposure Image Fusion via Infinite Pixel Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dynamic Multi-Exposure Image Fusion\" suggests combining multiple images, possibly from different exposures. \"Dynamic\" might imply some temporal aspect, but image fusion is more about combining data from different sources or modalities. \"Infinite Pixel Learning\" sounds like a method for processing pixels, maybe in a machine learning context.\n\nTime-series usually involves data points indexed in time order. This title doesn't mention time or sequences, so maybe not time-series. Multimodal refers to combining different types of data (like images and text), but here it's about fusing multiple images, which could be considered multimodal if the images are from different modalities. However, \"multi-exposure\" typically refers to different exposure settings in photography, so it's the same modality (images) but different exposures. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models like those combining retrieval with generation for tasks like question answering. The title doesn't mention anything about retrieval or generation, so probably not RAG. KG is Knowledge Graphs, which involve structured data and relationships. The title doesn't mention knowledge or graphs, so that's out.\n\nSo the options left are multimodal or none. Since the paper is about fusing multiple images (multi-exposure) into one, it's combining different data sources (even if they're the same type, like images with different exposures). In some contexts, multi-exposure image fusion could be considered multimodal because it's combining different modalities (exposures) of the same scene. However, typically, multimodal refers to different types of data (e.g., text and images). But given the options, \"multimodal\" might be the closest fit here. Alternatively, if the paper is purely about image processing without combining different data types, it might not fit any of the listed topics. But since the user is asking to choose between these four, and the closest is multimodal, I'll go with that.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32224@AAAI"},
{"title": "Enhancing Generalized Few-Shot Semantic Segmentation via Effective Knowledge Transfer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Generalized Few-Shot Semantic Segmentation via Effective Knowledge Transfer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Generalized Few-Shot Semantic Segmentation\" sounds like a machine learning problem, specifically in computer vision. Few-shot learning is about learning from very few examples. Semantic segmentation is a task where each pixel in an image is labeled. So the paper is about improving this task with few examples.\n\nNow, the method mentioned is \"Effective Knowledge Transfer.\" Knowledge transfer could relate to transferring knowledge from one model to another, which might be part of transfer learning. But how does this connect to the given topics?\n\nLooking at the options: time-series deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. Multimodal would involve combining different data types, like text and images. The title is about semantic segmentation, which is image-related, but there's no mention of combining modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to generate answers. That's more about text generation with retrieval. The paper here is about image segmentation, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses a knowledge graph to transfer knowledge, maybe. But the title says \"Knowledge Transfer,\" which is a broader concept. However, knowledge transfer could be part of a knowledge graph approach. But the term \"Knowledge Graph\" is specific. The title doesn't mention graphs or structured knowledge, just \"knowledge transfer.\" So maybe it's not KG either.\n\nAlternatively, maybe the paper is using some form of knowledge distillation or transfer learning, which isn't explicitly listed in the options. Since the options are time-series, multimodal, RAG, or KG, and none of these seem to directly fit, the answer might be \"none.\" But wait, maybe I'm missing something. Let me check again.\n\nThe key term is \"Knowledge Transfer.\" If \"KG\" refers to Knowledge Graphs, then unless the paper is using a knowledge graph structure for the transfer, it's not KG. The title doesn't specify that. So the answer is probably none. But wait, maybe \"Knowledge Transfer\" is part of RAG? No, RAG is about retrieval and generation. So I think the correct answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32225@AAAI"},
{"title": "Diffusion Models for Attribution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Diffusion Models for Attribution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. Diffusion models are a type of generative model, right? They're used in areas like image generation, maybe text too. But the key part here is \"for Attribution.\" Attribution in machine learning usually refers to understanding which features or inputs contribute to a model's output. Like, why did the model make that prediction? So, techniques like SHAP or LIME are used for attribution.\n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or weather. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge sources during generation. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title doesn't mention anything about time, so time-series is probably out. It's not about combining different data modalities, so multimodal doesn't fit. RAG and KG are both about knowledge, but the focus here is on attribution, which is more about model interpretability. Diffusion models for attribution might be a method to explain how the model generates outputs, but none of the four topics directly relate to model attribution. RAG uses retrieval, but that's not the same as attribution. KG is about structured knowledge, which isn't the focus here. So, I think the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32226@AAAI"},
{"title": "M3Net: Multimodal Multi-task Learning for 3D Detection, Segmentation, and Occupancy Prediction in Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"M3Net: Multimodal Multi-task Learning for 3D Detection, Segmentation, and Occupancy Prediction in Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Multimodal Multi-task Learning.\" The word \"Multimodal\" immediately stands out. Multimodal usually refers to using multiple types of data, like combining images, text, audio, etc. So that's a strong hint towards the multimodal category.\n\nThen there's \"Multi-task Learning,\" which is a machine learning approach where a model is trained to perform multiple tasks simultaneously. But the question is about the research topic, not the method. The options given are time-series, multimodal, RAG, or KG. Since the title explicitly mentions \"Multimodal,\" that's a direct match. \n\nTime-series would involve data over time, like stock prices or sensor data over time. The title doesn't mention anything about time-series data. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships. The paper here is about autonomous driving tasks using multimodal data, so it's definitely multimodal. \n\nI don't see any indication of RAG or KG here. The tasks are 3D detection, segmentation, and occupancy prediction, which are computer vision tasks, but the key differentiator is the use of multimodal data. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32227@AAAI"},
{"title": "Recoverable Compression: A Multimodal Vision Token Recovery Mechanism Guided by Text Information", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Recoverable Compression: A Multimodal Vision Token Recovery Mechanism Guided by Text Information.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multimodal\" is right there in the title. That's a big hint. The paper talks about a vision token recovery mechanism guided by text information. So, combining vision and text, which are different modalities. That definitely sounds like multimodal research. \n\nNow, checking the other options. Time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences over time. RAG stands for Retrieval-Augmented Generation, which is more about using retrieval to enhance generation models, often in NLP. The title doesn't mention retrieval or generation. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about knowledge graphs. \n\nSo, the key term here is \"multimodal,\" and the description fits that category. The paper is about integrating different data types (vision and text), which is a core aspect of multimodal research. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32229@AAAI"},
{"title": "Dr. Tongue: Sign-Oriented Multi-label Detection for Remote Tongue Diagnosis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dr. Tongue: Sign-Oriented Multi-label Detection for Remote Tongue Diagnosis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or sensor data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The paper is about tongue diagnosis, which might involve images, but the title doesn't specify using multiple modalities. It just mentions \"Sign-Oriented,\" which could be about gestures or signs, but not sure if that's multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate answers. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, the title doesn't mention anything about building or using a knowledge graph.\n\nThe paper seems to focus on multi-label detection for a medical diagnosis task, specifically tongue diagnosis. That sounds like a computer vision or machine learning problem, but none of the given topics (time-series, multimodal, RAG, KG) directly fit. Unless \"Sign-Oriented\" implies using multiple modalities, but I'm not sure. Since the options are limited, and it doesn't clearly fit any of the four, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32230@AAAI"},
{"title": "GIM: A Million-scale Benchmark for Generative Image Manipulation Detection and Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GIM: A Million-scale Benchmark for Generative Image Manipulation Detection and Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Generative Image Manipulation\" suggests that the paper is about detecting and localizing manipulations in images generated by some method, maybe like deepfakes or edited images. The term \"Benchmark\" indicates it's a dataset or evaluation framework. The \"Million-scale\" part means it's a large dataset.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on image manipulation detection. That's primarily about images, which is a single modality. There's no mention of combining different data types (so not multimodal), nor is it about time-based data (so not time-series). RAG and KG are more about text-based models and knowledge representation. Since the paper is about a benchmark for image manipulation, it doesn't fit into RAG or KG either. Therefore, it doesn't belong to any of the listed topics. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32231@AAAI"}
{"title": "GIM: A Million-scale Benchmark for Generative Image Manipulation Detection and Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GIM: A Million-scale Benchmark for Generative Image Manipulation Detection and Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Generative Image Manipulation\" suggests that the paper is about detecting and localizing manipulations in images generated by some method, maybe like deepfakes or edited images. The term \"Benchmark\" indicates it's a dataset or evaluation framework. The \"Million-scale\" part means it's a large dataset.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on image manipulation detection. That's primarily about images, which is a single modality. There's no mention of combining different data types (so not multimodal), nor is it about time-based data (so not time-series). RAG and KG are more about text-based models and knowledge representation. Since the paper is about a benchmark for image manipulation, it doesn't fit into RAG or KG either. Therefore, it doesn't belong to any of the listed topics. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32231@AAAI"},
{"title": "Comprehensive Multi-Modal Prototypes Are Simple and Effective Classifiers for Vast-Vocabulary Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Comprehensive Multi-Modal Prototypes Are Simple and Effective Classifiers for Vast-Vocabulary Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Multi-Modal Prototypes\" and \"Vast-Vocabulary Object Detection.\" The word \"Multi-Modal\" immediately stands out. Multimodal typically refers to using multiple types of data or modalities, like combining text, images, audio, etc. So that's a strong hint towards the \"multimodal\" category.\n\nThe other parts of the title mention classifiers and object detection, which are common in machine learning and computer vision. But the main differentiator here is the \"Multi-Modal\" part. The other options are RAG (Retrieval-Augmented Generation), which is more about combining retrieval with generation models, often in NLP. KG (Knowledge Graphs) involve structured data and relationships, which doesn't seem to be the focus here. Time-series is about data over time, which also doesn't fit. \n\nSo the answer should be multimodal. The title directly uses the term \"Multi-Modal,\" which aligns with the multimodal research topic. The other options don't fit based on the keywords provided.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32232@AAAI"},
{"title": "3D Measurement of Complex Textured Objects Based on Bidirectional Fringe Projection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"3D Measurement of Complex Textured Objects Based on Bidirectional Fringe Projection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about 3D measurement using fringe projection, which is a technique in computer vision. But does it involve multiple modalities? The title mentions \"complex textured objects,\" which might relate to visual data, but I'm not sure if it's combining different data types. Maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. This paper seems to be about a measurement technique, not about generating text or using retrieval. So probably not RAG.\n\nKG is Knowledge Graph, which involves structured data and relationships between entities. The paper is about 3D measurement using fringe projection, which is more of a technical method in imaging or engineering. Doesn't seem related to knowledge graphs.\n\nSo none of the four topics seem to fit. The paper is about a specific 3D measurement technique, which is in the field of computer vision or optical measurement. Since the options given don't include those, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32233@AAAI"},
{"title": "Alleviate and Mining: Rethinking Unsupervised Domain Adaptation for Mitochondria Segmentation from Pseudo-Label Perspective", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If none fit, I should respond with \"none\".\n\nFirst, I need to break down the title: \"Alleviate and Mining: Rethinking Unsupervised Domain Adaptation for Mitochondria Segmentation from Pseudo-Label Perspective\". \n\nThe main components here are unsupervised domain adaptation, mitochondria segmentation, and pseudo-labels. Let's recall what each of the four topics entails.\n\nTime-series research typically involves data points indexed in time order, like stock prices over time or sensor data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title is about segmentation, which is image processing, but there's no indication of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on domain adaptation and segmentation using pseudo-labels, which doesn't directly relate to building or using knowledge graphs.\n\nUnsupervised domain adaptation is a machine learning technique where a model trained on a source domain is adapted to a target domain without labeled data in the target. Pseudo-labels are often used in semi-supervised learning, where the model generates labels for unlabeled data. The paper is about improving domain adaptation for mitochondria segmentation using pseudo-labels. None of the four topics (time-series, multimodal, RAG, KG) directly relate to domain adaptation or pseudo-labels. \n\nTherefore, the correct answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32234@AAAI"},
{"title": "Unsupervised Diffusion-Based Degradation Modeling for Real-World Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unsupervised Diffusion-Based Degradation Modeling for Real-World Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Unsupervised\" suggests the method doesn't use labeled data. \"Diffusion-Based\" might refer to diffusion models, which are a type of generative model. \"Degradation Modeling\" probably relates to understanding how images degrade, which is common in tasks like image restoration. \"Real-World Super-Resolution\" means enhancing low-resolution images to high-resolution, especially in real-world scenarios where degradation can be complex.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. This paper is about images, so maybe not time-series. Multimodal involves combining different data types, like text and images. The title doesn't mention multiple modalities. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to aid in generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on using a diffusion model for degradation in super-resolution. Diffusion models are a type of generative model, but the key here is the application to image degradation modeling. None of the four topics (time-series, multimodal, RAG, KG) directly relate to diffusion models or super-resolution. The topics listed are more about data types (time-series, multimodal) or specific techniques (RAG, KG). Since the paper is about a specific application in image processing using a diffusion model, and none of the given topics match this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32235@AAAI"},
{"title": "SVGBuilder: Component-Based Colored SVG Generation with Text-Guided Autoregressive Transformers", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SVGBuilder: Component-Based Colored SVG Generation with Text-Guided Autoregressive Transformers.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. SVGBuilder is generating SVGs, which are vector graphics. The key parts here are \"Component-Based Colored SVG Generation\" and \"Text-Guided Autoregressive Transformers.\" \n\nTime-series usually involves data over time, like stock prices or weather data. This doesn't seem related to time-based data analysis, so probably not time-series.\n\nMultimodal refers to combining multiple modalities, like text and images. The paper mentions text-guided generation of SVGs. So text (a modality) is used to generate another modality (SVG images). That sounds like multimodal because it's using text to create visual content. \n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch information and then generates text. The title doesn't mention anything about retrieval or using external data sources, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about generating SVGs, not about building or using knowledge graphs. So probably not KG.\n\nSo the main clue here is the text-guided generation of SVGs. Since it's using text to generate another type of data (images), that's a multimodal task. The model is likely taking text input and producing visual output, which combines two different modalities. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32236@AAAI"},
{"title": "EvHDR-GS: Event-guided HDR Video Reconstruction with 3D Gaussian Splatting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EvHDR-GS: Event-guided HDR Video Reconstruction with 3D Gaussian Splatting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Event-guided\" suggests that events are part of the input or process. HDR stands for High Dynamic Range, so it's about video reconstruction. 3D Gaussian Splatting is a technique used in rendering or visualizing 3D data. \n\nTime-series usually involves data over time, like stock prices or sensor data. This paper is about video, which is a time-series of images, but the key here is whether the focus is on time-series analysis. However, the main contribution seems to be the reconstruction method using Gaussian splatting, which is more about the technique rather than time-series analysis.\n\nMultimodal would involve combining different types of data, like text and images. The title mentions \"event-guided,\" which could be a different modality (like event data from a camera) combined with video. If events are a separate modality from the video, then it's multimodal. But I'm not sure if event data here is considered a different modality. Event cameras do produce a stream of events, which is different from traditional frame-based video, so combining event data with video could be multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, typically in NLP. This paper doesn't mention anything about retrieval or generation in that context, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo, the main question is whether this is multimodal. If the method uses both event data and video data (as two different modalities) to reconstruct HDR video, then it's multimodal. The term \"event-guided\" suggests that event data is used to guide the reconstruction process, which would be combining event data (a modality) with video data. Therefore, it's likely a multimodal approach. \n\nTime-series could be a stretch because video is a time-series of frames, but the primary focus here is on the reconstruction technique using different data types (events and video), making multimodal the better fit.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32237@AAAI"},
{"title": "EvHDR-NeRF: Building High Dynamic Range Radiance Fields with Single Exposure Images and Events", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EvHDR-NeRF: Building High Dynamic Range Radiance Fields with Single Exposure Images and Events.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. EvHDR-NeRF probably refers to a method for creating High Dynamic Range (HDR) radiance fields. Radiance fields are used in 3D scene reconstruction, like in NeRF (Neural Radiance Fields). The key part here is \"Single Exposure Images and Events.\" Single exposure suggests that they're using images taken with one exposure setting, which might be related to dynamic range. Events could refer to event-based sensors, like those in neuromorphic cameras that capture changes in light over time, which is different from traditional frame-based cameras.\n\nNow, the four topics: time-series, multimodal, RAG, KG. Time-series usually involves data collected over time, like stock prices or sensor data over time. Multimodal refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title mentions using both images and events. If \"events\" here are from event cameras, that's a different modality than traditional images. So combining images (visual data) with event data (which is more like a stream of asynchronous events) would be a multimodal approach. Therefore, the research is combining two different types of data (images and events) to build HDR radiance fields. That fits under multimodal.\n\nTime-series might be a stretch if the events are time-based, but the key here is the combination of different data types, not just temporal data. RAG and KG don't seem relevant here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32238@AAAI"},
{"title": "VFM-Adapter: Adapting Visual Foundation Models for Dense Prediction with Dynamic Hybrid Operation Mapping", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VFM-Adapter: Adapting Visual Foundation Models for Dense Prediction with Dynamic Hybrid Operation Mapping.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual Foundation Models\" probably refers to models like CLIP or other vision models that are pre-trained. \"Adapting\" suggests they're modifying these models for a specific task. \"Dense Prediction\" might be tasks like semantic segmentation or object detection where the output is pixel-wise. \"Dynamic Hybrid Operation Mapping\" sounds like combining different operations or layers in a flexible way.\n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually combines different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge retrieval during generation. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper is about adapting visual models for dense prediction. Visual models are image-based, so unless they're combining with another modality like text or audio, it's not multimodal. The title doesn't mention text or other data types, so maybe not multimodal. RAG and KG are more about knowledge integration. The term \"Adapter\" here is about modifying the model, but not necessarily retrieving knowledge. The focus is on the model's architecture for dense prediction. So none of the four topics seem to fit. The paper is about adapting visual models, which is more related to computer vision techniques rather than the listed topics. So the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32239@AAAI"},
{"title": "VersaGen: Unleashing Versatile Visual Control for Text-to-Image Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VersaGen: Unleashing Versatile Visual Control for Text-to-Image Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-to-Image Synthesis\" immediately makes me think of generating images from text descriptions. That's a common task in multimodal learning because it involves combining different modalities—text and images. So multimodal is a possibility. \n\nNow, let's check the other options. Time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about sequences over time, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database to enhance its responses. The title doesn't mention retrieval or augmentation, so RAG might not fit here. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't reference knowledge graphs either. \n\nSo, the key part here is \"Text-to-Image Synthesis,\" which is a classic example of a multimodal task because it combines text (language) and images (vision). The \"Visual Control\" part suggests that the model is generating images based on textual input, which again points to multimodal. \n\nI don't see any indication that the paper is about time-series data, RAG, or knowledge graphs. Therefore, the most fitting category is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32240@AAAI"}
{"title": "EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EchoMimic: Lifelike Audio-Driven Portrait Animations through Editable Landmark Conditions.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Audio-Driven Portrait Animations\" suggests that audio is being used to drive the animation. So, there's an interaction between audio (which is a time-series signal) and visual elements (portraits). That makes me think of multimodal because it's combining different modalities—audio and video or images. \n\nMultimodal research typically involves integrating multiple types of data, like text, images, audio, etc. Here, the audio is driving the animation, so it's definitely using both audio and visual data. The \"editable landmark conditions\" part might refer to using specific points (landmarks) on the face that can be adjusted, which could be part of the model's architecture. \n\nTime-series could be a possibility because audio is a time-series data, but the main focus here seems to be on combining different modalities rather than just analyzing time-series data. RAG (Retrieval-Augmented Generation) is more about using retrieval mechanisms to enhance generation, which doesn't seem to be the case here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. \n\nSo, the key here is the combination of audio and visual data to create animations. That points to multimodal. The paper is likely about integrating audio and visual modalities to generate animations, making it a multimodal research topic.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32241@AAAI"},
{"title": "Spatiotemporal Blind-Spot Network with Calibrated Flow Alignment for Self-Supervised Video Denoising", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spatiotemporal Blind-Spot Network with Calibrated Flow Alignment for Self-Supervised Video Denoising.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatiotemporal\" refers to both space and time, which makes me think of time-series data since time is a component. But wait, video data is inherently spatiotemporal because it involves frames over time. So maybe time-series is a candidate here. \n\nThe \"Blind-Spot Network\" part might be a specific architecture. I'm not sure, but the key terms are \"self-supervised video denoising.\" Denoising video would involve processing sequences of frames, which again points to time-series. \n\nNow, checking the other options. Multimodal usually involves combining different types of data like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is unlikely. \n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention knowledge graphs or structured data, so that's probably not it either. \n\nSo, the main focus here is on video denoising using a spatiotemporal network, which deals with time-based data. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32242@AAAI"},
{"title": "Filter or Compensate: Towards Invariant Representation from Distribution Shift for Anomaly Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Filter or Compensate: Towards Invariant Representation from Distribution Shift for Anomaly Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on creating invariant representations that handle distribution shifts for anomaly detection. Invariant representations usually mean the model should perform consistently even when the data distribution changes. Anomaly detection is a common task in various domains, but the key here is how they handle distribution shifts.\n\nTime-series analysis involves data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal refers to combining different data types, like text and images. The title doesn't talk about multiple modalities, so probably not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention graphs or knowledge bases, so that's probably not it either.\n\nSo, the paper is about making representations invariant to distribution shifts for anomaly detection. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The focus is on invariant representations and distribution shifts, which might be a general machine learning topic rather than one of the specified areas. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32243@AAAI"},
{"title": "Gradient Alignment Improves Test-Time Adaptation for Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Gradient Alignment Improves Test-Time Adaptation for Medical Image Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. The title mentions medical image segmentation, which is more about images, so maybe not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention multiple data types, just image segmentation. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation, often in NLP. The paper is about medical image segmentation and test-time adaptation, which doesn't seem to involve retrieval or generation. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nThe paper is about improving test-time adaptation through gradient alignment in medical image segmentation. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32244@AAAI"},
{"title": "ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ResAdapter: Domain Consistent Resolution Adapter for Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"ResAdapter\" probably refers to a resolution adapter. The key part here is \"Domain Consistent Resolution Adapter for Diffusion Models.\" Diffusion models are a type of generative model used in machine learning, often for image generation. The adapter is about adjusting resolution while maintaining domain consistency. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather data. Multimodal usually refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation tasks, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on adapting resolution in diffusion models. Diffusion models are typically used in image or video generation, which might involve multimodal data if they combine different modalities. However, the title doesn't mention combining different data types. It's more about adjusting the resolution while keeping the domain consistent. \n\nRAG and KG don't seem relevant here. The paper isn't about retrieval or knowledge graphs. Time-series also doesn't fit because it's about resolution adaptation in diffusion models, not temporal data. \n\nMultimodal could be a stretch if the adapter is used across different modalities, but the title doesn't specify that. The main focus is on resolution and domain consistency in diffusion models, which are usually image-based. So, maybe it's not any of the four topics. The answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32245@AAAI"},
{"title": "3DPGS: 3D Probabilistic Graph Search for Archaeological Piece Grouping", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"3DPGS: 3D Probabilistic Graph Search for Archaeological Piece Grouping.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"3D Probabilistic Graph Search\" suggests some kind of graph-based method. The application is in archaeological piece grouping, which might involve organizing or categorizing artifacts. \n\nNow, the options. Time-series usually involves data over time, like stock prices or weather. This title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The title mentions 3D and graph search, but there's no indication of multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representations, often using graphs. The term \"graph\" in the title might point towards a knowledge graph. The method is a probabilistic graph search, which could be part of a knowledge graph application, especially in grouping archaeological pieces. \n\nSo, the most likely answer is KG. The paper uses a graph-based approach for grouping, which aligns with knowledge graphs. The other options don't fit as well. Let me double-check. The key term here is \"graph,\" which is central to knowledge graphs. So yes, I think it's KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32246@AAAI"},
{"title": "Effective Diffusion Transformer Architecture for Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Effective Diffusion Transformer Architecture for Image Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Diffusion Transformer\" probably refers to a type of neural network architecture. \"Image Super-Resolution\" is about enhancing the resolution of images, which is a computer vision task. \n\nLooking at the options: time-series deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents. KG stands for Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about an architecture for image super-resolution. The key terms here are \"diffusion\" and \"transformer.\" Diffusion models are a type of generative model, often used in image generation. Transformers are a type of neural network architecture, commonly used in NLP but also in vision tasks. \n\nSince the focus is on image processing and not on combining different data modalities, time-series, RAG, or KG don't seem to fit. The term \"multimodal\" would require the model to handle multiple types of data (like text and images together), but the title only mentions image super-resolution. So it's a single modality (images) task. \n\nTherefore, the paper doesn't fit into any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32247@AAAI"},
{"title": "DIDiffGes: Decoupled Semi-Implicit Diffusion Models for Real-time Gesture Generation from Speech", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DIDiffGes: Decoupled Semi-Implicit Diffusion Models for Real-time Gesture Generation from Speech.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components are diffusion models, real-time gesture generation, and speech. Diffusion models are a type of generative model, often used in image or sequence generation. The key here is that they're generating gestures from speech. So, the input is speech (audio) and the output is gestures, which could be visual or motion data. \n\nNow, the topics to consider. Time-series usually involves data that's sequential over time, like stock prices or sensor data. Multimodal refers to combining multiple modalities, like text and images, or in this case, speech (audio) and gestures (visual/motion). RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge, not directly related here.\n\nThe paper is about generating gestures from speech, which are two different modalities. So, it's combining audio and gesture data. That points towards multimodal. The real-time aspect might involve time-series processing, but the core of the research is the integration of different data types (speech to gestures), which is multimodal. The use of diffusion models is the method, but the topic classification is about the data modalities involved. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32248@AAAI"},
{"title": "Graphic Design with Large Multimodal Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Graphic Design with Large Multimodal Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graphic Design\" is the application area here. The key part is \"Large Multimodal Model.\" The term \"multimodal\" refers to models that can process multiple types of data, like text, images, audio, etc. So if the paper is about using a model that handles multiple modalities for graphic design, then it's definitely in the multimodal category.\n\nTime-series would involve data over time, like stock prices or weather data. RAG is Retrieval-Augmented Generation, which combines retrieval of information with generation models. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about time, retrieval, or knowledge graphs. So the only fitting category here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32249@AAAI"},
{"title": "Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-Video Representation Learning\" suggests that the paper is dealing with both text and video data. So that's combining different modalities, which makes me think of multimodal. Multimodal typically refers to models that handle multiple types of data, like text and images or video. \n\nThen, \"Ambiguity-Restrained\" might be about how the model handles ambiguous queries or data, but that's more about the method rather than the topic. \"Partially Relevant Video Retrieval\" is the task, which is about retrieving videos that are somewhat relevant to a query. \n\nNow, checking the options. Time-series would involve data over time, like stock prices or sensor data. This doesn't seem to fit. RAG (Retrieval-Augmented Generation) is about using retrieval to augment generation models, like in question-answering. The title mentions retrieval, but it's specifically about video retrieval, not combining retrieval with generation. KG (Knowledge Graphs) involves structured data and relationships, which isn't mentioned here. \n\nSo the key part is \"Text-Video,\" which are two different modalities. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32252@AAAI"}
{"title": "Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bridge 2D-3D: Uncertainty-aware Hierarchical Registration Network with Domain Alignment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Bridge 2D-3D\" suggests it's about connecting 2D and 3D data. \"Uncertainty-aware\" might relate to handling uncertainty in the data. \"Hierarchical Registration Network\" sounds like a neural network approach for registration, which is about aligning different data sets. \"Domain Alignment\" could mean aligning different domains, maybe different types of data or different modalities.\n\nLooking at the options: time-series is about data over time, which doesn't seem to fit here. Multimodal usually involves combining different types of data, like images and text. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus on 2D and 3D data alignment might be multimodal if it's combining different data types. But registration is more about aligning data in space, which could be part of computer vision or robotics. However, the options given don't include those. The closest might be multimodal if 2D and 3D are considered different modalities. But I'm not sure. Alternatively, if domain alignment refers to different domains (like different datasets or sensors), that could be multimodal. But maybe it's not one of the listed topics. The title doesn't mention anything about knowledge graphs, RAG, or time-series. So maybe it's none of the given topics. Wait, but the user says if it doesn't belong to any, respond with \"none\". So I need to check again.\n\nMultimodal typically refers to combining different types of data like text, image, audio. Here, 2D and 3D could be different modalities, but registration is more about spatial alignment. Maybe it's not exactly multimodal. The other options don't fit. So perhaps the answer is \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32251@AAAI"},
{"title": "Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Ambiguity-Restrained Text-Video Representation Learning for Partially Relevant Video Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-Video Representation Learning\" suggests that the paper is dealing with both text and video data. So that's combining different modalities, which makes me think of multimodal. Multimodal typically refers to models that handle multiple types of data, like text and images or video. \n\nThen, \"Ambiguity-Restrained\" might be about how the model handles ambiguous queries or data, but that's more about the method rather than the topic. \"Partially Relevant Video Retrieval\" is the task, which is about retrieving videos that are somewhat relevant to a query. \n\nNow, checking the options. Time-series would involve data over time, like stock prices or sensor data. This doesn't seem to fit. RAG (Retrieval-Augmented Generation) is about using retrieval to augment generation models, like in question-answering. The title mentions retrieval, but it's specifically about video retrieval, not combining retrieval with generation. KG (Knowledge Graphs) involves structured data and relationships, which isn't mentioned here. \n\nSo the key part is \"Text-Video,\" which are two different modalities. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32252@AAAI"},
{"title": "Zero-Shot Scene Change Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Zero-Shot Scene Change Detection\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should say \"none\".\n\nFirst, I need to understand what each of these topics entails. \n\nTime-series research typically involves data points indexed in chronological order, like stock prices over time or weather data. Scene change detection might involve analyzing sequences of images or videos over time, so maybe time-series? But I'm not sure yet.\n\nMultimodal refers to combining multiple types of data, such as text and images, or audio and video. If the paper uses different data modalities to detect scene changes, that would fit. But the title doesn't mention anything about combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model retrieves relevant information from a database to enhance its responses. This seems more related to text generation and information retrieval, not directly to scene change detection.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. If the paper uses a knowledge graph to detect scene changes, that would be the case. But again, the title doesn't mention anything about knowledge graphs.\n\nNow, focusing on the title: \"Zero-Shot Scene Change Detection\". Zero-shot learning refers to a machine learning scenario where the model is trained on a set of classes and then tested on classes not seen during training. Scene change detection is about identifying when a scene in a video or image sequence changes. This could involve analyzing sequences of images over time, which might be considered time-series data. However, scene change detection is often part of video processing, which is a type of time-series but more specific. But does it fall under the time-series category as defined here? The user's options are time-series, multimodal, RAG, KG. \n\nAlternatively, if the paper uses multimodal data (like combining audio and visual cues for scene changes), it would be multimodal. But the title doesn't specify that. Zero-shot learning is a technique, not a topic. The main task here is scene change detection. \n\nGiven that, I think the most likely is time-series if the detection is based on sequential data over time. However, sometimes scene change detection in videos is considered a different domain. But since the options are limited, and time-series is about sequential data, maybe that's the best fit. But I'm not entirely sure. Alternatively, if the paper doesn't use any of these four topics, the answer would be \"none\". \n\nWait, the user's instruction says if it belongs to one of the four, respond with the topic. Otherwise, \"none\". So I need to check if the paper's topic is one of these four. \n\nTime-series: if the paper is about analyzing time-series data for scene changes. But scene change detection is more about video frames, which are a type of time-series. However, in academic terms, time-series analysis is a broader field. If the paper is specifically about time-series methods, then yes. But if it's about video processing without using time-series techniques, maybe not. \n\nMultimodal: if it uses multiple data types. The title doesn't mention that. \n\nRAG and KG: seem unrelated. \n\nSo, the answer might be time-series. But I'm not 100% certain. Alternatively, maybe it's none. But given the options, time-series is the closest. However, I should check if scene change detection is typically considered a time-series problem. For example, in video processing, each frame is a data point in a sequence, so analyzing sequences for changes would be time-series. Therefore, the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32253@AAAI"},
{"title": "Enhancing Robustness in Incremental Learning with Adversarial Training", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Robustness in Incremental Learning with Adversarial Training.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus is on incremental learning, which is a type of machine learning where the model learns sequentially over time, updating itself with new data without forgetting previous knowledge. The goal here is to enhance robustness, probably against adversarial attacks or data shifts. Adversarial training is a method used to improve model robustness by training with adversarial examples.\n\nNow, looking at the four options. Time-series refers to data that's sequential over time, like stock prices or weather data. The paper's title mentions incremental learning, which is about learning over time, but the key here is whether the data itself is time-series. Incremental learning can be applied to various data types, not just time-series. So maybe not time-series unless the data is specifically time-dependent.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about multiple modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generation, often used in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is probably not relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo, the paper is about adversarial training in incremental learning. None of the four topics (time-series, multimodal, RAG, KG) directly relate to adversarial training or incremental learning. The focus is on robustness in a learning paradigm, not on the data type (time-series, multimodal) or specific methods like RAG or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32254@AAAI"},
{"title": "Elevating Flow-Guided Video Inpainting with Reference Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Elevating Flow-Guided Video Inpainting with Reference Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Video Inpainting\" refers to filling in missing or damaged parts of a video. \"Flow-Guided\" probably relates to optical flow, which is about the motion between frames in a video. That's a time-series aspect because videos are sequences over time. But wait, the other part is \"Reference Generation.\" Reference Generation (RAG) is a technique where a model generates references or examples to help in tasks like question answering or text generation. \n\nSo, the paper is combining flow-guided methods with reference generation for video inpainting. The key here is whether \"Reference Generation\" here refers to the RAG (Retrieval-Augmented Generation) concept. If they're using RAG to generate references for the inpainting process, then it would fall under RAG. However, if \"reference generation\" is just about creating reference frames or data for the video processing, it might not be the RAG topic. \n\nBut the title specifically mentions \"Reference Generation,\" which aligns with the RAG approach where the model generates references to aid in the task. Since RAG is one of the options, and the paper is using that technique, the answer should be RAG. Time-series could be a possible angle because of the video, but the key innovation here is the reference generation part. So I think the correct topic is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32255@AAAI"},
{"title": "Distribution-Level Feature Distancing for Machine Unlearning: Towards a Better Trade-off Between Model Utility and Forgetting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Distribution-Level Feature Distancing for Machine Unlearning: Towards a Better Trade-off Between Model Utility and Forgetting.\" Hmm. I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Machine Unlearning\" sounds like it's about removing data from a model, right? Like, if you trained a model on some data and then want to forget it. The goal here is to balance model utility (so the model still works well) and forgetting (so the data is effectively removed). \n\nNow, the methods mentioned are \"Distribution-Level Feature Distancing.\" That part is about adjusting the model's features at the distribution level. But how does that relate to the given topics? \n\nTime-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal would involve combining different data types, like text and images. The title doesn't talk about multiple modalities, so that's probably out. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus seems to be on unlearning and model utility, not on building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about machine unlearning, which is a different area, possibly related to model privacy or data removal. Since the options given don't include unlearning or privacy, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32256@AAAI"},
{"title": "SIDL: A Real-World Dataset for Restoring Smartphone Images with Dirty Lenses", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SIDL: A Real-World Dataset for Restoring Smartphone Images with Dirty Lenses.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or weather data. This paper is about restoring images, so maybe not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions a dataset for restoring images, but it doesn't specify using multiple modalities. It's just about images with dirty lenses, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The paper is about image restoration, not text generation or retrieval, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper is about a dataset for image restoration, not building or using a knowledge graph. \n\nSo none of the topics seem to fit. The paper is about image restoration using a dataset, which is more related to computer vision or image processing, but the given options don't include those. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32257@AAAI"},
{"title": "Intrinsic Image Decomposition for Robust Self-supervised Monocular Depth Estimation on Reflective Surfaces", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Intrinsic Image Decomposition for Robust Self-supervised Monocular Depth Estimation on Reflective Surfaces.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Intrinsic image decomposition refers to separating an image into components like reflectance and shading. Monocular depth estimation is about predicting depth from a single image. Reflective surfaces might be a challenge here. Self-supervised learning is a method where the model learns without explicit labels, using the data itself for supervision.\n\nNow, the four options. Time-series would involve data over time, like sequences or temporal data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal usually refers to combining multiple types of data, like text and images. The paper here is about depth estimation from images, but the title doesn't mention combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to enhance generation tasks, like in some NLP models. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image processing and depth estimation, not on building or using knowledge graphs. So KG is probably not it.\n\nSo none of the four topics seem to fit. The paper is about computer vision techniques for depth estimation, specifically dealing with reflective surfaces using self-supervised learning and intrinsic image decomposition. Since the topics given don't include computer vision, image processing, or self-supervised learning, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32258@AAAI"},
{"title": "DynASyn: Multi-Subject Personalization Enabling Dynamic Action Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DynASyn: Multi-Subject Personalization Enabling Dynamic Action Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"DynASyn\" probably stands for Dynamic Action Synthesis. The key parts here are \"Multi-Subject Personalization\" and \"Dynamic Action Synthesis.\" \n\nTime-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time or sequential data, so maybe not time-series. \n\nMultimodal refers to using multiple types of data, like text and images. The title doesn't specify different data modalities, so that might not be it either. \n\nRAG is Retrieval-Augmented Generation, which combines retrieval of information with generating responses. The title doesn't mention retrieval or generation in that context. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data. \n\nThe main focus here seems to be on personalizing actions dynamically across multiple subjects. That sounds more like a problem in action synthesis, which could be related to robotics or animation, but none of the given topics directly fit. The options are time-series, multimodal, RAG, or KG. Since none of these seem to align with dynamic action synthesis or multi-subject personalization, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32259@AAAI"},
{"title": "Digging into Intrinsic Contextual Information for High-fidelity 3D Point Cloud Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Digging into Intrinsic Contextual Information for High-fidelity 3D Point Cloud Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions 3D point cloud completion, which sounds more like a spatial problem rather than temporal. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention anything about combining different data types, just working with 3D point clouds. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on 3D point cloud completion, which is more about geometry and data completion. Unless the paper uses a knowledge graph to inform the completion, but the title doesn't indicate that. The term \"intrinsic contextual information\" might refer to the internal structure of the point cloud itself rather than an external knowledge graph.\n\nSo, none of the four topics seem to fit. The paper is about 3D point cloud completion, which is a computer vision or machine learning task, but not directly related to the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32260@AAAI"}
{"title": "What to Preserve and What to Transfer: Faithful, Identity-Preserving Diffusion-based Hairstyle Transfer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"What to Preserve and What to Transfer: Faithful, Identity-Preserving Diffusion-based Hairstyle Transfer.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about hairstyle transfer, which doesn't seem to involve time-based data. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about transferring hairstyles, which might involve images and maybe some other data types. But the title doesn't explicitly mention multiple modalities. Hmm.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation in that context. The method here is diffusion-based, which is a type of generative model, but not necessarily RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about graphs or structured data, so probably not KG.\n\nThe key terms here are \"diffusion-based\" and \"hairstyle transfer.\" Diffusion models are a type of generative model used in image generation. The task is about transferring a hairstyle while preserving identity, which sounds like a computer vision problem. The options given don't include computer vision or image processing. The closest might be multimodal if it uses different data types, but the title doesn't specify that. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to diffusion models or image transfer, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32261@AAAI"},
{"title": "MASS: Overcoming Language Bias in Image-Text Matching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MASS: Overcoming Language Bias in Image-Text Matching.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Image-Text Matching\" suggests that the paper deals with both images and text. That immediately makes me think of multimodal because multimodal research involves combining different types of data, like images and text. Time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is a method for enhancing models with external information retrieval, but the title doesn't mention anything about retrieval or generation. KG (Knowledge Graphs) are structured representations of knowledge, which also doesn't seem to fit. The main focus here is on matching between images and text, which is a classic multimodal task. The mention of \"language bias\" might indicate that the model is trying to balance or improve the interaction between the textual and visual modalities. So, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32262@AAAI"},
{"title": "AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AttackBench: Evaluating Gradient-based Attacks for Adversarial Examples.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"AttackBench\" sounds like a benchmark or evaluation framework. The key terms here are \"gradient-based attacks\" and \"adversarial examples.\" Adversarial examples are a concept in machine learning where small, often imperceptible perturbations are added to input data to cause models to make mistakes. Gradient-based attacks refer to methods that use gradients (like in backpropagation) to generate these adversarial examples. \n\nNow, looking at the four topics. Time-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to combining multiple data types, such as text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP that combines retrieval of information with generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on evaluating attacks in the context of adversarial examples, specifically gradient-based ones. This seems related to machine learning security or adversarial machine learning. None of the four topics listed (time-series, multimodal, RAG, KG) directly relate to adversarial attacks or gradient-based methods. Time-series is about temporal data, multimodal about multiple data types, RAG and KG are specific techniques in NLP and knowledge representation. The paper isn't about any of these. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32263@AAAI"},
{"title": "LOMA: Language-assisted Semantic Occupancy Network via Triplane Mamba", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LOMA: Language-assisted Semantic Occupancy Network via Triplane Mamba.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Language-assisted\" suggests that language is involved, maybe combining text with another modality. \"Semantic Occupancy Network\" sounds like it's related to 3D space or spatial data, maybe something like occupancy grids used in robotics or computer vision. \"Triplane Mamba\" – I'm not sure what Triplane refers to, but Mamba could be a model or architecture. \n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually means combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge sources. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper uses language (text) to assist a semantic occupancy network. That sounds like combining text (language) with spatial data (occupancy), which are different modalities. So multimodal makes sense here. The other terms like Triplane Mamba might be specific to their architecture, but the key is the combination of language and another modality. So the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32264@AAAI"},
{"title": "Multi-task Visual Grounding with Coarse-to-Fine Consistency Constraints", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-task Visual Grounding with Coarse-to-Fine Consistency Constraints.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-task\" suggests that the research involves handling multiple tasks simultaneously. \"Visual Grounding\" usually refers to connecting visual elements (like images) with language or other modalities. So, that's a hint towards multimodal, since it's combining vision and language. \n\n\"Coarse-to-Fine Consistency Constraints\" might be about refining the model's predictions step by step, ensuring consistency across different levels of detail. But the key part here is the combination of different modalities—visual and textual. \n\nTime-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation models, often in NLP. KG (Knowledge Graphs) involves structured data and relationships between entities. \n\nSince the paper is about visual grounding, which is a classic multimodal task (combining images and text), the topic should be multimodal. The other terms like multi-task and consistency constraints don't point to the other categories. So the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32265@AAAI"},
{"title": "DCSF-KD: Dynamic Channel-wise Spatial Feature Knowledge Distillation for Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DCSF-KD: Dynamic Channel-wise Spatial Feature Knowledge Distillation for Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dynamic Channel-wise Spatial Feature\" suggests something related to features in different channels and spatial aspects, which is common in computer vision tasks like object detection. \"Knowledge Distillation (KD)\" is a technique where a smaller model is trained using a larger, more accurate model as a teacher. So the main focus here is on knowledge distillation applied to object detection, specifically with dynamic channel-wise spatial features.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's title doesn't mention anything about time-series data, so that's out. It's focused on object detection, which is a computer vision task, and the method is about knowledge distillation. Knowledge Distillation isn't one of the listed options (RAG and KG are separate). Wait, the options are RAG, KG, time-series, multimodal. The paper is about knowledge distillation, which isn't listed here. So none of the four topics match. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32266@AAAI"},
{"title": "GCD-Sampling: A General Cross-scale Decoupled Sampling for Point Cloud", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GCD-Sampling: A General Cross-scale Decoupled Sampling for Point Cloud.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"GCD-Sampling\" is the method's name. \"General Cross-scale Decoupled Sampling\" suggests it's a sampling technique for point clouds. Point clouds are typically used in 3D data processing, like in computer vision or robotics. \n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on sampling methods for point clouds. None of the four topics directly relate to point cloud processing. Time-series is about temporal data, which isn't mentioned here. Multimodal would involve multiple data modalities, but the title doesn't indicate that. RAG and KG are about information retrieval and knowledge representation, which also don't seem relevant here. The paper is about a specific sampling technique for 3D data, which doesn't fit into any of the given categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32267@AAAI"},
{"title": "Harmonious Music-driven Group Choreography with Trajectory-Controllable Diffusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Harmonious Music-driven Group Choreography with Trajectory-Controllable Diffusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Music-driven\" suggests that music is involved, which is an audio modality. \"Group Choreography\" implies movement or dance, which could be visual or motion data. So combining music and choreography might involve multiple modalities, like audio and video or motion data. That points towards multimodal. \n\n\"Trajectory-Controllable Diffusion\" makes me think of generating trajectories, which could be time-series data since trajectories over time are sequences. But the key here is whether the paper is about the time-series aspect itself or using time-series as part of a multimodal approach. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which doesn't seem directly related here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. \n\nSo the main elements are combining music (audio) and choreography (motion), which are different modalities. The paper is likely about generating choreography that's synchronized with music, using both modalities. That fits the multimodal category. Even though there's a time-series element in the trajectories, the primary focus seems to be on integrating different data types. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32268@AAAI"},
{"title": "Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Image Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Self-Corrected Flow Distillation for Consistent One-Step and Few-Step Image Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Self-Corrected Flow Distillation\" sounds like a method or technique. \"Consistent One-Step and Few-Step Image Generation\" suggests that the focus is on generating images, possibly in a step-by-step manner. \n\nTime-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so maybe not time-series. \n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about image generation, but does it involve multiple modalities? The title doesn't mention text or other data types, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title doesn't mention retrieval or using external data, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem related to building or using knowledge graphs. \n\nSo, the paper is about image generation techniques, specifically using flow distillation and self-correction. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The closest might be multimodal if image generation is part of a multimodal system, but the title doesn't indicate that. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32269@AAAI"},
{"title": "PIXELS: Progressive Image Xemplar-based Editing with Latent Surgery", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PIXELS: Progressive Image Xemplar-based Editing with Latent Surgery.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Progressive Image Xemplar-based Editing\" suggests it's about image editing using examples (xemplars). \"Latent Surgery\" probably refers to manipulating the latent space of a model, like in GANs or VAEs. So the main focus here is on image generation or editing techniques. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually combines different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured data representations. \n\nThe paper's title doesn't mention anything about time, so time-series is out. It's about image editing, which is a single modality (images), so multimodal might not fit unless it combines other data types. RAG involves retrieval and generation, but the title doesn't mention retrieval or using external data for generation. KG is about structured knowledge, which isn't indicated here. \n\nSo, none of the four topics seem to fit. The paper is about image editing techniques using latent space manipulation, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32270@AAAI"}
{"title": "Single Exposure Quantitative Phase Imaging with a Conventional Microscope Using Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Single Exposure Quantitative Phase Imaging with a Conventional Microscope Using Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main subject is quantitative phase imaging, which is a technique in microscopy. The key part here is \"using diffusion models.\" Diffusion models are a type of machine learning model, often used in image generation and processing. But how does that relate to the given topics?\n\nTime-series research typically involves data collected over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data modalities, like text and images. The title mentions a conventional microscope and phase imaging, but there's no indication of combining different types of data. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on imaging techniques using diffusion models, not on building or using knowledge graphs. So KG is probably not the right fit.\n\nThe paper uses diffusion models for a specific imaging task. None of the four topics (time-series, multimodal, RAG, KG) directly relate to diffusion models in this context. The application here is in image processing with a microscope, which doesn't fall under the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32271@AAAI"},
{"title": "Deep Non-Rigid Structure-from-Motion Revisited: Canonicalization and Sequence Modeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Deep Non-Rigid Structure-from-Motion Revisited: Canonicalization and Sequence Modeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Structure-from-Motion (SfM) is a technique in computer vision where 3D structures are reconstructed from 2D image sequences. The term \"non-rigid\" suggests that the objects being reconstructed are deformable, not fixed in shape. The mention of \"sequence modeling\" might imply that the method uses sequences of data, which could relate to time-series. \n\nTime-series analysis involves data points indexed in time order. If the paper is using sequences of images or data over time to model the structure, that could be time-series. However, SfM is more about reconstructing 3D structures from multiple images, which might not necessarily be time-ordered. But the \"sequence modeling\" part does hint at handling sequences, which is a key aspect of time-series.\n\nMultimodal refers to combining multiple data types (like text, images, audio). The title doesn't mention different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to augment their responses. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't indicate anything about knowledge graphs either.\n\nSo, the most plausible is time-series because of the sequence modeling aspect. Even though SfM can be done with unordered images, the \"sequence\" part here might imply temporal sequences, making it a time-series topic. I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32272@AAAI"},
{"title": "DiffCorr: Conditional Diffusion Model with Reliable Pseudo-Label Guidance for Unsupervised Point Cloud Shape Correspondence", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffCorr: Conditional Diffusion Model with Reliable Pseudo-Label Guidance for Unsupervised Point Cloud Shape Correspondence.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Conditional Diffusion Model\" suggests they're using a type of generative model, maybe similar to diffusion models used in image generation. Then \"Reliable Pseudo-Label Guidance\" might refer to using pseudo-labels to guide the model during training, which is a common technique in semi-supervised learning. The main application here is \"Unsupervised Point Cloud Shape Correspondence,\" which involves aligning or matching shapes in point clouds without labeled data.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. Multimodal usually refers to combining different data types, like text and images. The paper is about point clouds, which are 3D data, but there's no mention of combining with other modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to enhance generation tasks, like in question-answering. The paper doesn't mention retrieval or augmentation, so probably not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on shape correspondence in point clouds, not on building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about a diffusion model for point cloud correspondence, which is more related to computer vision or 3D geometry processing. Since the options given don't include those areas, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32273@AAAI"},
{"title": "Adaptive Siamese Masked Autoencoder with Global Optimization for Unsupervised Point Cloud Shape Correspondence", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adaptive Siamese Masked Autoencoder with Global Optimization for Unsupervised Point Cloud Shape Correspondence.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Siamese Masked Autoencoder\" sounds like a neural network architecture. Siamese networks are often used for tasks where you need to compare two inputs, like in similarity learning. Masked autoencoders are a type of model used in self-supervised learning, where parts of the input are masked and the model has to reconstruct them. \n\n\"Global Optimization\" might refer to an optimization technique to avoid local minima, which is common in training neural networks. \"Unsupervised Point Cloud Shape Correspondence\" – point clouds are 3D data points, so this is about finding correspondences between different shapes without labeled data. \n\nNow, the topics: time-series deals with sequential data over time. Multimodal involves combining different data types like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data representations, like graphs of entities and relations.\n\nThe paper's focus is on point cloud data, which is a type of 3D data. The methods mentioned (Siamese, autoencoder) are machine learning models, but none of the topics listed directly relate to 3D shape correspondence. Time-series is about time-based data, which isn't the case here. Multimodal would involve multiple data modalities, but the paper seems focused on a single modality (point clouds). RAG and KG don't seem relevant here either. The paper is about unsupervised learning for shape matching, which doesn't fit into any of the four categories provided. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32274@AAAI"},
{"title": "OTIAS: OcTree Implicit Adaptive Sampling for Multispectral and Hyperspectral Image Fusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OTIAS: OcTree Implicit Adaptive Sampling for Multispectral and Hyperspectral Image Fusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multispectral and Hyperspectral Image Fusion\" suggests combining images from different spectral bands. Multispectral and hyperspectral images are types of data that capture information across multiple wavelengths, so this is about combining different data sources. That makes me think of multimodal, since multimodal typically refers to integrating data from different modalities or sources. \n\nBut wait, the other parts of the title: \"OcTree Implicit Adaptive Sampling.\" OcTree is a data structure used for spatial partitioning, which might be a method for processing the images. The key part here is \"Multispectral and Hyperspectral Image Fusion.\" Since these are different types of image data, combining them would be a multimodal task. \n\nTime-series usually involves data collected over time, like stock prices or weather data. This title doesn't mention anything about time, so probably not time-series. RAG (Retrieval-Augmented Generation) is more about using retrieved information to enhance generation tasks, like in NLP. KG (Knowledge Graph) involves structured data representations, which doesn't seem to fit here. \n\nSo the main focus is on fusing different types of images (multispectral and hyperspectral), which are different modalities. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32275@AAAI"},
{"title": "Boundary-Aware Temporal Dynamic Pseudo-Supervision Pairs Generation for Zero-Shot Natural Language Video Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Boundary-Aware Temporal Dynamic Pseudo-Supervision Pairs Generation for Zero-Shot Natural Language Video Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Dynamic\" suggests something related to time, which might point to time-series. But time-series usually refers to data collected over time, like stock prices or weather data. However, in this case, the context is video localization, which involves video data. Videos are inherently time-series because they consist of frames over time. So maybe time-series is a candidate.\n\nNext, \"Natural Language Video Localization\" combines language (text) with video. That sounds like multimodal, since it's using both text and video data. Multimodal research deals with integrating different types of data, like text, images, audio, etc. So that's another possible topic.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation, so RAG might not be relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about building or using knowledge graphs, so that's probably not it either.\n\nNow, the key part is \"Boundary-Aware Temporal Dynamic Pseudo-Supervision Pairs.\" The term \"temporal\" again points to time-series aspects. However, the main focus here is on generating pseudo-supervision pairs for zero-shot learning in video localization. The zero-shot aspect implies that the model is trained to recognize something it hasn't seen before, using natural language descriptions. Since it's combining video (a time-series medium) with natural language, this seems like a multimodal problem. The temporal aspect is part of the video data, but the core of the research is integrating different modalities (video and text) for localization. \n\nTherefore, even though there's a temporal component, the primary research topic here is multimodal because it's about combining different data types (video and language) to achieve a task. Time-series might be a part of the video data, but the main focus isn't on time-series analysis per se. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32276@AAAI"},
{"title": "SSLFusion: Scale and Space Aligned Latent Fusion Model for Multimodal 3D Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SSLFusion: Scale and Space Aligned Latent Fusion Model for Multimodal 3D Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal\" is right there in the title. That's one of the options. The paper is about 3D object detection using multimodal data. So multimodal is a strong candidate. \n\nThe other parts mention \"latent fusion model,\" which might relate to how different modalities are combined. But the key term here is \"multimodal.\" The other options: time-series would involve data over time, like sequences. RAG is Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks. KG is Knowledge Graphs, which are structured representations of information. \n\nSince the title explicitly states \"multimodal,\" and the other terms don't align with the other topics, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32278@AAAI"},
{"title": "Dis²Booth: Learning Image Distribution with Disentangled Features for Text-to-Image Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dis²Booth: Learning Image Distribution with Disentangled Features for Text-to-Image Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title here is about text-to-image diffusion models, which doesn't seem to involve sequences over time. So probably not time-series.\n\nMultimodal refers to combining multiple modalities, like text and images. The paper is about generating images from text, which is a classic multimodal task. So that's a possibility. But let me check the other options.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text. The title doesn't mention anything about retrieval or augmenting generation with retrieved data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nSo the most likely answer is multimodal because it's about text-to-image generation, which combines text (language) and images (vision) modalities. The disentangled features part is about separating different aspects of the image distribution, which is a technique used in multimodal models to better handle the combination of different data types. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32279@AAAI"},
{"title": "Muses: 3D-Controllable Image Generation via Multi-Modal Agent Collaboration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Muses: 3D-Controllable Image Generation via Multi-Modal Agent Collaboration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts are \"Multi-Modal Agent Collaboration.\" The term \"multi-modal\" immediately stands out. That usually refers to using multiple types of data, like text, images, audio, etc., together. So that's a hint towards the \"multimodal\" topic.\n\nThen, the paper is about image generation, which is a common task in multimodal systems where different modalities (like text and image) are combined. The mention of \"agent collaboration\" might imply that different agents or models are working together, possibly handling different modalities. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation tasks, often in NLP. KG (Knowledge Graph) involves structured data representations. The title doesn't mention anything about time, retrieval, or knowledge graphs. \n\nSo the most fitting category here is \"multimodal\" because of the explicit mention of multi-modal collaboration in the title. The other terms in the title align with multimodal research areas, like combining different data types for image generation.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32280@AAAI"},
{"title": "AS-Det: Active Sampling for Adaptive 3D Object Detection in Point Clouds", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AS-Det: Active Sampling for Adaptive 3D Object Detection in Point Clouds.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data over time. The title mentions 3D object detection in point clouds. Point clouds are typically from LiDAR or 3D scans, which are spatial data, not necessarily time-dependent. So maybe not time-series.\n\nMultimodal refers to using multiple data types, like combining text and images. The title doesn't mention combining different modalities, just point clouds. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to augment their responses. This paper is about object detection in point clouds, which is more about perception and not retrieval. So RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on active sampling for 3D detection, which doesn't seem to involve building or using a knowledge graph. \n\nSo none of the four topics seem to fit. The paper is about 3D object detection in point clouds using active sampling, which is more related to computer vision or machine learning techniques for point cloud data. Since it doesn't align with time-series, multimodal, RAG, or KG, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32281@AAAI"}
{"title": "AS-Det: Active Sampling for Adaptive 3D Object Detection in Point Clouds", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AS-Det: Active Sampling for Adaptive 3D Object Detection in Point Clouds.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data over time. The title mentions 3D object detection in point clouds. Point clouds are typically from LiDAR or 3D scans, which are spatial data, not necessarily time-dependent. So maybe not time-series.\n\nMultimodal refers to using multiple data types, like combining text and images. The title doesn't mention combining different modalities, just point clouds. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to augment their responses. This paper is about object detection in point clouds, which is more about perception and not retrieval. So RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on active sampling for 3D detection, which doesn't seem to involve building or using a knowledge graph. \n\nSo none of the four topics seem to fit. The paper is about 3D object detection in point clouds using active sampling, which is more related to computer vision or machine learning techniques for point cloud data. Since it doesn't align with time-series, multimodal, RAG, or KG, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32281@AAAI"},
{"title": "GarFast: Realistic and Fast Garment Transfer with a Simplified Parser-Free Approach", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GarFast: Realistic and Fast Garment Transfer with a Simplified Parser-Free Approach.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Garment Transfer\" probably refers to transferring clothing onto a person in an image, maybe like changing clothes in a photo. \"Parser-Free Approach\" suggests they're avoiding using a parser, which in computer vision might be something that segments or analyzes the image structure. The goal is making it realistic and fast.\n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nGarment transfer sounds like an image processing task. If it's about modifying images of clothes, maybe using some kind of model. But does it involve time-series? Probably not, since it's about images, not sequences over time. Multimodal? If it uses both images and text, maybe, but the title doesn't mention text. RAG? That's more about using retrieved data to generate text or something else. KG? If they're using a knowledge graph to structure garment information, but again, the title doesn't mention that. The \"parser-free\" part might relate to avoiding complex models, but I'm not sure how that ties into the four topics. Since none of the four topics seem to directly relate to garment transfer or image processing techniques mentioned, maybe the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32282@AAAI"},
{"title": "Latent Diffusion-Enhanced Virtual Try-On via Optimized Pseudo-Label Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Latent Diffusion-Enhanced Virtual Try-On via Optimized Pseudo-Label Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Virtual Try-On\" sounds like it's related to trying on clothes virtually, probably in an image or video context. \"Latent Diffusion-Enhanced\" might refer to using a diffusion model in the latent space, which is common in generative models. \"Optimized Pseudo-Label Generation\" suggests some kind of semi-supervised learning where pseudo-labels are generated to improve the model.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge retrieval during generation. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus seems to be on generating images (virtual try-on) using a diffusion model and pseudo-labels. There's no mention of time-series data, so that's out. It's using a generative model, but does that fall under multimodal? Well, virtual try-on might involve images and maybe some other modalities, but the title doesn't explicitly mention combining different data types. RAG and KG are about knowledge retrieval and structured data, which don't seem relevant here. The main techniques are diffusion models and pseudo-labels, which don't directly map to the given topics. So maybe it doesn't fit any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32283@AAAI"},
{"title": "HybridReg: Robust 3D Point Cloud Registration with Hybrid Motions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HybridReg: Robust 3D Point Cloud Registration with Hybrid Motions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. The title mentions 3D point cloud registration, which is more about spatial data alignment. So probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper is about 3D point clouds, which is a single data type, so maybe not multimodal unless they're using multiple modalities. But the title doesn't mention that.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks, like in NLP. This paper seems to be about registration, which is a geometric problem, so RAG doesn't fit here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on point cloud registration, which is a computer vision or robotics problem. Doesn't seem related to knowledge graphs.\n\nSo none of the four topics seem to fit. The paper is about 3D point cloud registration with hybrid motions, which is a specific technical area in computer vision or robotics, not related to the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32284@AAAI"},
{"title": "Out of Length Text Recognition with Sub-String Matching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Out of Length Text Recognition with Sub-String Matching.\" Hmm, I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title doesn't mention anything about time or sequences over time, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title is about text recognition, but I don't see any indication of combining different modalities. It's just about text, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information before generating a response. The title mentions \"sub-string matching,\" which sounds like a retrieval method. If the paper is about using substring matching to retrieve information to aid in text recognition, that could be RAG. But I'm not entirely sure. Let me think more.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper is about building or using a knowledge graph, that would fit. But the title doesn't mention anything about graphs or structured data, so probably not KG.\n\nSo, the options are RAG or none. The key part here is \"sub-string matching.\" In RAG, retrieval is a key component, and substring matching could be a method used to retrieve relevant documents or substrings. If the paper is about improving text recognition by retrieving substrings, that might align with RAG. However, if it's just about recognizing text that's out of a certain length using substring techniques, maybe it's more about text processing algorithms rather than RAG. \n\nWait, RAG typically involves retrieving from a large corpus to augment generation. If the paper is about a method where during text recognition, the model retrieves substrings from a database to help recognize the text, then it's RAG. But if it's just a substring matching algorithm for text recognition without retrieval, maybe it's not RAG. The title is a bit vague. \n\nAlternatively, maybe it's none of the above. If the paper is about text recognition techniques using substring matching as a method, but not related to retrieval-augmented generation, then it might not fit into any of the four categories. Since the title doesn't clearly indicate RAG, KG, time-series, or multimodal, the safest answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32285@AAAI"},
{"title": "InstructOCR: Instruction Boosting Scene Text Spotting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"InstructOCR: Instruction Boosting Scene Text Spotting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"InstructOCR\" probably refers to an OCR (Optical Character Recognition) system that's enhanced with instructions. \"Instruction Boosting\" suggests that the model is using some form of instructions to improve its performance. \"Scene Text Spotting\" is about detecting and recognizing text in images, like street signs or natural scenes.\n\nNow, the four options. Time-series deals with data over time, like stock prices or weather. That doesn't seem relevant here. Multimodal involves combining different data types, like text and images. Since OCR is about text in images, maybe multimodal? But wait, the key here is whether the paper is about integrating multiple modalities. If InstructOCR uses both text and images, then it's multimodal. But if it's just improving OCR with instructions, maybe not. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. That's more about combining retrieval with text generation, like in question-answering systems. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data.\n\nSo, the main question is whether this is multimodal. OCR itself is multimodal because it processes images (visual modality) and text (linguistic modality). However, the term \"Instruction Boosting\" might imply that the model is using instructions, which could be a form of additional input. If the instructions are in a different modality, like text instructions for an image-based task, that would be multimodal. But if the instructions are part of the same modality (like text instructions for text processing), maybe not. \n\nBut given that OCR is inherently multimodal (image and text), and the paper is about improving scene text spotting with instructions, it's likely that the research is in the multimodal domain. The other options don't fit. Time-series is unrelated. RAG and KG are not mentioned in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32286@AAAI"},
{"title": "A Diffusion-Based Framework for Occluded Object Movement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Diffusion-Based Framework for Occluded Object Movement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Diffusion-Based Framework\" suggests they're using a diffusion model, which is a type of generative model often used in image generation or sequence modeling. \"Occluded Object Movement\" implies that the research is about objects that are partially hidden or blocked in some way, and how they move. So maybe it's about predicting or reconstructing movement when objects are occluded.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like sequences. Multimodal would involve combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on movement, which is inherently a time-dependent process. If they're modeling how objects move over time, especially when occluded, that sounds like a time-series problem. They might be predicting future positions or reconstructing past movements based on partial observations. Diffusion models can be applied to time-series data, so that fits. \n\nMultimodal would require combining different modalities, but the title doesn't mention anything like that. RAG and KG don't seem relevant here either. The problem is about object movement over time, which is a sequence, so time-series makes sense. I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32287@AAAI"},
{"title": "DiffRetouch: Using Diffusion to Retouch on the Shoulder of Experts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffRetouch: Using Diffusion to Retouch on the Shoulder of Experts.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"DiffRetouch\" probably refers to a method using diffusion for retouching. Diffusion models are a type of generative model, often used in image generation or editing. Retouching here likely means image editing or enhancement. The phrase \"on the shoulder of experts\" might suggest leveraging expert knowledge or models, maybe through some form of collaboration or integration with existing systems.\n\nNow, the four options: time-series, multimodal, RAG, KG. \n\nTime-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal usually refers to combining different data types, like text and images. The paper's focus seems to be on retouching, which is image-related, but I'm not sure if it's combining multiple modalities. The title doesn't explicitly mention other data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to pull information and then generates a response. If the paper is about using retrieved information to assist in retouching, maybe. But the title mentions diffusion models, which are more about generation than retrieval. Not sure yet.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses a knowledge graph to inform the retouching process, that would fit. However, the title doesn't mention anything about graphs or structured knowledge. The \"shoulder of experts\" might metaphorically refer to using expert knowledge, but unless it's explicitly a knowledge graph, it's a stretch.\n\nSo, considering all this, the paper seems to be about using diffusion models for image retouching. None of the four topics (time-series, multimodal, RAG, KG) directly relate to diffusion models or image retouching. The closest might be multimodal if it's combining different data types, but the title doesn't indicate that. Therefore, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32288@AAAI"},
{"title": "IniRetinex: Rethinking Retinex-type Low-Light Image Enhancer via Initialization Perspective", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"IniRetinex: Rethinking Retinex-type Low-Light Image Enhancer via Initialization Perspective.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. Retinex is a term I've heard in image processing, related to enhancing images, especially in low-light conditions. The paper is about improving a Retinex-type enhancer by looking at initialization. So the main focus is on image enhancement techniques, specifically for low-light images.\n\nNow, the possible topics. Time-series deals with data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. Multimodal refers to combining multiple data types, like text and images. The title doesn't mention combining different modalities, just enhancing images. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses. That's more about text models using external data. KG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or retrieval-augmented generation. \n\nSo the paper is about image processing, specifically enhancing low-light images using a Retinex approach with a focus on initialization. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The paper is in the field of computer vision or image processing, but the given options don't include that. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32289@AAAI"},
{"title": "Vision-guided Text Mining for Unsupervised Cross-modal Hashing with Community Similarity Quantization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Vision-guided Text Mining for Unsupervised Cross-modal Hashing with Community Similarity Quantization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-guided Text Mining\" suggests that there's a combination of visual data (vision) and text. So that's two different modalities, right? Then \"Cross-modal Hashing\" definitely points to multimodal because cross-modal usually refers to handling multiple types of data, like images and text. Hashing here is probably about creating compact representations for efficient retrieval or comparison across these modalities. \n\nThe other part, \"Community Similarity Quantization,\" might be about grouping similar items or communities, but the key term here is cross-modal. The main focus seems to be on integrating different data types (vision and text) for hashing. \n\nLooking at the options: time-series is about data over time, which doesn't fit. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks. KG is Knowledge Graphs, which involve structured data and relationships. None of those seem to fit here. The cross-modal aspect is the key, so multimodal is the right choice.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32290@AAAI"}
{"title": "Depth-Centric Dehazing and Depth-Estimation from Real-World Hazy Driving Video", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Depth-Centric Dehazing and Depth-Estimation from Real-World Hazy Driving Video.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Depth-Centric Dehazing\" suggests that the main focus is on depth information to remove haze. \"Depth-Estimation\" is part of the process, and it's using real-world hazy driving video. So, the paper is about estimating depth from videos that are hazy, which is a common problem in autonomous driving or computer vision for vehicles.\n\nNow, the possible topics. Time-series usually involves data over time, like sequences. Multimodal refers to using multiple types of data (e.g., text and images). RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation in models. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about processing video (which is a sequence of images over time) to estimate depth and dehaze. Video is a time-series data type, so maybe time-series. But wait, depth estimation from video could involve both spatial and temporal aspects. However, the key here is whether the research is specifically focused on time-series analysis. Alternatively, multimodal could be if they're combining different modalities like RGB and depth, but the title mentions \"depth-centric,\" which might imply that depth is the main modality, not combining with others. \n\nRAG and KG don't seem relevant here. The paper is about computer vision tasks in videos, not about knowledge graphs or retrieval-augmented generation. So between time-series and multimodal. Since the input is a video (a time-series of frames), and the tasks involve processing that sequence, it might be time-series. However, sometimes video processing is considered multimodal if it combines different data types, but the title doesn't mention other modalities. The focus is on depth estimation from hazy videos. So maybe time-series is the right category here. Alternatively, if the paper is about combining depth with other data, but the title doesn't specify that. \n\nHmm. The problem is whether depth estimation from video is considered time-series. Since video is a sequence of frames over time, the data is inherently a time-series. So the research could be in the time-series domain. Therefore, the answer might be time-series. But I'm not 100% sure. Let me check again. The other options: multimodal would require multiple data types. RAG and KG are unrelated. So the most likely is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32291@AAAI"},
{"title": "EventPillars: Pillar-based Efficient Representations for Event Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EventPillars: Pillar-based Efficient Representations for Event Data.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Event Data\" suggests that the paper is dealing with events, which are typically time-stamped occurrences. So maybe time-series? Time-series data often involves sequences of data points over time, which could include events. But the term \"EventPillars\" and \"pillar-based\" is a bit unclear. Pillars might refer to some structure or method for organizing the data.\n\nThe key part is \"Efficient Representations.\" That could relate to how the data is structured or compressed. Time-series analysis often involves creating efficient representations to capture temporal patterns. But I need to check the other options.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about multiple modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper is about building a graph structure for events, maybe. But the term \"pillar-based\" doesn't immediately suggest a graph. Pillars might be more like segments or partitions in the data.\n\nSo, considering all this, the most likely topic is time-series. Event data is often time-series in nature, and efficient representations for such data would fall under time-series analysis. The other options don't fit as well. I don't see any mention of multiple modalities, retrieval-augmented generation, or knowledge graphs in the title. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32292@AAAI"},
{"title": "Combating Semantic Contamination in Learning with Label Noise", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Combating Semantic Contamination in Learning with Label Noise.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Semantic Contamination\" probably refers to issues where the meaning or semantics of the data are affected. \"Learning with Label Noise\" suggests that the problem is about machine learning models dealing with incorrect or noisy labels in the training data. The goal here is to combat or mitigate this contamination.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to data that combines multiple modalities, like text and images. The title doesn't mention different data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generation, often used in NLP. The title doesn't seem to relate to retrieval or generation processes, so RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured knowledge, so that's probably not it either.\n\nSo, the paper is about handling label noise in machine learning, specifically addressing semantic contamination. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this problem. The focus is on improving learning in the presence of noisy labels, which is a general machine learning problem, not specific to any of the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32293@AAAI"},
{"title": "EMHI: A Multimodal Egocentric Human Motion Dataset with HMD and Body-Worn IMUs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EMHI: A Multimodal Egocentric Human Motion Dataset with HMD and Body-Worn IMUs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal\" is right there in the title. That's one of the options. The dataset uses HMD (Head-Mounted Display) and body-worn IMUs (Inertial Measurement Units). So, they're combining data from different sources or modalities, like visual data from the HMD and motion data from the IMUs. That definitely sounds like multimodal data. \n\nNow, checking the other options. Time-series usually refers to data collected over time, which this might be, since motion data is often time-series. But the question is about the main topic. The title explicitly mentions \"Multimodal,\" so that's a strong indicator. \n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to be mentioned here. The paper is about a dataset, not about models or knowledge structures. So RAG and KG are probably not relevant here. \n\nEven though the data could be time-series, the key term in the title is \"Multimodal,\" so the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32294@AAAI"},
{"title": "CoSDA: Enhancing the Robustness of Inversion-based Generative Image Watermarking Framework", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CoSDA: Enhancing the Robustness of Inversion-based Generative Image Watermarking Framework.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Generative Image Watermarking\" suggests it's about adding watermarks to images using generative models. \"Inversion-based\" might refer to techniques that invert some process, maybe like generating images from data. \"Robustness\" implies making the watermarking method more resistant to attacks or distortions. \n\nNow, the possible topics. Time-series is about data over time, which doesn't seem related here. Multimodal usually involves combining different data types like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generative models. KG is Knowledge Graphs, which are structured data representations. \n\nThe paper's focus is on image watermarking using generative models. None of the four topics directly relate to watermarking or inversion-based generative methods. RAG is about retrieval and generation, but the title doesn't mention retrieval. Multimodal might be a stretch if it's combining image and text, but the title doesn't indicate that. Time-series and KG are clearly not relevant here. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32295@AAAI"},
{"title": "SSUN-Net: Spatial-Spectral Prior-Aware Unfolding Network for Pan-Sharpening", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SSUN-Net: Spatial-Spectral Prior-Aware Unfolding Network for Pan-Sharpening.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Pan-Sharpening\" refers to a technique in remote sensing where a high-resolution panchromatic image is combined with a lower-resolution multispectral image to produce a high-resolution color image. So this is about image processing, specifically combining different types of data.\n\nThe term \"Spatial-Spectral\" suggests that the method uses both spatial (geographical) and spectral (color/wavelength) information. \"Prior-Aware\" might mean the model incorporates prior knowledge or constraints. \"Unfolding Network\" could imply an iterative or unfolded architecture, maybe similar to unfolding optimization steps into neural network layers.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time, so probably not time-series.\n\nMultimodal usually refers to combining different types of data, like text and images, or audio and video. In this case, the paper is combining panchromatic and multispectral images, which are different types of data. So that's a possibility. But wait, in remote sensing, panchromatic and multispectral are different spectral bands, so maybe it's more about spectral data rather than different modalities. However, since they are combining two different types of images (pan and multispectral), it could be considered multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representations. The title doesn't mention knowledge graphs or structured data, so that's out.\n\nSo the main contenders are multimodal and maybe something else. But given the options, the best fit is multimodal because it's combining different data types (pan and multispectral images) to achieve a better result. Even though they are both images, they are different in terms of resolution and spectral information, which could be considered different modalities in the context of the problem. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32296@AAAI"},
{"title": "Guided Real Image Dehazing Using YCbCr Color Space", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Guided Real Image Dehazing Using YCbCr Color Space.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or weather data. This paper is about image dehazing, which is an image processing task, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, just image dehazing using a specific color space. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The paper's title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, the paper is about image processing, not structured data or knowledge representation. \n\nSo none of the four topics seem to fit. The paper is about image dehazing using a specific color space, which is a computer vision or image processing technique. Since the options given don't include image processing or computer vision, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32297@AAAI"},
{"title": "Multi-Pair Temporal Sentence Grounding via Multi-Thread Knowledge Transfer Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Pair Temporal Sentence Grounding via Multi-Thread Knowledge Transfer Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal\" suggests something related to time, which might point to time-series. \"Sentence Grounding\" could be about aligning text with some data, maybe in a video or audio context, which might be multimodal. \"Multi-Thread Knowledge Transfer Network\" – \"Knowledge Transfer\" makes me think of knowledge graphs (KG) since they involve structured data and relationships. But wait, RAG (Retrieval-Augmented Generation) also involves knowledge retrieval. However, RAG is more about using retrieved information to enhance generation, whereas knowledge transfer in a network might be about transferring knowledge between different parts of the model or between models. \n\n\"Multi-Pair\" and \"Multi-Thread\" could imply handling multiple data sources or modalities. But the key term here is \"Temporal,\" which is a strong indicator for time-series analysis. However, time-series typically deals with sequential data over time, like stock prices or sensor data. Sentence grounding in a temporal context might involve aligning text with time-based data, such as video or audio, which could be multimodal. But the mention of \"Knowledge Transfer Network\" might lean towards knowledge graphs if it's about structured knowledge. However, the term \"Knowledge Transfer\" could also be a method rather than the topic itself. \n\nWait, the options are time-series, multimodal, RAG, or KG. Let me check again. If the paper is about temporal data alignment (sentence grounding in time), that's time-series. But if it's about combining different modalities (like text and video), it's multimodal. The title mentions \"sentence grounding,\" which is often in the context of video or audio, making it multimodal. However, the \"Knowledge Transfer Network\" part might be a method used, not the main topic. The main focus seems to be on temporal aspects and sentence grounding, which could be time-series. But I'm a bit confused. Let me think again. \n\nIn NLP, temporal sentence grounding often refers to locating sentences in a timeline, which is time-series. But if it's about aligning text with other modalities (like video frames) over time, that's multimodal. The title says \"Multi-Pair,\" which could mean multiple pairs of sentences and their temporal contexts. The \"Multi-Thread Knowledge Transfer Network\" is probably the model architecture they're using. So the main topic is the task they're addressing. If the task is about temporal alignment (time-series) or combining text with other modalities (multimodal). Since \"sentence grounding\" in temporal contexts is often part of multimodal tasks, like in videos where you have text and visual data. So maybe multimodal. But I'm not 100% sure. Alternatively, if the focus is on the temporal aspect without other modalities, it's time-series. The title doesn't mention other modalities explicitly, just temporal. Hmm. The term \"grounding\" in NLP usually refers to mapping text to real-world data, which can be multimodal. For example, grounding a sentence in a video. So if it's about aligning text with temporal data (like video), it's multimodal. But if it's just about time-based data without other modalities, it's time-series. The title doesn't specify other modalities, but \"sentence grounding\" often implies multimodal. I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32298@AAAI"},
{"title": "AE-NeRF: Augmenting Event-Based Neural Radiance Fields for Non-ideal Conditions and Larger Scenes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AE-NeRF: Augmenting Event-Based Neural Radiance Fields for Non-ideal Conditions and Larger Scenes.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Event-Based Neural Radiance Fields\" – I know that Neural Radiance Fields (NeRF) are used for 3D scene reconstruction from 2D images. Event-based might refer to using event cameras, which capture changes in brightness over time, so that's time-sensitive data. But the main focus here is on augmenting these NeRF models for non-ideal conditions and larger scenes. \n\nNow, looking at the options. Time-series usually involves data points indexed in time order. If the paper is about handling temporal data, maybe. But NeRF is more about spatial data. However, event-based data could be time-series, but the main application here seems to be improving the NeRF model's performance under certain conditions, not necessarily the time aspect itself.\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention combining different modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This paper is about a neural network model (AE-NeRF) for 3D reconstruction, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data representation.\n\nSo, the paper is about improving a specific type of neural network (NeRF) using event-based data. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to the core focus of this paper, which is enhancing NeRF for specific conditions, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32299@AAAI"},
{"title": "PROSAC: Provably Safe Certification for Machine Learning Models under Adversarial Attacks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PROSAC: Provably Safe Certification for Machine Learning Models under Adversarial Attacks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Provably Safe Certification\" suggests it's about ensuring the safety or robustness of ML models. \"Adversarial Attacks\" refers to attacks where inputs are slightly perturbed to fool the model. So the paper is likely about methods to certify that a model is safe against such attacks.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. Multimodal deals with multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which combines retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on certification against adversarial attacks. None of the four topics directly relate to adversarial robustness or certification. Time-series, multimodal, RAG, and KG are all about data types or model architectures. The paper is more about model safety and security, which isn't covered by any of these categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32300@AAAI"}
{"title": "VQA4CIR: Boosting Composed Image Retrieval with Visual Question Answering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VQA4CIR: Boosting Composed Image Retrieval with Visual Question Answering.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. VQA stands for Visual Question Answering. That's when you have an image and a question about it, and the model answers the question. So VQA is definitely a multimodal task because it involves both visual (image) and textual (question) data. \n\nThe term \"Composed Image Retrieval\" (CIR) probably refers to retrieving images based on a composition of elements, maybe combining text and images. So if they're using VQA to enhance CIR, that suggests they're integrating visual and textual information. \n\nLooking at the options: time-series is about data over time, which doesn't seem relevant here. RAG is Retrieval-Augmented Generation, which is more about using retrieved documents to augment model outputs, but the title mentions image retrieval, not text-based retrieval for generation. KG is Knowledge Graphs, which are structured data representations, not directly related. \n\nMultimodal is about combining multiple modalities like text and images. Since VQA is a classic multimodal task and the paper is using it to improve image retrieval, which likely involves combining visual and textual inputs, this fits under multimodal. \n\nI don't see any mention of knowledge graphs, RAG, or time-series aspects here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32301@AAAI"},
{"title": "PoseLLaVA: Pose Centric Multimodal LLM for Fine-Grained 3D Pose Manipulation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PoseLLaVA: Pose Centric Multimodal LLM for Fine-Grained 3D Pose Manipulation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Pose Centric\" suggests it's focused on pose data. \"Multimodal LLM\" stands out. Multimodal usually refers to models that handle multiple types of data, like combining text with images or other modalities. The term \"multimodal\" is one of the options given. \n\nThe other parts mention \"Fine-Grained 3D Pose Manipulation,\" which might involve processing 3D data, but that's more about the application rather than the research topic. The key here is the \"Multimodal LLM\" part. Since multimodal is one of the options, this seems to fit. \n\nTime-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about time, retrieval, or knowledge graphs. So the most fitting topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32302@AAAI"},
{"title": "Residual Diffusion Deblurring Model for Single Image Defocus Deblurring", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Residual Diffusion Deblurring Model for Single Image Defocus Deblurring.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title is about image deblurring, so probably not time-series. \n\nMultimodal would involve combining different types of data, like text and images. The title mentions a single image, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image processing, not on building or using knowledge graphs. \n\nSo, the answer should be none. The paper is about image deblurring using a residual diffusion model, which doesn't fit any of the given topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32303@AAAI"},
{"title": "DiT4Edit: Diffusion Transformer for Image Editing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiT4Edit: Diffusion Transformer for Image Editing.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image editing, which is more about images, not time-based data. So probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image editing using a diffusion transformer. If it's using a model that integrates different modalities, maybe. But the title doesn't explicitly mention combining different data types. It's focused on image editing, which is a single modality. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch information and then generates a response. The title doesn't mention anything about retrieval or combining it with generation. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data. So that's probably not it either.\n\nSo the answer is none. The paper is about image editing using a diffusion transformer, which doesn't fit into any of the listed topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32304@AAAI"},
{"title": "Semantic Ambiguity Modeling and Propagation for Fine-Grained Visual Cross View Geo-Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Semantic Ambiguity Modeling and Propagation for Fine-Grained Visual Cross View Geo-Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Semantic Ambiguity Modeling\" suggests dealing with ambiguous meanings in data. \"Propagation\" might refer to how these ambiguities spread or affect the model. \"Fine-Grained Visual Cross View Geo-Localization\" involves using visual data for precise location determination across different views. \n\nTime-series usually involves data over time, like stock prices or weather. This title doesn't mention time or sequences, so probably not time-series. \n\nMultimodal would involve combining different data types, like text and images. The paper uses visual data (images) and mentions semantic aspects, which could be text. But the main focus here is on modeling ambiguity in visual data for geo-localization. Not sure if it's combining multiple modalities. Maybe, but not certain.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graphs) involve structured data and relationships. The title doesn't mention graphs or structured knowledge, so likely not KG.\n\nSo, the closest might be multimodal if they're combining visual and semantic (maybe textual) data. But the title emphasizes modeling ambiguity in visual data for a specific task. Maybe it's not combining multiple modalities but rather focusing on the visual aspect with semantic analysis. So maybe it's not multimodal either. \n\nAlternatively, if \"semantic ambiguity\" involves integrating different data sources or modalities, but the title doesn't specify that. Without more details, it's hard to say. But given the options, I think it's none of the four. The main topics here are visual geo-localization and semantic ambiguity, which don't directly map to the given categories. So the answer would be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32305@AAAI"},
{"title": "Weakly Supervised Gland Segmentation with Class Semantic Consistency and Purified Labels Filtration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Weakly Supervised Gland Segmentation with Class Semantic Consistency and Purified Labels Filtration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Weakly Supervised\" refers to a type of machine learning where the model is trained with limited or noisy labels. \"Gland Segmentation\" suggests this is in the medical imaging field, probably using images to identify glands. The methods mentioned are \"Class Semantic Consistency\" and \"Purified Labels Filtration.\" \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents. KG is Knowledge Graph, which involves structured data and relationships between entities.\n\nThe paper is about image segmentation in a medical context using weak supervision. None of the topics listed directly relate to image segmentation or weakly supervised learning. The methods mentioned don't seem to involve time-series data, multiple modalities, retrieval-augmented generation, or knowledge graphs. So it doesn't fit any of the four categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32306@AAAI"},
{"title": "HDLayout: Hierarchical and Directional Layout Planning for Arbitrary Shaped Visual Text Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HDLayout: Hierarchical and Directional Layout Planning for Arbitrary Shaped Visual Text Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title mentions \"Visual Text Generation,\" which could involve both text and visual elements. So maybe multimodal? But I need to check the other options.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation tasks. The title doesn't mention retrieval or augmentation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo the most likely is multimodal because it's about generating visual text, which combines text and visual elements. The hierarchical and directional layout planning might involve structuring how different modalities are arranged. I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32307@AAAI"},
{"title": "Simplifying Control Mechanism in Text-to-Image Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Simplifying Control Mechanism in Text-to-Image Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about text-to-image models, which don't seem to be time-dependent. So probably not time-series.\n\nMultimodal refers to models that handle multiple types of data, like text and images. Since the paper is about text-to-image, that's combining text (language) and images. So multimodal might be a fit here.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title doesn't mention anything about retrieval or augmenting generation with external data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge bases, so probably not KG.\n\nSo the most likely answer is multimodal because it's dealing with both text and image data in a model. The control mechanism simplification is part of how the model handles these two modalities. I don't see any mention of time-series data, retrieval, or knowledge graphs here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32309@AAAI"},
{"title": "BGHR: Bridging the Gap Between HBox-Supervised and RBox-Supervised Oriented Object Detection via Adaptive Fine-Grained Sample Mining", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BGHR: Bridging the Gap Between HBox-Supervised and RBox-Supervised Oriented Object Detection via Adaptive Fine-Grained Sample Mining.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on object detection, specifically oriented object detection. The terms HBox and RBox probably refer to different types of bounding boxes. HBox might be horizontal boxes, and RBox rotated boxes. The paper is trying to bridge the gap between these two supervision methods using adaptive sample mining.\n\nNow, looking at the four options. Time-series is about data over time, like stock prices or weather. This title doesn't mention anything about time, so probably not time-series. Multimodal usually involves combining different data types, like text and images. The title is about object detection, which is computer vision, but there's no mention of combining modalities. RAG stands for Retrieval-Augmented Generation, which is more about using external knowledge in models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on improving object detection by adapting sample mining between two types of supervised data. It's about the model's training process and how it handles different bounding box annotations. None of the four topics directly relate to this. The paper is in computer vision, specifically object detection, but the given options don't include that. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32310@AAAI"},
{"title": "Foundation Model Driven Appearance Extraction for Robust Multiple Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Foundation Model Driven Appearance Extraction for Robust Multiple Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Foundation Model Driven\" probably refers to using a pre-trained model, like a foundation model in AI. \"Appearance Extraction\" suggests they're extracting visual features. \"Robust Multiple Object Tracking\" implies tracking multiple objects over time, which is common in video analysis.\n\nTime-series usually involves data over time, like stock prices or sensor data. This paper is about tracking objects in video, which is a time-series problem because it's sequential data over time. But wait, the main focus here is on appearance extraction using a foundation model. Foundation models are typically large pre-trained models, like CLIP or ViT, which are used for various tasks. \n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention combining different modalities, so maybe not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit.\n\nSo, the key part is \"Multiple Object Tracking,\" which is a time-series problem because it's tracking over time. The appearance extraction is part of the method, but the core task is tracking over time. So the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32311@AAAI"}
{"title": "Foundation Model Driven Appearance Extraction for Robust Multiple Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Foundation Model Driven Appearance Extraction for Robust Multiple Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Foundation Model Driven\" probably refers to using a pre-trained model, like a foundation model in AI. \"Appearance Extraction\" suggests they're extracting visual features. \"Robust Multiple Object Tracking\" implies tracking multiple objects over time, which is common in video analysis.\n\nTime-series usually involves data over time, like stock prices or sensor data. This paper is about tracking objects in video, which is a time-series problem because it's sequential data over time. But wait, the main focus here is on appearance extraction using a foundation model. Foundation models are typically large pre-trained models, like CLIP or ViT, which are used for various tasks. \n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention combining different modalities, so maybe not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit.\n\nSo, the key part is \"Multiple Object Tracking,\" which is a time-series problem because it's tracking over time. The appearance extraction is part of the method, but the core task is tracking over time. So the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32311@AAAI"},
{"title": "Exploring Unbiased Deepfake Detection via Token-Level Shuffling and Mixing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring Unbiased Deepfake Detection via Token-Level Shuffling and Mixing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on deepfake detection. The methods mentioned are token-level shuffling and mixing. The goal is unbiased detection. \n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The title doesn't specify using multiple modalities, so that might not be it either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge structures, so that's unlikely.\n\nThe paper is about deepfake detection using token-level techniques. Tokens here might refer to elements in a model, like in NLP. The methods involve shuffling and mixing tokens to detect deepfakes. This seems more related to machine learning models, perhaps in computer vision or NLP, but none of the four topics listed (time-series, multimodal, RAG, KG) directly apply here. The paper isn't about time-based data, multiple modalities, retrieval-augmented generation, or knowledge graphs. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32312@AAAI"},
{"title": "MFL-Owner: Ownership Protection for Multi-modal Federated Learning via Orthogonal Transform Watermark", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MFL-Owner: Ownership Protection for Multi-modal Federated Learning via Orthogonal Transform Watermark.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal Federated Learning\" is mentioned. The term \"multi-modal\" suggests that the research involves multiple types of data, like text, images, audio, etc. So that points towards the \"multimodal\" topic. \n\nThe other parts of the title talk about ownership protection using a watermark through orthogonal transforms. But the key part here is \"Multi-modal Federated Learning.\" Even though federated learning is a technique, the question is about the research topic. Since the paper is about multi-modal data in federated learning, the primary topic here would be multimodal. \n\nThe other options: time-series would involve data over time, like stock prices or weather. RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models. KG is Knowledge Graphs, which are structured representations of knowledge. None of these seem to fit the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32313@AAAI"},
{"title": "DFDNet: Disentangling and Filtering Dynamics for Enhanced Video Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DFDNet: Disentangling and Filtering Dynamics for Enhanced Video Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. DFDNet is the model name. The key parts are \"Disentangling and Filtering Dynamics\" and \"Enhanced Video Prediction.\" Video prediction involves forecasting future frames in a video, which is a sequence of images over time. That makes me think of time-series data because videos are inherently temporal. Time-series analysis deals with data points indexed in time order, so predicting the next frame fits here.\n\nNow, checking the other options. Multimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation tasks, often in NLP. The title doesn't mention retrieval or generation, so RAG is unlikely. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem relevant here.\n\nThe focus is on dynamics in video, which are temporal. Disentangling and filtering dynamics might refer to separating different aspects of motion or changes over time. So, the core of the research is about handling temporal sequences in video data. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32314@AAAI"},
{"title": "PNVC: Towards Practical INR-based Video Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PNVC: Towards Practical INR-based Video Compression.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. PNVC probably stands for something, but the key part here is \"INR-based Video Compression.\" INR could be an abbreviation, maybe \"Implicit Neural Representation\"? I've heard that term in the context of neural networks for representing images or videos. So, the paper is about video compression using INRs.\n\nNow, the four options. Time-series usually refers to data that's sequential over time, like stock prices or sensor data. Video is a form of time-series data because it's a sequence of frames over time. But the question is whether the research topic is specifically about time-series analysis. However, video compression is more about data compression techniques, which might not directly fall under time-series unless the focus is on temporal modeling.\n\nMultimodal refers to combining multiple types of data, like text and images, or audio and video. The title doesn't mention combining different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to augment its responses. That doesn't seem related to video compression.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. Again, not directly related to video compression.\n\nSo, the main question is whether video compression falls under time-series. Video is a time-series of images, but the research topic here is about compression techniques using INRs. The focus is on the method (INR-based) for compressing video, which is a form of time-series data. However, the primary research area might be more about neural representations or compression algorithms rather than time-series analysis specifically. But since video is inherently a time-series, maybe the answer is time-series. Alternatively, if the paper is about the INR method itself, which is a type of model, but the options don't include neural networks or compression. The given options are time-series, multimodal, RAG, KG. Since video is a time-series, and the paper is about video compression, perhaps the answer is time-series. But I'm not entirely sure. Maybe the answer is none if it's not directly about time-series analysis. Wait, the question is which research topic does the paper belong to. If the paper is about video compression using INRs, the main topic might be video compression, which isn't listed. The four options are time-series, multimodal, RAG, KG. Since none of these directly relate to video compression or INRs, maybe the answer is none. But wait, video is a time-series, so maybe time-series is the closest. Hmm. I'm a bit confused. Let me think again. The paper's title is about video compression, which is a specific application. The research topics listed are broader. Time-series is a data type, not a research topic. The paper's topic is video compression, which isn't one of the four. So the answer would be none. But maybe the fact that video is a time-series makes it fall under time-series? But the research topic here is about the method (INR-based compression), not the analysis of time-series data. So perhaps the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32315@AAAI"},
{"title": "AIM: Let Any Multimodal Large Language Models Embrace Efficient In-Context Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AIM: Let Any Multimodal Large Language Models Embrace Efficient In-Context Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Large Language Models\" is right there. Multimodal usually refers to models that handle multiple types of data, like text and images or audio. So that's a hint. The other part is \"In-Context Learning,\" which I think relates to how models learn from examples provided in the input, like few-shot learning. But the key term here is \"Multimodal.\" The options include multimodal as one of the topics. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or weather. RAG is Retrieval-Augmented Generation, which uses external data retrieval. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about time, retrieval, or knowledge graphs. So the main keyword here is \"Multimodal.\" Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32316@AAAI"},
{"title": "TC-LLaVA: Rethinking the Transfer of LLava from Image to Video Understanding with Temporal Considerations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TC-LLaVA: Rethinking the Transfer of LLava from Image to Video Understanding with Temporal Considerations.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"LLaVA\" is probably a model name, maybe related to vision and language. The term \"Transfer from Image to Video\" suggests moving a model trained on images to handle videos. Video understanding involves processing sequences of frames over time, which brings in temporal aspects. The \"Temporal Considerations\" part directly mentions time, so that's a hint towards time-series. \n\nNow, the options. Time-series deals with data over time, like sequences. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating answers. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about adapting a model (LLaVA) from images to videos, focusing on temporal aspects. Since video is a sequence of images over time, the temporal aspect here is about handling time-series data. So the topic would be time-series. \n\nBut wait, could it be multimodal? Well, LLaVA might be a multimodal model (image and text), but the paper is about transferring it to video, which is a different modality. However, the main focus here is the temporal aspect of video, not the multimodal aspect. So the key is the temporal considerations, which point to time-series. \n\nI don't see any mention of RAG or KG in the title. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32317@AAAI"},
{"title": "Learning 2D Invariant Affordance Knowledge for 3D Affordance Grounding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning 2D Invariant Affordance Knowledge for 3D Affordance Grounding.\" Hmm, I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Learning 2D Invariant Affordance Knowledge\" suggests they're working with 2D data, maybe images, and trying to make the knowledge invariant, so it's not dependent on specific 2D features. Then \"for 3D Affordance Grounding\" means applying this knowledge to 3D environments. Affordance here refers to the possible interactions an object allows, like a chair can be sat on.\n\nNow, the options. Time-series would involve data over time, like sequences or temporal data. The title doesn't mention anything about time, so probably not that. Multimodal usually involves combining different data types, like text and images. The paper is about 2D and 3D, which are different modalities, but the title doesn't explicitly say they're combining them. Wait, maybe it's using 2D data to inform 3D understanding, which could be a form of multimodal learning. But I'm not sure if that's the case here.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The title mentions \"knowledge,\" but it's about affordance knowledge, which might be structured, but the term \"knowledge\" here could be more about the model's learned representations rather than a formal knowledge graph. \n\nSo, the key is whether it's multimodal. The paper is using 2D data (images) to learn something that's applied to 3D (like 3D environments or objects). That could be considered multimodal because it's combining different data types (2D and 3D). However, sometimes 2D to 3D tasks are seen as a form of cross-modal learning. But the term \"multimodal\" typically refers to combining different modalities like vision and text. If the paper is just using 2D data to train a model for 3D tasks without combining with another modality, maybe it's not strictly multimodal. \n\nAlternatively, if the 3D grounding involves other modalities, but the title doesn't specify. The term \"affordance grounding\" might involve understanding how objects can be used in 3D space, which could involve sensor data or other modalities. But without more info, it's tricky. \n\nGiven the options, the closest might be multimodal because it's dealing with 2D and 3D data, which are different modalities. But I'm not entirely certain. Alternatively, if it's about knowledge graphs, but the title doesn't mention structured data or graphs. RAG and time-series are out. So maybe multimodal is the best fit here.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32318@AAAI"},
{"title": "EventMamba: Enhancing Spatio-Temporal Locality with State Space Models for Event-Based Video Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EventMamba: Enhancing Spatio-Temporal Locality with State Space Models for Event-Based Video Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Event-Based Video Reconstruction\" suggests that the paper is dealing with reconstructing videos from events. Event-based cameras, like neuromorphic sensors, capture changes in brightness as events over time, which is inherently temporal. So there's a time component here.\n\nThe phrase \"Spatio-Temporal Locality\" refers to both spatial (location in the image) and temporal (time) aspects. That makes me think of time-series data because time-series analysis often involves temporal sequences. But wait, video is also a time-series of images, so maybe that's a clue.\n\nThe method mentioned is \"State Space Models.\" State space models are commonly used in time-series analysis for modeling dynamic systems. They represent systems with a set of input, output, and state variables, which evolve over time. So that's another hint towards time-series.\n\nNow, checking the other options. Multimodal would involve combining different types of data (like text and images), but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which isn't mentioned here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem relevant.\n\nSo putting it all together: the paper is about reconstructing videos from event-based data using state space models that handle spatio-temporal aspects. Since time-series involves data points indexed in time order, and the paper is dealing with temporal data (events over time), the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32319@AAAI"},
{"title": "Implicit Location-Caption Alignment via Complementary Masking for Weakly-Supervised Dense Video Captioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Implicit Location-Caption Alignment via Complementary Masking for Weakly-Supervised Dense Video Captioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on video captioning. Dense video captioning involves generating captions for specific moments in a video. The term \"location-caption alignment\" suggests that the model is trying to align the location (probably spatial or temporal) with the captions. \"Complementary Masking\" might be a technique used to achieve this alignment. The \"Weakly-Supervised\" part indicates that the model isn't using fully labeled data, which is common in scenarios where annotations are limited.\n\nNow, looking at the possible topics. Time-series typically deals with sequential data over time, like stock prices or sensor data. While video does involve time, the key here is the captioning aspect, which is more about understanding content rather than just temporal sequences. \n\nMultimodal refers to combining different types of data, such as text and images or video. Since the paper is about video (which is a combination of visual and auditory data) and generating captions (text), this seems like a multimodal task. The alignment between visual elements (location in the video) and textual captions is a classic multimodal problem.\n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves relevant information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or using external data sources, so RAG might not be the right fit here.\n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't indicate the use of a knowledge graph or structured data, so that's probably not it either.\n\nPutting it all together, the paper is about aligning video content (which is multimodal) with captions, using a weakly supervised approach. The key elements are combining visual and textual data, which points to the multimodal topic. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32320@AAAI"}
{"title": "ParseCaps: An Interpretable Parsing Capsule Network for Medical Image Diagnosis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ParseCaps: An Interpretable Parsing Capsule Network for Medical Image Diagnosis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. The title mentions medical image diagnosis, which is more about images, so probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention combining different data types, just a capsule network for images. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information and then generate responses. This seems more related to text-based models, not image diagnosis. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on a neural network architecture (capsule network) for medical images, not on building or using a knowledge graph. So KG doesn't fit here either.\n\nThe paper introduces a new neural network model (ParseCaps) for medical image diagnosis. The key terms are \"capsule network\" and \"medical image,\" which are related to computer vision and deep learning. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to capsule networks or image diagnosis, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32321@AAAI"},
{"title": "Auto-Regressive Diffusion for Generating 3D Human-Object Interactions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Auto-Regressive Diffusion for Generating 3D Human-Object Interactions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Auto-Regressive Diffusion\" sounds like a model or method. Auto-regressive models are common in time-series data, like predicting the next value based on previous ones. But diffusion models are typically used in generative tasks, such as image or audio generation. However, the application here is generating 3D human-object interactions. \n\nNow, the key part is \"3D Human-Object Interactions.\" This involves modeling interactions between humans and objects in 3D space. That could involve multiple modalities, like visual data (images or 3D models) and maybe motion data. But does that make it multimodal? Multimodal usually refers to combining different types of data, like text and images. If the paper is generating 3D interactions, maybe it's using different data types, but I'm not sure if that's the case here.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using a retrieval system to fetch information and then generate text based on that. That doesn't seem to fit here since the title doesn't mention retrieval or text generation.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so probably not that.\n\nTime-series is about data over time. If the 3D interactions involve sequences over time, like motion sequences, then maybe. But the title doesn't explicitly mention time-series. However, auto-regressive models can be used for time-series, but they're also used in other contexts. The diffusion part is more about generating data step by step, which could be temporal, but not necessarily.\n\nMultimodal could be if the model uses different modalities (e.g., visual and textual) to generate the 3D interactions. But the title doesn't specify combining different data types. It just says generating 3D interactions, which might involve 3D data (like point clouds or meshes) and possibly motion data. If it's combining different data types, then multimodal. But without more info, it's hard to say.\n\nGiven the options, the most likely is multimodal if the generation involves multiple data types. But if it's just generating 3D data without combining different modalities, then maybe none. However, since the title doesn't mention RAG, KG, or time-series explicitly, and the method is auto-regressive diffusion, which is a generative model, but not necessarily time-series. So maybe none? Wait, but auto-regressive models can be time-series. However, in this case, the application is 3D interactions, which might not be time-series. Hmm. I'm a bit stuck. Let me think again.\n\nThe key is to map the title to the four options. The paper is about generating 3D human-object interactions using an auto-regressive diffusion model. The topics are time-series, multimodal, RAG, KG. \n\nIf the 3D interactions involve sequences over time (like motion), then it's time-series. But the title doesn't specify that. If the model uses multiple modalities (e.g., text and 3D data), then multimodal. But again, the title doesn't mention that. RAG and KG are not relevant here. So maybe the answer is none? But wait, maybe the auto-regressive part is time-series. Auto-regressive models are used in time-series forecasting, but they're also used in other contexts like image generation (pixel by pixel). So if the model is generating 3D interactions in a sequence (like step by step), maybe it's time-series. But without more context, it's hard to say. However, given the options, the most plausible is none, because the primary focus is on generating 3D interactions, which doesn't clearly fit into the four categories. Alternatively, if the model is using auto-regressive for time-based generation, then time-series. But I'm not sure. Maybe the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32322@AAAI"},
{"title": "Domain Generalized Medical Landmark Detection via Robust Boundary-Aware Pre-Training", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Domain Generalized Medical Landmark Detection via Robust Boundary-Aware Pre-Training.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Domain Generalized\" suggests that the model is being trained to work across different domains, which is common in medical imaging where data can vary a lot. \"Medical Landmark Detection\" refers to identifying specific points or structures in medical images, like anatomical landmarks. \"Robust Boundary-Aware Pre-Training\" implies that the model is pre-trained with a focus on boundaries, which might be important for accurate detection in images.\n\nNow, looking at the possible topics. Time-series would involve data over time, like ECG signals or longitudinal studies. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal usually refers to combining different types of data, like images and text. The title is about medical landmark detection, which is image-based, but there's no mention of combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on pre-training for landmark detection, not on building or using a knowledge graph. So KG probably isn't it either.\n\nSo, the paper is about medical image analysis, specifically landmark detection with domain generalization and boundary-aware pre-training. None of the four topics (time-series, multimodal, RAG, KG) directly apply here. The closest might be multimodal if there were multiple data types, but since it's focused on images and domain adaptation, it doesn't fit. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32323@AAAI"},
{"title": "Rethinking Masked Data Reconstruction Pretraining for Strong 3D Action Representation Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Rethinking Masked Data Reconstruction Pretraining for Strong 3D Action Representation Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Masked Data Reconstruction Pretraining\" sounds like a method where parts of the data are masked and the model has to reconstruct them. That's similar to techniques like BERT's masked language modeling. But how does that relate to the given topics?\n\n\"3D Action Representation Learning\" suggests that the data is 3D actions, maybe from videos or motion capture. So the focus is on learning representations for actions in 3D space. \n\nNow, looking at the options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models. KG (Knowledge Graph) involves structured data and relationships.\n\nThe paper's title doesn't mention anything about time-series data explicitly. It's about 3D actions, which could be time-series if the actions are sequences over time. But the key part here is the pretraining method. Masked reconstruction is a common technique in self-supervised learning, but does that tie it to any of the four topics?\n\nRAG and KG are more about specific architectures or data structures. The title doesn't mention retrieval or knowledge graphs. Multimodal would require combining different modalities, but the title only mentions 3D action data. Unless the 3D data is combined with another modality, but the title doesn't specify that. \n\nSo maybe it's none of the four. The main focus is on a pretraining method for 3D action representations, which doesn't directly align with time-series, multimodal, RAG, or KG. Unless there's an implicit connection I'm missing. For example, 3D actions could be time-series data, but the title doesn't explicitly state that. The key term here is \"masked data reconstruction,\" which is a method, not a topic. The topics listed are more about data types or specific approaches. \n\nTherefore, the answer is probably \"none\" because it doesn't clearly fit into any of the four categories provided.\n</think>\n\nnone", "url": "https://papers.cool/venue/32324@AAAI"},
{"title": "Queryable Prototype Multiple Instance Learning with Vision-Language Models for Incremental Whole Slide Image Classification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Queryable Prototype Multiple Instance Learning with Vision-Language Models for Incremental Whole Slide Image Classification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language Models\" immediately makes me think of multimodal learning because they combine visual and textual data. So that's a hint towards the multimodal category. Then there's \"Multiple Instance Learning,\" which is a type of machine learning where each example is a bag of instances, but that's more about the learning framework. The \"Incremental\" part suggests that the model is updated over time with new data, but that's more about the learning process rather than the data type.\n\nTime-series would involve data points indexed in time order, like stock prices over days. The title doesn't mention anything about time or sequential data, so probably not time-series. RAG (Retrieval-Augmented Generation) is about using retrieval systems to augment model outputs, often in NLP tasks. The title doesn't mention retrieval or generation, so maybe not RAG. KG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention knowledge graphs either.\n\nSo the key part here is \"Vision-Language Models,\" which are inherently multimodal because they process both visual (images) and language (text) data. Even though there's other components in the title, the use of vision-language models points directly to multimodal. The other terms like \"prototype\" or \"incremental\" don't fall under the other categories listed. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32325@AAAI"},
{"title": "Efficient Connectivity-Preserving Instance Segmentation with Supervoxel-Based Loss Function", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Efficient Connectivity-Preserving Instance Segmentation with Supervoxel-Based Loss Function.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Instance segmentation is a computer vision task where the goal is to identify and segment each individual object in an image. The term \"connectivity-preserving\" suggests that the method maintains the connected regions of the segmented objects, which is important for accurate segmentation. \"Supervoxel-Based Loss Function\" refers to using supervoxels, which are 3D analogs of superpixels, in the loss function to improve segmentation.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order, like stock prices or sensor data over time. This paper's title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal research involves combining multiple types of data, such as text and images, or audio and video. The title here is focused on a specific segmentation technique using supervoxels, not combining different data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model retrieves relevant information from a database to enhance its responses. This doesn't seem related to image segmentation. \n\nKG is Knowledge Graph, which involves structured data representation and reasoning. The paper's focus is on a loss function for segmentation, not on building or using a knowledge graph.\n\nSo, none of the four topics (time-series, multimodal, RAG, KG) seem to fit. The paper is about a specific computer vision technique for instance segmentation using supervoxels, which doesn't align with any of the listed research areas. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32326@AAAI"},
{"title": "MaintaAvatar: A Maintainable Avatar Based on Neural Radiance Fields by Continual Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MaintaAvatar: A Maintainable Avatar Based on Neural Radiance Fields by Continual Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are \"Maintainable Avatar,\" \"Neural Radiance Fields,\" and \"Continual Learning.\" \n\nNeural Radiance Fields (NeRF) are typically used for 3D scene reconstruction and rendering, right? They take 2D images and create a 3D model that can be viewed from different angles. So that's more about computer vision and 3D modeling. \n\nContinual Learning refers to a machine learning approach where the model learns continuously over time, adapting to new data without forgetting previous knowledge. That's a learning paradigm, not a specific topic like time-series or multimodal. \n\nNow, the options given are time-series, multimodal, RAG, or KG. Let's consider each:\n\n- Time-series: Involves data points indexed in time order. The paper doesn't mention anything about time-based data analysis, so probably not this one.\n- Multimodal: Combines multiple types of data (like text, images, audio). The paper is about creating an avatar using NeRF, which is a 3D model. If it uses multiple modalities (e.g., images and text), it might be multimodal. But the title doesn't specify using different data types. It just mentions Neural Radiance Fields, which are image-based. So maybe not multimodal.\n- RAG (Retrieval-Augmented Generation): This is a method where a model retrieves information from a database to augment its generation. The title doesn't mention anything about retrieval or generation in that context. The focus is on continual learning for maintaining an avatar, not retrieving information to generate text or something else.\n- KG (Knowledge Graph): Involves structured data representation, relationships between entities. The paper doesn't mention knowledge graphs or structured data. \n\nSo, none of the four topics seem to fit. The paper is about creating a maintainable avatar using NeRF and continual learning, which relates to 3D modeling and machine learning techniques, but not the specified topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32327@AAAI"},
{"title": "HGSFusion: Radar-Camera Fusion with Hybrid Generation and Synchronization for 3D Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HGSFusion: Radar-Camera Fusion with Hybrid Generation and Synchronization for 3D Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Radar-Camera Fusion\" immediately makes me think of combining data from different sensors. Radar and camera are different modalities, right? So that's multimodal. The term \"fusion\" here is key because it refers to integrating data from multiple sources. \n\nThen there's \"Hybrid Generation and Synchronization.\" Hybrid might refer to combining different methods or data types. Synchronization could be about aligning the data in time or space, which is common in multimodal systems where different sensors might have different timing or formats. \n\nThe application is \"3D Object Detection,\" which is a computer vision task. But the key part here is the fusion of radar and camera data. So the main research topic here is about combining different modalities (radar and camera) to improve detection. \n\nLooking at the options: time-series is about data over time, which isn't the focus here. RAG (Retrieval-Augmented Generation) is more about using retrieved information to augment generation, which doesn't seem relevant. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. \n\nSo the answer should be multimodal because it's about fusing different sensor data types.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32328@AAAI"},
{"title": "OT-StainNet: Optimal Transport Driven Semantic Matching for Weakly Paired H&E-to-IHC Stain Transfer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OT-StainNet: Optimal Transport Driven Semantic Matching for Weakly Paired H&E-to-IHC Stain Transfer.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"OT-StainNet\" probably refers to a neural network using optimal transport (OT). The key part here is \"Semantic Matching for Weakly Paired H&E-to-IHC Stain Transfer.\" H&E and IHC are types of histological stains used in medical imaging. So, the paper is about transferring stains between these two types of images. \n\nNow, the question is whether this falls under one of the four categories. Let's consider each option:\n\n1. **Time-series**: This usually involves data points indexed in time order. The title doesn't mention anything about time or sequences, so probably not time-series.\n\n2. **Multimodal**: This refers to combining different types of data (like text and images, or different image modalities). Here, the paper is dealing with two different staining methods (H&E and IHC) in histopathology images. Since these are different modalities of the same tissue samples, this could be multimodal. The term \"weakly paired\" might imply that the data isn't perfectly aligned, which is common in multimodal studies where different data types are paired but not perfectly synchronized.\n\n3. **RAG (Retrieval-Augmented Generation)**: This is typically about using external knowledge bases for generating responses, common in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\n4. **KG (Knowledge Graph)**: Involves structured data representations. The paper seems focused on image processing rather than building or using knowledge graphs, so likely not KG.\n\nSo, the most plausible is multimodal. The paper is about transferring between two different image modalities (H&E and IHC), which are different types of data (stains) representing the same tissue. The use of semantic matching and optimal transport suggests they're handling the alignment between these modalities, which is a common challenge in multimodal research.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32329@AAAI"},
{"title": "You Should Learn to Stop Denoising on Point Clouds in Advance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"You Should Learn to Stop Denoising on Point Clouds in Advance.\" Hmm. I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"denoising,\" \"point clouds,\" and \"learn to stop.\" Point clouds are typically 3D data points, often used in computer vision or robotics for representing objects in space. Denoising refers to removing noise from data. So the paper is probably about improving denoising techniques for point clouds.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generative models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on point cloud denoising. Point clouds are a type of data, but the techniques used here might involve machine learning models. However, none of the four topics directly relate to point cloud processing. Time-series is about temporal data, which isn't the case here. Multimodal would involve multiple data modalities, but the title doesn't mention that. RAG and KG are more about information retrieval and knowledge representation, which don't seem relevant to denoising point clouds. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32331@AAAI"}
{"title": "You Should Learn to Stop Denoising on Point Clouds in Advance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"You Should Learn to Stop Denoising on Point Clouds in Advance.\" Hmm. I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"denoising,\" \"point clouds,\" and \"learn to stop.\" Point clouds are typically 3D data points, often used in computer vision or robotics for representing objects in space. Denoising refers to removing noise from data. So the paper is probably about improving denoising techniques for point clouds.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generative models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on point cloud denoising. Point clouds are a type of data, but the techniques used here might involve machine learning models. However, none of the four topics directly relate to point cloud processing. Time-series is about temporal data, which isn't the case here. Multimodal would involve multiple data modalities, but the title doesn't mention that. RAG and KG are more about information retrieval and knowledge representation, which don't seem relevant to denoising point clouds. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32331@AAAI"},
{"title": "Surgical Workflow Recognition and Blocking Effectiveness Detection in Laparoscopic Liver Resection with Pringle Maneuver", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Surgical Workflow Recognition and Blocking Effectiveness Detection in Laparoscopic Liver Resection with Pringle Maneuver.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Surgical workflow recognition sounds like it's about identifying the sequence of steps in a surgery. That might involve time-series data because surgeries are time-dependent processes. But I'm not sure yet. Blocking effectiveness detection refers to how well a certain maneuver (Pringle Maneuver) is working during the surgery. \n\nNow, the four options. Time-series analysis deals with data over time, which could fit if they're tracking the workflow over time. Multimodal would involve multiple types of data, like combining video, audio, and sensor data. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to generate responses, maybe in NLP. KG is Knowledge Graphs, which structure information in a graph format, perhaps for organizing medical knowledge.\n\nThe paper's focus seems to be on recognizing workflows and detecting effectiveness during a specific surgical procedure. If they're using data from different modalities (like video, instrument usage, etc.), it could be multimodal. But the title doesn't explicitly mention multiple data types. Time-series could be if they're analyzing the sequence of actions over time. However, the main terms here are workflow recognition and effectiveness detection. \n\nI don't see any mention of retrieval or knowledge graphs. RAG is typically for models that retrieve information to assist in generating answers, which doesn't seem relevant here. KG would involve creating a structured knowledge base, which isn't indicated in the title. \n\nSo, between time-series and multimodal. If the workflow is analyzed as a sequence of events over time, time-series might be the fit. But if they're using multiple data sources (like video and sensor data) to recognize the workflow, then multimodal. The title doesn't specify, but \"workflow recognition\" in surgery often involves time-series analysis of the steps. However, without explicit mention of multiple modalities, maybe it's not multimodal. \n\nAlternatively, maybe it's none of these. The problem is about surgical procedures, which might not fall under the given categories. But the user wants to check if it's one of the four. Since the title doesn't clearly indicate RAG or KG, and the options are between time-series and multimodal. If the workflow is a sequence of actions, time-series could be the answer. But I'm not 100% sure. Maybe the answer is none if it doesn't clearly fit any. But the user might expect one of the four. Hmm.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32332@AAAI"},
{"title": "Cross-Spectral Gaussian Splatting with Spatial Occupancy Consistency", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cross-Spectral Gaussian Splatting with Spatial Occupancy Consistency.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Spectral\" might refer to different spectral bands or frequencies, which could be related to multimodal data if it's combining different types of data. \"Gaussian Splatting\" sounds like a technique for rendering or modeling, maybe in 3D graphics or computer vision. \"Spatial Occupancy Consistency\" suggests something about spatial data and how objects occupy space, possibly in a 3D context.\n\nTime-series usually involves data over time, like sequences or temporal analysis. The title doesn't mention time or sequences, so maybe not time-series. \n\nMultimodal could be a fit if the research combines different data types, like images and text, or different spectral data. \"Cross-Spectral\" might imply using multiple spectral data sources, which could be multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG. \n\nKG (Knowledge Graphs) involve structured data and relationships. The title doesn't mention graphs or knowledge structures, so likely not KG. \n\nPutting it together: The key terms are cross-spectral and spatial occupancy. If cross-spectral refers to combining different spectral data (like RGB and infrared), that's multimodal. So the answer might be multimodal. But I'm not 100% sure. Let me double-check. Gaussian splatting is a rendering technique, but the cross-spectral part is the clue here. If they're integrating different spectral data, that's multimodal. So I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32333@AAAI"},
{"title": "Enhancing Low-Rank Adaptation with Recoverability-Based Reinforcement Pruning for Object Counting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Low-Rank Adaptation with Recoverability-Based Reinforcement Pruning for Object Counting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Low-Rank Adaptation\" probably refers to a method where the model is adapted using low-rank matrices, which is a common technique in model compression or transfer learning. Then \"Recoverability-Based Reinforcement Pruning\" sounds like a pruning method that uses reinforcement learning to determine which parts of the model to prune, ensuring that the model can still recover or perform well after pruning. The application here is \"Object Counting,\" which is a computer vision task.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to generate responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on improving a model (probably a neural network) for object counting through pruning techniques. There's no mention of time-series data, so that's out. It's a single modality (images for object counting), so not multimodal. RAG and KG are about retrieval and knowledge graphs, which don't seem related to model pruning or adaptation. The paper is about model optimization techniques, which doesn't fit any of the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32334@AAAI"},
{"title": "Towards a Comprehensive, Efficient and Promptable Anatomic Structure Segmentation Model Using 3D Whole-Body CT Scans", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards a Comprehensive, Efficient and Promptable Anatomic Structure Segmentation Model Using 3D Whole-Body CT Scans.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title mentions 3D CT scans, which are spatial data, not time-based. So probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper uses 3D CT scans, which are a type of medical imaging. But the title doesn't mention combining different data types, just using CT scans for segmentation. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper is about segmenting anatomic structures, which could involve creating a structured representation, but the title doesn't explicitly mention knowledge graphs. The focus seems to be on the segmentation model itself, not on building a knowledge graph.\n\nSo none of the four topics seem to fit. The paper is about medical image segmentation using 3D CT scans, which is more related to computer vision or medical imaging, not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32335@AAAI"},
{"title": "MetaNeRV: Meta Neural Representations for Videos with Spatial-Temporal Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MetaNeRV: Meta Neural Representations for Videos with Spatial-Temporal Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"MetaNeRV\" probably stands for something, but the key parts are \"Neural Representations for Videos\" and \"Spatial-Temporal Guidance.\" Videos are sequences of frames over time, so they inherently involve time-series data. The spatial-temporal aspect suggests that the model is considering both the spatial elements (like objects in each frame) and the temporal elements (how they change over time). \n\nTime-series analysis deals with data points indexed in time order, which fits here because videos are a form of time-series data. The mention of spatial-temporal guidance implies that the model is handling both spatial and temporal dimensions, which is common in video processing. \n\nMultimodal would involve combining different types of data, like text and images, but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, which isn't indicated here. KG (Knowledge Graphs) involve structured data representations, which also don't seem relevant. \n\nSo, the most fitting topic here is time-series because the research is about video data, which is a time-series, and the spatial-temporal guidance is part of processing that time-series data.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32336@AAAI"},
{"title": "PromptDet: A Lightweight 3D Object Detection Framework with LiDAR Prompts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PromptDet: A Lightweight 3D Object Detection Framework with LiDAR Prompts.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on 3D object detection using LiDAR. LiDAR is a sensor that provides point cloud data, which is often used in autonomous vehicles for environment perception. The term \"PromptDet\" suggests it's a detection framework, and \"lightweight\" implies it's optimized for efficiency.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or weather data. This paper is about 3D object detection, which is more spatial than temporal, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The paper mentions LiDAR, which is a type of sensor data. If they're using LiDAR along with other modalities (like camera images or radar), it would be multimodal. But the title only mentions LiDAR. However, sometimes LiDAR is used with other sensors in object detection. The title doesn't specify, though. Hmm. Maybe the \"prompts\" part is key here. Wait, \"LiDAR Prompts\" – maybe they're using some form of prompting technique, like in vision-language models where text prompts are used. But LiDAR is a sensor, so maybe they're using a prompting method to guide the detection. But I'm not sure if that's multimodal. If the model uses LiDAR data and another modality, then it's multimodal. But the title doesn't mention another modality. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving relevant documents and generating answers. This paper is about object detection in 3D space, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses a knowledge graph to enhance the detection, it would fall under KG. But the title doesn't mention anything about knowledge graphs or structured data. The focus is on LiDAR and a lightweight framework.\n\nSo, the options left are multimodal or none. The paper uses LiDAR, which is a single modality. Unless \"LiDAR Prompts\" implies combining LiDAR with another modality through prompts. For example, maybe using text prompts to guide the LiDAR processing. But that's speculative. If the framework is using LiDAR data and another modality (like images or radar) in a multimodal setup, then it would be multimodal. However, the title doesn't explicitly state that. The term \"prompts\" might refer to a method of guiding the model, not necessarily combining modalities. Without more information, it's hard to say. But given the title only mentions LiDAR, I might lean towards it not being multimodal. Therefore, the answer might be \"none.\" But wait, maybe \"LiDAR Prompts\" is a technique that uses multiple modalities. For example, if the prompts are from another source. Alternatively, maybe the model is multimodal in the sense of combining LiDAR with other data types. But the title doesn't specify. Since the user is asking to determine based on the title, and the title doesn't mention other modalities, I think it's safer to say \"none.\" However, sometimes in 3D object detection, LiDAR is combined with cameras, making it multimodal. But again, the title doesn't mention that. So the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32337@AAAI"},
{"title": "OpenVIS: Open-vocabulary Video Instance Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OpenVIS: Open-vocabulary Video Instance Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video Instance Segmentation\" suggests that the paper is about segmenting objects in videos. Instance segmentation typically refers to identifying and segmenting each individual object in an image or video. The \"Open-vocabulary\" part might mean that the model can recognize objects beyond a fixed set of categories, possibly using some kind of language model or external knowledge.\n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices or sensor data over time. This seems more about video processing, which is a sequence of images, so maybe time-series? But video processing is often considered under computer vision, which might not directly map to time-series unless the focus is on temporal analysis.\n\nMultimodal refers to combining multiple types of data, like text and images. The term \"Open-vocabulary\" might imply using text (like class names) in addition to video data, so that could be multimodal. However, the main task here is instance segmentation, which is a computer vision task. If the model uses both visual and textual information, then multimodal would be the right category.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. This doesn't seem directly related to video segmentation unless the paper uses retrieval for some part of the process, but the title doesn't mention that.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses a knowledge graph to enhance the segmentation, that would fit. But again, the title doesn't mention anything about knowledge graphs.\n\nSo, the key here is \"Open-vocabulary.\" Open-vocabulary models often use external knowledge or language models to recognize new classes. For example, using CLIP (Contrastive Language-Image Pretraining) which combines text and images. If the model uses text descriptions to recognize objects in videos, that's multimodal. Therefore, the paper likely combines visual (video) and textual (vocabulary) data, making it multimodal. \n\nBut wait, could it be time-series? Video is a sequence over time, so technically, it's a time-series of images. However, the primary focus here is on instance segmentation, which is more about computer vision. The term \"time-series\" is usually for data like stock prices, sensor data, etc., not video processing. So time-series might not be the right fit here. \n\nTherefore, the most likely answer is multimodal because it combines video (visual) and open-vocabulary (textual) information.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32338@AAAI"},
{"title": "Controllable 3D Dance Generation Using Diffusion-Based Transformer U-Net", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Controllable 3D Dance Generation Using Diffusion-Based Transformer U-Net.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. The paper is about generating 3D dance, which is a sequence of movements over time. So maybe time-series? But I'm not sure yet.\n\nMultimodal refers to combining different types of data, like text and images. The title mentions 3D dance, which could involve different modalities, but the focus here seems to be on generating the dance itself, not combining multiple data types. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title doesn't mention anything about retrieval or using external data for generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't seem to involve building or using a knowledge graph, so that's probably out.\n\nSo the main contenders are time-series and multimodal. Since dance generation involves sequences of movements over time, it's likely a time-series problem. The model uses a diffusion-based transformer U-Net, which is a type of model that can handle sequential data. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32339@AAAI"},
{"title": "SpikeGS: Reconstruct 3D Scene Captured by a Fast-Moving Bio-Inspired Camera", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SpikeGS: Reconstruct 3D Scene Captured by a Fast-Moving Bio-Inspired Camera.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"SpikeGS\" probably refers to a method or system. The main task is \"Reconstruct 3D Scene,\" which suggests they're creating a 3D model from some kind of input. The input here is captured by a \"Fast-Moving Bio-Inspired Camera.\" \n\nBio-inspired cameras might be related to how biological systems, like eyes, process visual information. Fast-moving implies that the camera is moving quickly, so maybe the data is collected over time, but the key here is the 3D reconstruction. \n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order. If the camera is moving fast, maybe they're capturing data over time, but the main focus is on 3D reconstruction. However, time-series might not be the main topic here unless the method specifically deals with temporal data analysis.\n\nMultimodal refers to using multiple types of data (like combining text, images, audio). The title mentions a camera, which is visual data, but there's no indication of combining different modalities. Unless the bio-inspired camera uses different sensors, but the title doesn't specify that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. This doesn't seem related to 3D scene reconstruction from a camera.\n\nKG is Knowledge Graph, which involves structured data representation. The paper is about reconstructing a 3D scene, which is more about geometry and computer vision, not knowledge graphs.\n\nSo, the main focus is on reconstructing a 3D scene using a specific type of camera. The key here is whether any of the four topics apply. Time-series could be a stretch if the camera's movement over time is part of the data processing, but the primary task is spatial reconstruction. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to 3D scene reconstruction from a camera, especially a bio-inspired one, the answer might be \"none.\" But wait, maybe multimodal? If the camera is bio-inspired, perhaps it uses different modalities (like combining different types of sensory data), but the title doesn't mention that. The title only mentions a camera, so unless it's using multiple modalities, it's not multimodal. So I think the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32340@AAAI"}
{"title": "VTG-LLM: Integrating Timestamp Knowledge into Video LLMs for Enhanced Video Temporal Grounding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VTG-LLM: Integrating Timestamp Knowledge into Video LLMs for Enhanced Video Temporal Grounding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video LLMs\" probably refers to large language models applied to video data. \"Temporal Grounding\" suggests dealing with time-related aspects in videos, like locating events in time. The key part here is \"Integrating Timestamp Knowledge,\" which directly relates to time. \n\nTime-series analysis involves data points indexed in time order. Since the paper is about video temporal grounding using timestamps, that seems like a time-series application. But wait, video is a multimodal data type (combining visual and auditory elements), so could it be multimodal? However, the main focus here is on the temporal aspect, not the combination of different data types. \n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to be mentioned here. The title doesn't talk about retrieval or knowledge graphs. So the main topic is likely time-series. But I should double-check. Multimodal could be a possibility if the model uses both video and text, but the key innovation here is the timestamp integration for temporal grounding, which is more about time-series data. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32341@AAAI"},
{"title": "LLaVA Needs More Knowledge: Retrieval Augmented Natural Language Generation with Knowledge Graph for Explaining Thoracic Pathologies", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LLaVA Needs More Knowledge: Retrieval Augmented Natural Language Generation with Knowledge Graph for Explaining Thoracic Pathologies.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. LLaVA is a model, probably a multimodal one since it's often associated with vision and language tasks. The phrase \"Retrieval Augmented Natural Language Generation\" makes me think of RAG, which stands for Retrieval-Augmented Generation. That's a method where a model uses retrieved information to enhance its responses. Then there's \"Knowledge Graph for Explaining Thoracic Pathologies.\" Knowledge Graph (KG) is another term here. So the paper is combining RAG with a Knowledge Graph to improve explanations in a medical context.\n\nNow, the options are time-series, multimodal, RAG, or KG. The title mentions both RAG and KG. But the question is which topic it belongs to. Since RAG is a specific method and the paper is about using retrieval-augmented generation, that's a strong indicator. However, the use of a Knowledge Graph is also present. But the main focus seems to be on the retrieval-augmented generation part, enhanced by a knowledge graph. The primary research topic here would be RAG, as the title explicitly mentions \"Retrieval Augmented.\" Even though KG is part of the approach, the main category is RAG. Multimodal might be a possibility if LLaVA is involved, but the title doesn't focus on multimodal aspects beyond the method. Time-series isn't mentioned. So the answer should be RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32342@AAAI"},
{"title": "DuMo: Dual Encoder Modulation Network for Precise Concept Erasure", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DuMo: Dual Encoder Modulation Network for Precise Concept Erasure.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Dual Encoder Modulation Network\" suggests some kind of neural network architecture using two encoders. The term \"modulation\" might imply adjusting or modifying something. The goal is \"Precise Concept Erasure,\" which sounds like removing specific concepts from a model or data.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so that might not fit either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance model outputs. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus on concept erasure might relate to modifying knowledge in a graph, but the title doesn't explicitly mention graphs. However, \"concept erasure\" could be about removing nodes or relationships in a knowledge graph. But the term \"Dual Encoder Modulation Network\" sounds more like a neural network approach rather than a knowledge graph structure. \n\nAlternatively, maybe it's about modifying a model's knowledge, which could be related to RAG if it's about retrieval, but again, the title doesn't mention retrieval. The term \"concept erasure\" might be about forgetting or unlearning certain concepts, which is a topic in machine learning, but not necessarily tied to the four options given. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) are clearly mentioned in the title, and the focus is on a neural network for concept erasure, which doesn't directly map to any of these, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32343@AAAI"},
{"title": "GGS: Generalizable Gaussian Splatting for Lane Switching in Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GGS: Generalizable Gaussian Splatting for Lane Switching in Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Gaussian Splatting\" sounds like a technique, maybe related to 3D rendering or point cloud processing. \"Generalizable\" suggests it's designed to work across different scenarios. \"Lane Switching in Autonomous Driving\" is the application area. So the paper is about a method for autonomous vehicles to handle lane changes using Gaussian splatting.\n\nNow, the possible topics. Time-series would involve data over time, like sequences. Multimodal would combine different data types, like images and text. RAG is Retrieval-Augmented Generation, which is for models that use external information. KG is Knowledge Graphs, which are structured data representations.\n\nGaussian splatting is a rendering technique, often used in computer graphics for 3D scenes. In autonomous driving, this might relate to processing sensor data (like LiDAR) to create a scene representation. But does this fit into any of the four categories? Time-series? Maybe if they process data over time, but the title doesn't mention that. Multimodal? If they combine different sensor data (e.g., camera and LiDAR), but again, the title doesn't specify that. RAG or KG don't seem relevant here. The focus is on a specific technical method for lane switching, not on knowledge graphs or retrieval-augmented generation. So it might not fit any of the four. The answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32344@AAAI"},
{"title": "ProPose: Probabilistic 3D Human Pose Estimation with Instance-Level Distribution and Normalizing Flow", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ProPose: Probabilistic 3D Human Pose Estimation with Instance-Level Distribution and Normalizing Flow.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The paper's title mentions 3D human pose estimation, which is about predicting positions of body joints in 3D space. That doesn't immediately sound like time-series unless they're tracking over time, but the title doesn't specify temporal aspects. Maybe it's a single frame?\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention multiple modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. This paper is about pose estimation, which is computer vision, so RAG seems unrelated.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on probabilistic modeling using normalizing flows and instance-level distributions. Normalizing flows are a type of generative model used for density estimation. That's more about statistical modeling rather than knowledge graphs.\n\nSo, the paper is about probabilistic 3D pose estimation using specific statistical methods. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The methods mentioned (normalizing flow, instance-level distribution) are more about probabilistic modeling and generative models, which aren't covered in the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32345@AAAI"},
{"title": "DME-Driver: Integrating Human Decision Logic and 3D Scene Perception in Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DME-Driver: Integrating Human Decision Logic and 3D Scene Perception in Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or sensor data over time. The title mentions autonomous driving, which does involve time-series data from sensors, but the main focus here seems to be on integrating human decision logic and 3D scene perception. So maybe time-series is part of it, but is that the main topic?\n\nMultimodal refers to combining different types of data, like text, images, audio, etc. The title talks about integrating human decision logic (which could be rules or some form of reasoning) and 3D scene perception (which is visual data). So combining different modalities like visual and logical reasoning might make it multimodal. That's a possibility.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper might use a knowledge graph if it's integrating human decision logic into a structured format. However, the title doesn't explicitly mention knowledge graphs. It's more about integrating two components rather than building a graph structure.\n\nSo between multimodal and time-series. Autonomous driving does use time-series data from sensors, but the key here is the integration of different elements: human decision logic (maybe rules or symbolic AI) and 3D scene perception (which is visual data). That sounds like combining different modalities. So I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32346@AAAI"},
{"title": "Boosting Segment Anything Model Towards Open-Vocabulary Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Boosting Segment Anything Model Towards Open-Vocabulary Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The \"Segment Anything Model\" probably refers to a segmentation model, which is typically used in computer vision for tasks like image segmentation. The term \"open-vocabulary learning\" suggests that the model is being enhanced to handle a broader range of vocabulary, which might relate to understanding or generating text in addition to images. \n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or sensor data. That doesn't seem relevant here. Multimodal refers to models that handle multiple types of data, such as both images and text. Since segmentation is an image task and open-vocabulary learning might involve text, this could be multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generation, often used in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about retrieval or knowledge graphs specifically. \n\nSo, the key here is whether the paper is about combining different modalities (like image and text) to improve segmentation with open vocabulary. If the model is being made to handle both visual and textual information, then it's multimodal. The mention of \"open-vocabulary\" might imply that the model can now understand new classes not seen during training, which could involve text-based descriptions. Therefore, the topic is likely multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32347@AAAI"},
{"title": "CoDTS: Enhancing Sparsely Supervised Collaborative Perception with a Dual Teacher-Student Framework", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CoDTS: Enhancing Sparsely Supervised Collaborative Perception with a Dual Teacher-Student Framework.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"CoDTS\" is probably an acronym. \"Sparsely Supervised\" suggests that the model is trained with limited labeled data. \"Collaborative Perception\" might refer to combining information from multiple sources or sensors, which could hint at multimodal if it's using different data types. The \"Dual Teacher-Student Framework\" sounds like a training method where two models (teacher and student) work together, maybe in a distillation setup.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data over time. The title doesn't mention anything about time, so maybe not. Multimodal usually involves combining different modalities like text, image, audio. If collaborative perception is about integrating data from different sources (like cameras and LiDAR in autonomous vehicles), that would be multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem relevant.\n\nSo, the key part is \"Collaborative Perception.\" If that's about combining different data types, then multimodal. The dual teacher-student framework might be a method to handle the sparsely supervised data, but the main topic would be the collaboration of different modalities. So I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32348@AAAI"},
{"title": "AsyncDSB: Schedule-Asynchronous Diffusion Schrödinger Bridge for Image Inpainting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AsyncDSB: Schedule-Asynchronous Diffusion Schrödinger Bridge for Image Inpainting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Diffusion Schrödinger Bridge\" sounds like a method related to generative models, maybe something like diffusion models. Image inpainting is the task of filling in missing parts of an image, which is a common problem in computer vision. \n\nNow, the options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on image inpainting using a specific diffusion model technique. The term \"Schedule-Asynchronous\" might refer to the training process or how the model handles different schedules in the diffusion process. Since the main application is image inpainting, which is a computer vision task, and the method is a type of diffusion model, none of the listed topics (time-series, multimodal, RAG, KG) seem to directly apply. The paper isn't about combining multiple modalities, using retrieval, or knowledge graphs. It's more about a specific model architecture for image generation. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32349@AAAI"},
{"title": "ID-Sculpt: ID-aware 3D Head Generation from Single In-the-wild Portrait Image", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ID-Sculpt: ID-aware 3D Head Generation from Single In-the-wild Portrait Image.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. This paper is about generating 3D heads from images, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper uses a single portrait image to generate a 3D model. It might involve different modalities if, say, it uses both images and text, but the title mentions only a single image input. Not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks, like in question-answering systems. This paper is about generating 3D models, so unless it's retrieving data to help with generation, but the title doesn't mention retrieval. Maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data. \n\nSo, the main focus is generating 3D heads from a single image. The term \"ID-aware\" might imply that it's using identity information, perhaps from a database or some kind of knowledge about identities. But does that relate to a Knowledge Graph? Maybe if they're using a KG to get identity information. However, the title doesn't explicitly state that. Alternatively, \"ID-aware\" could just mean the model is trained to recognize and preserve the identity in the 3D generation, which might not involve a KG. \n\nMultimodal could be a stretch if they're combining different data types, but the input is a single image. Unless the output is a 3D model which is a different modality, but that's part of the task, not the input. \n\nRAG seems unlikely. Time-series is out. So maybe none of the four topics? But the options are time-series, multimodal, RAG, KG, or none. \n\nWait, maybe multimodal? If generating a 3D model from an image involves different modalities (like image input and 3D output), but typically multimodal refers to combining different input modalities. Since the input is a single image, maybe not. \n\nAlternatively, if the model uses both the image and some other data (like text or another modality) during training or generation, but the title doesn't mention that. The title says \"from single in-the-wild portrait image,\" so input is just an image. \n\nSo, I think it doesn't fit any of the four topics. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32350@AAAI"}
{"title": "Multi-Frame Deformable Look-Up Table for Compressed Video Quality Enhancement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Frame Deformable Look-Up Table for Compressed Video Quality Enhancement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The paper is about video quality enhancement, which does involve sequences of frames over time. So maybe time-series? But wait, the term \"Multi-Frame\" suggests using multiple frames, which is common in video processing. However, time-series is a broader category. But does the method specifically deal with time-series analysis? The Deformable Look-Up Table part might be a technique for processing these frames. Not sure yet.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention different modalities, just video frames. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks, like in NLP. The title doesn't mention anything about retrieval or generation, so RAG is probably not it.\n\nKG is Knowledge Graph, which involves structured data representations. The paper's title doesn't mention knowledge graphs or structured data, so that's out.\n\nSo the remaining options are time-series or none. The video processing aspect uses multiple frames over time, which is a time-series data structure. However, the specific techniques mentioned (Deformable Look-Up Table) might be more about image processing or video compression rather than traditional time-series analysis. But since the topic is about processing a sequence of frames (time-based), it could fall under time-series. Alternatively, if the focus is on the spatial aspects of the video frames rather than the temporal sequence, maybe not. But the \"Multi-Frame\" part does imply temporal processing. So I think it's time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32351@AAAI"},
{"title": "V2C-CBM: Building Concept Bottlenecks with Vision-to-Concept Tokenizer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"V2C-CBM: Building Concept Bottlenecks with Vision-to-Concept Tokenizer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"V2C\" probably stands for Vision-to-Concept. The term \"Concept Bottlenecks\" suggests that the model is creating some kind of intermediate representation or bottleneck layer that captures concepts. The \"Vision-to-Concept Tokenizer\" part implies that the model is taking visual data (like images) and converting them into concept tokens. \n\nNow, considering the possible topics. Time-series usually deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to models that handle multiple modalities, like combining text and images. The V2C part suggests vision (image) to concept, which might involve another modality (like text concepts), so this could be multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to augment generation, often in NLP. The title doesn't mention retrieval or generation, so maybe not RAG. \n\nKG (Knowledge Graphs) involve structured data and relationships between entities. The term \"Concept Bottlenecks\" might relate to knowledge concepts, but the title doesn't explicitly mention graphs or structured knowledge. \n\nPutting it together: The model is taking visual input and converting it into concept tokens, which sounds like a multimodal approach because it's combining vision with conceptual (possibly textual) information. So the topic is likely multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32352@AAAI"},
{"title": "PointRWKV: Efficient RWKV-Like Model for Hierarchical Point Cloud Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PointRWKV: Efficient RWKV-Like Model for Hierarchical Point Cloud Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"PointRWKV\" suggests it's related to the RWKV model. RWKV is a type of neural network architecture that's been used in various contexts. The \"Point\" in the name might refer to point clouds, which are sets of data points in space, often used in 3D data processing. So the model is designed for hierarchical point cloud learning, which involves processing 3D data in a hierarchical manner.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order. Multimodal refers to combining multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on a model for point cloud data. Point clouds are typically used in 3D vision tasks, such as object recognition or scene understanding. The RWKV architecture is a type of model that can handle sequential data, but in this case, it's adapted for point clouds. Since the model is hierarchical, it might process data at different levels of granularity, but that's more about the model structure than the data type.\n\nNone of the four topics directly relate to point cloud processing. Time-series is about temporal data, which isn't the case here. Multimodal would involve combining different data types, but the paper is focused on a single modality (point clouds). RAG and KG are about retrieval and knowledge graphs, which don't seem relevant here. The paper is introducing a new model for a specific type of data (point clouds) but doesn't fall under the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32353@AAAI"},
{"title": "Efficient Online Training for Zero-Shot Time-Lapse Microscopy Denoising and Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. The title is \"Efficient Online Training for Zero-Shot Time-Lapse Microscopy Denoising and Super-Resolution\". \n\nFirst, I need to break down the title. The key parts here are \"Time-Lapse Microscopy\", \"Denoising\", and \"Super-Resolution\". Time-lapse microscopy usually involves capturing images over time, which suggests a sequence of data points. That makes me think of time-series data because time-series involves data points indexed in time order. \n\nNow, looking at the options: time-series, multimodal, RAG, KG. Multimodal typically refers to using multiple types of data (like text and images), which doesn't seem to be the case here. RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge, not directly related here.\n\nThe paper's focus is on denoising and super-resolution in time-lapse microscopy. Time-lapse implies a sequence over time, so time-series analysis would be involved. The methods might involve processing sequences of images to improve quality. Even though the main application is image processing, the temporal aspect (time-lapse) points towards time-series. \n\nI don't see any mention of multiple modalities, RAG, or knowledge graphs in the title. So the most fitting category here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32354@AAAI"},
{"title": "DiffCalib: Reformulating Monocular Camera Calibration as Diffusion-Based Dense Incident Map Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffCalib: Reformulating Monocular Camera Calibration as Diffusion-Based Dense Incident Map Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Monocular camera calibration is about adjusting a single camera's parameters to correct for distortions or to determine intrinsic/extrinsic parameters. The term \"diffusion-based\" might refer to a method using diffusion processes, which are common in generative models like diffusion models. \"Dense incident map generation\" sounds like creating a detailed map of light incidence, which is part of the calibration process.\n\nNow, the four options. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The paper is about camera calibration, which is a single modality (visual), so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's focus is on camera calibration using a diffusion-based method, which doesn't seem to involve building or using a knowledge graph. \n\nSo, none of the four topics seem to fit. The paper is about a novel approach to camera calibration using diffusion models, which is more related to computer vision or machine learning techniques rather than the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32355@AAAI"},
{"title": "MagicMan: Generative Novel View Synthesis of Humans with 3D-Aware Diffusion and Iterative Refinement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MagicMan: Generative Novel View Synthesis of Humans with 3D-Aware Diffusion and Iterative Refinement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Generative Novel View Synthesis\" suggests creating new views, probably of humans. \"3D-Aware Diffusion\" might refer to using a diffusion model that's aware of 3D structures. \"Iterative Refinement\" implies improving the output through multiple steps.\n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't seem related. Multimodal would involve combining different data types, like text and images. The paper is about generating views of humans, which might involve images or videos, but the title doesn't mention combining different modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which isn't mentioned here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nThe focus is on generating new views using 3D-aware models, which is more about computer vision and generative models. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to 3D-aware diffusion or view synthesis, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32356@AAAI"},
{"title": "Long-Tailed Out-of-Distribution Detection: Prioritizing Attention to Tail", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Long-Tailed Out-of-Distribution Detection: Prioritizing Attention to Tail.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series research usually deals with data points indexed in time order, like stock prices or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't talk about different modalities, so probably not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title is about detecting out-of-distribution samples, which is more about model robustness or data distribution, not retrieval or generation. So RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so that's probably not it either.\n\nThe paper seems to focus on detecting out-of-distribution examples, especially in a long-tailed distribution scenario. This is related to machine learning model reliability and data distribution challenges. None of the given topics (time-series, multimodal, RAG, KG) directly address this. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32357@AAAI"},
{"title": "Achieving Speed-Accuracy Balance in Vision-based 3D Occupancy Prediction via Geometric-Semantic Disentanglement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Achieving Speed-Accuracy Balance in Vision-based 3D Occupancy Prediction via Geometric-Semantic Disentanglement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on 3D occupancy prediction using vision-based methods. The key terms here are \"vision-based,\" which suggests using visual data, and \"3D occupancy prediction,\" which is about predicting spatial information. The method mentioned is \"geometric-semantic disentanglement,\" which implies separating geometric (shape/structure) and semantic (meaning/context) aspects.\n\nNow, looking at the possible topics. Time-series would involve data over time, like sequences or temporal data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal refers to using multiple types of data, like combining images with text or audio. The paper is vision-based, so maybe it's using only visual data. Unless \"geometric-semantic\" implies combining different modalities, but geometric and semantic could be aspects of the same modality (vision). So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance generation. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on disentangling geometric and semantic aspects for 3D prediction, which doesn't seem to involve building or using a knowledge graph. \n\nSo, none of the four topics seem to fit. The paper is about vision-based 3D occupancy prediction using a specific disentanglement method, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32358@AAAI"},
{"title": "Disentangle Nighttime Lens Flares: Self-supervised Generation-based Lens Flare Removal", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Disentangle Nighttime Lens Flares: Self-supervised Generation-based Lens Flare Removal.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The paper is about removing lens flares in images, but the title doesn't mention combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate a response, often in NLP tasks. The title mentions \"self-supervised generation-based,\" but I'm not sure if it's using retrieval. The focus seems more on generating the correct image by removing flares, not retrieving information. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using a knowledge graph, so probably not KG.\n\nSo the options are none. The paper is about image processing, specifically removing lens flares using a self-supervised generative method. None of the given topics (time-series, multimodal, RAG, KG) fit here. The correct answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32359@AAAI"},
{"title": "BUFF: Bayesian Uncertainty Guided Diffusion Probabilistic Model for Single Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BUFF: Bayesian Uncertainty Guided Diffusion Probabilistic Model for Single Image Super-Resolution\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus here is on a diffusion probabilistic model for single image super-resolution. Super-resolution in images usually refers to enhancing the resolution of an image, making it higher quality. The model uses Bayesian uncertainty guidance, which might relate to handling uncertainty in the model's predictions.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather data. This paper is about images, so probably not time-series. Multimodal typically refers to combining different types of data, like text and images. The title mentions \"single image\", so it's just one modality, not multiple. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP tasks. The title doesn't mention anything about retrieval or generation in that context. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about knowledge graphs.\n\nThe model here is a diffusion model, which is a type of generative model. Diffusion models are used in image generation and super-resolution. The key terms here are \"diffusion probabilistic model\" and \"single image super-resolution\". None of the four topics (time-series, multimodal, RAG, KG) directly relate to diffusion models or image super-resolution. The paper is about a specific model for image processing, but the given options don't include image processing or generative models. Therefore, it doesn't fit into any of the provided topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32360@AAAI"}
{"title": "Robust and Consistent Online Video Instance Segmentation via Instance Mask Propagation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Robust and Consistent Online Video Instance Segmentation via Instance Mask Propagation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Online Video Instance Segmentation\" suggests that the paper is about processing video data in real-time, segmenting each instance (like objects) in the video. The method mentioned is \"Instance Mask Propagation,\" which probably involves tracking or propagating masks across video frames to maintain consistency.\n\nNow, looking at the possible topics. Time-series typically deals with data points indexed in time order, often numerical data over time. Video processing can be considered a form of time-series since it's sequential frames, but the main focus here is on instance segmentation, which is more about computer vision tasks. \n\nMultimodal research involves combining multiple types of data, like text and images, or audio and video. The title doesn't mention combining different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't indicate the use of knowledge graphs either.\n\nSo, the paper is about video instance segmentation, which is a computer vision task. The options given don't include computer vision or video processing specifically. The closest might be time-series if we consider video as a time-series of images, but the primary research area here is more about segmentation and tracking in videos, which isn't one of the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32361@AAAI"},
{"title": "Generalized Class Discovery in Instance Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generalized Class Discovery in Instance Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Generalized Class Discovery\" sounds like it's about identifying new classes in a dataset, maybe in a way that generalizes beyond the training data. \"Instance Segmentation\" refers to a computer vision task where each object instance is segmented and identified. So the paper is probably about improving instance segmentation by discovering new classes, perhaps in an open-world or few-shot learning scenario.\n\nNow, looking at the options. Time-series is about data over time, like stock prices or sensor data. That doesn't seem related to image segmentation. Multimodal would involve combining different data types, like text and images. The title doesn't mention anything about combining modalities. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on instance segmentation and class discovery, which are computer vision tasks. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The paper isn't about time-based data, combining different data types, retrieval-augmented generation, or knowledge graphs. So it doesn't fit any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32362@AAAI"},
{"title": "WildFake: A Large-Scale and Hierarchical Dataset for AI-Generated Images Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"WildFake: A Large-Scale and Hierarchical Dataset for AI-Generated Images Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's collected over time, like stock prices or weather data. The title here is about images, so maybe not time-series. \n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about detecting AI-generated images, which might involve analyzing images, but the title doesn't mention combining different data types. It's a dataset for image detection, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The paper's focus is on a dataset for image detection, not on retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's title doesn't mention anything about knowledge graphs or structured data. \n\nSo, the dataset is for detecting AI-generated images. None of the given topics (time-series, multimodal, RAG, KG) seem to fit. The main focus is on image detection and dataset creation, which doesn't align with any of the four options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32363@AAAI"},
{"title": "FashionTailor: Controllable Clothing Editing for Human Images with Appearance Preserving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FashionTailor: Controllable Clothing Editing for Human Images with Appearance Preserving.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about editing clothing in images, so probably not time-series. \n\nMultimodal refers to using multiple data types, like combining text and images. The paper is about editing images, but the title doesn't mention combining different modalities. Maybe it's just image processing, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses. This seems more about image editing, not text generation with retrieval. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo the paper is about clothing editing in images, which is computer vision. The given options don't include computer vision or image processing. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32364@AAAI"},
{"title": "Prompt Tuning In a Compact Attribute Space", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Prompt Tuning In a Compact Attribute Space.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Prompt Tuning\" sounds like it's related to adjusting prompts in machine learning, maybe in the context of models like GPT or other transformers. \"Compact Attribute Space\" suggests they're working with a compressed or efficient representation of attributes. \n\nNow, looking at the options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which uses external data retrieval to enhance model outputs. KG is Knowledge Graphs, which are structured representations of information.\n\nPrompt tuning is a technique where you modify the input prompts to a model to get better results. RAG specifically uses retrieval from a database to augment the model's knowledge. If the paper is about prompt tuning in a compact space, maybe it's optimizing how prompts are structured or retrieved. But does that directly relate to RAG? RAG typically involves retrieving documents and then generating a response. If the attribute space is compact, perhaps they're making the retrieval more efficient. Alternatively, maybe it's about the model's internal prompt space, which could be part of RAG's retrieval mechanism. \n\nAlternatively, could it be multimodal? If the attributes are from different modalities, but the title doesn't mention that. Time-series seems unrelated. KGs are about structured knowledge, but the title doesn't mention graphs or knowledge bases. So the most likely is RAG, as prompt tuning in a compact space might relate to how retrieval is done efficiently. But I'm not 100% sure. Maybe it's none? Wait, the user says if it doesn't fit any, respond with none. But I think RAG is the closest here. Let me check again. RAG involves retrieval, and prompt tuning could be part of how the retrieved information is used. If the attribute space is compact, maybe they're optimizing the retrieval process. So I'll go with RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32365@AAAI"},
{"title": "ZeroMamba: Exploring Visual State Space Model for Zero-Shot Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ZeroMamba: Exploring Visual State Space Model for Zero-Shot Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual State Space Model\" – state space models are often used in time-series analysis, like in SSMs (State Space Models) which are used for sequential data. So maybe time-series? But the term \"visual\" here might imply that it's dealing with images or visual data. So combining visual data with state space models. \n\nZero-shot learning is a concept where a model can recognize or predict classes that it hasn't been trained on. This is common in machine learning, especially in areas like computer vision or NLP. But how does that tie into the four topics? \n\nTime-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different types of data, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data representations, like graphs of entities and relationships.\n\nThe paper's focus is on a visual state space model. State space models are typically for time-series, but here it's applied to visual data. So maybe they're using a time-series model (like SSM) for visual tasks. However, the mention of \"zero-shot learning\" might not directly relate to any of the four topics. \n\nWait, the question is about the research topic the paper belongs to. The four options are time-series, multimodal, RAG, KG. The paper is about a state space model (time-series) applied to visual data. But does that make it multimodal? If the model is combining visual data with sequential aspects, maybe it's multimodal? Or is it just using a time-series model for a different modality (visual)? \n\nAlternatively, if the model is processing visual data over time (like video), then it's time-series. But the title doesn't specify video; it just says \"visual.\" So maybe it's using a state space model for static images? That's less common. \n\nHmm. The key here is the state space model part. Since state space models are a time-series method, even if applied to visual data, the core technique is time-series. So the topic would be time-series. \n\nBut wait, multimodal is about combining multiple modalities. If the model is using both visual and temporal data, but the title doesn't mention combining with another modality like text or audio. It's just visual. So maybe it's not multimodal. \n\nRAG and KG don't seem relevant here. The title doesn't mention retrieval, generation, or knowledge graphs. \n\nTherefore, the most likely answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32366@AAAI"},
{"title": "BloomScene: Lightweight Structured 3D Gaussian Splatting for Crossmodal Scene Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BloomScene: Lightweight Structured 3D Gaussian Splatting for Crossmodal Scene Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"3D Gaussian Splatting\" sounds like a technique in computer graphics or 3D modeling. \"Crossmodal Scene Generation\" suggests that the method involves generating scenes that combine different modalities, like combining visual data with another type, such as audio or text. So \"crossmodal\" implies multiple modalities, which would relate to the \"multimodal\" topic. \n\nNow, checking the options. Multimodal is one of the given topics. The other options are time-series (which deals with data over time), RAG (Retrieval-Augmented Generation, which is about using retrieval to enhance generation models), and KG (Knowledge Graphs, which are structured representations of knowledge). \n\nThe paper's focus on crossmodal scene generation points to combining different data types (like text and images), which is a key aspect of multimodal research. There's no mention of time-series data, RAG, or knowledge graphs in the title. So the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32367@AAAI"},
{"title": "Training-and-Prompt-Free General Painterly Harmonization via Zero-Shot Disentenglement on Style and Content References", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Training-and-Prompt-Free General Painterly Harmonization via Zero-Shot Disentenglement on Style and Content References.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Painterly Harmonization\" sounds like it's about making images or art styles consistent. \"Zero-Shot Disentenglement\" suggests that the model can handle new, unseen data without prior training on it. \"Style and Content References\" implies that the model uses both style (like artistic style) and content (the actual subject) as inputs. \n\nNow, looking at the options. Time-series usually involves data over time, like stock prices or weather. This doesn't seem to fit. Multimodal refers to using multiple types of data, like text and images. The paper mentions both style and content references, which could be different modalities. For example, maybe using an image for style and another for content. \n\nRAG (Retrieval-Augmented Generation) is about using a retrieval system to get information and then generating text. The title doesn't mention retrieval or generation in that context. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem relevant here. \n\nSo, the key terms are \"style and content references,\" which are different modalities. The model is probably taking images or other data types for style and content. Since it's combining different types of inputs (style vs. content), that's multimodal. The \"zero-shot\" part might relate to not needing training data for new styles, but the main focus is on combining different modalities. Therefore, the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32368@AAAI"},
{"title": "GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Image Super-Resolution\" refers to enhancing the resolution of images, making them higher quality. The method mentioned is \"2D Gaussian Splatting,\" which sounds like a technique for rendering or processing images using Gaussian distributions. The term \"High Fidelity\" suggests it's about maintaining quality in the upscaled images.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order, like stock prices over time. That doesn't seem related to image processing. Multimodal refers to using multiple types of data (like text and images together), but the title is focused on image super-resolution, not combining different data types. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks, typically in NLP. KG is Knowledge Graphs, which are structured representations of knowledge, usually for semantic reasoning or data integration.\n\nThe paper's focus is on a specific image processing technique using Gaussian splatting. None of the four topics (time-series, multimodal, RAG, KG) directly relate to image super-resolution methods. The techniques mentioned here are more about computer vision and image processing rather than the listed topics. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32369@AAAI"},
{"title": "VRVVC: Variable-Rate NeRF-Based Volumetric Video Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VRVVC: Variable-Rate NeRF-Based Volumetric Video Compression.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. VRVVC stands for Variable-Rate NeRF-Based Volumetric Video Compression. NeRF is Neural Radiance Fields, which are used for 3D scene reconstruction and rendering. Volumetric video compression probably refers to compressing 3D video data. \n\nTime-series usually involves data points indexed in time order, like stock prices over time. This title doesn't mention anything about time series data analysis or modeling temporal sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple data modalities, like text and images. The title mentions volumetric video, which is 3D video, but there's no indication of combining different modalities. So probably not multimodal.\n\nRAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on video compression using NeRF, which is a 3D reconstruction technique. There's no mention of knowledge graphs or structured data here.\n\nSo, the paper is about video compression using a specific 3D rendering technique. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32370@AAAI"}
{"title": "MonoBox: Tightness-Free Box-Supervised Polyp Segmentation Using Monotonicity Constraint", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MonoBox: Tightness-Free Box-Supervised Polyp Segmentation Using Monotonicity Constraint.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Polyp Segmentation\" suggests it's related to medical imaging, maybe colonoscopy images where they detect polyps. \"Box-Supervised\" might mean using bounding boxes as supervision, which is common in object detection. \"Tightness-Free\" could imply that the method doesn't require tight bounding boxes, which is a common issue in segmentation tasks. \"Monotonicity Constraint\" is a bit tricky. Monotonicity usually refers to a function that either never increases or never decreases, so maybe they're applying a constraint that enforces some sort of order or consistency in the segmentation process.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. This doesn't seem to fit because the title is about image segmentation. Multimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or retrieval. \n\nThe key here is the method used. The paper introduces a monotonicity constraint for segmentation without tight boxes. This seems more like a computer vision technique, specifically in medical image segmentation. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The paper is about a specific segmentation method with a novel constraint, which doesn't fall under the listed categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32371@AAAI"},
{"title": "Exploiting Multimodal Spatial-temporal Patterns for Video Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploiting Multimodal Spatial-temporal Patterns for Video Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal\" is right there in the title. That suggests it's using multiple types of data, like combining visual and audio information. Then \"spatial-temporal patterns\" refers to both space and time, which might relate to time-series data since time is a component. But the main focus here seems to be on using multiple modalities (multimodal) to track objects in video. \n\nTime-series typically involves data points indexed in time order, often in a single modality. But here, the key term is \"multimodal,\" which directly matches one of the options. RAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem relevant here. The paper is about video object tracking using multiple data types, so multimodal is the best fit. Even though there's a spatial-temporal aspect, the primary classification here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32372@AAAI"},
{"title": "Motion Decoupled 3D Gaussian Splatting for Dynamic Object Representation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Motion Decoupled 3D Gaussian Splatting for Dynamic Object Representation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. The title mentions \"dynamic object representation,\" which might involve time, but \"3D Gaussian Splatting\" sounds more like a spatial or geometric method. So maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't seem related to retrieval or generation, so RAG is out.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title is about 3D object representation, which might be part of a knowledge graph, but the term \"Gaussian Splatting\" is a rendering technique. I'm not sure. Maybe it's using a knowledge graph to represent dynamic objects? But the title doesn't explicitly mention KG. \n\nAlternatively, \"Motion Decoupled\" might imply separating motion aspects, which could be part of a knowledge graph's structure. But I'm not certain. The main terms here are 3D Gaussian Splatting and dynamic objects. Since none of the four topics directly relate to 3D rendering or dynamic object modeling, maybe the answer is \"none.\" But wait, maybe \"dynamic object representation\" is part of a knowledge graph? Hmm. I think the safest answer is \"none\" because the title doesn't clearly align with any of the four specified topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32373@AAAI"},
{"title": "V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Modal\" immediately makes me think of multimodal, since cross-modal usually refers to combining different types of data like text, video, audio, etc. So that's a hint towards the multimodal category. Then \"Video Summarization\" suggests they're working with video data, which is a type of multimedia. \n\nThe other parts: \"Temporal Prompt Instruction Tuning\" – temporal might relate to time-series, but the main focus here seems to be on the cross-modal aspect. The term \"instruction tuning\" is common in models that handle multiple modalities, like in multimodal models where you train the model to understand and generate responses across different data types. \n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to be mentioned here. The title doesn't talk about retrieving information from a database or using a knowledge graph structure. So those two are probably out. \n\nTime-series could be a possibility because of \"temporal,\" but the primary focus is on cross-modal video summarization, which is more about integrating different data modalities rather than analyzing data over time. So the main topic here is likely multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32374@AAAI"},
{"title": "Identity-Text Video Corpus Grounding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Identity-Text Video Corpus Grounding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Identity-Text Video Corpus Grounding.\" The key terms here are \"video,\" \"text,\" and \"corpus grounding.\" Video and text suggest that the research involves multiple modalities, like combining visual and textual data. That makes me think of multimodal. \n\nTime-series usually deals with data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is more about using retrieval to enhance generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe term \"corpus grounding\" might refer to linking textual information to a video corpus, which would involve aligning different data types. Since video and text are different modalities, this seems like a multimodal task. The paper is probably about integrating text and video data, which is a classic multimodal problem. \n\nI don't see any indication of time-series analysis here. RAG and KG don't fit either. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32375@AAAI"},
{"title": "SubjectDrive: Scaling Generative Data in Autonomous Driving via Subject Control", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SubjectDrive: Scaling Generative Data in Autonomous Driving via Subject Control.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Generative Data\" probably refers to creating synthetic data, which is common in machine learning. \"Autonomous Driving\" is the application area. \"Subject Control\" might mean controlling the generation based on specific subjects or aspects. \n\nNow, the four options. Time-series data involves sequences over time, like stock prices or sensor data. Multimodal refers to using multiple data types, like combining images and text. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about scaling generative data in autonomous driving. Autonomous driving often uses various sensors (cameras, lidar, radar), which are multimodal. But the title doesn't explicitly mention combining different modalities. It's more about generating data with subject control. RAG involves using retrieved data to inform generation, but the title doesn't mention retrieval. KGs are about structured knowledge, which isn't directly indicated here. Time-series could be relevant if the data is sequential, but the focus seems to be on generating data through control mechanisms rather than time-based sequences.\n\nSo, maybe none of the four topics fit. The main focus is on generative data scaling with subject control, which might not align directly with time-series, multimodal, RAG, or KG. Unless \"subject control\" implies using knowledge graphs to structure the control, but that's a stretch. I think the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32376@AAAI"},
{"title": "HUANG: A Robust Diffusion Model-based Targeted Adversarial Attack Against Deep Hashing Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HUANG: A Robust Diffusion Model-based Targeted Adversarial Attack Against Deep Hashing Retrieval.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main components are \"diffusion model,\" \"adversarial attack,\" and \"deep hashing retrieval.\" The term \"diffusion model\" is a type of generative model, often used in image generation or data synthesis. \"Adversarial attack\" refers to methods that create inputs designed to fool machine learning models. \"Deep hashing retrieval\" is about using deep learning for efficient data retrieval, probably through hashing techniques.\n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not that. Multimodal usually refers to combining different data types like text and images. The paper here is about attacking a retrieval system, not combining modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval from a database with generation models, often in NLP. The title mentions \"deep hashing retrieval,\" which is part of retrieval systems, but RAG specifically involves augmenting generation with retrieval. The paper is about attacking such a system, not about the RAG framework itself. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo, the paper is about adversarial attacks on a retrieval system using a diffusion model. None of the four topics (time-series, multimodal, RAG, KG) directly fit. The closest might be RAG if the retrieval is part of a RAG system, but the paper is about attacking the retrieval, not using it for augmentation. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32377@AAAI"},
{"title": "LPCG: A Self-conditional Architecture for Labeled Point Cloud Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LPCG: A Self-conditional Architecture for Labeled Point Cloud Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Labeled Point Cloud Generation\" suggests that the paper is about creating point clouds that have labels. Point clouds are typically used in 3D data, like in computer vision or robotics. The term \"Self-conditional Architecture\" might refer to a model that uses its own previous outputs to generate the next parts, which is common in generative models.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on generating labeled point clouds. Point clouds are a type of data, but the key here is the generation part. The self-conditional aspect might be a type of generative model. However, none of the given topics directly relate to point cloud generation. Time-series is about temporal data, which isn't mentioned here. Multimodal would require combining different data types, but the title doesn't indicate that. RAG and KG are about retrieval and knowledge graphs, which also don't seem relevant here. So, the answer might be \"none\" because the paper's topic doesn't fit into any of the provided categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32378@AAAI"},
{"title": "Densely Connected Parameter-Efficient Tuning for Referring Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Densely Connected Parameter-Efficient Tuning for Referring Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Referring Image Segmentation\" sounds like a computer vision task where you segment an image based on a referring expression, like a natural language query. So that's probably multimodal because it involves both images and text. But wait, the other parts of the title mention \"Densely Connected Parameter-Efficient Tuning.\" That part is about model architecture or optimization techniques, maybe making the model more efficient in terms of parameters. \n\nNow, the options are time-series, multimodal, RAG, or KG. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. \n\nMultimodal is about combining different data types, like text and images. Since referring image segmentation uses both images and language, that's a strong candidate. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention retrieval or generation, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem to relate to building or using knowledge graphs. \n\nSo the main focus here is on combining image and text data for segmentation, which is a multimodal task. The parameter-efficient tuning is the method, but the topic is the application area. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32380@AAAI"},
{"title": "AUTE: Peer-Alignment and Self-Unlearning Boost Adversarial Robustness for Training Ensemble Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AUTE: Peer-Alignment and Self-Unlearning Boost Adversarial Robustness for Training Ensemble Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are Peer-Alignment, Self-Unlearning, Adversarial Robustness, and Training Ensemble Models. \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't talk about different data modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance model outputs. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data, so that's out.\n\nThe paper is about adversarial robustness in ensemble models using peer alignment and self-unlearning. These terms relate to machine learning models, specifically ensemble methods and adversarial training. None of the four topics (time-series, multimodal, RAG, KG) directly relate to adversarial robustness or ensemble models. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32382@AAAI"}
{"title": "Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Wavelet-Assisted Multi-Frequency Attention Network for Pansharpening.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Wavelet-Assisted\" probably refers to using wavelet transforms, which are often used in signal processing for analyzing different frequency components. \"Multi-Frequency Attention Network\" suggests that the model is handling multiple frequencies, maybe through attention mechanisms. \"Pansharpening\" is a term I've heard in remote sensing or image processing. It's the process of combining a high-resolution panchromatic image with lower-resolution multispectral images to produce a high-resolution color image. So this is an image processing task.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data over time. The title doesn't mention anything about time, so probably not time-series. Multimodal usually refers to combining different types of data, like text and images, or audio and video. Pansharpening is about combining different types of images (panchromatic and multispectral), which are different modalities. So maybe multimodal? But wait, the key here is whether the paper is about combining different data types (multimodal) or just processing a single type with multiple frequencies. The term \"multi-frequency\" might relate to different frequency bands in the images, which could be part of the same modality (like different spectral bands in multispectral images). So maybe it's not multimodal in the traditional sense of combining different data types, but rather processing within the same modality. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. KG is Knowledge Graphs, which involve structured data and relationships. Again, the title doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo the main contenders are multimodal and time-series. Since pansharpening is about combining different image types (panchromatic and multispectral), which are different data sources, that could be considered multimodal. However, sometimes in image processing, combining different spectral bands is part of the same modality (e.g., multispectral images have multiple bands). The term \"multi-frequency\" might refer to different frequency components in the wavelet transform, not different data modalities. So maybe the paper is using wavelets to handle different frequency components in the images, which is a processing technique rather than combining different modalities. Therefore, it might not fit the multimodal category. \n\nAlternatively, if the panchromatic and multispectral images are considered different modalities, then combining them would be multimodal. But I'm not entirely sure. The term \"multimodal\" in research usually refers to combining different types of data (like text and images), not different spectral bands. So perhaps the correct answer is none. But the options are time-series, multimodal, RAG, KG. If it's about combining different image types, maybe multimodal is the closest. But I'm a bit uncertain. Let me check again. The task is pansharpening, which is a specific image processing technique. The methods used (wavelet and attention) are techniques, not necessarily indicating the research topic. The research topics here are the broader categories. Since the paper is about combining different image data (panchromatic and multispectral), which are different types of images, that could be considered multimodal. So the answer might be multimodal. But I'm not 100% sure. Alternatively, if the focus is on the wavelet and attention mechanisms for multi-frequency processing, maybe it's not any of the listed topics. But the options are limited. Given the choices, I think the best fit is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32381@AAAI"},
{"title": "AUTE: Peer-Alignment and Self-Unlearning Boost Adversarial Robustness for Training Ensemble Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AUTE: Peer-Alignment and Self-Unlearning Boost Adversarial Robustness for Training Ensemble Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are Peer-Alignment, Self-Unlearning, Adversarial Robustness, and Training Ensemble Models. \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't talk about different data modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance model outputs. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data, so that's out.\n\nThe paper is about adversarial robustness in ensemble models using peer alignment and self-unlearning. These terms relate to machine learning models, specifically ensemble methods and adversarial training. None of the four topics (time-series, multimodal, RAG, KG) directly relate to adversarial robustness or ensemble models. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32382@AAAI"},
{"title": "EvoChart: A Benchmark and a Self-Training Approach Towards Real-World Chart Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EvoChart: A Benchmark and a Self-Training Approach Towards Real-World Chart Understanding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"EvoChart\" sounds like it's related to charts, maybe evolutionary charts? But the main part is about a benchmark and a self-training approach for real-world chart understanding. So the focus is on understanding charts, which are visual data representations. \n\nNow, the four options. Time-series usually deals with data points indexed in time order. Multimodal refers to combining multiple data modalities, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about chart understanding. Charts can be part of multimodal data because they combine visual elements (images) and possibly textual elements (labels, titles). If the research involves processing both the visual aspects of the chart and any associated text, that would be multimodal. The mention of a self-training approach might involve using different data sources, but the key here is the chart itself, which is a visual modality. \n\nTime-series could be a possibility if the charts are time-based, but the title doesn't specify that. The main focus is on understanding real-world charts in general, not specifically time-series charts. RAG and KG don't seem relevant here unless the paper is using a knowledge graph to enhance chart understanding, but the title doesn't mention that. The self-training approach might be a method, but the topic is about the data (charts) and the approach to understand them, which is multimodal. \n\nSo, I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32383@AAAI"},
{"title": "VProChart: Answering Chart Question Through Visual Perception Alignment Agent and Programmatic Solution Reasoning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VProChart: Answering Chart Question Through Visual Perception Alignment Agent and Programmatic Solution Reasoning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Answering Chart Question\" suggests it's about interpreting charts, which are visual data. Then \"Visual Perception Alignment Agent\" implies there's a component dealing with visual data processing. \"Programmatic Solution Reasoning\" might refer to using code or logical steps to solve the problem. \n\nMultimodal research typically involves combining different types of data, like text and images. Since the paper is about answering questions on charts, which are visual, and possibly using both visual and textual information, this could be multimodal. \n\nTime-series would involve data over time, but the title doesn't mention time-based data specifically. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which isn't directly indicated here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem to fit. \n\nSo the most likely topic is multimodal because it combines visual perception (images/charts) with reasoning, possibly integrating different modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32384@AAAI"},
{"title": "SLIP: Spoof-Aware One-Class Face Anti-Spoofing with Language Image Pretraining", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SLIP: Spoof-Aware One-Class Face Anti-Spoofing with Language Image Pretraining.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Face Anti-Spoofing\" refers to detecting fake faces, like in biometric systems. \"One-Class\" might mean it's trained on genuine samples and detects anomalies. \"Language Image Pretraining\" suggests using both text (language) and images. So combining different modalities, like text and images. That sounds like multimodal. \n\nTime-series would involve data over time, like sequences. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured data representations. The paper's focus on pretraining with language and images doesn't seem to involve time-series data, RAG, or building a knowledge graph. So the most likely topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32385@AAAI"},
{"title": "Resolving Multi-Condition Confusion for Finetuning-Free Personalized Image Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Resolving Multi-Condition Confusion for Finetuning-Free Personalized Image Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Condition Confusion\" suggests that there are multiple conditions or inputs being considered. \"Finetuning-Free\" means the model doesn't require additional training for personalization. \"Personalized Image Generation\" implies creating images tailored to specific users or preferences.\n\nLooking at the options: time-series deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about generating personalized images without finetuning, which might involve using different conditions (like text prompts, user preferences, etc.) to generate images. Since it's combining multiple conditions (which could be different modalities like text, style, etc.), this sounds like multimodal. The key here is that multiple conditions are being used, which are different data types, so multimodal makes sense. RAG is more about using retrieved documents to inform generation, which isn't mentioned here. KG would involve structured knowledge, which isn't indicated. Time-series is unrelated. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32386@AAAI"},
{"title": "Unleashing the Temporal-Spatial Reasoning Capacity of GPT for Training-Free Audio and Language Referenced Video Object Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's tackle this. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If none fit, I should respond with \"none\".\n\nFirst, I'll break down the title: \"Unleashing the Temporal-Spatial Reasoning Capacity of GPT for Training-Free Audio and Language Referenced Video Object Segmentation.\" \n\nLooking at the key terms here. \"Temporal-Spatial Reasoning\" suggests dealing with both time (temporal) and space (spatial), which might relate to time-series data. But time-series typically refers to data points indexed in time order, often in one dimension. However, the mention of \"Video Object Segmentation\" implies processing video, which is inherently time-series (frames over time) but also involves spatial information (each frame's image). So maybe time-series is a candidate here.\n\nNext, \"Audio and Language Referenced\" indicates that the paper uses both audio and language inputs. That's a strong hint towards multimodal, since multimodal research involves integrating multiple types of data (like text, audio, video). The combination of audio and language (text) with video for segmentation would definitely be multimodal.\n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to augment its responses. The title doesn't mention anything about retrieval or augmenting generation, so RAG might not be relevant here.\n\nKG (Knowledge Graph) involves structured data representations, often for linking entities and relationships. The title doesn't mention knowledge graphs or structured data, so that's probably not it.\n\nNow, the main task here is video object segmentation, which uses audio, language, and video. The key is combining different modalities (audio, language, video) to perform the task. So the primary topic here is multimodal. The temporal-spatial aspect is part of the method (using GPT's reasoning for time and space), but the core of the research is integrating multiple data types. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32387@AAAI"},
{"title": "ZoRI: Towards Discriminative Zero-Shot Remote Sensing Instance Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ZoRI: Towards Discriminative Zero-Shot Remote Sensing Instance Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Zero-Shot\" usually refers to a machine learning scenario where the model is trained on a set of classes and then tested on classes it hasn't seen before. So, zero-shot learning. \"Remote Sensing\" involves data collected from a distance, like satellite or aerial imagery. \"Instance Segmentation\" is a computer vision task where each object in an image is identified and segmented. \n\nNow, the four options. Time-series is about data over time, like stock prices or weather data. Multimodal refers to using multiple types of data (e.g., text and images). RAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generation models, often used in NLP. KG is Knowledge Graph, which is a structured representation of knowledge.\n\nThe paper's focus is on instance segmentation in remote sensing with zero-shot learning. None of the four topics directly relate to this. Time-series isn't involved here. It's not multimodal since it's about a single data type (remote sensing images). RAG and KG are more about information retrieval and knowledge representation, which don't seem to connect to instance segmentation in this context. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32388@AAAI"},
{"title": "DreamPhysics: Learning Physics-Based 3D Dynamics with Video Diffusion Priors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DreamPhysics: Learning Physics-Based 3D Dynamics with Video Diffusion Priors.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Learning Physics-Based 3D Dynamics\" suggests they're modeling physical movements in 3D space. \"Video Diffusion Priors\" implies they're using video data, which is a sequence of images over time. So, video is a time-series of frames. But the main focus here is on physics-based dynamics, which might involve simulating or predicting how objects move over time. That could relate to time-series analysis because it's about sequences and temporal data.\n\nMultimodal usually refers to combining different types of data, like text and images. The title mentions video, which is a type of data, but there's no indication of combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't mention anything about retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on physics dynamics and video data, not on building or using knowledge graphs. So KG is out.\n\nSo the main contenders are time-series and multimodal. Since the paper uses video (which is a time-series of frames) and is about dynamics over time, it's likely related to time-series analysis. Even though video is a form of multimodal data (combining visual and temporal aspects), the primary research focus here seems to be on modeling temporal dynamics with physics, which aligns more with time-series. The mention of \"diffusion priors\" might relate to generative models, but the key aspect here is the temporal aspect of the video data. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32389@AAAI"},
{"title": "Efficient Indoor Depth Completion Network Using Mask-adaptive Gated Convolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Efficient Indoor Depth Completion Network Using Mask-adaptive Gated Convolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data collected sequentially. The title mentions depth completion, which is about filling in missing depth information in images, probably from a camera or LiDAR. That seems more like computer vision, not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper's title doesn't mention combining different data types, just depth completion using a specific convolution method. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on a neural network architecture for depth completion, not on building or using a knowledge graph. So KG is out.\n\nNone of the four topics seem to fit. The paper is about a specific neural network technique for depth completion, which is a computer vision task. Since the options given don't include computer vision or depth estimation, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32390@AAAI"}
{"title": "Manta: Enhancing Mamba for Few-Shot Action Recognition of Long Sub-Sequence", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Manta: Enhancing Mamba for Few-Shot Action Recognition of Long Sub-Sequence.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Few-Shot Action Recognition\" suggests that the paper is about recognizing actions with limited examples, which is a common problem in machine learning. \"Long Sub-Sequence\" might imply that the data is sequential, possibly time-series data. The term \"Mamba\" here is likely referring to a model or architecture. I remember that Mamba is a type of model designed for processing sequences efficiently, similar to transformers but with a different approach. So, if they're enhancing Mamba for action recognition, which is a task in video or time-based data, that points towards time-series analysis. \n\nNow, checking the other options. Multimodal would involve combining different types of data like text and images, but the title doesn't mention that. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generative models, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nThe key part here is \"Long Sub-Sequence,\" which is a term often used in time-series analysis to describe segments of a sequence. Action recognition in videos is typically a time-series problem because it involves analyzing sequences of frames over time. Therefore, the paper is likely focused on time-series data processing using the Mamba model. \n\nI don't see any mention of multiple modalities, retrieval, or knowledge graphs in the title. So the most fitting category here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32391@AAAI"},
{"title": "CLIP-RestoreX: Restore Image Structure and Perception in Exposure Correction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CLIP-RestoreX: Restore Image Structure and Perception in Exposure Correction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about image restoration, so probably not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. CLIP is a model that connects text and images, so maybe this is multimodal? The paper's title mentions restoring image structure and perception, which might involve using text or another modality for guidance. CLIP is known for multimodal tasks, so that's a possibility.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, often in text. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured data representations. The title doesn't seem to relate to knowledge graphs either.\n\nSo, the most likely is multimodal because CLIP is a multimodal model (text and images), and the task involves image restoration which might use multimodal inputs. The mention of \"perception\" could relate to how the model understands the image in context, possibly using text descriptions. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32392@AAAI"},
{"title": "DAMPER: A Dual-Stage Medical Report Generation Framework with Coarse-Grained MeSH Alignment and Fine-Grained Hypergraph Matching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DAMPER: A Dual-Stage Medical Report Generation Framework with Coarse-Grained MeSH Alignment and Fine-Grained Hypergraph Matching.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on a medical report generation framework. The key components mentioned are Coarse-Grained MeSH Alignment and Fine-Grained Hypergraph Matching. MeSH is the Medical Subject Headings, which is a controlled vocabulary used in medical literature. Hypergraph matching might relate to graph structures, which could be part of a knowledge graph (KG). \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. Multimodal usually refers to combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database to aid in generation. KG is Knowledge Graph, which involves structured data and relationships between entities.\n\nThe paper mentions MeSH alignment and hypergraph matching. MeSH is a controlled vocabulary, so aligning to MeSH terms might involve linking to a knowledge base. Hypergraph matching could be a way to model complex relationships, which is common in knowledge graphs. The framework is dual-stage, which might involve different stages of processing, but the key here is the use of structured data (MeSH and hypergraphs) which points towards a knowledge graph approach. \n\nRAG involves retrieving information to generate text, but the title doesn't mention retrieval from a database. Instead, it's about aligning and matching within a structured format. So, the use of MeSH and hypergraphs suggests that the framework is leveraging a knowledge graph structure for medical report generation. Therefore, the topic is likely KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32393@AAAI"},
{"title": "Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nThe title is \"Towards a Multimodal Large Language Model with Pixel-Level Insight for Biomedicine.\" First, I need to break down the key terms here. The word \"Multimodal\" stands out right away. Multimodal typically refers to models that can process and integrate multiple types of data, like text, images, audio, etc. So if the paper is about a multimodal model, that's a strong indicator.\n\nThen there's \"Large Language Model,\" which is a common term in AI, but the addition of \"Multimodal\" suggests it's not just text-based. The \"Pixel-Level Insight\" part might imply that the model is handling images at a detailed level, which would be part of the multimodal approach, combining text and images. The application area is biomedicine, which could involve various data types like medical images, text reports, etc., further supporting the multimodal aspect.\n\nNow, checking the other options. Time-series would involve data points indexed in time order, like stock prices or sensor data over time. The title doesn't mention anything about time or sequences, so probably not time-series. RAG (Retrieval-Augmented Generation) is about combining retrieval of information with generation, often used in question-answering systems. The title doesn't mention retrieval or augmentation, so RAG is unlikely. KG (Knowledge Graph) involves structured data representations, which again isn't indicated here. The focus is on a model that handles multiple modalities, so the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32394@AAAI"},
{"title": "PSReg: Prior-guided Sparse Mixture of Experts for Point Cloud Registration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PSReg: Prior-guided Sparse Mixture of Experts for Point Cloud Registration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Point Cloud Registration\" refers to aligning different sets of 3D points, which is a common problem in computer vision or robotics. The method mentioned is a \"Sparse Mixture of Experts\" guided by prior knowledge. \n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on point cloud registration using a specific model architecture. None of the terms in the title directly relate to time-series data, combining multiple modalities, retrieval-augmented generation, or knowledge graphs. The key terms here are about a specific machine learning model (mixture of experts) applied to a 3D data problem. Since none of the four topics are directly addressed, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32395@AAAI"},
{"title": "Medical MLLM Is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Medical MLLM Is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, the key terms here are \"Multimodal Large Language Models\" (MLLM). The term \"multimodal\" suggests that the model handles multiple types of data, like text and images. The paper is discussing vulnerabilities in these models, specifically cross-modality attacks and mismatched attacks. \n\nTime-series would involve data over time, like stock prices or weather data. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance model outputs. KG (Knowledge Graph) involves structured data representations. The title doesn't mention anything about time, retrieval, or knowledge graphs. The focus is clearly on multimodal models and their vulnerabilities. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32396@AAAI"},
{"title": "L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components are LiDAR and 4DRadar fusion. Fusion of different sensors usually implies combining data from multiple sources. So, multimodal might be a candidate here because multimodal research often involves integrating different types of data, like combining visual and auditory information. LiDAR and radar are different modalities, so their fusion would be multimodal.\n\nTime-series typically deals with data points indexed in time order, like stock prices over time or sensor data collected over time. While LiDAR and radar might generate time-series data, the key here is the fusion of different modalities, not the temporal aspect. So maybe not time-series.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on sensor fusion for object detection, not on building or using knowledge graphs. So KG is out.\n\nSo the most likely answer is multimodal because it's about combining LiDAR and radar data, which are different modalities. The fusion aspect is key here. The goal is weather-robust detection, which might require combining strengths of both sensors. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32397@AAAI"},
{"title": "Zero-Shot Low-Light Image Enhancement via Latent Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Zero-Shot Low-Light Image Enhancement via Latent Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Zero-Shot\" probably refers to the model being able to handle tasks it wasn't explicitly trained on. \"Low-Light Image Enhancement\" is about improving images taken in low-light conditions. \"Latent Diffusion Models\" sounds like a type of generative model, maybe similar to diffusion models used in image generation.\n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which uses external information retrieval during generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about image enhancement using a specific model. Since it's dealing with images, maybe multimodal? But multimodal typically involves combining multiple modalities, like text and images. Here, it's just image processing. The model is a latent diffusion model, which is a type of generative model. None of the four topics directly relate to generative models or image enhancement. RAG and KG are more about using external data or knowledge. Time-series is unrelated here. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32398@AAAI"},
{"title": "Distilling Knowledge from Heterogeneous Architectures for Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Distilling Knowledge from Heterogeneous Architectures for Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Distilling Knowledge\" sounds like knowledge distillation, which is a technique where a smaller model is trained using the outputs of a larger, more complex model. \"Heterogeneous Architectures\" suggests that the models involved are different in structure or type. \"Semantic Segmentation\" is a computer vision task where each pixel in an image is classified into a category.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to generate answers. KG is Knowledge Graph, which is a structured representation of knowledge.\n\nThe paper's focus is on knowledge distillation between different architectures for a computer vision task. None of the topics directly relate to time-series data. It's not about combining multiple data modalities, so not multimodal. RAG and KG are more about retrieving and using external knowledge, which isn't the main point here. The key here is knowledge distillation, which isn't listed in the given topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32399@AAAI"},
{"title": "SeFAR: Semi-supervised Fine-grained Action Recognition with Temporal Perturbation and Learning Stabilization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SeFAR: Semi-supervised Fine-grained Action Recognition with Temporal Perturbation and Learning Stabilization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Fine-grained Action Recognition\" suggests it's about recognizing specific actions, which is common in video analysis. \"Temporal Perturbation\" and \"Learning Stabilization\" might relate to handling sequences over time. Time-series analysis deals with data points indexed in time order, so if the paper is about processing sequences, like video frames over time, that could be time-series. \n\nBut wait, action recognition in videos is often considered a time-series problem because each frame is a time step. However, some might categorize it under multimodal if it combines different data types, like video and audio. But the title doesn't mention other modalities, just \"action recognition,\" which is typically visual. \n\nRAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, usually in NLP. KG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval. \n\nSo the key terms here are \"Temporal Perturbation\" and \"Learning Stabilization.\" Temporal refers to time, so that's a strong indicator of time-series. The paper is likely dealing with time-dependent data, like video sequences, to recognize actions. Therefore, the topic should be time-series. \n\nI don't see any mention of multiple modalities (like text and image), so multimodal is out. RAG and KG are not relevant here. So the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32400@AAAI"}
{"title": "PoseMamba: Monocular 3D Human Pose Estimation with Bidirectional Global-Local Spatio-Temporal State Space Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PoseMamba: Monocular 3D Human Pose Estimation with Bidirectional Global-Local Spatio-Temporal State Space Model.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main task here is 3D human pose estimation using a monocular camera. The key part for the topic is the \"Bidirectional Global-Local Spatio-Temporal State Space Model.\" \n\nTime-series analysis involves data points indexed in time order. Since the model is spatio-temporal, it's handling both spatial (position in space) and temporal (time) data. So, the model is likely processing sequences of data over time, which is typical in time-series. For example, estimating poses over a video sequence would involve time-series data.\n\nMultimodal would involve combining different types of data, like text and images, but the title mentions monocular, which is a single camera input, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval systems to augment model outputs, which doesn't seem relevant here. KG (Knowledge Graphs) involve structured data representations, which also don't fit the context of pose estimation.\n\nSo, the spatio-temporal aspect points towards time-series. The model uses a state space model, which is often used in time-series analysis for modeling temporal dynamics. The bidirectional part suggests it's looking at past and future data points, which is common in time-series models like LSTMs or Transformers. Therefore, the paper likely belongs to the time-series topic.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32401@AAAI"},
{"title": "Generative Medical Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generative Medical Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. \"Generative\" might refer to generative models, like GANs or VAEs, which are used in creating data. \"Medical Segmentation\" is about segmenting medical images, like MRI or CT scans, to identify different tissues or structures. \n\nNow, looking at the options. Time-series analysis deals with data over time, like stock prices or sensor data. Multimodal refers to using multiple data types, such as combining text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which structures information in a graph format to represent relationships between entities.\n\nThe paper's title doesn't mention anything about time, so time-series is probably out. It's about medical segmentation, which is typically an image processing task. Generative models in this context are likely used for creating or enhancing segmented images. But does that fit into any of the listed topics? \n\nMultimodal would require combining different data types, but the title doesn't specify that. RAG is about retrieval and generation in text models, which doesn't seem related to image segmentation. KG involves structured knowledge, which also doesn't directly connect here. \n\nSo, the paper is about using generative models for medical image segmentation. None of the four topics (time-series, multimodal, RAG, KG) directly apply here. The closest might be multimodal if they're using multiple modalities (like combining MRI and X-ray), but the title doesn't specify that. Since the title only mentions segmentation and generative methods without those specific terms, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32402@AAAI"},
{"title": "EGSRAL:An Enhanced 3D Gaussian Splatting Based Renderer with Automated Labeling for Large-Scale Driving Scene", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EGSRAL: An Enhanced 3D Gaussian Splatting Based Renderer with Automated Labeling for Large-Scale Driving Scene.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components here are 3D Gaussian Splatting, a renderer, automated labeling, and application in driving scenes. Let's consider each part.\n\nTime-series usually involves data over time, like sequences or temporal data. This title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about a renderer, which might involve different data modalities, but the title specifically mentions 3D Gaussian Splatting and automated labeling. Not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about rendering and labeling in driving scenes. Automated labeling could relate to data annotation, but not necessarily building a knowledge graph. \n\nSo, the paper is focused on a rendering technique (3D Gaussian Splatting) with automated labeling for driving scenes. None of the four topics (time-series, multimodal, RAG, KG) seem to fit directly. The main focus is on rendering and labeling, which doesn't align with the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32403@AAAI"},
{"title": "High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. Frame interpolation sounds like it's about video frames, which are sequential in time. So maybe time-series? But wait, frame interpolation is more about generating intermediate frames between existing ones, which is a common task in video processing. That's part of computer vision, perhaps. \n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention anything about combining different data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation in that context, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, the title doesn't mention anything about knowledge graphs or structured data.\n\nSo, the main question is whether this is time-series. Frame interpolation in video is indeed a time-series problem because it deals with sequences of frames over time. However, sometimes computer vision tasks might not be strictly categorized under time-series. But given the options, time-series is the closest fit here. The other options don't seem to apply. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32404@AAAI"},
{"title": "Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Zero-shot Depth Completion via Test-time Alignment with Affine-invariant Depth Prior.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Zero-shot Depth Completion\" suggests that the method is completing depth information without prior training on specific data. \"Test-time Alignment\" might refer to adjusting or aligning data during testing. \"Affine-invariant Depth Prior\" implies using a prior that's invariant under affine transformations, which are linear transformations plus translations. \n\nNow, the possible topics. Time-series usually involves data over time, like sequences. Multimodal would involve combining different data types, like images and text. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models. KG (Knowledge Graph) involves structured data and relationships.\n\nThe paper seems focused on depth completion, which is a computer vision task, likely using images or 3D data. The mention of \"affine-invariant\" might relate to geometric transformations, but none of the four topics directly relate to that. The methods described don't seem to involve time-series data, multimodal inputs, retrieval-augmented generation, or knowledge graphs. So, it probably doesn't fit any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32405@AAAI"},
{"title": "VG-TVP: Multimodal Procedural Planning via Visually Grounded Text-Video Prompting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VG-TVP: Multimodal Procedural Planning via Visually Grounded Text-Video Prompting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal\" is right there in the title. That's one of the options. The other parts mention \"Visually Grounded Text-Video Prompting.\" So they're combining text and video, which are different modalities. That definitely sounds like multimodal research. \n\nNow, checking the other options. Time-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences in that sense. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, often in NLP. The title doesn't mention retrieval or generation in that context. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't reference knowledge graphs. \n\nSo the key term here is \"Multimodal,\" which is explicitly stated. The paper is about combining different modalities (text and video) for procedural planning. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32406@AAAI"},
{"title": "QORT-Former: Query-optimized Real-time Transformer for Understanding Two Hands Manipulating Objects", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"QORT-Former: Query-optimized Real-time Transformer for Understanding Two Hands Manipulating Objects.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Transformer\" suggests it's using a transformer model, which is common in many areas. \"Real-time\" might relate to time-series data since it's about processing data as it comes in. But \"Understanding Two Hands Manipulating Objects\" sounds like it's about actions or interactions, maybe involving vision or sensors. \n\nMultimodal usually refers to combining different types of data, like text and images. If the model is using both visual and maybe motion data, that could be multimodal. However, the title doesn't explicitly mention multiple modalities. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention knowledge graphs either. \n\nTime-series could be a fit if the model processes sequential data over time, like real-time hand movements. The \"real-time\" part might indicate time-series processing. However, the main focus here seems to be on understanding the manipulation of objects with two hands, which could involve video or sensor data over time. \n\nBut wait, \"Understanding Two Hands Manipulating Objects\" might involve both visual and motion data, making it multimodal. However, the term \"multimodal\" isn't in the title. The key here is whether the research combines different data types. If it's using, say, video (visual) and maybe depth sensors or motion tracking (another modality), then it's multimodal. \n\nAlternatively, if it's just processing a sequence of images or sensor data over time, that's time-series. But the term \"Transformer\" is often used in time-series models. However, the main application here is about understanding hand-object interactions, which could be a specific application area. \n\nGiven the options, I'm leaning towards multimodal if it's combining different data types. But without explicit mention, maybe it's time-series. However, the real-time aspect might be more about processing speed rather than time-series data. \n\nHmm. The title doesn't clearly indicate RAG or KG. Between time-series and multimodal. Since the task is about understanding hands manipulating objects, which could involve multiple modalities (like vision and maybe tactile), but the title doesn't specify. The term \"Transformer\" is used in both time-series and multimodal contexts. \n\nI think the best fit here is multimodal because understanding hand-object interactions often requires combining visual and possibly other sensory data. So the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32407@AAAI"},
{"title": "Every Component Counts: Rethinking the Measure of Success for Medical Semantic Segmentation in Multi-Instance Segmentation Tasks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Every Component Counts: Rethinking the Measure of Success for Medical Semantic Segmentation in Multi-Instance Segmentation Tasks.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on medical semantic segmentation, specifically in multi-instance segmentation tasks. The key terms here are \"semantic segmentation\" and \"multi-instance.\" \n\nSemantic segmentation is a computer vision task where each pixel in an image is classified into a category. Multi-instance segmentation would involve segmenting multiple instances of objects within the same image. The paper is about rethinking how success is measured in these tasks, which might relate to evaluation metrics or model components.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order, which doesn't seem relevant here. The paper is about image segmentation, not time-based data.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so maybe not this one.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The paper is about segmentation in medical imaging, not about generating text or using retrieval methods.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data representation.\n\nSo, none of the given topics (time-series, multimodal, RAG, KG) directly relate to the content of the paper as described in the title. The paper is focused on medical image segmentation and evaluation metrics, which doesn't fit into any of the provided categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32408@AAAI"},
{"title": "FastLGS: Speeding Up Language Embedded Gaussians with Feature Grid Mapping", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FastLGS: Speeding Up Language Embedded Gaussians with Feature Grid Mapping.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Language Embedded Gaussians\" suggests that there's some language model involved, maybe using Gaussian distributions. \"Feature Grid Mapping\" might be a technique to speed things up. The main goal here is to make something faster, specifically \"Speeding Up Language Embedded Gaussians.\"\n\nNow, looking at the possible topics. Time-series usually deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance language models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's title doesn't mention anything about time or sequential data, so probably not time-series. It's about language models, but does it combine multiple modalities? The term \"Language Embedded\" might imply text, but without another modality like images or audio, it's not multimodal. RAG involves retrieval, but the title doesn't mention retrieval or generation. KGs are about structured knowledge, and again, the title doesn't reference that. The focus here is on optimizing Gaussian embeddings in a language model, which might be part of a larger system but doesn't clearly fit into any of the four categories listed. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32410@AAAI"},
{"title": "ContextHOI: Spatial Context Learning for Human-Object Interaction Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ContextHOI: Spatial Context Learning for Human-Object Interaction Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Human-Object Interaction Detection\" sounds like a computer vision task, maybe in action recognition or something related to understanding interactions between people and objects. The key part here is \"Spatial Context Learning.\" Spatial context usually refers to understanding the arrangement or positions of objects in space, which is different from temporal aspects (which would be time-series). \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. Multimodal typically involves combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of information, usually involving entities and relationships.\n\nThe paper's focus is on spatial context for detecting interactions between humans and objects. That seems more related to computer vision and spatial reasoning. None of the four topics directly relate to spatial context learning. Time-series is about time, multimodal is about combining data types, RAG is about retrieval in generation, and KG is about structured knowledge. Since the paper is about spatial context in human-object interactions, which isn't covered by any of the given topics, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32411@AAAI"}
{"title": "ContextHOI: Spatial Context Learning for Human-Object Interaction Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ContextHOI: Spatial Context Learning for Human-Object Interaction Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Human-Object Interaction Detection\" sounds like a computer vision task, maybe in action recognition or something related to understanding interactions between people and objects. The key part here is \"Spatial Context Learning.\" Spatial context usually refers to understanding the arrangement or positions of objects in space, which is different from temporal aspects (which would be time-series). \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. Multimodal typically involves combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of information, usually involving entities and relationships.\n\nThe paper's focus is on spatial context for detecting interactions between humans and objects. That seems more related to computer vision and spatial reasoning. None of the four topics directly relate to spatial context learning. Time-series is about time, multimodal is about combining data types, RAG is about retrieval in generation, and KG is about structured knowledge. Since the paper is about spatial context in human-object interactions, which isn't covered by any of the given topics, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32411@AAAI"},
{"title": "Orchestrating the Symphony of Prompt Distribution Learning for Human-Object Interaction Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Orchestrating the Symphony of Prompt Distribution Learning for Human-Object Interaction Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Prompt Distribution Learning\" sounds like it's about how prompts are distributed, maybe in a machine learning context. \"Human-Object Interaction Detection\" refers to identifying interactions between humans and objects, which is a computer vision task. \n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually combines different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time or sequential data, so probably not time-series. It's about human-object interactions, which might involve images or videos, but the key term here is \"Prompt Distribution Learning.\" That doesn't directly relate to multimodal, RAG, or KG. Wait, maybe \"Prompt Distribution Learning\" is a method that could be part of a larger system. But none of the four topics seem to fit. The paper is about a specific learning method for interaction detection, which might not fall under the given categories. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32412@AAAI"},
{"title": "Doubly Contrastive Learning for Source-Free Domain Adaptive Person Search", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Doubly Contrastive Learning for Source-Free Domain Adaptive Person Search.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Doubly Contrastive Learning\" sounds like a machine learning technique, maybe related to contrastive learning which is used in self-supervised learning. \"Source-Free Domain Adaptive\" suggests domain adaptation without access to the source domain data. \"Person Search\" is the application area, probably in computer vision for identifying people across different domains or datasets.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. Multimodal usually refers to combining different data types, like text and images. The paper is about person search, which might involve images or videos, but the title doesn't specify combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about knowledge graphs or structured data.\n\nSo the paper is about domain adaptation in person search using a specific learning method. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The main focus is on domain adaptation and contrastive learning, which are more general machine learning areas not covered by the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32413@AAAI"},
{"title": "DesignEdit: Unify Spatial-Aware Image Editing via Training-free Inpainting with a Multi-Layered Latent Diffusion Framework", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DesignEdit: Unify Spatial-Aware Image Editing via Training-free Inpainting with a Multi-Layered Latent Diffusion Framework.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on image editing, specifically using a method called training-free inpainting. The term \"spatial-aware\" suggests that the model is considering spatial relationships in the image, which is common in image processing tasks. The framework mentioned is a multi-layered latent diffusion model. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. Multimodal refers to combining different types of data, like text and images. The title doesn't mention combining different modalities, just image editing. RAG stands for Retrieval-Augmented Generation, which is often used in models that combine retrieval of information with generation, like in some NLP tasks. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on a specific image editing technique using a diffusion model. Since none of the terms in the title relate to time-series data, combining multiple data types (multimodal), retrieval-augmented generation, or knowledge graphs, it doesn't fit into any of the four categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32414@AAAI"},
{"title": "FlexiTex: Enhancing Texture Generation via Visual Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FlexiTex: Enhancing Texture Generation via Visual Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions \"Visual Guidance,\" which might imply using visual data, but does it combine different modalities? The main focus here is on texture generation using visual input. If it's just using visual data to generate textures, maybe it's not multimodal unless it's combining, say, text and images. But the title doesn't specify multiple modalities, so maybe not.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information before generating a response. The title doesn't mention anything about retrieval or augmenting generation with retrieved data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge, so that's unlikely.\n\nSo, none of the four topics seem to fit. The paper is about texture generation using visual guidance, which might be in computer vision or generative models, but not the specified categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32415@AAAI"},
{"title": "Granularity-Adaptive Spatial Evidence Tokenization for Video Question Answering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Granularity-Adaptive Spatial Evidence Tokenization for Video Question Answering.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video Question Answering\" suggests that the research is about answering questions related to videos. Videos are a combination of visual (frames) and audio elements, so that's probably multimodal. But wait, maybe there's more to it. The term \"Granularity-Adaptive Spatial Evidence Tokenization\" – \"spatial\" might refer to the visual aspects, like different parts of the video frames. \"Tokenization\" here could be about how the model processes the video data into tokens, which is common in multimodal models that handle both text and images/videos.\n\nTime-series usually deals with data points indexed in time order, like stock prices or sensor data. While videos do have a temporal component (they play over time), the title doesn't mention time-series analysis specifically. The focus here seems more on spatial aspects and tokenization for QA, which is more about combining different modalities (video and text) rather than analyzing time-based data.\n\nRAG (Retrieval-Augmented Generation) involves using a retriever to find relevant documents and then generating answers. The title doesn't mention retrieval or generation, so probably not RAG. KG (Knowledge Graphs) involve structured data and relationships between entities. The title doesn't reference knowledge graphs either.\n\nMultimodal is about integrating multiple data types, like combining video (visual) and text (questions/answers). The paper's focus on video QA and tokenization suggests it's handling different modalities. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32416@AAAI"},
{"title": "ARNet: Self-Supervised FG-SBIR with Unified Sample Feature Alignment and Multi-Scale Token Recycling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ARNet: Self-Supervised FG-SBIR with Unified Sample Feature Alignment and Multi-Scale Token Recycling.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. FG-SBIR probably stands for Fine-Grained Similarity-Based Image Retrieval. So the paper is about image retrieval, specifically in a fine-grained context. The methods mentioned are self-supervised learning, unified sample feature alignment, and multi-scale token recycling. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal research deals with combining different data types, like text and images. The title mentions image retrieval but doesn't specify combining multiple modalities. Unless FG-SBIR inherently uses multiple modalities, but I think it's more about images. \n\nRAG stands for Retrieval-Augmented Generation, which is typically in the context of models that retrieve information to augment their generation, like in language models. The paper here is about image retrieval, not augmenting generation. So maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge bases, so probably not KG. \n\nSo the options are time-series, multimodal, RAG, or KG. The paper seems to be about image retrieval using self-supervised methods. None of the four topics directly fit. The closest might be multimodal if there's a combination of data types, but the title doesn't specify that. Since the answer has to be one of the four or none, I think the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32417@AAAI"},
{"title": "RRT-MVS: Recurrent Regularization Transformer for Multi-View Stereo", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RRT-MVS: Recurrent Regularization Transformer for Multi-View Stereo.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Recurrent Regularization Transformer\" suggests some kind of neural network model, maybe using recurrent elements. \"Multi-View Stereo\" refers to a computer vision task where you reconstruct 3D scenes from multiple 2D images. So the paper is about improving MVS using a transformer with recurrent regularization.\n\nNow, looking at the options. Time-series usually involves data over time, like stock prices or sensor data. This paper is about 3D reconstruction from images, which is more spatial than temporal, so maybe not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The paper is about using multiple images (multi-view) but all from the same modality (images), so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't seem to be about building or using knowledge graphs, so that's probably out.\n\nSo the remaining options are none. Wait, but maybe I'm missing something. The term \"multi-view\" could be related to multimodal if each view is considered a different modality, but typically multi-view in computer vision refers to different perspectives of the same scene, not different data types. So I think the correct answer here is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32418@AAAI"},
{"title": "SCCS: Deep Neural Spectral Clustering for Self-Supervised Subcellular Structure Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SCCS: Deep Neural Spectral Clustering for Self-Supervised Subcellular Structure Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Deep Neural Spectral Clustering\" suggests they're using a neural network approach with spectral clustering. \"Self-Supervised\" indicates the model is trained without labeled data, which is a common technique in machine learning. \"Subcellular Structure Segmentation\" refers to segmenting parts of a cell, probably in images. \n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. Multimodal usually involves combining different types of data, like text and images. The paper is about segmentation in images, but the title doesn't mention combining multiple modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to generate answers. That's more about combining retrieval with generation, like in some NLP tasks. The title doesn't mention retrieval or generation, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of information. The paper is about segmentation using a neural network, which doesn't seem to involve building or using a knowledge graph. \n\nSo, none of the four topics seem to fit. The paper is about a deep learning method for image segmentation in a biological context. The key terms here are spectral clustering, self-supervised learning, and subcellular structures. None of the listed topics (time-series, multimodal, RAG, KG) are directly related to this. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32419@AAAI"},
{"title": "PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PixelMan: Consistent Object Editing with Diffusion Models via Pixel Manipulation and Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper here is about object editing using diffusion models, which are typically image-based. But the title doesn't mention combining different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate text, often in NLP tasks. The paper is about image editing with diffusion models, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on pixel manipulation and generation, not on structured data or knowledge representation. So KG is probably not it either.\n\nThe paper uses diffusion models for object editing, which is more related to computer vision and image generation. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32420@AAAI"}
{"title": "Restabilizing Diffusion Models with Predictive Noise Fusion Strategy for Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Restabilizing Diffusion Models with Predictive Noise Fusion Strategy for Image Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are diffusion models, predictive noise fusion, and image super-resolution. Diffusion models are a type of generative model used in image generation, right? They work by adding noise to data and then learning to reverse that process. Image super-resolution is about enhancing the resolution of images, so the model is probably generating higher-quality images from lower ones.\n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The title here is focused on image super-resolution using diffusion models, so unless they're combining multiple modalities, it's not multimodal. The title doesn't mention other data types, so maybe not.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information before generating a response. The title doesn't mention anything about retrieval or using external data sources, so RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of information. If the paper was about integrating knowledge graphs into the model, that would be the case. But the title doesn't mention knowledge graphs or structured data, so probably not KG.\n\nSo, the paper is about improving diffusion models for image super-resolution using a predictive noise fusion strategy. None of the four topics (time-series, multimodal, RAG, KG) seem to directly apply here. The main focus is on the diffusion model's stabilization and noise handling for image processing. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32421@AAAI"},
{"title": "LATTE: Improving Latex Recognition for Tables and Formulae with Iterative Refinement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LATTE: Improving Latex Recognition for Tables and Formulae with Iterative Refinement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about LaTeX recognition, which is more about document processing, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like text and images. The paper is about recognizing LaTeX in tables and formulae. If it's processing different modalities (e.g., images of equations and text), maybe multimodal. But the title doesn't explicitly mention combining different data types. It's about improving recognition through iterative refinement, which might be a method rather than the data type.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about LaTeX recognition, which doesn't seem related to building or using knowledge graphs.\n\nSo, the closest might be multimodal if the approach uses different data types (like images and text) for recognition. But the title doesn't specify that. Alternatively, maybe it's none of the above. The main focus is on improving LaTeX recognition through iterative refinement, which could be a method in natural language processing or computer vision, but none of the given topics directly fit. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32422@AAAI"},
{"title": "Move and Act: Enhanced Object Manipulation and Background Integrity for Image Editing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Move and Act: Enhanced Object Manipulation and Background Integrity for Image Editing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title here is about image editing, specifically object manipulation and background integrity. That doesn't seem to involve sequences over time, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about image editing, but the title doesn't mention combining different modalities. It's focused on manipulating objects within images, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically used in models that retrieve information from a database to enhance generation, like in question-answering systems. The title doesn't mention anything about retrieval or generation, so RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's focus is on image editing techniques, not on building or using knowledge graphs. So KG probably isn't it either.\n\nThe paper is about improving object manipulation in images while maintaining the background. This seems more related to computer vision tasks, like image processing or editing techniques. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32423@AAAI"},
{"title": "Energy-Guided Optimization for Personalized Image Editing with Pretrained Text-to-Image Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Energy-Guided Optimization for Personalized Image Editing with Pretrained Text-to-Image Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper mentions text-to-image diffusion models, which use both text (for the prompt) and images (for generating or editing). So that's a possibility. The \"personalized image editing\" part might involve using text to guide image changes, which is a multimodal approach.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text. The title doesn't mention anything about retrieving information or augmenting generation with retrieved data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about graphs or structured knowledge, so probably not KG.\n\nSo the most likely answer is multimodal because it's combining text and image data in a diffusion model for image editing. The energy-guided optimization part is a method, but the main data types involved are text and images, making it multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32424@AAAI"},
{"title": "Query Quantized Neural SLAM", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Query Quantized Neural SLAM\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"SLAM\" stands for Simultaneous Localization and Mapping. That's a common term in robotics and computer vision, where a robot or device builds a map of an unknown environment while keeping track of its location within that map. So SLAM is about spatial data, right?\n\nNow, \"Neural SLAM\" probably refers to using neural networks in the SLAM process. Then \"Query Quantized\" – quantized might relate to quantization, which is a method to reduce the precision of data, often used in machine learning to make models more efficient. But how does that tie into the topics given?\n\nLooking at the options: time-series deals with data over time, like stock prices or sensor data. Multimodal is about combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time-series data, so probably not that. It's about SLAM, which is more spatial. Multimodal could be a stretch unless they're combining different data types, but the title doesn't specify that. RAG and KG are more about information retrieval and knowledge representation. The term \"Query Quantized\" might relate to optimizing queries in a system, but I'm not sure how that connects to RAG or KG. \n\nSince none of the four topics directly relate to SLAM, neural networks, or quantization, I think the answer is \"none\". The paper is about a specific application in robotics or computer vision, which isn't covered by the given topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32425@AAAI"},
{"title": "Sensing Surface Patches in Volume Rendering for Inferring Signed Distance Functions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sensing Surface Patches in Volume Rendering for Inferring Signed Distance Functions.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title here is about volume rendering and surface patches, which sounds more like computer graphics or 3D data. Not sure if that's multimodal. Maybe if it's using different data sources, but the title doesn't specify that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, the title is about volume rendering and signed distance functions, which seems more related to 3D modeling or computer vision. Doesn't mention knowledge graphs.\n\nSo, none of the four topics seem to fit. The paper is about a technique in volume rendering to infer signed distance functions, which is more related to computer graphics or computational geometry. Since the options given don't include those areas, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32426@AAAI"},
{"title": "What Kind of Visual Tokens Do We Need? Training-Free Visual Token Pruning for Multi-Modal Large Language Models from the Perspective of Graph", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"What Kind of Visual Tokens Do We Need? Training-Free Visual Token Pruning for Multi-Modal Large Language Models from the Perspective of Graph\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Multi-Modal Large Language Models\". That immediately makes me think of multimodal, since multimodal refers to models that handle multiple types of data, like text and images. The paper is about visual tokens, which are part of the visual modality, so combining that with language models (text) would be multimodal.\n\nThen there's \"from the Perspective of Graph\". Graphs are related to Knowledge Graphs (KG), which are structured representations of information. But the paper is about pruning visual tokens using a graph perspective. Wait, maybe it's using graph structures to analyze or process the tokens, but does that make it a Knowledge Graph topic? Knowledge Graphs are more about representing entities and relationships. The graph here might be a different kind, like a computational graph or a graph neural network approach. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval systems to augment the generation process in models. The title doesn't mention retrieval or generation, so probably not RAG.\n\nTime-series is about data over time, which isn't mentioned here. The focus is on visual tokens and multimodal models. So the main topic here is multimodal. The graph part might be a method used within the multimodal context, but the primary category is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32427@AAAI"},
{"title": "Weighted Poisson-disk Resampling on Large-Scale Point Clouds", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Weighted Poisson-disk Resampling on Large-Scale Point Clouds.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. This title mentions point clouds, which are sets of data points in space, often used in 3D modeling or computer vision. So maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different data types, just point clouds. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't seem related to information retrieval or generation. \n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, the title is about resampling point clouds, which is more about data processing or geometry. \n\nSo none of the four topics seem to fit. The paper is about a resampling technique for point clouds, which is more related to computational geometry or computer graphics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32428@AAAI"},
{"title": "SpatioTemporal Learning for Human Pose Estimation in Sparsely-Labeled Videos", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SpatioTemporal Learning for Human Pose Estimation in Sparsely-Labeled Videos.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"SpatioTemporal Learning\" suggests that the model is dealing with both spatial and temporal aspects. Human pose estimation in videos would involve tracking body positions over time, which is a time-series aspect. But the term \"SpatioTemporal\" combines spatial (like the positions in each frame) and temporal (how those positions change over time). So time-series is a possibility here because of the temporal component.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which involve structured data and relationships. The paper's focus is on pose estimation in videos, which doesn't seem to involve building or using a knowledge graph. So KG is unlikely.\n\nSo the main candidates are time-series and multimodal. Since the paper is about learning over time (temporal) in videos, time-series makes sense. Even though it's sparsely labeled, the core of the problem is temporal data analysis. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32429@AAAI"},
{"title": "Optimizing Human Pose Estimation Through Focused Human and Joint Regions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Optimizing Human Pose Estimation Through Focused Human and Joint Regions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title is about human pose estimation, which is typically a computer vision task using images or videos. But the title doesn't mention combining different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents. The paper here is about optimizing pose estimation, which is a different area. Doesn't seem related to RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo the paper is about improving human pose estimation by focusing on specific regions (human and joints). This seems like a computer vision technique, maybe using attention mechanisms or region-based models. Since none of the given topics (time-series, multimodal, RAG, KG) fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32430@AAAI"}
{"title": "Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Visual Prompting Upgrades Neural Network Sparsification: A Data-Model Perspective.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual Prompting\" suggests something related to using visual elements as prompts, which might be part of multimodal learning since it combines different data types like images and text. Then \"Neural Network Sparsification\" refers to making neural networks more efficient by reducing the number of parameters or connections, which is a model optimization technique. The \"Data-Model Perspective\" part implies looking at both data and model aspects.\n\nNow, the four options. Time-series is about data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not that. Multimodal involves combining multiple data modalities, like text and images. Since \"Visual Prompting\" is mentioned, that could be part of multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, often in NLP. The title doesn't mention retrieval or generation. KG (Knowledge Graphs) are structured representations of knowledge, which also isn't mentioned here.\n\nSo, the key term is \"Visual Prompting,\" which is about using visual data as input, which is a modality. Combining that with neural networks might be part of multimodal research. The paper is about improving sparsification through visual prompting, which could be a method in multimodal models. Therefore, the topic is likely multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32431@AAAI"},
{"title": "Exploring More from Multiple Gait Modalities for Human Identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring More from Multiple Gait Modalities for Human Identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multiple Gait Modalities\" suggests that they're using more than one type of data or method related to gait (how someone walks). The term \"modalities\" here probably refers to different data sources or features, like video, audio, or other sensors. So \"multimodal\" comes to mind because that's about combining different types of data or modalities.\n\n\"Human Identification\" is the task, which is like biometric recognition. Now, the options are time-series, multimodal, RAG, or KG. Time-series would involve data over time, which gait could be, since walking is a sequence over time. But the key part here is \"multiple modalities,\" which directly points to multimodal. \n\nRAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in NLP. KG is Knowledge Graphs, which involve structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval-augmented methods. \n\nSo even though gait analysis could involve time-series data (since walking is a sequence), the main focus here is on using multiple modalities for identification. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32432@AAAI"},
{"title": "LogicAD: Explainable Anomaly Detection via VLM-based Text Feature Extraction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LogicAD: Explainable Anomaly Detection via VLM-based Text Feature Extraction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Anomaly detection is the main task here. The method uses VLM-based text feature extraction. VLM stands for Vision-Language Model, right? So that's combining vision and text, which makes me think of multimodal approaches. Multimodal typically involves using multiple types of data, like text and images together. Since VLMs are used for tasks that require understanding both visual and textual information, this seems like a multimodal technique.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. RAG is Retrieval-Augmented Generation, which is more about using retrieval to enhance generation models, often in NLP. The paper here is about anomaly detection using text features, but there's no mention of retrieval or generation. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't reference knowledge graphs either.\n\nSo the key here is the use of VLM, which is a multimodal model. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32433@AAAI"},
{"title": "Pedestrian Attribute Recognition: A New Benchmark Dataset and a Large Language Model Augmented Framework", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Pedestrian Attribute Recognition: A New Benchmark Dataset and a Large Language Model Augmented Framework.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, pedestrian attribute recognition. That sounds like computer vision, maybe image or video analysis. Attributes could be things like clothing, gender, age, etc. So, if they're using images or videos, that might involve multiple modalities, like combining visual data with other types. But the title mentions a \"Large Language Model Augmented Framework.\" Large language models are part of NLP, so combining that with computer vision would be multimodal. \n\nWait, the options are time-series, multimodal, RAG, KG. Time-series would be data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which uses external data retrieval. KG is Knowledge Graphs, which are structured data representations. \n\nThe paper introduces a new dataset and a framework using a large language model. If they're augmenting with a language model, maybe they're using text data alongside images. That would be multimodal. But the term \"augmented\" here might refer to using the LLM to enhance the model, which could be part of RAG if they're retrieving information. But RAG typically involves retrieving documents to inform the generation process. \n\nAlternatively, if the framework is combining different data types (like images and text), that's multimodal. The title doesn't mention time-series aspects. It's about attributes of pedestrians, which could be in images or videos, but the key here is the use of a large language model. If the LLM is being used to process text data along with visual data, then it's multimodal. \n\nSo, I think the answer is multimodal. The other options don't fit as well. Time-series isn't mentioned. RAG and KG are more specific and not directly indicated here. The combination of different data types (visual and text) points to multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32434@AAAI"},
{"title": "A Method for Enhancing Generalization of Adam by Multiple Integrations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Method for Enhancing Generalization of Adam by Multiple Integrations.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Adam is an optimization algorithm used in machine learning, right? So the paper is about improving Adam's generalization through multiple integrations. The key terms here are \"Adam,\" \"generalization,\" and \"multiple integrations.\" \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time-based data, so time-series is probably out. There's no indication of combining different data modalities, so multimodal might not fit. RAG and KG are more about specific techniques or structures. The paper is about improving an optimization algorithm's generalization. None of the four topics directly relate to optimization algorithms or generalization in this context. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32435@AAAI"},
{"title": "Constructing Fair Latent Space for Intersection of Fairness and Explainability", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Constructing Fair Latent Space for Intersection of Fairness and Explainability.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Fair latent space\" suggests something related to machine learning models, maybe in the context of fairness and explainability. The key terms here are fairness and explainability. The paper is about creating a latent space that's fair, which probably involves ensuring that the model's representations don't have biases and are interpretable.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. The title doesn't mention anything about time or sequential data, so probably not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nThe paper is focused on fairness and explainability in the latent space. These are more general machine learning topics, possibly related to model interpretability and ethical AI. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to fairness or explainability, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32436@AAAI"},
{"title": "Bridging the Semantic Granularity Gap Between Text and Frame Representations for Partially Relevant Video Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bridging the Semantic Granularity Gap Between Text and Frame Representations for Partially Relevant Video Retrieval.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The key parts are \"Semantic Granularity Gap,\" \"Text and Frame Representations,\" and \"Partially Relevant Video Retrieval.\" \n\n\"Text and Frame Representations\" suggests that the paper is dealing with both textual data and visual frames (like images or video frames). That immediately makes me think of multimodal learning because multimodal typically involves combining different types of data, such as text and images or video. \n\nThe phrase \"Bridging the Semantic Gap\" is common in multimodal research where the goal is to align different modalities in a shared semantic space. For example, in tasks like image captioning or video retrieval, you need to match text descriptions with visual content. \n\nTime-series usually refers to data that is sequential over time, like stock prices or sensor data. While video does involve a sequence of frames over time, the main focus here seems to be on the combination of text and visual data rather than the temporal aspect. So time-series might not be the best fit unless the paper specifically focuses on temporal modeling, which the title doesn't indicate.\n\nRAG (Retrieval-Augmented Generation) is a method that combines retrieval from a database with generation, often used in NLP tasks. The title mentions \"Video Retrieval,\" but the key part here is \"Partially Relevant,\" which might imply that the retrieval is not exact. However, RAG typically involves generating answers using retrieved information, whereas this seems more about aligning text and video representations for retrieval. So maybe not RAG.\n\nKG (Knowledge Graphs) involve structured data and relationships between entities. The title doesn't mention anything about structured knowledge or graphs, so that's probably not it.\n\nPutting it all together, the main elements are combining text and video (frames) for retrieval, which is a classic multimodal problem. The semantic gap bridging is a common challenge in multimodal tasks. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32437@AAAI"},
{"title": "Event-Enhanced Blurry Video Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Event-Enhanced Blurry Video Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Event-Enhanced\" suggests that events are being used to improve something. \"Blurry Video Super-Resolution\" refers to enhancing the resolution of blurry videos. So the main focus is on improving video quality using events.\n\nNow, the possible topics. Time-series usually involves data over time, like sequences. Multimodal combines different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to generate responses. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about video super-resolution. Video is a time-series of frames, but the key here is \"event-enhanced.\" Events could be from event cameras, which capture changes in brightness over time, providing temporal information. So using event data (which is time-based) to enhance video resolution might involve time-series data. However, if the events are from a different modality (like event streams vs. RGB frames), it could be multimodal. But the term \"event-enhanced\" might refer to integrating event data with video frames, which are different data types. Wait, event cameras produce a different kind of data (events) compared to traditional video frames. So combining these two modalities (events and video) would be multimodal. But maybe the focus is on the temporal aspect of events. Hmm. Alternatively, if the method uses the temporal sequence of events to improve resolution, that's time-series. But I'm not sure. Let me think again. Super-resolution for video typically involves temporal information between frames, so time-series could be a fit. However, if the events are a separate modality (like from an event camera), then it's multimodal. The title says \"event-enhanced,\" which might imply using event data as an additional input modality to the video. So combining two modalities (events and video) would make it multimodal. Therefore, the answer might be multimodal. Alternatively, if the events are part of the time-series data, maybe time-series. But I'm leaning towards multimodal because it's integrating different data types (events and video frames). So the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32438@AAAI"},
{"title": "NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional Generalization.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Neuro-Symbolic\" suggests a combination of neural networks (neuro) and symbolic AI. \"Concept Composer\" implies building or combining concepts. \"Compositional Generalization\" refers to the ability to generalize by combining known concepts in new ways. \n\nNow, looking at the options. Time-series research deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. KG (Knowledge Graphs) are structured representations of knowledge, often using graphs to link entities.\n\nThe paper's focus is on compositional generalization using a neuro-symbolic approach. That sounds more like combining symbolic reasoning (which is related to knowledge representation) with neural networks. Knowledge Graphs (KG) are a form of structured knowledge, so maybe this is related. However, the term \"neuro-symbolic\" is a blend of neural and symbolic methods, which might be used in various contexts. \n\nBut compositional generalization is a concept often discussed in machine learning, especially in areas where models need to combine learned concepts. However, the specific mention of \"concept composer\" might relate to building structured knowledge, which could tie into Knowledge Graphs. Alternatively, if it's about combining different modalities (like text and images), it would be multimodal. But the title doesn't mention different data types. \n\nRAG is about retrieval and generation, which doesn't seem to fit here. Time-series is unrelated. So between multimodal and KG. Since the title doesn't mention multiple data modalities, and the focus is on composing concepts symbolically, I think it's more aligned with Knowledge Graphs (KG). But wait, neuro-symbolic approaches can also be part of other areas. However, given the options, KG seems the closest fit. Alternatively, maybe it's none of them. But the user wants to check if it's one of the four. \n\nWait, another angle: compositional generalization is a problem in NLP and machine learning, but the neuro-symbolic aspect might be a method. If the paper is about creating a system that composes concepts symbolically, that's more about knowledge representation, which is part of KG. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32439@AAAI"},
{"title": "Exploring Enhanced Contextual Information for Video-Level Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring Enhanced Contextual Information for Video-Level Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. But the title is about video-level object tracking. Videos are sequences of frames over time, so maybe time-series? But object tracking in videos is more about tracking objects across frames, which is a sequence, but does that make it a time-series topic? Maybe, but I'm not sure if the paper is specifically about time-series analysis or something else.\n\nMultimodal refers to combining multiple data types, like text and images. The title mentions \"contextual information,\" but does it involve multiple modalities? The paper is about video, which is a combination of visual and possibly audio, but the title doesn't explicitly mention multiple modalities. It's focused on enhancing contextual info for tracking, which might be within a single modality (video frames).\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nSo, the options are time-series or multimodal. Since the paper is about video tracking, which is a sequence of frames over time, maybe time-series. But object tracking in videos is a common computer vision task, often considered under video analysis. However, the key here is whether the research topic is classified as time-series. Time-series analysis is more about statistical analysis of time-ordered data. If the paper is about improving tracking by considering temporal context, maybe it's time-series. But I'm not certain. Alternatively, if the enhanced contextual information involves multiple modalities (like combining visual and audio), then it would be multimodal. But the title doesn't specify that. The term \"contextual information\" could be referring to spatial or temporal context within the video itself. Without more details, it's a bit tricky. But given the options, I think the best fit is time-series because video tracking involves temporal sequences. However, I'm not 100% sure. Alternatively, if the paper is about integrating different data sources (like combining video with other sensors), then multimodal. But the title doesn't mention that. So I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32440@AAAI"}
{"title": "CodecNeRF: Toward Fast Encoding and Decoding, Compact, and High-quality Novel-view Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CodecNeRF: Toward Fast Encoding and Decoding, Compact, and High-quality Novel-view Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"NeRF\" stands for Neural Radiance Fields, which I know is a method for 3D scene reconstruction and novel view synthesis. So the paper is about improving NeRF, making it faster, more compact, and higher quality. \n\nNow, the options are time-series, multimodal, RAG, or KG. Time-series usually involves data over time, like stock prices or sensor data. This paper doesn't mention anything about time-based data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so maybe not that either.\n\nRAG is Retrieval-Augmented Generation, which is used in models like those that combine retrieval with generation for tasks like question answering. The paper's focus is on encoding/decoding and novel views, which doesn't seem related to retrieval or generation in that context.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, none of the four topics seem to fit. The paper is about improving NeRF for novel view synthesis, which is more related to computer vision and 3D reconstruction, not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32441@AAAI"},
{"title": "C2PD: Continuity-Constrained Pixelwise Deformation for Guided Depth Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"C2PD: Continuity-Constrained Pixelwise Deformation for Guided Depth Super-Resolution.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Guided Depth Super-Resolution\" suggests that the paper is about enhancing the resolution of depth images, probably using some guidance. The method mentioned is \"Continuity-Constrained Pixelwise Deformation,\" which sounds like a technique to deform pixels in a way that maintains continuity, maybe to improve the depth map's quality.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data over time. This doesn't seem to fit because the title is about image processing, specifically depth maps, which are spatial rather than temporal.\n\nMultimodal refers to combining different types of data, like text and images. The title mentions \"guided\" which might imply using another modality (like RGB images) to guide the depth super-resolution. If that's the case, it could be multimodal. But I need to check if the guidance is from another modality. The term \"guided\" here might mean using a higher-resolution image or some other data to guide the deformation process. If the guidance is from another modality (e.g., RGB image), then it's multimodal. But if the guidance is within the same modality (like using a low-res depth image to generate a high-res one), then it's not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to augment its generation. This doesn't seem related to image super-resolution.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data, so probably not KG.\n\nSo the main contenders are multimodal and maybe none. If the guided depth super-resolution uses another modality (like RGB images) to guide the process, then it's multimodal. The term \"guided\" in this context is common in multimodal tasks where one modality (e.g., RGB) is used to enhance another (depth). For example, using RGB images to guide the super-resolution of depth maps. Therefore, this paper likely falls under the multimodal topic.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32442@AAAI"},
{"title": "DiffusionREC: Diffusion Model with Adaptive Condition for Referring Expression Comprehension", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffusionREC: Diffusion Model with Adaptive Condition for Referring Expression Comprehension.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Diffusion Model\" suggests it's using a type of generative model, maybe similar to diffusion processes in machine learning. \"Adaptive Condition\" might refer to adjusting conditions during the model's operation. \"Referring Expression Comprehension\" (REC) is a task in NLP where the model identifies an object in an image based on a textual description. So, this seems like a problem that involves both text and images, which are different modalities. \n\nMultimodal research deals with integrating multiple data types, like text and images. Since REC requires understanding both a referring expression (text) and an image, this would fall under multimodal. The other options: time-series is about sequential data over time, which doesn't fit here. RAG (Retrieval-Augmented Generation) involves using retrieval mechanisms to enhance generation, but the title doesn't mention retrieval. KG (Knowledge Graphs) are structured data representations, which also don't seem relevant here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32443@AAAI"},
{"title": "Learning to Prompt with Text Only Supervision for Vision-Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning to Prompt with Text Only Supervision for Vision-Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Learning to Prompt\" suggests some kind of prompting method, maybe in machine learning. \"Text Only Supervision\" means the model is trained using only text data, not images or other modalities. But the target is \"Vision-Language Models,\" which are models that handle both visual and textual information. So, the model is being trained with text-only data but is intended to work with both vision and language. \n\nMultimodal refers to models that process multiple types of data, like text and images. Since Vision-Language Models are inherently multimodal (they combine vision and language), this seems like a fit. The paper is about training such models using only text supervision, which is a common challenge in multimodal learning where you might not have paired data. \n\nTime-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) involves using retrieval mechanisms to enhance generation, but the title doesn't mention retrieval. KG (Knowledge Graphs) are structured data representations, which also aren't mentioned. \n\nSo the most likely topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32444@AAAI"},
{"title": "PLATYPUS: Progressive Local Surface Estimator for Arbitrary-Scale Point Cloud Upsampling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PLATYPUS: Progressive Local Surface Estimator for Arbitrary-Scale Point Cloud Upsampling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on point cloud upsampling. Point clouds are sets of data points in space, often used in 3D modeling or computer vision. Upsampling means increasing the number of points, making the cloud denser. The method is called a \"Progressive Local Surface Estimator,\" which suggests it's a technique for estimating surfaces locally and progressively.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or sensor data. This doesn't seem related to time-series since the title is about point clouds, which are spatial data, not temporal.\n\nMultimodal refers to combining multiple data types, like text and images. The paper's title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on point cloud processing, not on building or using knowledge graphs. So KG is probably not the right fit.\n\nSince none of the four topics (time-series, multimodal, RAG, KG) are clearly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32445@AAAI"},
{"title": "Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Generalized Zero-Shot Learning\" refers to a machine learning approach where the model can recognize classes not seen during training. \"Point Cloud Segmentation\" is about processing 3D data, like from LiDAR, to segment objects. \"Evidence-Based Dynamic Calibration\" suggests some method for adjusting the model's predictions based on evidence, maybe uncertainty or confidence.\n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation, like in some NLP tasks. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on point cloud data, which is a type of 3D data. Segmentation here is a computer vision task. The mention of zero-shot learning and dynamic calibration doesn't immediately point to any of the four topics. Time-series doesn't fit because it's about 3D data, not sequences over time. Multimodal would require combining different modalities, but the title doesn't mention that. RAG and KG are more about information retrieval or structured knowledge, which isn't the focus here. The paper seems to be about improving segmentation models with a specific learning approach, but none of the four topics directly apply. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32446@AAAI"},
{"title": "APR-RD: Complemental Two Steps for Self-Supervised Real Image Denoising", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"APR-RD: Complemental Two Steps for Self-Supervised Real Image Denoising.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Real Image Denoising\" suggests it's about removing noise from images. The method is called APR-RD, which probably stands for something related to the process. The key terms here are \"Self-Supervised\" and \"Real Image Denoising.\" \n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't seem to fit because the focus is on images, not sequences over time. \n\nMultimodal research deals with combining different types of data, like text and images. The title doesn't mention anything about combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses. That's more about text generation with external knowledge. The paper here is about image denoising, so RAG doesn't seem relevant.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, the paper is about image denoising using a self-supervised approach. None of the given topics (time-series, multimodal, RAG, KG) directly relate to image denoising. The closest might be multimodal if it involved multiple data types, but since it's just images, it's not. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32447@AAAI"},
{"title": "Prediction-Feedback DETR for Temporal Action Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Prediction-Feedback DETR for Temporal Action Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Action Detection\" suggests something related to time, like sequences or time-based data. DETR is a model, probably a variant of the Transformer-based model used in computer vision, like for object detection. The term \"Prediction-Feedback\" might refer to a mechanism where predictions are used to refine the model's output over time.\n\nTime-series analysis deals with data points indexed in time order. Temporal action detection sounds like identifying actions in a video over time, which is a time-series problem. So maybe it's time-series. \n\nMultimodal would involve combining different data types, like text and images, but the title doesn't mention that. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about knowledge graphs or retrieval. \n\nSo the most likely topic here is time-series. The focus on temporal aspects in action detection aligns with time-series analysis.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32448@AAAI"},
{"title": "DEEPTalk: Dynamic Emotion Embedding for Probabilistic Speech-Driven 3D Face Animation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DEEPTalk: Dynamic Emotion Embedding for Probabilistic Speech-Driven 3D Face Animation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dynamic Emotion Embedding\" suggests that emotions are being modeled in some way, possibly over time. \"Probabilistic Speech-Driven\" implies that speech is the input, and there's a probabilistic model involved. \"3D Face Animation\" is the output, so it's about generating facial animations based on speech.\n\nTime-series usually involves data that changes over time, like stock prices or sensor data. This paper might involve time-series if the speech input is processed as a sequence over time. But the main focus here seems to be on emotion and animation, not just time-based data analysis.\n\nMultimodal refers to combining multiple types of data, like text, audio, and video. Here, the input is speech (audio) and the output is a 3D face animation (visual), so it's combining audio and visual data. That fits the multimodal category.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, often in NLP. The title doesn't mention anything about retrieving information or using a knowledge base for generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships between entities. The paper doesn't mention knowledge graphs or structured data, so that's out.\n\nSo the most likely topic is multimodal because it's combining speech (audio) and 3D face animation (visual) data. The dynamic emotion embedding might involve time aspects, but the primary classification here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32449@AAAI"},
{"title": "ProtoOcc: Accurate, Efficient 3D Occupancy Prediction Using Dual Branch Encoder-Prototype Query Decoder", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ProtoOcc: Accurate, Efficient 3D Occupancy Prediction Using Dual Branch Encoder-Prototype Query Decoder.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. The title mentions 3D occupancy prediction, which sounds more like spatial data, maybe for robotics or autonomous vehicles. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention different data modalities, just a 3D occupancy prediction method. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo the answer is \"none\" because the paper's topic doesn't fit any of the given categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32450@AAAI"}
{"title": "HiCM²: Hierarchical Compact Memory Modeling for Dense Video Captioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HiCM²: Hierarchical Compact Memory Modeling for Dense Video Captioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Hierarchical Compact Memory Modeling\" suggests some kind of memory structure, maybe for processing sequences. \"Dense Video Captioning\" implies that the paper is about generating captions for videos, which are sequences of frames over time. So video data is involved, which is a time-series because videos are sequences over time. But wait, video is also multimodal since it combines visual (frames) and possibly audio elements. However, the main focus here is on the modeling approach for dense captioning, which is about generating captions at multiple points in the video. \n\nThe term \"Hierarchical Compact Memory\" might relate to how the model processes temporal information. Time-series analysis often involves models that handle sequences, like RNNs, LSTMs, or transformers. But the title doesn't mention any specific time-series techniques like forecasting or anomaly detection. Instead, it's about memory modeling for video captioning. \n\nMultimodal would involve combining different types of data, like text and images or video and audio. Since the paper is about video captioning, which typically uses both visual and temporal information, maybe multimodal is a fit. But the key here is the hierarchical memory structure. However, the problem itself is about video, which is a time-series of images. \n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to aid in generation. The title doesn't mention retrieval, so probably not RAG. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem to be the case here. \n\nSo, the main aspects are video (time-series of frames) and the hierarchical memory model. Since the task is dense video captioning, which is a time-series problem (processing sequences of video frames over time), the topic would be time-series. However, video is inherently multimodal (visual + temporal), but the primary research focus here is on the modeling approach for the temporal aspect. The term \"dense\" suggests that captions are generated at multiple time points, which is a time-series aspect. \n\nBut wait, multimodal could also be a consideration if the model is integrating different modalities. However, the title doesn't explicitly mention multimodal. The key terms are \"hierarchical memory\" and \"dense video captioning.\" Since video is a time-series, and the problem is about modeling the sequence, I think the correct topic is time-series. Alternatively, if the model is combining different modalities (like visual and audio), it would be multimodal. But the title doesn't specify that. The focus is on the memory modeling for the video, which is a time-series. So I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32451@AAAI"},
{"title": "MoDiTalker: Motion-Disentangled Diffusion Model for High-Fidelity Talking Head Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MoDiTalker: Motion-Disentangled Diffusion Model for High-Fidelity Talking Head Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Motion-Disentangled Diffusion Model\" suggests they're using a diffusion model, which is a type of generative model. The term \"Motion-Disentangled\" might mean they're separating motion aspects from other features. \"Talking Head Generation\" implies creating realistic talking heads, which could involve video or animation where a person's head is generated with speech.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about generating talking heads, which likely involves video (visual) and audio (speech), so that's combining different modalities. The term \"diffusion model\" is a generative model, but the key here is whether it's multimodal. Since talking heads would need to integrate visual and audio elements, this seems like a multimodal task. The motion disentanglement part might be about separating different aspects of the motion, but the main focus is on generating a talking head, which is a combination of visual and audio data. So the topic would be multimodal. Time-series might be involved in the temporal aspect of the video, but the primary classification here is multimodal because it's combining different data types. RAG and KG don't seem relevant here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32452@AAAI"},
{"title": "TSDF-Based Efficient Motion-Compensated Temporal Interpolation for 3D Dynamic Sequences", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TSDF-Based Efficient Motion-Compensated Temporal Interpolation for 3D Dynamic Sequences.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. TSDF probably stands for Truncated Signed Distance Function. That's often used in 3D reconstruction and computer vision. Then \"Efficient Motion-Compensated Temporal Interpolation\" suggests they're dealing with time-based data, trying to interpolate between frames, considering motion. \"3D Dynamic Sequences\" implies sequences over time, so time-series data. \n\nTime-series analysis involves data points indexed in time order. Since the paper is about temporal interpolation for dynamic sequences, that's a strong indicator of time-series. The other options: multimodal would involve multiple data types (like text and images), RAG is Retrieval-Augmented Generation, and KG is Knowledge Graphs. None of those seem to fit here. The focus is on temporal data processing, so the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32453@AAAI"},
{"title": "ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image Captioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"ViPCap\" is probably the name of the method or model. \"Retrieval Text-Based Visual Prompts\" suggests that they're using some kind of retrieval mechanism where text is used to get visual prompts. \"Lightweight Image Captioning\" means the goal is to generate captions for images in a computationally efficient way.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This doesn't seem related to time-based data. Multimodal refers to combining different data types, like text and images. The paper mentions both text (retrieval text-based) and visual prompts (images), so that's a strong indicator. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and then generates a response. The title does mention \"retrieval,\" so maybe RAG is a possibility. However, RAG typically involves using retrieved documents to enhance the generation process, often in text-to-text scenarios. Here, the retrieval is for visual prompts, which might be part of a multimodal approach rather than a pure RAG setup.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about structured data or knowledge graphs, so probably not KG.\n\nSo, the main contenders are multimodal and RAG. The key here is that the paper is combining text and visual data (retrieval text-based for visual prompts) to create image captions. That's a classic multimodal task. Even though there's a retrieval component, the primary focus is on integrating different modalities (text and image) for captioning. RAG is more about using retrieved information to augment generation, which might be a part of the process here, but the core of the research is the multimodal aspect. Therefore, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32454@AAAI"},
{"title": "Multi-Modal Grounded Planning and Efficient Replanning for Learning Embodied Agents with a Few Examples", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Modal Grounded Planning and Efficient Replanning for Learning Embodied Agents with a Few Examples.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That immediately makes me think the topic is multimodal. But I should check the rest to be sure. The paper is about planning and replanning for embodied agents, which are agents that interact with the environment, probably using different types of data. The term \"grounded\" might refer to using real-world data or integrating different modalities. \n\nNow, the other options. Time-series usually involves data over time, like sequences. The title doesn't mention time or sequences explicitly. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which isn't mentioned here. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't seem to be the focus. \n\nThe key term here is \"Multi-Modal,\" which directly corresponds to the multimodal topic. Even though the paper is about planning, the multimodal aspect is a core part of the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32455@AAAI"},
{"title": "DiffuseHigh: Training-Free Progressive High-Resolution Image Synthesis Through Structure Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffuseHigh: Training-Free Progressive High-Resolution Image Synthesis Through Structure Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"DiffuseHigh\" probably refers to a method or model name. \"Training-Free\" suggests that it doesn't require training, maybe using pre-trained models or some other approach. \"Progressive High-Resolution Image Synthesis\" indicates that it's about generating high-resolution images, possibly step by step. \"Structure Guidance\" might mean using structural information to guide the synthesis process.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which uses retrieval to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about image synthesis, specifically high-resolution and using structure guidance. None of the topics directly relate to time-series. Multimodal could be a stretch if it's combining different modalities, but the title doesn't mention that. RAG and KG are more about text generation with retrieval or knowledge graphs. Since the focus is on image synthesis without training, and none of the listed topics fit, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32456@AAAI"},
{"title": "SatCLIP: Global, General-Purpose Location Embeddings with Satellite Imagery", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SatCLIP: Global, General-Purpose Location Embeddings with Satellite Imagery.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"SatCLIP\" probably refers to a model or method related to satellite imagery. \"Global, General-Purpose Location Embeddings\" suggests they're creating embeddings for locations, which could be used for various tasks. The key part here is \"Satellite Imagery,\" which is a type of data. \n\nNow, the four options. Time-series usually involves data over time, like stock prices or weather data. Multimodal refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper uses satellite imagery, which is a visual modality. If they're combining satellite images with another modality, like text, then it would be multimodal. The title mentions \"Location Embeddings,\" which might involve combining different data types. For example, if they're using both satellite images and textual information about locations, that's multimodal. \n\nRAG and KG don't seem to fit here. RAG is more about retrieval during generation, and KG is about structured knowledge. Time-series would require temporal data, but the title doesn't mention time. \n\nSo, the most likely answer is multimodal because they're using satellite imagery (a modality) to create embeddings, possibly combining it with other data types. The term \"embeddings\" often comes up in multimodal contexts where different modalities are encoded together. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32457@AAAI"},
{"title": "Sequence Matters: Harnessing Video Models in 3D Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sequence Matters: Harnessing Video Models in 3D Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Sequence Matters\" suggests that the order or sequence of data is important. \"Harnessing Video Models\" implies using models designed for video, which is a sequence of frames over time. \"3D Super-Resolution\" refers to enhancing the resolution of 3D images or videos. \n\nTime-series analysis deals with data points indexed in time order. Since video is a sequence of frames over time, that's a time-series aspect. The paper is using video models, which process sequences, so time-series seems relevant here. \n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention multiple modalities, so maybe not. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation tasks, which doesn't seem to fit. KG (Knowledge Graphs) involve structured data representations, which also doesn't appear here. \n\nSo the most likely topic is time-series because the focus is on video sequences and their temporal aspects in super-resolution.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32458@AAAI"},
{"title": "UniDet3D: Multi-dataset Indoor 3D Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UniDet3D: Multi-dataset Indoor 3D Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or weather data. The title mentions 3D object detection, which is more about spatial data, so probably not time-series.\n\nNext, multimodal refers to using multiple types of data, like combining text and images. The title says \"Multi-dataset,\" which might mean using data from different sources or formats. But \"multi-dataset\" could just mean training on multiple datasets, not necessarily different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses. This seems unrelated to 3D object detection.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's title doesn't mention anything about knowledge graphs or structured data, so probably not KG.\n\nSo the options left are none. The paper is about 3D object detection using multiple datasets, which doesn't fit into the given categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32459@AAAI"},
{"title": "Efficient Gaussian Splatting for Monocular Dynamic Scene Rendering via Sparse Time-Variant Attribute Modeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Efficient Gaussian Splatting for Monocular Dynamic Scene Rendering via Sparse Time-Variant Attribute Modeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Gaussian Splatting\" is a technique used in computer graphics for rendering. \"Monocular Dynamic Scene Rendering\" suggests using a single camera (monocular) to render dynamic scenes. The key part here might be \"Sparse Time-Variant Attribute Modeling.\" The term \"Time-Variant\" directly relates to time, so that's a hint. Time-series analysis deals with data points indexed in time order. So if the paper is modeling attributes that change over time, that's time-series. \n\nMultimodal would involve combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe title doesn't mention anything about combining different data modalities, so probably not multimodal. It's about rendering dynamic scenes, which involves time, so time-series seems likely. The \"Time-Variant\" part is a strong indicator. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32460@AAAI"}
{"title": "Do Not DeepFake Me: Privacy-Preserving Neural 3D Head Reconstruction Without Sensitive Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Do Not DeepFake Me: Privacy-Preserving Neural 3D Head Reconstruction Without Sensitive Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on 3D head reconstruction using neural networks, with an emphasis on privacy and avoiding sensitive images. The term \"DeepFake\" is mentioned, which is related to generating realistic fake videos or images, often using AI. The paper is about preventing that by making the reconstruction process privacy-preserving.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or sensor data. This paper doesn't mention anything about time-based data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The title mentions 3D head reconstruction, which might involve images or video, but there's no indication of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation models, often used in NLP tasks. The paper is about reconstruction, not generating text based on retrieved data, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper doesn't mention anything about building or using knowledge graphs, so that's probably out.\n\nThe paper is focused on a specific AI application in 3D reconstruction with privacy considerations. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The main areas here are computer vision and privacy in AI, which aren't among the given options. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32461@AAAI"},
{"title": "Real-Time Neural Denoising with Render-Aware Knowledge Distillation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Real-Time Neural Denoising with Render-Aware Knowledge Distillation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Neural Denoising\" suggests some kind of neural network used for removing noise, maybe in images or signals. \"Real-Time\" implies it's optimized for speed, which is common in applications like video processing. \"Render-Aware\" might relate to how the model considers rendering processes, perhaps in computer graphics or 3D rendering. \"Knowledge Distillation\" is a technique where a smaller model is trained using a larger, more complex model's outputs. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance model outputs, often in NLP. KG (Knowledge Graph) involves structured data representations, like relationships between entities.\n\nThe paper's focus seems to be on denoising, which is often in image or signal processing. Knowledge distillation is a method, not a topic category. Render-aware might relate to computer graphics, but none of the given topics directly match that. The key here is whether any of the four topics are relevant. Since the title doesn't mention time-series data, multimodal inputs, RAG, or knowledge graphs, it doesn't fit into any of the specified categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32462@AAAI"},
{"title": "MHBench: Demystifying Motion Hallucination in VideoLLMs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MHBench: Demystifying Motion Hallucination in VideoLLMs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Motion Hallucination\" probably refers to errors or artifacts in motion within videos. \"VideoLLMs\" would be large language models applied to video data. So the paper is about understanding or addressing motion hallucinations in video-based language models.\n\nNow, the four options. Time-series typically involves data over time, like stock prices or sensor data. Multimodal refers to models that handle multiple types of data, like text and images or video. RAG is Retrieval-Augmented Generation, which uses external data retrieval during generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about video data, which is a combination of visual and temporal information. VideoLLMs likely process both visual and textual data, making them multimodal. The focus on motion in videos suggests handling both spatial and temporal aspects, which is common in multimodal models. Since the problem is about hallucinations in video understanding, it's about how the model integrates different modalities (like video frames and text) correctly. So this seems to fit under multimodal. Time-series could be a part of it, but the key here is the combination of different data types (video and text), so multimodal is more accurate. RAG and KG don't seem relevant here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32463@AAAI"},
{"title": "COLUMBUS: Evaluating COgnitive Lateral Understanding Through Multiple-Choice reBUSes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"COLUMBUS: Evaluating COgnitive Lateral Understanding Through Multiple-Choice reBUSes.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"COLUMBUS\" is the acronym, probably standing for something related to cognitive lateral understanding. The key parts here are \"Cognitive Lateral Understanding\" and \"Multiple-Choice reBUSes.\" \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title mentions \"Multiple-Choice,\" which could be a type of question format, but there's no indication of combining different modalities. Unless \"reBUSes\" is a term I'm not familiar with, but I don't think so. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate answers. The title talks about evaluating understanding through multiple-choice questions. If it's about how well a model can retrieve and use information to answer questions, that might fit RAG. But the title doesn't explicitly mention retrieval or generation. It's more about cognitive understanding, which could be a different aspect.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper is about building or using a knowledge graph to enhance understanding, that might be it. But again, the title doesn't mention graphs or structured data.\n\nThe term \"Cognitive Lateral Understanding\" sounds like it's about how models understand or process information in a way that's lateral, maybe reasoning or problem-solving. The \"Multiple-Choice reBUSes\" part is a bit unclear. \"reBUS\" might be a typo or a specific term. If it's related to reasoning or problem-solving tasks, maybe it's testing the model's ability to answer multiple-choice questions, which could relate to RAG if it's about retrieving information to answer. But without more context, it's hard to say.\n\nSince the title doesn't clearly mention time-series data, multiple modalities, retrieval-augmented generation, or knowledge graphs, it might not fit any of the given topics. The focus seems to be on evaluating cognitive understanding through multiple-choice questions, which could be a different area like NLP evaluation or reasoning tasks. Therefore, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32464@AAAI"},
{"title": "Stable Mean Teacher for Semi-supervised Video Action Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Stable Mean Teacher for Semi-supervised Video Action Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Semi-supervised\" suggests that the method uses both labeled and unlabeled data, which is a common approach in machine learning. \"Video Action Detection\" implies that the task is about identifying actions in videos. Videos are sequences of frames over time, so that might relate to time-series data. But wait, time-series usually refers to data points indexed in time order, like stock prices or sensor data. Video is a form of time-series, but maybe the key here is whether the paper specifically addresses time-series analysis techniques.\n\n\"Mean Teacher\" is a method used in semi-supervised learning where a model's predictions are averaged over time to create a more stable target. The \"Stable\" part might refer to making the Mean Teacher approach more robust. \n\nNow, looking at the possible topics. Time-series would involve temporal data analysis. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about video action detection, which involves processing video data (a sequence over time) but the main focus here is on the semi-supervised learning method using Mean Teacher. The key term is \"Mean Teacher,\" which is a technique in semi-supervised learning. However, none of the four topics directly relate to semi-supervised learning methods. Time-series is about temporal data, but the paper's main contribution is the method, not the data type. Since the paper doesn't mention multimodal data (combining different modalities like text and video), RAG, or KG, it doesn't fit those. The closest might be time-series if video is considered a time-series, but the primary focus is on the learning approach rather than the temporal aspect. Since none of the four topics exactly match the focus of the paper, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32465@AAAI"},
{"title": "A Unified Degradation-Robust Approach to SSL and UDA for 3D Medical Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Unified Degradation-Robust Approach to SSL and UDA for 3D Medical Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. SSL stands for Semi-Supervised Learning, and UDA is Unsupervised Domain Adaptation. The focus is on 3D medical images. The key terms here are degradation-robust, SSL, UDA, and 3D medical images. \n\nTime-series usually involves data points indexed in time order, like stock prices over time or sensor data over time. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions 3D medical images, but there's no indication of combining different modalities (e.g., text, images, audio). So maybe not multimodal.\n\nRAG is Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on SSL and UDA for 3D images, not on building or using knowledge graphs. So KG is probably not it.\n\nThe paper is about making SSL and UDA robust to degradation in 3D medical images. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The main areas here are SSL, UDA, and 3D medical imaging, which don't fall under the given categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32466@AAAI"},
{"title": "SAFIRE: Segment Any Forged Image Region", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SAFIRE: Segment Any Forged Image Region.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. The title doesn't mention anything about time, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title is about segmenting forged image regions, which is image processing. But does it combine different modalities? The title doesn't specify, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate a response. The title is about image segmentation, not retrieval or generation. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data. \n\nSo the task is image segmentation for forged regions. None of the given topics (time-series, multimodal, RAG, KG) seem to fit. The paper is about image processing, specifically forgery detection, which isn't listed in the options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32467@AAAI"},
{"title": "Mind the Uncertainty in Human Disagreement: Evaluating Discrepancies Between Model Predictions and Human Responses in VQA", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Mind the Uncertainty in Human Disagreement: Evaluating Discrepancies Between Model Predictions and Human Responses in VQA.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, VQA stands for Visual Question Answering. That's a task where a model has to answer questions about images, right? So it involves both visual data and textual questions. That makes me think it's multimodal because it combines different types of data (images and text). \n\nNow, the main focus here is on discrepancies between model predictions and human responses. The paper is evaluating how models and humans differ in their answers. But does that relate to any of the specific topics listed? Let's break down the options:\n\n- Time-series: That's about data over time, like stock prices or weather. The title doesn't mention anything about time, so probably not.\n- Multimodal: Since VQA uses both images and text, this seems likely. The model is processing multiple modalities, so the research could be about how to handle that, or evaluate discrepancies in multimodal tasks.\n- RAG (Retrieval-Augmented Generation): That's when a model uses retrieved information to generate answers. The title doesn't mention retrieval or using external data sources, so maybe not RAG.\n- KG (Knowledge Graphs): These are structured representations of knowledge. The paper doesn't mention building or using a knowledge graph, so probably not KG.\n\nThe key here is the multimodal aspect of VQA. The paper is about evaluating discrepancies in a task that inherently uses multiple modalities. So the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32468@AAAI"},
{"title": "Exploiting Diffusion Prior for Real-World Image Dehazing with Unpaired Training", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploiting Diffusion Prior for Real-World Image Dehazing with Unpaired Training.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. The title here is about image dehazing, which is an image processing task, so time-series doesn't seem relevant.\n\nMultimodal refers to combining different types of data, like text and images. The paper's title doesn't mention anything about combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically used in models that combine retrieval of information with generating responses, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image dehazing using a diffusion prior, which is a technique in generative models. There's no mention of knowledge graphs here.\n\nSo, the paper is about using a diffusion model for image dehazing. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The techniques used might be in computer vision or generative models, but the specified options don't include those. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32469@AAAI"},
{"title": "Color Transfer with Modulated Flows", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Color Transfer with Modulated Flows.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. Color transfer is about modifying the color of images, maybe transferring color from one image to another. That sounds like it's working with images, which is a single modality. Unless there's another modality involved, but the title doesn't specify. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically in NLP, where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem related to building or using knowledge graphs. \n\nSo, the paper is about color transfer using modulated flows. Modulated flows might refer to some kind of neural network architecture, like normalizing flows with modulation. This seems more related to computer vision or image processing. Since none of the given topics (time-series, multimodal, RAG, KG) fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32470@AAAI"}
{"title": "Progressive Multi-granular Alignments for Grounded Reasoning in Large Vision-Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Progressive Multi-granular Alignments for Grounded Reasoning in Large Vision-Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Progressive Multi-granular Alignments\" suggests that there's some alignment happening at different levels or granularities. \"Grounded Reasoning\" might refer to reasoning that's based on real-world data or context. \"Large Vision-Language Models\" immediately makes me think of models that handle both visual and language data, which is a multimodal approach. Vision and language are two different modalities, so combining them would fall under multimodal research. \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences over time, so probably not time-series. RAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generation models. The title doesn't mention retrieval or generation, so RAG might not be it. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention graphs or knowledge structures either. \n\nSo, the key part here is \"Vision-Language Models,\" which are inherently multimodal because they process both images (vision) and text (language). The rest of the title talks about how they align these modalities at different granularities for reasoning. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32471@AAAI"},
{"title": "Multispectral Pedestrian Detection with Sparsely Annotated Label", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multispectral Pedestrian Detection with Sparsely Annotated Label.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multispectral\" refers to using multiple spectral bands, like different wavelengths of light. So that's probably related to using different types of data, maybe from different sensors. \"Pedestrian detection\" is the task, which is a computer vision problem. \"Sparsely annotated label\" suggests that the dataset has limited or sparse annotations, which might relate to how the model is trained with less labeled data.\n\nNow, looking at the options. Time-series is about data over time, like stock prices or sensor data over time. This title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images, or different sensor data. Since \"multispectral\" implies using multiple spectral data (like visible and infrared), that's combining different data types. So multimodal might be the right fit here.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so that's unlikely.\n\nSo the most likely answer is multimodal because multispectral data involves multiple modalities (different types of data inputs). The sparsely annotated labels might relate to how the model handles limited data, but the key term here is \"multispectral,\" which points to multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32472@AAAI"},
{"title": "Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Open-Vocabulary Segmentation\" suggests that the model can recognize and segment objects or regions beyond a fixed set of classes, which is common in some vision tasks. \"Radiance Fields\" refers to 3D representations used in computer graphics, like NeRFs. \"3D Space\" indicates the work is in three dimensions, possibly related to 3D reconstruction or rendering.\n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. That doesn't seem to fit here. Multimodal involves combining different data types, like text and images. The title doesn't mention combining different modalities. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation, typically in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on segmentation in 3D radiance fields with open vocabulary. None of the four topics directly relate to this. Segmentation is a computer vision task, but the specific mention of radiance fields and 3D space doesn't align with time-series, multimodal, RAG, or KG. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32473@AAAI"},
{"title": "VidChain: Chain-of-Tasks with Metric-based Direct Preference Optimization for Dense Video Captioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VidChain: Chain-of-Tasks with Metric-based Direct Preference Optimization for Dense Video Captioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Dense Video Captioning\" suggests that the paper is about generating captions for videos, which involves both visual and temporal information. Video is a sequence of frames over time, so maybe time-series? But dense captioning usually means generating multiple captions for different parts of the video, which could involve both spatial and temporal aspects.\n\n\"Chain-of-Tasks\" might refer to a method where multiple tasks are chained together. \"Metric-based Direct Preference Optimization\" sounds like an optimization technique, possibly using some kind of preference metrics. But how does that relate to the four topics?\n\nTime-series typically deals with data points indexed in time order, like stock prices or sensor data. If the paper is about video, which is a sequence over time, maybe time-series. But video captioning is more about understanding the content, which might involve both visual (images) and temporal (sequence) data. However, the primary focus here is on generating captions, which is a task that combines vision and language, making it multimodal.\n\nMultimodal refers to the use of multiple types of data, like combining text, images, and audio. Since video captioning involves processing video (visual) and generating text (language), it's a multimodal task. The paper's title doesn't mention anything about knowledge graphs (KG) or retrieval-augmented generation (RAG), which are more about using external knowledge sources or retrieval systems. So, it's probably not RAG or KG.\n\nTherefore, the most likely topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32474@AAAI"},
{"title": "NBA3D: Neighbor-Based Confidence Adjustment for 3D Rare Object Detection Using LiDAR", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"NBA3D: Neighbor-Based Confidence Adjustment for 3D Rare Object Detection Using LiDAR.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on 3D rare object detection using LiDAR. The method mentioned is \"Neighbor-Based Confidence Adjustment.\" So, the key elements here are 3D detection, LiDAR data, and adjusting confidence based on neighbors.\n\nTime-series usually involves data over time, like sequences or temporal data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining images with text or audio. The paper uses LiDAR, which is a type of sensor data, but there's no mention of combining it with another modality like images or text. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. This paper is about object detection, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which involve structured data and relationships between entities. The title doesn't mention anything about knowledge graphs or structured data relationships.\n\nThe paper is about improving detection of rare objects in 3D using LiDAR by adjusting confidence based on neighbors. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The methods used here are more about computer vision and sensor data processing, which don't fall under the listed categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32475@AAAI"},
{"title": "Navigating Label Ambiguity for Facial Expression Recognition in the Wild", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Navigating Label Ambiguity for Facial Expression Recognition in the Wild.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Facial Expression Recognition\" is about identifying emotions or expressions from faces. \"In the Wild\" usually means real-world scenarios, not controlled environments. \"Label Ambiguity\" suggests that the labels (like what expression is being shown) might be unclear or conflicting. \n\nNow, the possible topics. Time-series would involve data over time, like sequences. Multimodal refers to using multiple data types, like combining text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nFacial expression recognition is typically a computer vision task, using images or videos. If it's in the wild, maybe they're using real-world data which could be multimodal if they combine different data sources. But the title doesn't mention combining different modalities. It's about handling ambiguous labels. That might relate to data labeling challenges, but none of the four topics directly address label ambiguity. \n\nWait, maybe multimodal? If the research uses both images and other data types (like text or audio) to recognize expressions, but the title doesn't specify that. The main focus here is on label ambiguity, which could be a data issue, but the four options don't include data labeling as a category. \n\nRAG and KG are more about knowledge retrieval and structured data. Time-series would involve temporal data, like videos, but the title doesn't mention time. So, none of the four topics seem to fit. The problem is about handling ambiguous labels in facial expression recognition, which is a computer vision task, but the given options don't cover that. So the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32476@AAAI"},
{"title": "Video Diffusion Models Are Strong Video Inpainter", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Video Diffusion Models Are Strong Video Inpainter.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data over time, like stock prices or weather data. Video is a sequence of frames over time, so maybe time-series? But video inpainting is about filling in missing parts of a video, which could involve temporal information. However, the term \"diffusion models\" here might be more about generative models. \n\nMultimodal refers to combining multiple data types, like text and images. The title is about video, which is a single modality (visual), so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title doesn't mention retrieval or combining with external data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo, the main options are time-series or multimodal. Since video is a time-series of images, and inpainting in video would involve temporal coherence, maybe time-series. But I'm not entirely sure. However, the term \"diffusion models\" is often used in generative models for images and videos, which might not strictly fall under time-series. But given the options, time-series might be the closest. Alternatively, if the paper is about combining different modalities (like video and text), it would be multimodal. But the title only mentions video. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32477@AAAI"},
{"title": "MAMS: Model-Agnostic Module Selection Framework for Video Captioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MAMS: Model-Agnostic Module Selection Framework for Video Captioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video captioning\" involves generating descriptions for videos. Videos are sequences of frames over time, so maybe time-series? But time-series usually refers to data points indexed in time order, like stock prices or sensor data. Video is a form of time-series data, but the main focus here might be on combining different modalities. \n\n\"Model-Agnostic Module Selection Framework\" suggests that the method is applicable across different models. The term \"module selection\" might imply choosing between different components or models. But how does that relate to the given topics? \n\nMultimodal typically involves combining multiple types of data, like text and images or video. Since video captioning involves both visual (video) and textual (caption) data, this could be multimodal. \n\nRAG (Retrieval-Augmented Generation) is a method that combines retrieval of information with generation, often used in NLP tasks. The title doesn't mention retrieval or generation in that context, so maybe not RAG. \n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention knowledge graphs or structured data, so probably not KG. \n\nSo, the key here is whether video captioning is considered multimodal. Since video is a combination of visual and auditory elements, and captioning adds text, it's definitely multimodal. The framework being model-agnostic might not directly relate to the topic categories, but the core task of video captioning is multimodal. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32478@AAAI"},
{"title": "Enabling Region-Specific Control via Lassos in Point-Based Colorization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enabling Region-Specific Control via Lassos in Point-Based Colorization.\" Hmm. I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Region-Specific Control\" suggests that the research is about controlling specific regions in an image or some spatial data. \"Lassos\" probably refers to the lasso tool used in image editing, which allows users to select specific areas. \"Point-Based Colorization\" implies that the method uses points to apply color, maybe in an image. So the paper is likely about image colorization techniques where users can control specific regions using lasso selections.\n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or weather. That doesn't seem related here. Multimodal usually involves combining different types of data, like text and images. The title doesn't mention combining different data types. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on image colorization with region control, which is a computer vision or graphics topic. None of the four topics (time-series, multimodal, RAG, KG) directly relate to image colorization techniques. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32479@AAAI"},
{"title": "Diverse Rare Sample Generation with Pretrained GANs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Diverse Rare Sample Generation with Pretrained GANs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Diverse Rare Sample Generation\" suggests they're creating samples that are both diverse and rare. \"Pretrained GANs\" means they're using Generative Adversarial Networks that have been pretrained. GANs are typically used for generating data, like images or other types of data, by learning from existing datasets.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or weather data. Multimodal refers to combining multiple types of data, such as text and images. RAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper uses GANs for generating rare samples. GANs are a type of generative model, but the key here is whether the topic fits into one of the four categories. Since the paper is about generating data using GANs, but none of the four topics directly relate to GANs or data generation in general. Time-series would require the data to be time-dependent. Multimodal would involve multiple data types. RAG and KG are more about combining retrieval with generation or structured knowledge. \n\nThe title doesn't mention anything about time-series data, multiple modalities, retrieval-augmented methods, or knowledge graphs. It's focused on generating rare samples using pretrained GANs, which is more about generative models and data augmentation. Since none of the four topics (time-series, multimodal, RAG, KG) are directly addressed here, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32480@AAAI"}
{"title": "Concept Matching with Agent for Out-of-Distribution Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Concept Matching with Agent for Out-of-Distribution Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Concept Matching\" sounds like it's about aligning or comparing concepts. \"Agent\" might refer to an AI agent or some autonomous system. \"Out-of-Distribution Detection\" is about identifying data that's different from the training data, which is a common problem in machine learning, especially in areas like anomaly detection or robustness.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't seem to involve retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper is about concept matching using a knowledge graph, that could fit. But the title mentions an \"Agent,\" which might not be directly related to KGs. However, concept matching could involve aligning concepts in a knowledge graph. Alternatively, maybe the agent is part of a system that uses a knowledge graph for matching concepts. But the title doesn't explicitly mention a knowledge graph. \n\nAlternatively, maybe the agent is a reasoning agent that uses some form of knowledge, but without explicit mention of RAG or KG, it's unclear. The main focus here is on concept matching for out-of-distribution detection. None of the four topics seem to directly align. The problem of out-of-distribution detection is a general machine learning problem, but the specific methods mentioned here don't clearly map to time-series, multimodal, RAG, or KG. So perhaps the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32481@AAAI"},
{"title": "ConDSeg: A General Medical Image Segmentation Framework via Contrast-Driven Feature Enhancement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ConDSeg: A General Medical Image Segmentation Framework via Contrast-Driven Feature Enhancement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. The title mentions medical image segmentation, which is more about images, so probably not time-series.\n\nMultimodal refers to combining different data types, like text and images. The paper is about image segmentation, but does it use multiple modalities? The title doesn't specify combining different data types, just enhancing features through contrast. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to augment their responses. This seems more related to NLP or combining retrieval with generation. The paper is about image segmentation, so RAG might not fit here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. The focus is on feature enhancement in medical images.\n\nSo, the paper is about a framework for medical image segmentation using contrast-driven features. None of the given topics (time-series, multimodal, RAG, KG) seem to directly apply. The main focus is on image processing techniques rather than the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32482@AAAI"},
{"title": "FNIN: A Fourier Neural Operator-based Numerical Integration Network for Surface-from-gradients", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FNIN: A Fourier Neural Operator-based Numerical Integration Network for Surface-from-gradients\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Fourier Neural Operator\", \"Numerical Integration Network\", and \"Surface-from-gradients\". The main focus seems to be on using a neural network (specifically a Fourier Neural Operator) for numerical integration to reconstruct surfaces from gradients. \n\nTime-series analysis usually involves data points indexed in time order, like stock prices over time. This paper doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation, so RAG is out.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on numerical integration and surface reconstruction, not on building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about a specific neural network architecture for a numerical problem in surface reconstruction, which doesn't align with the given categories. Therefore, the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32483@AAAI"},
{"title": "Bridging Knowledge Gap Between Image Inpainting and Large-Area Visible Watermark Removal", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bridging Knowledge Gap Between Image Inpainting and Large-Area Visible Watermark Removal.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about image inpainting and watermark removal, which are image processing tasks. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper here is comparing two image-related tasks, but it's not clear if it's combining different modalities. Maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't mention anything about retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title mentions \"Bridging Knowledge Gap,\" which might be a play on words. The actual content is about connecting two image processing techniques, not about knowledge graphs. So probably not KG.\n\nSince none of the four topics seem to fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32484@AAAI"},
{"title": "KDAT: Inherent Adversarial Robustness via Knowledge Distillation with Adversarial Tuning for Object Detection Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"KDAT: Inherent Adversarial Robustness via Knowledge Distillation with Adversarial Tuning for Object Detection Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge Distillation\" is a technique where a smaller model is trained to mimic a larger, more complex model. \"Adversarial Tuning\" suggests they're dealing with adversarial examples, which are inputs designed to fool machine learning models. The goal here is to make the object detection models more robust against such attacks.\n\nNow, the options. Time-series would involve data over time, like stock prices or weather. This paper is about object detection, which is image-related, so probably not time-series. \n\nMultimodal refers to using multiple data types, like combining text and images. The title doesn't mention multiple modalities, just object detection, which is typically visual. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. This paper is about adversarial robustness in object detection, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of information. The title mentions \"Knowledge Distillation,\" but that's a different concept. Knowledge Distillation is a model compression technique, not directly related to Knowledge Graphs. The paper's focus is on making models robust through distillation and adversarial tuning, not on building or using a knowledge graph.\n\nSo none of the four topics (time-series, multimodal, RAG, KG) seem to fit. The paper is about adversarial robustness in object detection using knowledge distillation and adversarial tuning, which doesn't align with any of the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32485@AAAI"},
{"title": "Disentangled Motion Modeling for Video Frame Interpolation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Disentangled Motion Modeling for Video Frame Interpolation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. Video frame interpolation is about generating intermediate frames between existing ones, which is a video processing task. Videos are sequences over time, so maybe time-series? But wait, video processing can also be considered a computer vision problem. However, the key here is the term \"motion modeling.\" Motion in videos is inherently temporal, so modeling motion could relate to time-series analysis. But I'm not sure if that's the primary focus here.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't relate to knowledge graphs either.\n\nSo, the main contenders are time-series and none. But video frame interpolation is more about computer vision and generating frames, which is a sequence problem but not necessarily a time-series analysis in the traditional sense. Time-series analysis often involves statistical methods for temporal data, whereas video interpolation is more about spatial and temporal modeling in a visual context. However, since the task involves sequences of frames over time, maybe it's considered time-series. But I'm a bit torn here. The term \"disentangled motion modeling\" suggests separating motion components, which could be part of temporal modeling. Maybe the answer is time-series. Alternatively, if the paper is about generating frames, it might not fit neatly into any of the four categories. But given the options, time-series might be the closest. I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32486@AAAI"},
{"title": "Tri-Ergon: Fine-Grained Video-to-Audio Generation with Multi-Modal Conditions and LUFS Control", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Tri-Ergon: Fine-Grained Video-to-Audio Generation with Multi-Modal Conditions and LUFS Control.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main task here is generating audio from video, which is a form of cross-modal generation. The term \"Multi-Modal Conditions\" is mentioned, which suggests that the model uses more than one type of data (like video and audio) as input or conditions. That points towards the multimodal topic. \n\nTime-series usually refers to data that's sequential over time, like stock prices or sensor data. While video and audio are time-based, the key here is the combination of different modalities (video and audio), not just the temporal aspect. \n\nRAG (Retrieval-Augmented Generation) involves using a retrieval system to pull information and then generate text, but the title doesn't mention anything about retrieval or augmenting with external data. \n\nKG (Knowledge Graph) is about structured data representations, which isn't indicated here. \n\nSo the main clue is \"Multi-Modal Conditions,\" which aligns with the multimodal topic. The answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32487@AAAI"},
{"title": "StyO: Stylize Your Face in Only One-Shot", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"StyO: Stylize Your Face in Only One-Shot.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title talks about stylizing a face, which is an image, but does it use multiple modalities? The \"one-shot\" part might refer to using a single example, but not sure if that's multimodal. Maybe if it uses both images and text for styling, but the title doesn't specify. Hmm.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate a response. The title doesn't mention anything about retrieving information or generating text based on that. It's about stylizing a face, which sounds more like image processing.\n\nKG is Knowledge Graph. Those are structured representations of knowledge. The title doesn't mention anything about building or using a knowledge graph. So probably not KG.\n\nSo, the options left are multimodal or none. The task is to stylize a face in one shot. If \"one-shot\" refers to using a single example to generate the style, maybe it's a one-shot learning problem. But one-shot learning isn't one of the listed topics. The paper might be about image generation, which could be multimodal if it uses text and images. For example, if you input a text description and an image to stylize, that's multimodal. But the title doesn't specify. The term \"Stylize Your Face\" could be using a style transfer technique, which is typically image-based. If it's using a single image (one-shot) to apply a style, maybe it's not multimodal. Unless the style is defined by another modality like text. Without more info, it's hard to tell. The title doesn't mention multiple modalities, so maybe it's not multimodal either. So perhaps the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32488@AAAI"},
{"title": "FEAST-Mamba: FEAture and SpaTial Aware Mamba Network with Bidirectional Orthogonal Fusion for Cross-Modal Point Cloud Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FEAST-Mamba: FEAture and SpaTial Aware Mamba Network with Bidirectional Orthogonal Fusion for Cross-Modal Point Cloud Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The key parts here are \"Cross-Modal Point Cloud Segmentation.\" The term \"cross-modal\" immediately makes me think of multimodal data. Multimodal typically involves combining different types of data, like images and text, or in this case, maybe point clouds with another modality. The paper's focus on segmentation in point clouds using cross-modal techniques suggests it's dealing with integrating multiple data sources. \n\nLooking at the other parts: \"Bidirectional Orthogonal Fusion\" might refer to how different modalities are combined. The mention of \"Feature and Spatial Aware\" could be about how the model processes different features from various modalities. \n\nNow, checking the options. Time-series would involve data over time, like stock prices or sensor data over time. The title doesn't mention anything about time, so probably not that. RAG (Retrieval-Augmented Generation) is more about using retrieval mechanisms in generation tasks, like in NLP models. KG (Knowledge Graphs) involve structured data and relationships, which isn't mentioned here. \n\nSo, the key term is \"cross-modal,\" which directly relates to multimodal research. The paper is about combining different modalities (like point clouds with another data type) for segmentation. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32489@AAAI"},
{"title": "RemDet: Rethinking Efficient Model Design for UAV Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RemDet: Rethinking Efficient Model Design for UAV Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"UAV Object Detection\" refers to detecting objects using Unmanned Aerial Vehicles, like drones. The focus here is on efficient model design for this task. Now, the key part is determining which research area this falls under.\n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time-based data, so probably not time-series.\n\nMultimodal would involve combining different data types, like text and images. The title is about object detection, which is typically a computer vision task using images, but there's no mention of combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents. The paper here is about object detection in UAVs, which is a different domain. Doesn't seem related to RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo, the paper is about designing an efficient model for UAV object detection. The main focus is on model efficiency, perhaps optimizing for computational resources or speed. The topics given don't include computer vision, model efficiency, or UAVs specifically. Since none of the four topics (time-series, multimodal, RAG, KG) are directly related to the content of the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32490@AAAI"}
{"title": "U-KAN Makes Strong Backbone for Medical Image Segmentation and Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"U-KAN Makes Strong Backbone for Medical Image Segmentation and Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"U-KAN\" probably refers to a neural network architecture, maybe a variant of U-Net, which is commonly used in image segmentation. The terms \"Medical Image Segmentation and Generation\" suggest that the paper is about processing medical images, which are typically 2D or 3D images. \n\nTime-series analysis usually involves data points indexed in time order, like stock prices over time or sensor data. Since the title mentions image segmentation and generation, which are spatial tasks, time-series doesn't seem relevant here.\n\nMultimodal research involves combining different types of data, such as text and images, or audio and video. The title doesn't mention anything about combining different data types, so multimodal might not be the right fit.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information from a database with a generative model. This is often used in natural language processing tasks where the model can retrieve relevant documents and then generate a response. The title doesn't mention anything about retrieval or combining it with generation, so RAG might not apply here.\n\nKG stands for Knowledge Graph, which is a structured representation of knowledge, often used to represent relationships between entities. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, the paper is about using a specific architecture (U-KAN) for medical image tasks. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to image segmentation and generation in this context, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32491@AAAI"},
{"title": "Consistency of Compositional Generalization Across Multiple Levels", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Consistency of Compositional Generalization Across Multiple Levels.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Compositional Generalization\" sounds like it's about how models can generalize by combining different components or parts. \"Across Multiple Levels\" might refer to different layers or aspects of the model. \n\nTime-series research usually deals with data over time, like stock prices or weather. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal is about combining different types of data, like text and images. The title doesn't specify different data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which involves using retrieval systems to enhance model outputs. The title doesn't mention retrieval or generation, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title's focus on compositional generalization could relate to how knowledge is structured and combined, but \"consistency across multiple levels\" might refer to different layers in a model's architecture or reasoning processes. However, without explicit mention of knowledge graphs or their components, it's a stretch.\n\nSince none of the four topics are clearly indicated in the title, the answer is likely \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32492@AAAI"},
{"title": "An Efficient Framework for Enhancing Discriminative Models via Diffusion Techniques", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"An Efficient Framework for Enhancing Discriminative Models via Diffusion Techniques.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are \"discriminative models\" and \"diffusion techniques.\" Discriminative models are a type of machine learning model that focuses on distinguishing between different classes, like logistic regression or support vector machines. Diffusion techniques might refer to methods that use diffusion processes, which are often used in generative models like diffusion models. \n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so maybe not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so probably not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP tasks. The title doesn't mention retrieval or generation, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo, none of the four topics seem to fit. The paper is about enhancing discriminative models using diffusion techniques, which might be related to generative models or optimization methods, but not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32493@AAAI"},
{"title": "CALLIC: Content Adaptive Learning for Lossless Image Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CALLIC: Content Adaptive Learning for Lossless Image Compression.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title here is about image compression, so time-series doesn't seem relevant.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about image compression, but the title doesn't mention combining different data types. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, the title is about image compression, which doesn't directly relate to knowledge graphs.\n\nSo the paper is about lossless image compression using a content adaptive learning method. None of the given topics (time-series, multimodal, RAG, KG) directly apply here. The focus is on image compression techniques, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32494@AAAI"},
{"title": "Cascaded Diffusion Models for Virtual Try-On: Improving Control and Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cascaded Diffusion Models for Virtual Try-On: Improving Control and Resolution.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Cascaded Diffusion Models\" sounds like a type of machine learning model, maybe in computer vision. \"Virtual Try-On\" refers to trying on clothes virtually, which is an application in fashion tech. The goal is to improve control and resolution, so probably enhancing the image generation quality.\n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about diffusion models for virtual try-on. Diffusion models are typically used in image generation. Virtual try-on would involve generating images of a person wearing clothes, which might use both images (of the person and the clothes) and maybe some other data. But does that make it multimodal? If the model uses different modalities like images and text, then yes. However, if it's just using images and generating images, maybe not. The term \"cascaded\" suggests multiple stages, but not necessarily different data types.\n\nRAG and KG don't seem relevant here. The title doesn't mention retrieval or knowledge graphs. Time-series is about sequences over time, which isn't indicated here. So the closest might be multimodal if the model uses different data types. But if it's just image-to-image translation, maybe not. However, virtual try-on often involves combining a person's image with clothing images, which are different modalities. So maybe multimodal. But I'm not 100% sure. Let me think again. If the model is using both the person's image and the clothing image as inputs, that's multimodal. If it's just generating based on one modality, then not. The title doesn't specify, but virtual try-on typically uses both. So I'll go with multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32495@AAAI"},
{"title": "HomeDiffusion: Zero-Shot Object Customization with Multi-View Representation Learning for Indoor Scenes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HomeDiffusion: Zero-Shot Object Customization with Multi-View Representation Learning for Indoor Scenes.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Zero-Shot Object Customization\" suggests that the model can handle new objects without prior training examples. \"Multi-View Representation Learning\" implies using multiple perspectives or views of the data. \"Indoor Scenes\" probably refers to 3D environments or images of indoor settings.\n\nNow, the four options. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data representations, like relationships between entities.\n\nThe paper's focus seems to be on learning representations from multiple views (multi-view) for customizing objects in indoor scenes. Multi-view could relate to different angles or perspectives, which might involve different modalities (like images from different views), but \"multi-view\" here might not necessarily mean combining different data types. However, \"multi-view representation learning\" is a term often used in computer vision for 3D reconstruction or object recognition using multiple 2D images. \n\nSince the options are time-series, multimodal, RAG, or KG, and the paper doesn't mention anything about time-based data, retrieval-augmented generation, or knowledge graphs, the closest might be multimodal. But wait, multimodal typically refers to combining different modalities like text, image, audio. If \"multi-view\" here is about different images (same modality but different views), then it's not multimodal. However, sometimes multi-view is considered a form of multimodal if each view is treated as a separate modality. But I'm not sure. Alternatively, maybe it's none of these. The paper's main contribution is about object customization using multi-view learning, which might not fit into the given categories. \n\nBut the options are limited. Let me check again. The title doesn't mention anything about time, so time-series is out. RAG and KG are more about text-based models and knowledge structures. The key term is \"multi-view representation learning,\" which is more about computer vision techniques. Since the given options don't include computer vision or 3D reconstruction, maybe it's none. But the user wants to check if it's one of the four. If \"multi-view\" is considered multimodal (as in multiple modalities), then maybe multimodal. But I think in academic terms, multi-view learning is a subset of machine learning that uses multiple perspectives of the same data, not necessarily different modalities. So perhaps it's not multimodal. Therefore, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32496@AAAI"},
{"title": "VEGAS: Towards Visually Explainable and Grounded Artificial Social Intelligence", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VEGAS: Towards Visually Explainable and Grounded Artificial Social Intelligence.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Visually Explainable\" suggests that the model's decisions can be explained through visual means. \"Grounded\" might mean that the AI is connected to real-world data or context. \"Artificial Social Intelligence\" implies the AI is designed to interact socially, maybe understanding human behavior or social interactions.\n\nNow, the four options. Time-series usually involves data over time, like stock prices or weather. Multimodal refers to using multiple data types, such as text, images, audio. RAG is Retrieval-Augmented Generation, which combines retrieval of information with generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title mentions \"visually,\" which could relate to images or visual data. If the model uses both visual data and another modality (like text or audio), that would be multimodal. However, the title doesn't explicitly mention multiple modalities. \"Grounded\" might relate to knowledge graphs if it's about connecting to structured knowledge. But \"visually explainable\" could also be part of multimodal if it's using visual explanations alongside other data. RAG and time-series don't seem to fit here. The focus on social intelligence might involve understanding context, which could be multimodal. But without more info, it's a bit tricky. However, since the title emphasizes visual explanations, maybe it's multimodal if it combines vision with other modalities. But if it's just about visual explanations without other modalities, maybe not. The term \"grounded\" could hint at knowledge graphs, but I'm not sure. Given the options, I think the most likely is multimodal because of the visual aspect and possible integration with other data types for social intelligence.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32497@AAAI"},
{"title": "AIF-SFDA: Autonomous Information Filter Driven Source-Free Domain Adaptation for Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AIF-SFDA: Autonomous Information Filter Driven Source-Free Domain Adaptation for Medical Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Source-Free Domain Adaptation\" and \"Medical Image Segmentation.\" Domain adaptation is a concept in machine learning where a model trained on a source domain is adapted to perform well on a target domain without needing data from the source. Source-free means they don't use the source data during adaptation, which is a specific type of domain adaptation.\n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal refers to using multiple types of data (like text and images). RAG is Retrieval-Augmented Generation, which is about combining retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about domain adaptation in medical image segmentation. None of the four topics directly relate to domain adaptation. The paper isn't about time-series data, it's about images. It's not multimodal since it's focused on image segmentation. RAG and KG are unrelated here. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32498@AAAI"},
{"title": "BSAFusion: A Bidirectional Stepwise Feature Alignment Network for Unaligned Medical Image Fusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BSAFusion: A Bidirectional Stepwise Feature Alignment Network for Unaligned Medical Image Fusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"medical image fusion,\" \"feature alignment,\" and \"unaligned.\" Medical image fusion usually refers to combining images from different modalities, like MRI and CT scans, to get a more comprehensive view. So that's multimodal, right? Because multimodal typically involves integrating data from different sources or types. \n\nThe network is called a Bidirectional Stepwise Feature Alignment Network. The term \"feature alignment\" might relate to aligning features from different data sources, which again points to multimodal. Time-series would involve data over time, like stock prices or sensor data over time. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper is about fusing unaligned medical images, which are different types (modalities) of images. So the main focus is on combining different data types (modalities) to improve the fusion result. That fits under multimodal. There's no mention of time-series data, RAG, or knowledge graphs here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32499@AAAI"},
{"title": "Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single Image Denoising", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Prompt-SID: Learning Structural Representation Prompt via Latent Diffusion for Single Image Denoising.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on image denoising. The method mentioned is \"Learning Structural Representation Prompt via Latent Diffusion.\" So, the key terms here are \"Single Image Denoising,\" which is about improving image quality by removing noise. \n\nNow, looking at the four options. Time-series usually involves data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The title mentions a single image, so maybe not multimodal unless there's another modality involved. But the title doesn't mention anything else, so maybe not.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks, often in NLP. The title doesn't mention retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably out.\n\nThe paper is about image denoising using a latent diffusion model. The term \"latent diffusion\" might relate to diffusion models used in generative AI, which are common in image processing. The \"structural representation prompt\" part suggests they're using some kind of prompt-based method to guide the denoising process. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) directly relate to image denoising or diffusion models, the answer might be \"none.\" But wait, maybe I'm missing something. Let me double-check. \n\nMultimodal could be a stretch if the method uses multiple modalities, but the title specifies \"Single Image,\" so it's just images. RAG is about retrieval, which isn't mentioned. KG is about knowledge graphs, which isn't here. Time-series is unrelated. So the correct answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32500@AAAI"}
{"title": "M²RL-Net: Multi-View and Multi-Level Relation Learning Network for Weakly-Supervised Image Forgery Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"M²RL-Net: Multi-View and Multi-Level Relation Learning Network for Weakly-Supervised Image Forgery Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key parts are \"Multi-View and Multi-Level Relation Learning Network\" and \"Weakly-Supervised Image Forgery Detection.\" \n\nMulti-view and multi-level might suggest that the model is considering different perspectives or layers of data. Relation learning could imply that the network is learning relationships between different elements. The application is image forgery detection, which is about identifying manipulated images. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This paper is about images, so time-series might not fit. \n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention combining different data types, just multi-view and multi-level. So maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image forgery detection through relation learning, which might involve modeling relationships between different parts of the image. However, knowledge graphs are more about structured data and entities. \n\nWait, the term \"relation learning\" could be related to knowledge graphs, where relations between entities are important. But in this case, the relations are within the image data, not structured knowledge. So maybe not KG. \n\nAlternatively, \"multi-view\" could imply using different modalities or perspectives, but the term \"multimodal\" usually refers to different data types. Since the paper is about image forgery, perhaps it's using different views of the same image (like different regions or features), which might be considered multi-modal in a way. But I'm not sure. \n\nThe main focus here is on learning relations in the image data for forgery detection. None of the four topics seem to perfectly fit. The paper is about a neural network architecture for image analysis, which might not fall under any of the specified categories. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32501@AAAI"},
{"title": "MaskViM: Domain Generalized Semantic Segmentation with State Space Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MaskViM: Domain Generalized Semantic Segmentation with State Space Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Domain Generalized Semantic Segmentation\" suggests that the paper is about making a model work well across different domains, which is a common challenge in machine learning. Semantic segmentation is typically a computer vision task, so the model is probably processing images or videos.\n\nThen there's \"State Space Models.\" State space models are often used in time-series analysis because they model the state of a system over time. They're used for tasks like forecasting or filtering in sequences. So if the paper is using state space models, that might point towards time-series. But wait, semantic segmentation is usually about spatial data (like images), not temporal. However, maybe they're applying state space models to handle temporal aspects in the segmentation, like video segmentation where each frame is a time step. That would make it a time-series topic.\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention anything about combining modalities, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is out. KG (Knowledge Graphs) involve structured data and relationships between entities. Again, the title doesn't mention knowledge graphs, so that's probably not it.\n\nSo the key here is the use of State Space Models. If the paper is using them for domain generalization in semantic segmentation, and given that state space models are typically associated with time-series data, then the topic would be time-series. Even if the primary application is in images, the method's reliance on state space models (which are time-series oriented) would categorize it under time-series. Unless the state space models here are being used in a non-temporal way, but that's less common. I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32502@AAAI"},
{"title": "Block-Based Multi-Scale Image Rescaling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Block-Based Multi-Scale Image Rescaling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title mentions image rescaling, which is about images, not time data. So probably not time-series.\n\nNext, multimodal refers to combining multiple types of data, like text and images or audio and video. The title is about image rescaling, but it doesn't mention combining different data types. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The title is about image processing, not structured knowledge. So KG probably isn't it either.\n\nThe paper is about a block-based approach to multi-scale image rescaling. That sounds like image processing techniques, maybe related to scaling images at different resolutions using blocks. None of the given topics (time-series, multimodal, RAG, KG) directly relate to image rescaling methods. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32503@AAAI"},
{"title": "A²RNet: Adversarial Attack Resilient Network for Robust Infrared and Visible Image Fusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A²RNet: Adversarial Attack Resilient Network for Robust Infrared and Visible Image Fusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts are \"Adversarial Attack Resilient Network\" and \"Infrared and Visible Image Fusion.\" The main focus here seems to be on image fusion, combining infrared and visible images. That makes me think about multimodal data because it's using two different types of images (infrared and visible), which are different modalities. \n\nMultimodal research typically involves integrating data from multiple sources or types, like combining images with text or different kinds of images. In this case, infrared and visible images are two distinct modalities. The network is designed to be resilient against adversarial attacks, which is a security aspect, but the core task is the fusion of these two image types. \n\nTime-series would involve data over time, like sequences or temporal data. RAG (Retrieval-Augmented Generation) is more about using retrieval mechanisms in generative models, often in NLP. KG (Knowledge Graph) involves structured data and relationships between entities. None of these seem to fit the image fusion aspect. \n\nSo, the most likely topic here is multimodal because it's about integrating different modalities (infrared and visible images). The adversarial resilience is a method to make the fusion robust, but the primary research area is multimodal image fusion.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32504@AAAI"},
{"title": "Lightweight Contrastive Distilled Hashing for Online Cross-modal Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Lightweight Contrastive Distilled Hashing for Online Cross-modal Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-modal Retrieval\" immediately makes me think of multimodal. Because cross-modal usually refers to different types of data, like text and images, which are different modalities. So that's a hint towards multimodal. \n\nThen, \"Contrastive Distilled Hashing\" – hashing is often used in retrieval systems to map data into binary codes for faster search. Distilled might refer to knowledge distillation, a technique where a smaller model learns from a larger one. Contrastive learning is a method used in self-supervised learning to learn representations by contrasting similar and dissimilar examples. So combining these, it's about creating efficient hashing methods for cross-modal retrieval.\n\nThe term \"Online\" suggests that the retrieval is happening in real-time or as data comes in, but that's more about the application scenario rather than the core topic. \n\nNow, checking the options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. RAG (Retrieval-Augmented Generation) is about using retrieval to augment a generative model, like in question-answering systems. The title is about retrieval itself, not generation. KG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention knowledge graphs. \n\nSo the key term here is \"cross-modal retrieval,\" which is a subset of multimodal research. Therefore, the paper belongs to the multimodal topic.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32505@AAAI"},
{"title": "Rethinking Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Rethinking Transformer-Based Blind-Spot Network for Self-Supervised Image Denoising.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"Transformer-Based,\" \"Blind-Spot Network,\" and \"Self-Supervised Image Denoising.\" \n\nTransformers are a type of neural network architecture, commonly used in NLP but also in vision tasks. The \"Blind-Spot Network\" part might refer to a specific architecture where certain parts of the image are masked or not directly used during processing. Self-supervised learning is a method where the model learns from the data itself without explicit labels, often used in tasks like denoising, where the model learns to predict the original image from a noisy version.\n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about image denoising, which is a single modality (images), so maybe not multimodal unless it's using other data types, but the title doesn't indicate that.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about image processing, not knowledge representation, so likely not KG.\n\nSo, the paper is about image denoising using a transformer-based model. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The main focus is on the model architecture and self-supervised learning for image processing. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32506@AAAI"},
{"title": "FD2-Net: Frequency-Driven Feature Decomposition Network for Infrared-Visible Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FD2-Net: Frequency-Driven Feature Decomposition Network for Infrared-Visible Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The network is called FD2-Net, which probably stands for Frequency-Driven Feature Decomposition. The application is for object detection in infrared and visible images. So, the key parts here are \"infrared-visible,\" which suggests combining two different types of data—probably infrared and visible light images. That makes me think of multimodal learning because multimodal typically involves integrating different data types like images, text, audio, etc. In this case, infrared and visible images are two different modalities.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data over time. The title doesn't mention anything about time or sequences, so probably not time-series. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in language models. The title doesn't mention retrieval or generation, so RAG is unlikely. KG is Knowledge Graphs, which involve structured data and relationships. Again, the title doesn't mention anything about knowledge graphs or structured data.\n\nSo, the main clue here is \"infrared-visible,\" which points to using two different modalities (infrared and visible light) for object detection. That fits under multimodal research. The network's approach using frequency-driven features might be a method to handle the multimodal data, but the core topic is combining different data types. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32507@AAAI"},
{"title": "Know Where You Are From: Event-Based Segmentation via Spatio-Temporal Propagation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Know Where You Are From: Event-Based Segmentation via Spatio-Temporal Propagation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Event-Based Segmentation\" suggests that the paper is about segmenting events. \"Spatio-Temporal Propagation\" refers to something that involves both space and time. So, spatio-temporal usually relates to data that has both spatial (location) and temporal (time) components. That makes me think of time-series data, which is data over time. But time-series is just temporal, so maybe it's more than that. Wait, spatio-temporal could be a type of time-series but with spatial elements. However, the main categories here are time-series, multimodal, RAG, or KG.\n\nMultimodal would involve multiple types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe title doesn't mention anything about multiple data modalities, so probably not multimodal. RAG and KG are more about knowledge representation or retrieval. The key terms here are \"spatio-temporal\" and \"event-based segmentation.\" Spatio-temporal analysis is common in time-series data, especially when dealing with events that occur in both space and time. For example, weather data over time and location is spatio-temporal. So, this seems like it's dealing with time-series data that also has spatial components. Therefore, the topic would be time-series. \n\nI don't see any mention of knowledge graphs or retrieval-augmented generation. The focus is on segmentation of events using spatio-temporal propagation, which is a method for analyzing time-series data with spatial aspects. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32508@AAAI"},
{"title": "Prototypical Calibrating Ambiguous Samples for Micro-Action Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Prototypical Calibrating Ambiguous Samples for Micro-Action Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Micro-action recognition\" refers to identifying small, short-duration actions in videos, which is a common task in computer vision. The method mentioned is \"prototypical calibrating ambiguous samples.\" Prototypical might relate to using prototypes or exemplars for learning. Calibrating ambiguous samples suggests handling uncertain or noisy data points.\n\nNow, looking at the possible topics. Time-series analysis involves data over time, which could be relevant if the micro-actions are analyzed over time. However, micro-action recognition is more about video frames and spatial-temporal features, but time-series is a broader category. But the key here is whether the paper specifically focuses on time-series methods. The title doesn't explicitly mention time-series techniques like ARIMA, LSTMs, or temporal modeling, so maybe not.\n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities, so probably not multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG (Knowledge Graphs) involve structured data and relationships. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nSo, the remaining options are time-series or none. But micro-action recognition is typically in the domain of computer vision and video analysis, which might use temporal data but not necessarily time-series analysis in the traditional sense. The term \"prototypical calibrating\" might relate to clustering or prototype-based methods, which are more about machine learning models rather than time-series. Since the title doesn't clearly indicate time-series methods, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32509@AAAI"},
{"title": "MergeNet: Knowledge Migration Across Heterogeneous Models, Tasks, and Modalities", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MergeNet: Knowledge Migration Across Heterogeneous Models, Tasks, and Modalities.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge Migration\" suggests moving knowledge from one place to another. \"Across Heterogeneous Models, Tasks, and Modalities\" – the mention of \"modalities\" makes me think of multimodal, which deals with combining different types of data like text, images, audio. But the paper is about knowledge migration, which might relate to transferring knowledge between different models or tasks. \n\nWait, RAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge. Time-series is about data over time. \n\nThe term \"modalities\" in the title points towards multimodal, but the main focus here is on knowledge migration. However, multimodal research often involves integrating different data types. But the key part here is \"knowledge migration across... modalities.\" So if the paper is about transferring knowledge between different modalities (like from text to images), that would be multimodal. \n\nAlternatively, if it's about transferring knowledge between different models or tasks, maybe it's RAG or KG? RAG is more about using retrieved information to generate responses. KG is about structured knowledge. The title mentions \"knowledge migration,\" which could be related to knowledge graphs if they're moving structured knowledge. But the mention of \"modalities\" is a strong hint towards multimodal. \n\nSo I think the answer is multimodal. The paper is about moving knowledge across different modalities, which is a key aspect of multimodal research.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32510@AAAI"}
{"title": "Multi-View 3D Human Pose Estimation with Weakly Synchronized Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-View 3D Human Pose Estimation with Weakly Synchronized Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View\" suggests using multiple perspectives or sources. \"3D Human Pose Estimation\" is about determining the position of a person in 3D space. \"Weakly Synchronized Images\" implies that the images from different views aren't perfectly aligned in time. \n\nNow, looking at the topics. Time-series usually involves data points indexed in chronological order. This paper might involve sequences if they're tracking over time, but the title doesn't mention time explicitly. The key part is \"Multi-View,\" which could relate to using different modalities (like images from different angles) to get a 3D pose. \n\nMultimodal research deals with combining different types of data (e.g., text, images, audio). Here, the multi-view images could be considered different modalities. Even though they're all images, the different views might be treated as separate modalities. The weak synchronization might be a challenge in fusing these modalities. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, which doesn't seem relevant here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. \n\nSo, the most likely topic is multimodal because it's combining multiple views (modalities) to estimate 3D pose. Time-series might be a stretch unless the synchronization aspect is about time, but the primary focus is on integrating different image sources. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32511@AAAI"},
{"title": "Similar Modality Enhancement and Action Consistency Learning for Weakly Supervised Temporal Action Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Similar Modality Enhancement and Action Consistency Learning for Weakly Supervised Temporal Action Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Action Localization\" suggests something related to time, since \"temporal\" refers to time. That makes me think of time-series data, which is data over time. But I should check the other parts. \n\n\"Similar Modality Enhancement\" – modality usually refers to different types of data, like text, image, audio. So if they're enhancing similar modalities, maybe it's about combining or improving data from the same type? But multimodal typically involves multiple different modalities. However, \"similar modality\" might be a specific approach. \n\n\"Action Consistency Learning\" – action here could be in the context of video actions, like recognizing actions in videos. Weakly supervised implies that the training data isn't fully labeled, maybe using video-level labels instead of frame-level. \n\nSo, temporal action localization is about identifying actions in videos over time. That's a time-series problem because it's analyzing sequences over time. But wait, multimodal could be if they're using different data types (like combining video and audio). However, the title mentions \"similar modality,\" which might not be multiple modalities. \n\nRAG (Retrieval-Augmented Generation) is more about using retrieval to augment generation in models, which doesn't seem related here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo the main clue is \"temporal,\" which points to time-series. The paper is about localizing actions in time, which is a time-series task. Even though there's mention of modality, it's about enhancing similar ones, not combining different ones. So the topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32512@AAAI"},
{"title": "Multimodal Hypothetical Summary for Retrieval-based Multi-image Question Answering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multimodal Hypothetical Summary for Retrieval-based Multi-image Question Answering.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal\" is right there in the title. That's one of the options. The other parts mention \"Retrieval-based\" and \"Multi-image Question Answering.\" Retrieval-based could relate to RAG (Retrieval-Augmented Generation), which is a method that uses retrieval to augment model outputs. But the title specifically says \"Multimodal,\" which is one of the options. \n\nWait, but the question is to determine which of the four topics it belongs to. The options are time-series, multimodal, RAG, KG. The title has \"Multimodal\" explicitly, so that's a strong indicator. The other parts might relate to RAG, but the primary focus here seems to be on multimodal data (since it's multi-image and question answering involving different modalities like images and text). \n\nSo even though retrieval-based could hint at RAG, the presence of \"Multimodal\" in the title makes me think the correct answer is multimodal. I should check if there's any mention of knowledge graphs (KG) or time-series, but the title doesn't have those terms. Therefore, the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32513@AAAI"},
{"title": "REGNav: Room Expert Guided Image-Goal Navigation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"REGNav: Room Expert Guided Image-Goal Navigation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Image-Goal Navigation\" suggests that the system uses images as goals for navigation. So, maybe it's using visual data. \"Room Expert Guided\" might imply some kind of expert system or knowledge about rooms. But what does that translate to in the given options?\n\nTime-series usually involves data over time, like sequences. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple data types, like combining images and text. If the navigation uses images (visual) and maybe other modalities, like text or sensor data, it could be multimodal. But the title only mentions image-goal, so maybe it's just using images. Hmm, not sure yet.\n\nRAG stands for Retrieval-Augmented Generation. That's typically for models that retrieve information from a database and then generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs. If the \"Room Expert\" part refers to a structured knowledge base about rooms, maybe a knowledge graph is involved. But the term \"expert guided\" might not necessarily mean a knowledge graph. It could be a rule-based system or another type of expert system. However, without explicit mention of a graph or knowledge base, it's a bit uncertain.\n\nAlternatively, \"Room Expert Guided\" could be a model or module that's trained to understand room structures, which might be part of a multimodal approach if it combines visual data with spatial knowledge. But if the expert is a knowledge graph, then it's KG. However, the title doesn't specify that. The key here is whether the navigation system uses multiple modalities (like images and text) or a knowledge graph.\n\nSince the title mentions \"Image-Goal,\" it's using images as input, but if there's another modality involved, like text instructions or other sensors, it would be multimodal. However, the title doesn't explicitly state that. The term \"expert guided\" might imply some form of knowledge, but without more context, it's hard to say if it's a knowledge graph. Given the options, I think the most likely is multimodal because it's using images for navigation, which is a visual modality, and perhaps other data types. But I'm not entirely sure. Alternatively, if the expert is a knowledge graph, then KG. But the title doesn't mention a graph. So maybe it's multimodal. Wait, the problem says to choose from the four. If it's using images and maybe another modality, then multimodal. If it's using a knowledge graph, then KG. Since the title doesn't mention a graph, maybe it's multimodal. But I'm not 100% certain. Alternatively, maybe it's none. But I need to pick one. Let me think again. The key is the \"Image-Goal\" part. If the system uses images as input and maybe other modalities (like text or sensor data), then it's multimodal. If it's just images, then maybe not. But navigation often involves multiple sensors. However, the title doesn't specify. Given the options, I'll go with multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32514@AAAI"},
{"title": "Revisiting CAD Model Generation by Learning Raster Sketch", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Revisiting CAD Model Generation by Learning Raster Sketch.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. CAD model generation refers to creating computer-aided design models. The method mentioned is \"learning raster sketch.\" Raster sketches are probably 2D images or pixel-based representations. So the paper is about generating 3D CAD models from 2D raster sketches.\n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or sensor data. That doesn't seem relevant here. Multimodal involves combining different data types, like text and images. But the title is about generating a model from a sketch, which is a single modality (image). RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance generation. KG is Knowledge Graph, which is structured data representing entities and relationships. \n\nThe paper's focus is on learning from raster sketches to generate CAD models. It doesn't mention anything about time-based data, combining multiple modalities, retrieval-augmented generation, or knowledge graphs. So it doesn't fit any of the four categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32515@AAAI"},
{"title": "Temporal Action Localization with Cross Layer Task Decoupling and Refinement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Temporal Action Localization with Cross Layer Task Decoupling and Refinement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Action Localization\" – temporal usually relates to time, so that's a hint towards time-series data. Action localization in videos, maybe? Because videos are sequences over time. Then \"Cross Layer Task Decoupling and Refinement\" – cross layer might refer to different layers in a neural network, but not sure how that connects to the topics.\n\nLooking at the options: time-series deals with data over time, like sequences. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured data representations.\n\nThe key part here is \"Temporal Action Localization.\" Temporal implies time-based data, so that's a strong indicator for time-series. Action localization in videos is a common time-series problem where you identify actions over time frames. The other parts of the title don't mention multimodal inputs or knowledge graphs, and RAG isn't really related here. So the most likely topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32516@AAAI"},
{"title": "Region-aware Difference Distilling with Attribute-guided Contrastive Regularization for Change Captioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Region-aware Difference Distilling with Attribute-guided Contrastive Regularization for Change Captioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Change Captioning\" probably refers to generating descriptions of changes between two images or scenes. That sounds like a vision task, maybe involving images and text. \"Region-aware\" suggests that the model pays attention to specific regions in the image. \"Attribute-guided Contrastive Regularization\" might involve using attributes (like color, shape) to guide the learning process through contrastive methods. \n\nNow, looking at the topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to generate answers. KG (Knowledge Graph) is about structured data representing entities and their relationships.\n\nThe paper seems to be about image captioning, which is a multimodal task because it combines visual data (images) and textual data (captions). The mention of \"region-aware\" and \"attribute-guided\" suggests that the model is using both visual regions and their attributes, which are different modalities. There's no indication of time-series data, RAG's retrieval mechanism, or knowledge graphs here. So the most likely topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32517@AAAI"},
{"title": "Enhancing Generalizability via Utilization of Unlabeled Data for Occupancy Perception", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Generalizability via Utilization of Unlabeled Data for Occupancy Perception.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main goal here is enhancing generalizability, which usually refers to making a model perform well on new, unseen data. The method mentioned is using unlabeled data. That makes me think of semi-supervised learning or maybe self-supervised learning, where unlabeled data is used to improve model performance. \n\nNow, the application is \"occupancy perception.\" That could be about determining if a space is occupied, maybe in robotics or smart environments. But the key part here is the technique used. The question is whether this technique falls under one of the four categories.\n\nTime-series would involve data that's sequential over time, like stock prices or sensor data over time. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's a method where a model retrieves relevant information from a database and uses it to generate responses. The title doesn't mention retrieval or generation, so RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper was about building or using a knowledge graph, that would be the case. But again, the title doesn't mention anything about knowledge graphs.\n\nThe paper is about using unlabeled data to improve generalizability. That sounds more like a machine learning technique, perhaps semi-supervised learning. But the four options given don't include semi-supervised or self-supervised. The options are time-series, multimodal, RAG, or KG. None of these seem to directly relate to using unlabeled data for generalization. \n\nWait, maybe I'm missing something. RAG uses retrieval, but the paper isn't about retrieval. KG is about structured knowledge. The other two are about data types. Since the paper is about using unlabeled data, which is a data-related aspect but not covered in the given topics, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32518@AAAI"},
{"title": "SyncNoise: Geometrically Consistent Noise Prediction for Instruction-based 3D Editing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SyncNoise: Geometrically Consistent Noise Prediction for Instruction-based 3D Editing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather. This title mentions 3D editing and noise prediction, which doesn't seem time-dependent. So probably not time-series.\n\nMultimodal refers to using multiple data types, like combining text and images. The title says \"Instruction-based,\" which might involve text instructions, and 3D editing could involve visual data. So maybe multimodal? But I'm not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured data representations. The paper's focus on geometric consistency and noise prediction in 3D editing doesn't seem to involve knowledge graphs directly.\n\nSo, the most likely is multimodal because it combines instructions (text) with 3D editing (visual/data). But I should double-check. The key part is \"Instruction-based 3D Editing,\" which implies using textual instructions to guide the 3D editing process. That's combining different modalities (text and 3D data), so multimodal makes sense. The noise prediction part is about the method, but the multimodal aspect is about the input types. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32519@AAAI"},
{"title": "A Compact Implicit Neural Representation for Efficient Storage of Massive 4D Functional Magnetic Resonance Imaging", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Compact Implicit Neural Representation for Efficient Storage of Massive 4D Functional Magnetic Resonance Imaging.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"4D functional magnetic resonance imaging\" – 4D usually refers to three spatial dimensions plus time, so fMRI data over time. That makes me think of time-series because it's data collected over time. The paper is about storing this data efficiently using a neural representation. So maybe time-series?\n\nBut wait, the other options. Multimodal usually involves combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is more about using external information in models. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about combining different data types, retrieval, or knowledge graphs. It's focused on storage efficiency for 4D fMRI data, which is time-dependent. So time-series seems the most likely. The key here is the 4D aspect implying time, and the problem is about storage, which is a common issue in time-series data handling. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32520@AAAI"}
{"title": "Unsupervised Photometric-Consistent Depth Estimation from Endoscopic Monocular Video", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unsupervised Photometric-Consistent Depth Estimation from Endoscopic Monocular Video.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Unsupervised\" suggests the method doesn't use labeled data. \"Photometric-Consistent\" might relate to image consistency, maybe using visual data. \"Depth Estimation\" is about determining depth from images, which is a common task in computer vision. \"Endoscopic Monocular Video\" refers to using a single camera (monocular) in an endoscopic setting, like medical imaging.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This paper is about video, which is a sequence of images over time, so maybe time-series? But the main focus here is on depth estimation from video, not analyzing temporal patterns. So maybe not the best fit.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions monocular video, which is a single modality (visual), so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks, like in NLP. This paper doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about depth estimation, which doesn't involve building or using knowledge graphs. So KG is out.\n\nSo the options left are time-series or none. The video aspect could be considered time-series data, but the core problem here is depth estimation using photometric consistency, which is more about computer vision techniques. Since the main focus isn't on time-series analysis but rather on a specific computer vision task, maybe it doesn't fit any of the given topics. The answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32521@AAAI"},
{"title": "DigitalLLaVA: Incorporating Digital Cognition Capability for Physical World Comprehension in Multimodal LLMs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DigitalLLaVA: Incorporating Digital Cognition Capability for Physical World Comprehension in Multimodal LLMs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal LLMs\" is right there. Multimodal refers to models that can process multiple types of data, like text and images. The paper is about enhancing these models with digital cognition for understanding the physical world. So the key term here is \"Multimodal,\" which is one of the options. \n\nThe other parts of the title mention \"Digital Cognition Capability\" and \"Physical World Comprehension,\" but those don't directly point to the other topics. Time-series is about data over time, which isn't mentioned here. RAG (Retrieval-Augmented Generation) involves using retrieval systems to augment model outputs, and KG (Knowledge Graphs) are structured representations of knowledge. The title doesn't mention anything about retrieval or knowledge graphs. \n\nSo the main clue is \"Multimodal LLMs.\" Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32522@AAAI"},
{"title": "AIM: Additional Image Guided Generation of Transferable Adversarial Attacks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AIM: Additional Image Guided Generation of Transferable Adversarial Attacks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Additional Image Guided\" suggests that images are involved. \"Transferable Adversarial Attacks\" refers to creating adversarial examples that can fool different models. Adversarial attacks in machine learning, especially in computer vision, often involve modifying images to cause misclassification. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal usually refers to combining multiple types of data, like text and images. The title mentions images, but does it combine with another modality? The term \"Additional Image Guided\" might imply using images as a guide, but it's not clear if another modality is involved. Maybe it's using images to generate adversarial examples, but not necessarily combining with another data type. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks, like in language models. The title doesn't mention retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo the remaining options are either multimodal or none. Wait, the paper is about generating adversarial attacks using images. Adversarial attacks are a security topic in machine learning, particularly in computer vision. The key here is whether it's multimodal. If the attack uses images (a single modality) to generate adversarial examples, then it's not multimodal. Multimodal would require combining two or more modalities, like text and images. Since the title only mentions images, maybe it's not multimodal. \n\nBut wait, \"Additional Image Guided\" – maybe \"additional\" refers to using another image or some other data? Not sure. The main focus is on generating adversarial attacks that are transferable, which is a specific area in ML security. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to adversarial attacks or ML security, maybe the answer is \"none.\" \n\nBut wait, the options are time-series, multimodal, RAG, KG. The paper is about adversarial attacks in image generation. None of these topics seem to fit. So the correct answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32523@AAAI"},
{"title": "Generative Planning with 3D-Vision Language Pre-training for End-to-End Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generative Planning with 3D-Vision Language Pre-training for End-to-End Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Generative Planning\" suggests some kind of model that generates plans, maybe for autonomous driving. \"3D-Vision Language Pre-training\" implies that the model uses both visual data (3D vision) and language, so combining different modalities like images and text. \"End-to-End Autonomous Driving\" is the application area.\n\nMultimodal usually refers to models that process multiple types of data, like combining text, images, audio, etc. Since the title mentions both 3D vision (visual data) and language (text), that's a strong indicator of multimodal. \n\nTime-series would involve data that's sequential over time, like stock prices or sensor data over time. The title doesn't mention anything about time sequences, so probably not time-series.\n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate responses. The title doesn't mention retrieval or augmentation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so KG is probably not it either.\n\nSo the most fitting topic here is multimodal because it combines vision and language.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32524@AAAI"},
{"title": "Hyperbolic-Constraint Point Cloud Reconstruction from Single RGB-D Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hyperbolic-Constraint Point Cloud Reconstruction from Single RGB-D Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Point Cloud Reconstruction\" suggests it's about 3D data, maybe using depth information. \"Single RGB-D Images\" means the input is a combination of color (RGB) and depth (D) data from one image. So, the input is multimodal because it uses both visual and depth data. \n\nNow, the options are time-series, multimodal, RAG, or KG. Time-series would involve data over time, like sequences or temporal data. This paper is about reconstructing a point cloud from a single image, so time-series doesn't seem right. \n\nMultimodal is about combining different types of data. Since RGB-D uses both color and depth, that's two modalities. So maybe multimodal is the answer. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks, like in NLP. This paper doesn't mention anything about retrieval or generation, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about knowledge graphs or structured data, so that's out. \n\nSo the most likely answer is multimodal. The paper uses RGB and depth data together, which are different modalities. Even though the main task is reconstruction, the input is multimodal. I don't see any mention of time-series, RAG, or KG here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32525@AAAI"},
{"title": "Towards Realistic Semi-supervised Medical Image Classification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Realistic Semi-supervised Medical Image Classification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Semi-supervised\" refers to a machine learning approach where the model uses both labeled and unlabeled data. \"Medical Image Classification\" suggests that the focus is on images, probably from medical scans or similar. \n\nNow, looking at the options. Time-series deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to using multiple types of data, like combining images with text or audio. The title only mentions image classification, so maybe not multimodal unless there's an implication of combining different data types, but the title doesn't specify that. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval of information with generating responses, often in NLP tasks. The title is about classification, not generation, so RAG seems unlikely. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about building or using a knowledge graph, so that's probably not it either. \n\nSo, the paper is about semi-supervised learning in medical image classification. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The closest might be multimodal if the images are combined with other data types, but the title doesn't indicate that. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32526@AAAI"},
{"title": "Transferable Adversarial Face Attack with Text Controlled Attribute", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Transferable Adversarial Face Attack with Text Controlled Attribute.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Adversarial Face Attack\" suggests it's about creating adversarial examples in facial recognition. \"Transferable\" means the attack works across different models. \"Text Controlled Attribute\" implies that text is used to control some attributes of the attack. \n\nNow, the topics. Time-series is about data over time, like stock prices or weather. This doesn't seem related. Multimodal involves combining different data types, like text and images. Here, the attack uses text to control attributes of a face, which is an image. So that's combining text and images, making it multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships. The paper doesn't mention knowledge graphs or retrieval-augmented generation. \n\nSo the key here is the combination of text (a modality) and face images (another modality) to create an adversarial attack. That fits the multimodal category.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32527@AAAI"},
{"title": "MambaLCT: Boosting Tracking via Long-term Context State Space Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MambaLCT: Boosting Tracking via Long-term Context State Space Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"MambaLCT\" is probably the model name. \"Boosting Tracking\" suggests it's about improving some kind of tracking system. \"Long-term Context State Space Model\" is the key part here. State space models are often used in time-series analysis because they model the state of a system over time. The mention of \"long-term context\" implies that the model is handling sequences of data over extended periods, which is typical in time-series problems. \n\nNow, checking the options. Time-series research deals with data points indexed in time order, often using models like RNNs, LSTMs, or more recently, state space models. The State Space Model (SSM) mentioned here is a classic time-series approach. The other options: multimodal would involve combining different data types (like text and images), RAG is Retrieval-Augmented Generation, and KG is Knowledge Graphs. None of those seem to fit the title. The focus here is on temporal data and context over time, so time-series is the most likely category.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32528@AAAI"},
{"title": "PersonaMagic: Stage-Regulated High-Fidelity Face Customization with Tandem Equilibrium", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PersonaMagic: Stage-Regulated High-Fidelity Face Customization with Tandem Equilibrium.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"PersonaMagic\" sounds like a system or method name. \"Stage-Regulated\" might refer to different stages in a process. \"High-Fidelity Face Customization\" suggests creating realistic faces, maybe in computer graphics or AI. \"Tandem Equilibrium\" could be a technique they're using. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or weather. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper's focus seems to be on face customization, which is likely in computer vision or generative models. High-fidelity face generation might involve multimodal data if it uses both images and text, but the title doesn't mention combining different modalities. \"Stage-Regulated\" might refer to a pipeline with multiple stages, but that's more about the method's structure. Tandem Equilibrium could be a novel approach, but without more context, it's hard to say. Since none of the keywords directly point to time-series, RAG, or KG, and multimodal isn't clearly indicated either, maybe it's none. But wait, if it's about generating faces, maybe it's multimodal if it uses different inputs. However, the title doesn't specify combining modalities. So perhaps it's none of the listed topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32529@AAAI"},
{"title": "Feature Denoising Diffusion Model for Blind Image Quality Assessment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Feature Denoising Diffusion Model for Blind Image Quality Assessment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Blind Image Quality Assessment\" refers to evaluating the quality of an image without any reference, which is a common problem in image processing. The method mentioned is a \"Feature Denoising Diffusion Model.\" Diffusion models are a type of generative model, often used in image generation or denoising. The term \"feature denoising\" suggests that the model is working on features extracted from images, trying to remove noise from them.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. This paper is about images, so time-series doesn't seem relevant. Multimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so maybe not multimodal. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. The paper's focus is on image quality assessment, not on generating text or using retrieval. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo, the paper is about image quality assessment using a diffusion model. None of the listed topics (time-series, multimodal, RAG, KG) directly relate to this. The model is a type of machine learning model for image processing, but it doesn't fit into any of the four categories provided. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32530@AAAI"}
{"title": "Mamba-CAD: State Space Model for 3D Computer-Aided Design Generative Modeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Mamba-CAD: State Space Model for 3D Computer-Aided Design Generative Modeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"State Space Model\" makes me think of models that handle sequences or time-based data, like in time-series analysis. But wait, the application here is for 3D CAD generative modeling. So maybe it's using a state space model (like SSM) for generating 3D designs. \n\nTime-series typically involves data points indexed in time order. If the model is generating 3D models step by step or in a sequence, maybe that's time-series. But CAD modeling is more about spatial structures. However, some generative models for 3D might use sequential approaches. For example, Mamba is a type of state space model that's been used in vision tasks, which are spatial, not temporal. So maybe it's not time-series.\n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation. The title doesn't mention retrieval or using external data during generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about generative modeling for CAD, not about building or using knowledge graphs. So likely not KG.\n\nSo the remaining option is time-series. But wait, state space models can be used in both time-series and other domains. Since the application here is 3D CAD, which is spatial, maybe the model is using a state space approach for spatial data. However, the term \"State Space Model\" is often associated with time-series processing. But in recent research, models like Mamba have been applied to vision tasks (which are spatial) using state space models. So maybe the paper is using a state space model for spatial data, not time-series. In that case, it might not fit into the time-series category. But the options given are time-series, multimodal, RAG, KG. If the model is a state space model but applied to spatial data, does that still count as time-series? Or is time-series strictly for temporal data?\n\nHmm. The user's options are specific. If the paper is using a state space model for 3D CAD, which is a generative model, and the state space model is a type of model that's typically used in time-series, but here applied to spatial data, then maybe it's not time-series. But the user might categorize it under time-series if the model is a state space model regardless of the application. Alternatively, maybe the model is generating 3D models in a sequential manner, which could be considered time-series. For example, generating parts of the model step by step over time. But the title doesn't specify that. It just says \"State Space Model for 3D CAD Generative Modeling.\" \n\nGiven the options, the closest might be time-series because the model is a state space model, which is often associated with time-series. But I'm not entirely sure. Alternatively, if the model is using a state space approach for spatial data, maybe it's not time-series. However, the user's categories are strict. Since the model is a state space model, and time-series is one of the options, perhaps the answer is time-series. But I'm a bit conflicted here. Let me check if there's any other clues. The title mentions \"generative modeling,\" which could be part of time-series if generating sequences, but again, 3D CAD is spatial. \n\nAlternatively, maybe the paper is using a state space model for the structure of the 3D model, which is spatial. In that case, it's not time-series. But the user's options don't have a spatial category. So if the model is a state space model, regardless of application, maybe it's considered time-series. But I'm not certain. However, given the options, the most plausible answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32531@AAAI"},
{"title": "StructSR: Refuse Spurious Details in Real-World Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"StructSR: Refuse Spurious Details in Real-World Image Super-Resolution.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Image Super-Resolution\" refers to enhancing the resolution of images, which is a computer vision task. The key terms here are \"image\" and \"super-resolution.\" Now, the four options given are time-series, multimodal, RAG, and KG.\n\nTime-series usually involves data points indexed in time order, like stock prices over time. That doesn't seem related to image processing. Multimodal refers to using multiple types of data, like combining text and images. The paper's title doesn't mention anything about combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. That's more about text generation with retrieval. KG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, not directly related to image super-resolution.\n\nThe paper's focus is on improving image super-resolution by refusing spurious details. The methods here are likely related to computer vision techniques, maybe using neural networks or other image processing algorithms. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to image super-resolution or the specific techniques mentioned in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32532@AAAI"},
{"title": "Image Conductor: Precision Control for Interactive Video Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Image Conductor: Precision Control for Interactive Video Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. The paper is about video synthesis, which does involve sequences of frames over time. So maybe time-series? But I'm not sure yet.\n\nMultimodal refers to combining multiple types of data, like text and images. The title mentions \"Image Conductor\" and \"Interactive Video Synthesis,\" which might involve different modalities. But the focus here seems to be on controlling the video synthesis process, not necessarily combining different data types.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that uses retrieval of information to enhance generation tasks. The title doesn't mention anything about retrieval or augmenting with external data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't seem to be about building or using knowledge graphs, so that's probably not it either.\n\nSo, back to time-series. Video is a sequence of images over time, so video synthesis could be considered a time-series problem. However, sometimes video synthesis is categorized under computer vision or multimodal if it combines different inputs. But the key here is \"precision control for interactive video synthesis.\" The term \"interactive\" might imply real-time or user interaction, which could involve time-series processing. But I'm still a bit torn between time-series and multimodal.\n\nWait, multimodal would require combining different modalities like text, audio, and video. If the paper is about generating video with precise control, maybe it's using text or other inputs to guide the video generation. But the title doesn't specify that. It just mentions \"Image Conductor,\" which might be a method for controlling the video's visual aspects over time. \n\nHmm. Since the options are time-series, multimodal, RAG, or KG, and the paper is about video synthesis with precision control, I think the best fit is time-series because video is inherently a time-based sequence. Even though multimodal could be a possibility if it's combining different inputs, the title doesn't mention that. So I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32533@AAAI"},
{"title": "Text and Image Are Mutually Beneficial: Enhancing Training-Free Few-Shot Classification with CLIP", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Text and Image Are Mutually Beneficial: Enhancing Training-Free Few-Shot Classification with CLIP.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. It mentions \"Text and Image,\" which immediately makes me think of combining different data types. That's a hint towards multimodal, since multimodal typically involves integrating multiple modalities like text, images, audio, etc. The phrase \"mutually beneficial\" suggests that both modalities are being used together to enhance performance. \n\nThen there's \"CLIP\" mentioned. CLIP is a model developed by OpenAI that's known for its multimodal capabilities, specifically for understanding the relationship between images and text. So using CLIP in the context of text and image processing definitely points towards multimodal research. \n\nThe rest of the title talks about \"Training-Free Few-Shot Classification.\" Few-shot learning is a common problem in machine learning where the model is trained to recognize new classes with very few examples. Training-free implies that the model doesn't require additional training, which might be leveraging pre-trained models like CLIP. But the key here is the combination of text and image data, which is the hallmark of multimodal approaches. \n\nLooking at the other options: time-series would involve data points indexed in time order, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, often in NLP. KG (Knowledge Graph) involves structured data representations. None of these seem to fit the title's focus on combining text and image data. \n\nSo putting it all together, the paper is about using both text and image modalities together, leveraging CLIP, which is a multimodal model. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32534@AAAI"},
{"title": "RCTrans: Radar-Camera Transformer via Radar Densifier and Sequential Decoder for 3D Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RCTrans: Radar-Camera Transformer via Radar Densifier and Sequential Decoder for 3D Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components are Radar-Camera Transformer. So, they're using both radar and camera data. That immediately makes me think of multimodal because it's combining different types of data (radar and camera). Multimodal usually refers to integrating multiple data modalities, like text and images, or in this case, radar and camera. \n\nThen there's the Radar Densifier and Sequential Decoder. The Sequential Decoder might relate to processing sequences, which could be time-series, but the main focus here seems to be on combining radar and camera inputs. The application is 3D object detection, which is a computer vision task. \n\nRAG (Retrieval-Augmented Generation) is more about using retrieval mechanisms in generative models, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't appear relevant. Time-series would involve data over time, but the key here is the fusion of different sensor data. \n\nSo, the primary research topic here is multimodal since it's integrating radar and camera data for a detection task. The other components like the transformer and sequential decoder are methods, but the core topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32535@AAAI"},
{"title": "Micro-macro Wavelet-based Gaussian Splatting for 3D Reconstruction from Unconstrained Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Micro-macro Wavelet-based Gaussian Splatting for 3D Reconstruction from Unconstrained Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on 3D reconstruction using a method called Gaussian Splatting, which is wavelet-based. The terms \"micro-macro\" might refer to different scales or levels of detail in the reconstruction. The input is \"unconstrained images,\" meaning the images aren't taken under controlled conditions, like from a specific setup.\n\nNow, looking at the possible topics. Time-series research usually involves data collected over time, like stock prices or sensor data over time. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal typically involves combining different types of data, like text and images, or audio and video. The title here is about 3D reconstruction from images, but it doesn't mention combining different modalities. Unless the images themselves are from different sources or types, but the term \"unconstrained\" might refer to varying viewpoints or lighting, not different data types. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to augment its responses. This paper is about 3D reconstruction, which is more computer vision, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper were about building or using a knowledge graph, that would fit. But the title is about a specific algorithm for 3D reconstruction, not about knowledge representation.\n\nSo none of the four topics seem to fit. The paper is about a specific technique in 3D reconstruction using wavelets and Gaussian splatting, which is a computer vision topic. Since the options given don't include computer vision or 3D reconstruction, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32536@AAAI"},
{"title": "DAPoinTr: Domain Adaptive Point Transformer for Point Cloud Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DAPoinTr: Domain Adaptive Point Transformer for Point Cloud Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Point Cloud Completion\" refers to the task of reconstructing or completing missing parts of a 3D point cloud. The method mentioned is a \"Domain Adaptive Point Transformer,\" which suggests they're using a transformer model adapted to different domains. \n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually combines different data types, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on point cloud data, which is 3D spatial data. The domain adaptation part is about making the model work across different domains, but the core task is point cloud completion. None of the four topics directly relate to 3D point clouds or domain adaptation in this context. Time-series is about temporal data, which isn't the case here. Multimodal would require combining different modalities, but the paper is about a single modality (point clouds). RAG and KG don't seem relevant here either. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32537@AAAI"},
{"title": "Patch-level Sounding Object Tracking for Audio-Visual Question Answering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Patch-level Sounding Object Tracking for Audio-Visual Question Answering.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Audio-Visual\" immediately makes me think of multimodal because it's combining two modalities—audio and visual. Multimodal research deals with integrating different types of data, like text, images, audio, etc. So that's a strong hint towards the multimodal category.\n\nNext, \"Question Answering\" is a common task in NLP and multimodal settings. The fact that it's audio-visual suggests that the model is using both audio and visual information to answer questions, which is a classic multimodal problem. \n\nNow, checking the other options. Time-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about sequences over time, so probably not time-series. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, often in text-based tasks. The title doesn't mention retrieval or generation, so RAG is unlikely. \n\nKG (Knowledge Graphs) involve structured data and relationships between entities. The title doesn't reference knowledge graphs or structured data, so that's probably not it either. \n\nPutting it all together, the key elements are audio-visual data integration for a task, which points to multimodal. The mention of \"patch-level\" might refer to how the model processes parts of the audio and visual data, but the core aspect is combining different modalities. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32538@AAAI"},
{"title": "Sparse Transfer Learning Accelerates and Enhances Certified Robustness: A Comprehensive Study", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sparse Transfer Learning Accelerates and Enhances Certified Robustness: A Comprehensive Study.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Sparse Transfer Learning\" – transfer learning is a concept in machine learning where a model trained on one task is adapted to another related task. The term \"sparse\" here might refer to using fewer parameters or features, making the model more efficient. \n\nThen, \"Accelerates and Enhances Certified Robustness.\" Certified robustness is about ensuring that a model's predictions are reliable even when inputs are perturbed, like in adversarial attacks. So the paper is probably discussing methods to make models robust in a way that's mathematically guaranteed (certified), and transfer learning is being used to achieve this more efficiently.\n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The title doesn't mention retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about graphs or knowledge bases, so that's probably not it.\n\nSo the paper is about transfer learning and robustness. None of the four topics (time-series, multimodal, RAG, KG) directly relate to transfer learning or robustness. The paper's focus is on a specific ML technique (sparse transfer learning) and its application to robustness. Since none of the listed topics match, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32539@AAAI"},
{"title": "ENCODER: Entity Mining and Modification Relation Binding for Composed Image Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ENCODER: Entity Mining and Modification Relation Binding for Composed Image Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Entity Mining\" and \"Modification Relation Binding\" suggest working with entities and their relationships. \"Composed Image Retrieval\" implies that the research is about retrieving images that are composed, maybe combining different elements. \n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem to fit here. Multimodal usually involves combining different data types like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models. KG (Knowledge Graph) involves structured data representing entities and their relations. \n\nThe paper's focus on entity mining and modification relations sounds like it's dealing with structured knowledge, which aligns with Knowledge Graphs. The composed image retrieval part might involve using a knowledge graph to understand how entities and their modifications relate in images. So, the main topic here is likely KG. I don't see strong indicators for the other topics. Multimodal could be a stretch if it's combining text and images, but the title doesn't mention that. RAG and time-series are not relevant here. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32541@AAAI"}
{"title": "ENCODER: Entity Mining and Modification Relation Binding for Composed Image Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ENCODER: Entity Mining and Modification Relation Binding for Composed Image Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Entity Mining\" and \"Modification Relation Binding\" suggest working with entities and their relationships. \"Composed Image Retrieval\" implies that the research is about retrieving images that are composed, maybe combining different elements. \n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem to fit here. Multimodal usually involves combining different data types like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models. KG (Knowledge Graph) involves structured data representing entities and their relations. \n\nThe paper's focus on entity mining and modification relations sounds like it's dealing with structured knowledge, which aligns with Knowledge Graphs. The composed image retrieval part might involve using a knowledge graph to understand how entities and their modifications relate in images. So, the main topic here is likely KG. I don't see strong indicators for the other topics. Multimodal could be a stretch if it's combining text and images, but the title doesn't mention that. RAG and time-series are not relevant here. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32541@AAAI"},
{"title": "ProsodyTalker: 3D Visual Speech Animation via Prosody Decomposition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ProsodyTalker: 3D Visual Speech Animation via Prosody Decomposition.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"3D Visual Speech Animation\" suggests creating a visual representation of speech, probably using 3D models. \"Prosody Decomposition\" refers to breaking down the prosody, which is the rhythm, stress, and intonation in speech. So the paper is about generating 3D animations of speech by analyzing prosody.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal deals with combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which uses external information during generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about creating visual speech animations. That involves processing speech (audio) and generating visual output (3D animation). So it's combining different modalities—audio and visual. That sounds like multimodal. Time-series might be involved in the audio processing, but the main focus here is on integrating different data types (speech and visuals) to create an animation. RAG and KG don't seem relevant here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32542@AAAI"},
{"title": "Exploring the Potential of Large Vision-Language Models for Unsupervised Text-Based Person Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring the Potential of Large Vision-Language Models for Unsupervised Text-Based Person Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Large Vision-Language Models\" – that part sounds like combining vision and language, which are two different modalities. So that's probably multimodal. Then \"Unsupervised Text-Based Person Retrieval\" – they're using text to retrieve person information without supervision. But the key here is the use of vision and language models together. \n\nTime-series would involve data over time, like stock prices or weather data. This doesn't seem to fit. RAG is Retrieval-Augmented Generation, which is more about using retrieval to enhance generation in models, but the title mentions unsupervised retrieval, not generation. KG is Knowledge Graphs, which are structured data representations, and the title doesn't mention anything about graphs or structured knowledge. \n\nSo the main clue is the combination of vision and language models. That's a classic multimodal setup. The task is person retrieval using text, but the model is vision-language, which is multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32543@AAAI"},
{"title": "VidEvent: A Large Dataset for Understanding Dynamic Evolution of Events in Videos", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VidEvent: A Large Dataset for Understanding Dynamic Evolution of Events in Videos.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"VidEvent\" suggests it's related to videos and events. The dataset is for understanding the dynamic evolution of events in videos. So, dynamic evolution over time in videos. \n\nTime-series analysis deals with data points indexed in time order. Since the dataset is about events evolving over time in videos, that might fit. But wait, videos are a sequence of frames, so they inherently have a time component. But does the paper focus on time-series modeling specifically? The title mentions \"dynamic evolution,\" which implies changes over time, so maybe time-series is a candidate.\n\nMultimodal refers to combining multiple data types, like text, images, audio. The title doesn't mention multiple modalities, just videos. Unless the dataset includes other modalities alongside video, but the title doesn't specify that. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about a dataset for events in videos, not about building or using knowledge graphs. So likely not KG.\n\nSo the main contenders are time-series and multimodal. Since the dataset is for understanding dynamic events in videos, which are sequences over time, time-series seems plausible. But I should check if \"dynamic evolution\" is a key aspect here. Time-series analysis often involves analyzing data points over time, so if the paper's focus is on modeling the temporal aspects of events in videos, then time-series would be the right category. However, if the dataset is just a collection of videos without a specific focus on temporal modeling, maybe it's more about video understanding in general, which might not fit into the given categories. But given the options, time-series seems the closest. Alternatively, if the dataset is multimodal (e.g., combining video with text or audio), then multimodal would be the answer. But the title doesn't mention other modalities. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32544@AAAI"},
{"title": "Semantic-guided Masked Mutual Learning for Multi-modal Brain Tumor Segmentation with Arbitrary Missing Modalities", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Semantic-guided Masked Mutual Learning for Multi-modal Brain Tumor Segmentation with Arbitrary Missing Modalities.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the title. That suggests it's about using multiple data modalities, like different types of data (e.g., images, text, etc.) in the context of brain tumor segmentation. The term \"multi-modal\" directly points to the multimodal research area. \n\nThe other parts of the title mention \"masked mutual learning\" and handling \"arbitrary missing modalities.\" That part is about dealing with missing data in the modalities, which is a common challenge in multimodal learning. The method proposed is semantic-guided, which might involve using semantic information to guide the learning process when some modalities are missing. \n\nNow, checking the other options. Time-series would involve data over time, like sequences. The title doesn't mention anything about time or sequences, so probably not that. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, often in NLP. The paper is about segmentation in medical imaging, so RAG doesn't seem relevant here. KG (Knowledge Graphs) involve structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so that's out. \n\nTherefore, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32545@AAAI"},
{"title": "Look Inside for More: Internal Spatial Modality Perception for 3D Anomaly Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Look Inside for More: Internal Spatial Modality Perception for 3D Anomaly Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Internal Spatial Modality Perception\" – modality usually refers to different types of data inputs, like text, image, audio. So if it's about spatial modality, maybe it's using different data types. But the term \"internal\" might mean they're focusing on a specific modality within the model. However, the key part here is \"modality,\" which often relates to multimodal research where multiple data types are used together. But the title doesn't explicitly mention combining multiple modalities; it's about internal spatial modality. Hmm.\n\nThe task is 3D anomaly detection. Anomaly detection can be done in various domains. Time-series is about temporal data, but this is 3D, which is more spatial. So time-series is probably not it. RAG (Retrieval-Augmented Generation) is about using external knowledge for generation tasks, which doesn't seem related here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nMultimodal typically involves integrating different data types. The paper's focus on \"spatial modality\" might imply using a specific modality, but the term \"modality\" in the title could suggest that they are considering spatial aspects as a modality. However, if it's about internal perception within a model, maybe it's not combining multiple modalities. Wait, the title says \"Internal Spatial Modality,\" which might mean they're enhancing the model's ability to perceive spatial information internally, not combining with other modalities. So maybe it's not multimodal. \n\nAlternatively, maybe the model is using multiple modalities, but the title is focusing on the spatial aspect. But without explicit mention of combining different modalities (like text and image), it's hard to say. The term \"modality\" in the title could be a red herring. The main focus is on 3D anomaly detection using spatial perception. Since the options are time-series, multimodal, RAG, or KG, and none of these seem to fit perfectly, but the closest might be multimodal if they are using spatial modality as one of the modalities. However, if the paper is about improving spatial perception within a single modality (like 3D data), then it's not multimodal. \n\nGiven that, maybe the answer is none. But wait, the user wants to check if it's one of the four. Let me think again. The term \"modality\" in the title is part of \"Internal Spatial Modality Perception.\" If \"modality\" here refers to different types of data (like different sensors or data types), then it's multimodal. But if it's about the model's internal processing of spatial data, then it's not. The title is a bit ambiguous. However, given the options, the most likely is multimodal if they are considering spatial modality as a separate modality. But without more context, it's tricky. Alternatively, maybe it's none. But I need to decide. Since the title mentions \"modality,\" perhaps it's related to multimodal. But I'm not entirely sure. Maybe the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32546@AAAI"},
{"title": "Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Monocular 3D Semantic Scene Completion\" suggests that the research is about creating a 3D scene from a single 2D image, adding semantic information. The method used is \"Skip Mamba Diffusion.\" I'm not familiar with \"Mamba\" in this context, but \"diffusion\" might refer to diffusion models, which are a type of generative model. \n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on 3D scene completion from a single image. That seems more like a computer vision task, possibly using generative models. Since it's about generating 3D data from 2D, maybe using a diffusion model. None of the four topics directly relate to this. Time-series is about sequences over time, which isn't the case here. Multimodal would require combining different modalities, but the input is monocular (single image), so maybe not. RAG and KG don't seem relevant here either. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32547@AAAI"},
{"title": "DriveEditor: A Unified 3D Information-Guided Framework for Controllable Object Editing in Driving Scenes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DriveEditor: A Unified 3D Information-Guided Framework for Controllable Object Editing in Driving Scenes.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"DriveEditor\" suggests it's related to driving scenes. \"3D Information-Guided\" might imply using 3D data, which could be part of multimodal if it combines different data types like images, LiDAR, etc. \"Controllable Object Editing\" probably means modifying objects in the scene, maybe in a simulation or real-world setting. \n\nTime-series usually involves data over time, like sequences. If the paper is about editing over time, maybe, but the title doesn't mention time or sequences. RAG (Retrieval-Augmented Generation) is about using retrieved information to enhance generation, which doesn't seem to fit here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem to be the case here. \n\nMultimodal could be a fit if they're using multiple modalities like visual, 3D, and maybe sensor data in driving scenes. The \"3D Information-Guided\" part might combine different data types (like images and 3D models) for editing. So, multimodal seems possible. \n\nAlternatively, if it's just about 3D data without combining different modalities, maybe it's not multimodal. But the term \"unified framework\" might suggest integrating different data sources. So I think multimodal is the best fit here. The other options don't seem to apply. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32548@AAAI"},
{"title": "S-INF: Towards Realistic Indoor Scene Synthesis via Scene Implicit Neural Field", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"S-INF: Towards Realistic Indoor Scene Synthesis via Scene Implicit Neural Field.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Scene Implicit Neural Field\" sounds like it's related to neural networks and scene generation. The goal is realistic indoor scene synthesis. So, they're probably using some kind of neural field to generate 3D scenes or images. \n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal would involve combining different data types, like text and images. The title mentions scene synthesis, which might involve multiple modalities, but the key term here is \"Implicit Neural Field,\" which I'm not sure about. Maybe it's using different data sources, but the main focus seems to be on the neural field method.\n\nRAG stands for Retrieval-Augmented Generation. That's typically used in models that retrieve information from a database and then generate text based on that. The title doesn't mention anything about retrieval or augmenting generation with external data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's focus is on scene synthesis, which is more about generating visual data rather than building or using a knowledge graph. So KG seems unlikely.\n\nSo, the options left are multimodal or none. But the title doesn't explicitly mention combining multiple modalities. The term \"Scene Implicit Neural Field\" might be a specific technique in computer vision or 3D scene generation. Since none of the four topics (time-series, multimodal, RAG, KG) clearly fit, the answer might be \"none.\" But wait, maybe multimodal is a stretch here. If the scene synthesis uses multiple modalities like images, depth, and text, then it could be multimodal. However, the title doesn't specify that. The key term is \"Implicit Neural Field,\" which I think is more about the model architecture rather than the data modalities. So I'm leaning towards \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32549@AAAI"},
{"title": "Progressive Distribution Matching for Federated Semi-Supervised Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Progressive Distribution Matching for Federated Semi-Supervised Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Progressive Distribution Matching\" sounds like a method or technique. \"Federated Semi-Supervised Learning\" is the application area. Federated learning is about training models across decentralized data sources, right? Semi-supervised learning uses both labeled and unlabeled data. So the paper is about a method for federated semi-supervised learning.\n\nNow, the four options. Time-series would involve data over time, like stock prices or weather. Multimodal deals with multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which combines retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time, so probably not time-series. There's no indication of multiple modalities either. RAG and KG are more about specific models or data structures. The paper's focus is on distribution matching in a federated learning setup, which is more about the learning algorithm and data distribution alignment. None of the four topics directly relate to federated learning or semi-supervised methods. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32551@AAAI"}
{"title": "Progressive Distribution Matching for Federated Semi-Supervised Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Progressive Distribution Matching for Federated Semi-Supervised Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Progressive Distribution Matching\" sounds like a method or technique. \"Federated Semi-Supervised Learning\" is the application area. Federated learning is about training models across decentralized data sources, right? Semi-supervised learning uses both labeled and unlabeled data. So the paper is about a method for federated semi-supervised learning.\n\nNow, the four options. Time-series would involve data over time, like stock prices or weather. Multimodal deals with multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which combines retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time, so probably not time-series. There's no indication of multiple modalities either. RAG and KG are more about specific models or data structures. The paper's focus is on distribution matching in a federated learning setup, which is more about the learning algorithm and data distribution alignment. None of the four topics directly relate to federated learning or semi-supervised methods. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32551@AAAI"},
{"title": "Multi-Granularity Video Object Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Granularity Video Object Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Video Object Segmentation\" refers to identifying and segmenting objects in video frames. The term \"Multi-Granularity\" suggests that the segmentation is done at different levels of detail or scales. \n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices over time. This paper is about video, which is a sequence of images over time, so maybe time-series? But video processing isn't always categorized under time-series. Time-series is more about numerical data over time, whereas video is more about spatial and temporal data in images.\n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention combining different data types, just video segmentation. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. Doesn't seem related to video segmentation.\n\nKG is Knowledge Graph, which is a structured representation of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data.\n\nSo, the options left are time-series or none. But video is a sequence of frames, which is temporal data. However, in academic terms, video processing is often considered under computer vision rather than time-series analysis. Time-series is more about numerical sequences, while video is more about spatial and temporal analysis in images. So maybe this doesn't fit into any of the given categories. The answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32552@AAAI"},
{"title": "NightHaze: Nighttime Image Dehazing via Self-Prior Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"NightHaze: Nighttime Image Dehazing via Self-Prior Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. This paper is about image dehazing, which is an image processing task. So probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The title mentions nighttime images, but there's no indication of combining different modalities. It's focused on image dehazing using a self-prior learning method. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The paper's title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about image processing, not building or using knowledge graphs. So KG is probably not the right fit.\n\nThe paper is about a specific image processing technique using self-prior learning. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32553@AAAI"},
{"title": "DreamFit: Garment-Centric Human Generation via a Lightweight Anything-Dressing Encoder", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DreamFit: Garment-Centric Human Generation via a Lightweight Anything-Dressing Encoder.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about generating humans with garments, which might involve images and maybe text descriptions. But the title doesn't explicitly say it's using multiple modalities. Hmm.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text based on that. The title mentions \"Garment-Centric Human Generation,\" but I don't see anything about retrieval or augmenting generation with retrieved data. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus seems to be on generating images of humans with clothing, not on building or using a knowledge graph. So probably not KG.\n\nThe key part here is \"Garment-Centric Human Generation.\" This sounds like generating images of people wearing clothes, which is a computer vision or graphics task. The \"Lightweight Anything-Dressing Encoder\" suggests an encoder model that can handle various garments. But none of the four topics (time-series, multimodal, RAG, KG) directly relate to image generation or computer vision. The closest might be multimodal if it uses different data types, but the title doesn't specify that. Since the paper's focus is on generating images and not on the listed topics, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32554@AAAI"},
{"title": "Adversarial Attacks on Event-Based Pedestrian Detectors: A Physical Approach", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adversarial Attacks on Event-Based Pedestrian Detectors: A Physical Approach.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Adversarial Attacks\" refers to methods used to fool machine learning models, which is a common topic in security and AI. \"Event-Based Pedestrian Detectors\" suggests that the system is detecting pedestrians using event-based sensors, which are different from traditional frame-based cameras. Event-based sensors capture changes in light intensity asynchronously, which is more like a time-series of events rather than discrete frames. So maybe time-series is a possibility here.\n\n\"Multimodal\" would involve using multiple types of data, like combining images with text or audio. The title doesn't mention multiple modalities, so that's probably not it. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, like in language models. The paper doesn't mention anything about retrieval or generation, so RAG is out. KG (Knowledge Graphs) involve structured data and relationships between entities. Again, the title doesn't hint at knowledge graphs.\n\nThe key part here is \"event-based,\" which relates to time-series data because events are happening over time. Pedestrian detectors using event-based sensors would process a stream of events, which is inherently time-series data. Even though adversarial attacks are a general topic, the specific application here is in a system that uses time-series data. So the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32555@AAAI"},
{"title": "Decoupling Appearance Variations with 3D Consistent Features in Gaussian Splatting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Decoupling Appearance Variations with 3D Consistent Features in Gaussian Splatting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Decoupling Appearance Variations\" suggests they're trying to separate different aspects of appearance. \"3D Consistent Features\" implies working with 3D data, maybe in computer vision. \"Gaussian Splatting\" is a technique used in rendering 3D scenes, often in computer graphics or vision tasks. \n\nNow, the four options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using external data in models. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper seems focused on 3D features and Gaussian Splatting, which is a rendering method. None of the four topics directly relate to 3D rendering or computer vision techniques. Time-series is about temporal data, which isn't mentioned here. Multimodal would involve combining different modalities, but the title doesn't mention that. RAG and KG are more about data retrieval and knowledge representation, which don't fit either. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32556@AAAI"},
{"title": "InvSeg: Test-Time Prompt Inversion for Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"InvSeg: Test-Time Prompt Inversion for Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Test-Time Prompt Inversion\" sounds like it's about modifying or inverting prompts during testing. \"Semantic Segmentation\" is a computer vision task where each pixel in an image is classified. So the paper is probably about improving semantic segmentation models during testing by using some kind of prompt inversion technique.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. This doesn't seem related to time-series. Multimodal involves combining different data types, like text and images. The paper is about semantic segmentation, which is image-based, but the title doesn't mention combining modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. KG (Knowledge Graphs) involves structured data and relationships. \n\nThe key term here is \"Prompt Inversion.\" Prompt inversion is a concept from prompt-based learning, where you adjust the input prompts to improve model performance. This is more related to how the model is prompted during inference, which might be part of RAG if it's about retrieving information to generate prompts. However, RAG typically refers to using a retriever to fetch relevant documents and then generate a response. In this case, the inversion is happening at test time for segmentation, which is a different application. Since the paper is about semantic segmentation and prompt inversion during testing, it doesn't clearly fit into RAG or KG. It's not multimodal either. So maybe none of the given topics apply here. The answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32557@AAAI"},
{"title": "Leveraging RGB-D Data with Cross-Modal Context Mining for Glass Surface Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Leveraging RGB-D Data with Cross-Modal Context Mining for Glass Surface Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"RGB-D Data\" refers to data that includes both color (RGB) and depth (D) information. That's typically used in computer vision tasks where you have multiple types of data. Then \"Cross-Modal Context Mining\" – cross-modal usually means combining different types of data or modalities. So combining RGB and depth data would be cross-modal. The task here is glass surface detection, which is a computer vision problem.\n\nNow, looking at the possible topics. Time-series is about data over time, like sequences. This title doesn't mention anything about time or sequences, so probably not time-series. Multimodal refers to using multiple data modalities, which fits here because RGB and depth are different modalities. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to augment model outputs, often in NLP. KG is Knowledge Graphs, which involve structured data and relationships. The paper here is about combining different sensor data (RGB and depth) for detection, so it's more about multimodal data processing. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32558@AAAI"},
{"title": "Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Visual-Language Model\" suggests that the model uses both visual (like images or videos) and language data. That immediately makes me think of multimodal, since multimodal refers to combining multiple types of data, such as text and images. \n\nThe term \"Reprogramming\" might be a bit confusing. But in the context of models, reprogramming could mean adapting or modifying an existing model for a new task. The application here is \"General Deepfake Detection,\" which involves analyzing multimedia content (videos/images) to detect forgeries. Deepfake detection often requires analyzing both visual elements and possibly textual metadata or captions, which again points to multimodal approaches.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance model outputs, typically in text-based tasks. KG (Knowledge Graph) involves structured data representations, which isn't mentioned here. The paper doesn't mention anything about time-based data, retrieval systems, or knowledge graphs. \n\nSo, the key elements are visual and language data combined, which is the definition of multimodal. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32559@AAAI"},
{"title": "FlowMamba: Learning Point Cloud Scene Flow with Global Motion Propagation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FlowMamba: Learning Point Cloud Scene Flow with Global Motion Propagation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Point Cloud Scene Flow\" suggests that the paper is dealing with 3D data, specifically point clouds, and tracking motion between scenes. Scene flow is similar to optical flow but in 3D, which involves understanding how points move over time. So, there's a temporal aspect here, which might relate to time-series data. \n\n\"Global Motion Propagation\" implies that the model is considering motion across the entire scene, not just local areas. This could involve sequences of data points over time, which again points towards time-series analysis. Time-series research often deals with sequences of data points, so if the model is learning motion over time, that's a time-series aspect.\n\nNow, checking the other options. Multimodal would involve combining different types of data, like text and images, but the title only mentions point clouds, which are a single modality. RAG (Retrieval-Augmented Generation) is about using external knowledge during generation, which doesn't seem relevant here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. \n\nSo, the key elements here are point clouds and motion over time. Since the model is learning how these points move through time, it's likely dealing with time-series data. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32560@AAAI"}
{"title": "HandDiffuse: Generative Controllers for Two-Hand Interactions via Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HandDiffuse: Generative Controllers for Two-Hand Interactions via Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Generative Controllers\" suggests it's about generating some kind of control signals or actions. \"Two-Hand Interactions\" implies that the model deals with interactions involving both hands, which might involve multiple modalities, like visual and motion data. \"Diffusion Models\" are a type of generative model, so that's the method they're using.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or sensor data. Multimodal refers to combining multiple types of data, such as text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper uses diffusion models for generating controllers for two-hand interactions. Diffusion models are a type of generative model, but the key here is the application. Two-hand interactions might involve multiple modalities, like combining visual input with motion data. So, if the model is integrating different types of data (e.g., visual and motion), that would be multimodal. However, if it's just generating sequences over time, maybe time-series. But the term \"generative controllers\" might be about generating actions over time, which could be time-series. But the mention of \"two-hand interactions\" could imply multiple modalities. However, the title doesn't explicitly mention combining different data types. It's possible that the model is generating sequences for hand movements, which is time-series. But I'm not sure. Alternatively, if it's using both visual and motion data, that's multimodal. But the title doesn't specify that. The main focus seems to be on the generative model (diffusion) applied to hand interactions. Since diffusion models are a type of generative model, but the topics listed don't include generative models directly. The options are time-series, multimodal, RAG, or KG. If the paper is about generating sequences (like hand movements over time), then time-series. If it's combining different modalities (like visual and motion), then multimodal. The title doesn't explicitly mention multimodal, but two-hand interactions might involve multiple sensors or data types. However, without more info, it's a bit tricky. Alternatively, maybe it's none of these. But the options are limited. Let me think again. RAG is about retrieval and generation, which doesn't seem relevant here. KG is knowledge graphs, which also doesn't fit. So between time-series and multimodal. If the model is generating a sequence of hand movements over time, that's time-series. If it's combining different modalities (like visual and motion data), that's multimodal. The title says \"Two-Hand Interactions,\" which could be about coordinating two hands, possibly using different modalities. But the key term is \"generative controllers,\" which might be about generating control signals over time. So maybe time-series. But I'm not entirely sure. Alternatively, if the model uses both visual and motion data, it's multimodal. But the title doesn't specify that. Hmm. Maybe the answer is multimodal because two-hand interactions could involve multiple modalities. But I'm not certain. Alternatively, maybe it's none. Wait, the options are time-series, multimodal, RAG, KG. If the paper is about using diffusion models for generating controllers for hand interactions, which is a specific application, but doesn't fit into any of the four categories. But the user wants to assign it to one of the four. Let me check again. If it's about generating sequences (time-series), then time-series. If it's combining multiple data types (multimodal), then multimodal. The title doesn't mention retrieval or knowledge graphs. So between time-series and multimodal. The term \"diffusion models\" is a method, but the topic is about the application. Since the title mentions \"Two-Hand Interactions,\" which could involve multiple modalities (like visual and motion), but it's not explicitly stated. However, the use of \"generative controllers\" might be about generating sequences over time, which would be time-series. But I'm not sure. Maybe the answer is multimodal. Alternatively, maybe it's none. But the user wants to assign it to one of the four. Given the options, I think the most likely is multimodal because two-hand interactions might involve multiple modalities. But I'm not 100% sure. Alternatively, maybe it's time-series. Hmm. Let me think again. If the model is generating a sequence of hand movements over time, that's time-series. If it's combining different types of data (like visual and motion), that's multimodal. The title doesn't specify, but \"Two-Hand Interactions\" could imply using both hands' data, which might be considered multimodal. So I'll go with multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32561@AAAI"},
{"title": "Multi-StyleGS: Stylized Gaussian Splatting with Multiple Styles", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-StyleGS: Stylized Gaussian Splatting with Multiple Styles.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Gaussian Splatting\" sounds like a technique in computer graphics or 3D rendering. \"Stylized\" and \"Multiple Styles\" suggest that the method allows for different visual styles. The term \"Multi-StyleGS\" probably refers to applying multiple styles to Gaussian splatting. \n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or weather. That doesn't seem related here. Multimodal usually refers to combining different types of data, like text and images. But the title doesn't mention combining different data types. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, typically in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper seems focused on a specific rendering technique with multiple styles. None of the four topics directly relate to computer graphics techniques or stylization. So, it probably doesn't fit into any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32562@AAAI"},
{"title": "Memory Efficient Matting with Adaptive Token Routing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Memory Efficient Matting with Adaptive Token Routing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Matting\" usually refers to image matting, which is about separating the foreground from the background in an image. So that's an image processing task. \"Memory Efficient\" suggests they're optimizing for computational resources. \"Adaptive Token Routing\" – tokens are often used in machine learning models, especially in transformers. Token routing might relate to how tokens are processed or managed in a model.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus seems to be on improving matting efficiency through token routing. Since matting is an image processing task, and there's no mention of combining different data modalities, it's probably not multimodal. Time-series doesn't fit here either. RAG and KG are more about data retrieval and knowledge representation. The term \"token routing\" might be related to how the model processes tokens, but RAG specifically involves retrieval. There's no indication of retrieval here. Knowledge Graphs are about structured data, which doesn't seem relevant. So maybe it's none of these topics. The paper is about image matting with efficiency improvements, which doesn't directly align with the four given categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32563@AAAI"},
{"title": "AGLLDiff: Guiding Diffusion Models Towards Unsupervised Training-free Real-world Low-light Image Enhancement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AGLLDiff: Guiding Diffusion Models Towards Unsupervised Training-free Real-world Low-light Image Enhancement.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on image enhancement, specifically for low-light images. The method mentioned is a diffusion model, which is a type of generative model. The key terms here are \"diffusion models,\" \"unsupervised,\" \"training-free,\" and \"real-world low-light image enhancement.\"\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time-series data. It's about image enhancement, which is a computer vision task. The term \"multimodal\" isn't present, and there's no indication of combining different data modalities. RAG and KG are more about text generation and knowledge representation, which don't seem relevant here. The paper is focused on improving low-light images using a specific type of model (diffusion) without training, which is a novel approach in image processing. Since none of the four topics directly relate to image enhancement or diffusion models, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32564@AAAI"},
{"title": "DPLUT: Unsupervised Low-light Image Enhancement with Lookup Tables and Diffusion Priors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DPLUT: Unsupervised Low-light Image Enhancement with Lookup Tables and Diffusion Priors.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This paper is about image enhancement, so probably not time-series. \n\nMultimodal would involve combining different types of data, like text and images. The title mentions low-light image enhancement, but I don't see any mention of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to augment their responses. The title doesn't mention anything about retrieval or generation, so RAG might not be it.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything related to knowledge graphs either.\n\nThe paper uses Lookup Tables and Diffusion Priors. Diffusion models are a type of generative model, but the main focus here is on image enhancement using these techniques. Since none of the four topics (time-series, multimodal, RAG, KG) seem to fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32565@AAAI"},
{"title": "Deep Hierarchies and Invariant Disease-Indicative Feature Learning for Computer Aided Diagnosis of Multiple Fundus Diseases", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Deep Hierarchies and Invariant Disease-Indicative Feature Learning for Computer Aided Diagnosis of Multiple Fundus Diseases.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Deep Hierarchies\" probably refers to deep learning models with hierarchical structures. \"Invariant Disease-Indicative Feature Learning\" suggests they're trying to find features that are consistent (invariant) across different cases to indicate diseases. The application is in computer-aided diagnosis for fundus diseases, which are related to the eye's fundus, like retinal diseases.\n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like images and text. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about feature learning for medical diagnosis using fundus images. There's no mention of time-series data here. The focus is on learning features from images (fundus), which is a single modality. So it's not multimodal. RAG and KG are more about integrating external knowledge or retrieval, which doesn't seem to be the case here. The paper is about deep learning models for feature extraction in medical imaging. Therefore, it doesn't fit any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32566@AAAI"},
{"title": "Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Large Language Models\" immediately stands out. Multimodal usually refers to models that handle multiple types of data, like text and images. So that's a hint. The rest of the title talks about \"Visual Tokens Withdrawal\" and \"Rapid Inference.\" Visual tokens would be part of the multimodal aspect, as they're dealing with visual data. The method mentioned is about improving inference speed by withdrawing visual tokens. \n\nNow, checking the options. The four topics are time-series, multimodal, RAG, and KG. Time-series is about data over time, which doesn't seem relevant here. RAG is Retrieval-Augmented Generation, which involves using external data for generation, but the title doesn't mention retrieval. KG is Knowledge Graphs, which are structured data representations, not mentioned here. The title clearly mentions \"Multimodal,\" so that's the most direct fit. The paper is about enhancing multimodal models, so the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32567@AAAI"},
{"title": "SOVGaussian: Sparse-View 3D Gaussian Splatting for Open-Vocabulary Scene Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SOVGaussian: Sparse-View 3D Gaussian Splatting for Open-Vocabulary Scene Understanding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Sparse-View 3D Gaussian Splatting\" sounds like a technique for 3D scene reconstruction or rendering. \"Open-Vocabulary Scene Understanding\" suggests that the model can understand scenes with a wide range of objects, maybe using some kind of vocabulary or language model. \n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't seem to mention anything about time, so probably not time-series.\n\nMultimodal refers to combining different data types, like text and images. The title mentions \"scene understanding,\" which might involve multiple modalities, but the key term here is \"open-vocabulary.\" That makes me think of models that can handle a large set of possible inputs, maybe using a knowledge base or something like RAG (Retrieval-Augmented Generation) which combines retrieval with generation. \n\nRAG is about using a retriever to get relevant information and then generating a response. If the paper is using a large vocabulary for scene understanding, maybe they're retrieving information from a knowledge base. But the title doesn't explicitly mention retrieval or generation. \n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. If the scene understanding is enhanced by a knowledge graph, that could be a fit. However, the term \"Gaussian Splatting\" is a rendering technique, so maybe it's more about the 3D reconstruction part. \n\nWait, \"open-vocabulary\" is a term often used in models that can generalize beyond their training data, like in vision-language models. This might be using a pre-trained model (like CLIP) for open vocabulary, which could be part of a multimodal approach. But the main focus here is on 3D scene understanding with sparse views. \n\nAlternatively, if they're using a knowledge graph to enhance the scene understanding, that would be KG. But the title doesn't mention knowledge graphs explicitly. RAG is more about retrieval during inference. \n\nHmm. The key part is \"open-vocabulary,\" which in some contexts relates to using external knowledge (like RAG) or a knowledge graph. But without more details, it's a bit tricky. Since the options are RAG, KG, multimodal, or none. \n\nIf the paper is about using a knowledge base to enable open vocabulary, then it's RAG or KG. If it's combining different modalities (like 3D data and text), then multimodal. The title mentions \"scene understanding,\" which could involve both 3D data and language, making it multimodal. But the term \"open-vocabulary\" is more about the language aspect. \n\nI think the best fit here is multimodal because it's combining 3D scene data (visual) with open-vocabulary understanding (language). So the answer would be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32568@AAAI"},
{"title": "Towards Ship License Plate Recognition in the Wild: A Large Benchmark and Strong Baseline", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Ship License Plate Recognition in the Wild: A Large Benchmark and Strong Baseline.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or sensor data. This paper is about recognizing license plates on ships, which seems more like an image or computer vision problem. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention anything about combining different data types, just about recognizing license plates. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The paper's focus is on recognition, not generating text or using retrieval. So RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about creating a benchmark and a baseline for a specific task, not building a knowledge graph. So KG is probably not it either.\n\nThe paper is about developing a benchmark and a strong baseline for ship license plate recognition. This sounds like a computer vision task, possibly involving image datasets and models for detection. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32569@AAAI"},
{"title": "Incomplete Modality Disentangled Representation for Ophthalmic Disease Grading and Diagnosis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Incomplete Modality Disentangled Representation for Ophthalmic Disease Grading and Diagnosis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Incomplete Modality Disentangled Representation\" – modality here probably refers to different types of data inputs, like images, text, etc. Disentangled representation suggests they're trying to separate different factors in the data. \"Ophthalmic Disease Grading and Diagnosis\" is the application area, which is about eye diseases.\n\nMultimodal research deals with combining multiple data types (modalities) like images and text. The term \"modality\" in the title makes me think multimodal. Disentangled representations in multimodal contexts often aim to separate different sources or aspects of data. So if the paper is about handling incomplete data from different modalities (like maybe some data is missing) and using that for diagnosis, it's likely multimodal.\n\nTime-series would involve data over time, like sequences. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about time, retrieval, or knowledge graphs. So the most fitting is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32570@AAAI"}
{"title": "Perturbating, Tuning, and Collaborating: Harnessing Vision Foundation Models for Single Domain Generalization on Medical Imaging", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Perturbating, Tuning, and Collaborating: Harnessing Vision Foundation Models for Single Domain Generalization on Medical Imaging.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on using Vision Foundation Models for domain generalization in medical imaging. The terms \"Perturbating, Tuning, and Collaborating\" probably refer to methods or techniques applied to these models. \n\nVision Foundation Models are typically related to computer vision, which is a part of multimodal learning since they process visual data. However, the question is whether the paper's topic is specifically multimodal. The other options are time-series, RAG (Retrieval-Augmented Generation), or KG (Knowledge Graphs). \n\nTime-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. RAG is about enhancing models with external knowledge retrieval, often in NLP contexts. The title doesn't mention retrieval or generation, so RAG is unlikely. KG involves structured knowledge graphs, which again isn't mentioned here. \n\nThe paper is about medical imaging, which is a visual domain. If they're using vision models and possibly combining them with other modalities (like text or other data types), it could be multimodal. However, the title specifies \"Single Domain Generalization,\" which might mean they're focusing on a single modality (vision) but improving generalization across different domains within that modality. \n\nBut the key here is whether the research topic is multimodal. Since the paper is using Vision Foundation Models, which are unimodal (only vision), but the methods (perturbating, tuning, collaborating) might involve techniques that could be part of multimodal approaches if they integrate other data types. However, the title doesn't explicitly mention other modalities. \n\nWait, the title says \"Harnessing Vision Foundation Models for Single Domain Generalization.\" The term \"Single Domain\" might imply that they're working within one domain, but the methods could be multimodal if they combine vision with other data. However, without explicit mention of multiple modalities, it's safer to assume it's unimodal. \n\nBut the options are time-series, multimodal, RAG, KG. Since the paper is about vision models in medical imaging, and multimodal refers to combining multiple data types (like text and images), if the paper is only using images, then it's not multimodal. However, sometimes \"multimodal\" can refer to models that handle different types of data within the same modality, but that's a stretch. \n\nAlternatively, maybe the \"collaborating\" part refers to combining different models or techniques, but that's not necessarily multimodal. \n\nGiven that, the paper might not fit into any of the four categories. But wait, the options are time-series, multimodal, RAG, KG. If the paper is about vision models, which are part of multimodal learning when combined with other modalities, but the title doesn't mention that. So maybe it's not multimodal. \n\nAlternatively, maybe the paper is using multimodal approaches by combining vision with other data types for medical imaging. But the title doesn't specify that. The term \"Single Domain Generalization\" might mean they're focusing on one domain (like one type of medical image) but making the model generalize better. \n\nSince the title doesn't mention time-series, RAG, or KG, and the main focus is on vision models, which could be part of multimodal if they're integrating other data, but the title doesn't state that. Therefore, the answer might be \"none.\" \n\nWait, but the user is asking which of the four topics it belongs to. If the paper is about using vision foundation models, which are part of multimodal learning (since vision is a modality), but the paper might not be combining multiple modalities. So maybe it's not multimodal. \n\nAlternatively, maybe the methods (perturbating, tuning, collaborating) are techniques used in multimodal learning. But without explicit mention, it's hard to say. \n\nHmm. The safest answer here is probably \"none\" because the title doesn't clearly align with any of the four specified topics. The paper is about vision models in medical imaging, which is computer vision, but the four options don't include computer vision. The closest might be multimodal if they're combining vision with other data, but the title doesn't specify that. So I think the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32571@AAAI"},
{"title": "Thinking Racial Bias in Fair Forgery Detection: Models, Datasets and Evaluations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Thinking Racial Bias in Fair Forgery Detection: Models, Datasets and Evaluations.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not that. \n\nMultimodal would involve combining different types of data, like text and images. The paper is about forgery detection, which might involve images or text, but the title doesn't specify using multiple modalities. It's more about fairness and racial bias, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on models, datasets, and evaluations related to racial bias in forgery detection. Unless they're building a knowledge graph to represent the data, which isn't indicated here, KG might not fit.\n\nThe main themes here are fairness, racial bias, and forgery detection. None of the four topics directly relate to these aspects. The paper is more about ethical considerations in AI models rather than the specific technical areas listed. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32572@AAAI"},
{"title": "UFO: Enhancing Diffusion-Based Video Generation with a Uniform Frame Organizer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UFO: Enhancing Diffusion-Based Video Generation with a Uniform Frame Organizer.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, the main focus here is on video generation. Video is a sequence of frames over time, so that immediately makes me think of time-series data. Time-series analysis deals with data points indexed in time order, which fits video frames. The paper mentions a \"Uniform Frame Organizer,\" which probably helps in organizing the frames in a temporal sequence to improve the diffusion model's performance. \n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about combining different modalities, so that's probably not it. RAG (Retrieval-Augmented Generation) involves using retrieval mechanisms to enhance generation, but the title doesn't mention retrieval. KG (Knowledge Graph) is about structured data and relationships, which also doesn't seem relevant here. \n\nSo the key elements are video generation and frame organization over time. That points to time-series. The answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32573@AAAI"},
{"title": "Text to Point Cloud Localization with Multi-Level Negative Contrastive Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Text to Point Cloud Localization with Multi-Level Negative Contrastive Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. The title mentions point clouds, which are 3D data points, but there's no mention of time here. So probably not time-series.\n\nNext, multimodal. That's when the research uses multiple types of data, like text and images or text and audio. The title has \"Text to Point Cloud,\" which combines text with 3D point cloud data. That sounds like two different modalities, so multimodal might be the right category here.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge bases, so that's probably not it either.\n\nSo the most likely answer is multimodal because it's combining text and point cloud data for localization.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32574@AAAI"},
{"title": "Zero-Shot Noise2Mean: Gap Minimization for Efficient Denoising from a Single Noisy Image", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Zero-Shot Noise2Mean: Gap Minimization for Efficient Denoising from a Single Noisy Image.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Zero-Shot\" usually refers to a machine learning approach where the model can handle tasks it wasn't explicitly trained on. \"Noise2Mean\" sounds like a denoising technique, maybe related to image processing. \"Gap Minimization\" suggests optimizing the difference between something, perhaps the noisy and clean images. \"Efficient Denoising from a Single Noisy Image\" clearly indicates the problem is about removing noise from images, using just one input image.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. Multimodal involves combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not that. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on denoising a single image, which is a computer vision task. None of the four topics (time-series, multimodal, RAG, KG) directly relate to image denoising. The methods mentioned (Zero-Shot, Noise2Mean, Gap Minimization) don't align with the listed topics either. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32575@AAAI"},
{"title": "Making Large Vision Language Models to Be Good Few-Shot Learners", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Making Large Vision Language Models to Be Good Few-Shot Learners.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Large Vision Language Models\" – that sounds like models that handle both vision (images) and language (text), so that's probably multimodal. Multimodal refers to models that process multiple types of data, like combining images and text. \n\nThen \"Few-Shot Learners\" – few-shot learning is about training models with very few examples. But the question is about the topic of the research, not the learning paradigm. The main focus here is on the model's ability to handle vision and language together. \n\nLooking at the options: time-series is about data over time, like stock prices or weather. RAG is Retrieval-Augmented Generation, which involves using retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge. None of these seem to fit the title. The key terms here are \"Vision Language Models,\" which are definitely multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32576@AAAI"},
{"title": "DreamAlign: Dynamic Text-to-3D Optimization with Human Preference Alignment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DreamAlign: Dynamic Text-to-3D Optimization with Human Preference Alignment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Dynamic Text-to-3D Optimization\" suggests that the paper is about converting text into 3D models, and it's dynamic, meaning it might involve some iterative or real-time process. \"Human Preference Alignment\" implies that the model is being adjusted to align with what humans prefer, which could involve some form of feedback or preference learning.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images or text and audio. Here, the paper is about text-to-3D, which involves text and 3D data. So that's two modalities. That might fit under multimodal. But I need to check if the core focus is on combining different modalities. The main task is generating 3D from text, which is a form of multimodal generation, so maybe multimodal is the right category here.\n\nRAG stands for Retrieval-Augmented Generation, which typically involves using a retrieval system to pull relevant information and then generating text based on that. The title doesn't mention retrieval or using external data sources for generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so that's unlikely.\n\nSo the most likely candidate is multimodal. The paper is about converting text (a modality) into 3D models (another modality), which is a multimodal task. The dynamic optimization and human preference alignment are aspects of how the model is trained or optimized, but the core research topic here is the combination of different data modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32577@AAAI"},
{"title": "Multi-Label Few-Shot Image Classification via Pairwise Feature Augmentation and Flexible Prompt Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Label Few-Shot Image Classification via Pairwise Feature Augmentation and Flexible Prompt Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on image classification, which is a computer vision task. The terms \"Multi-Label\" and \"Few-Shot\" suggest that the model is handling multiple labels and learning from a small number of examples. The methods mentioned are \"Pairwise Feature Augmentation\" and \"Flexible Prompt Learning.\" \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. \n\nMultimodal refers to combining different data types, like text and images. The title doesn't mention combining different modalities, just image classification. So maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. The paper's methods are about feature augmentation and prompt learning, which might be related to prompting in models, but RAG specifically involves retrieval. Not sure yet. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG. \n\nFlexible Prompt Learning sounds like it could be related to prompt-based methods, which are common in few-shot learning. Prompt learning is often used in models like GPT, where prompts help the model adapt. However, RAG is a specific type of model that uses retrieval. The paper's title doesn't mention retrieval, so maybe it's not RAG. \n\nWait, the methods are Pairwise Feature Augmentation and Flexible Prompt Learning. Prompt learning is a technique used in various models, including those in few-shot learning. Since the paper is about image classification with few shots, maybe it's using prompt learning as a method. But does that fall under RAG? RAG is more about combining retrieval with generation. Since this is image classification, not generation, maybe it's not RAG. \n\nSo, the options left are multimodal, RAG, or none. Since the paper is about images and doesn't mention combining different data types, it's not multimodal. RAG doesn't seem to fit either. So maybe the answer is none. But wait, the user's options are time-series, multimodal, RAG, KG. If none of these fit, then the answer is \"none.\" \n\nAlternatively, maybe \"Flexible Prompt Learning\" is part of RAG? But RAG is specifically about retrieval-augmented generation. The paper's focus is on image classification with few shots, using prompt learning. Since the title doesn't mention retrieval, I think it's not RAG. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32578@AAAI"},
{"title": "UN-DETR: Promoting Objectness Learning via Joint Supervision for Unknown Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UN-DETR: Promoting Objectness Learning via Joint Supervision for Unknown Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The title is about object detection, which is typically in computer vision, but there's no mention of combining different modalities here. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't seem to relate to retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on object detection, specifically unknown objects, which doesn't immediately connect to knowledge graphs. \n\nThe paper is about improving object detection, particularly for unknown objects, using a method called UN-DETR. The key terms here are object detection and joint supervision. Object detection is a computer vision task, and the methods mentioned (like DETR, which is a transformer-based model for detection) don't directly relate to the four topics listed. Since none of the four topics (time-series, multimodal, RAG, KG) are clearly addressed in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32579@AAAI"},
{"title": "SCott: Accelerating Diffusion Models with Stochastic Consistency Distillation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SCott: Accelerating Diffusion Models with Stochastic Consistency Distillation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. The main subject here is \"Diffusion Models.\" Diffusion models are a type of generative model used in machine learning, often for tasks like image generation. The paper is about accelerating these models using a method called \"Stochastic Consistency Distillation.\" \n\nNow, looking at the four options. Time-series refers to data over time, like stock prices or weather data. Multimodal involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models, often in NLP. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title doesn't mention anything about time-series data, so that's probably not it. It's about accelerating a model, not combining different data types, so multimodal might not fit. RAG and KG are more about specific techniques or structures. The method here is about distillation, which is a model compression technique, but the key term is \"Stochastic Consistency Distillation.\" I'm not sure if that's related to RAG or KG. RAG is more about retrieval, and KG is about knowledge graphs. Since the paper is about improving diffusion models through a specific distillation method, none of the four topics seem to directly apply. The main focus is on model acceleration in diffusion models, which isn't covered by the given options. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32580@AAAI"}
{"title": "ProtoCar: Learning 3D Vehicle Prototypes from Single-View and Unconstrained Driving Scene Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ProtoCar: Learning 3D Vehicle Prototypes from Single-View and Unconstrained Driving Scene Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nNext, multimodal refers to using multiple types of data, like combining text and images. The paper here is about learning 3D models from images. Wait, but the input is single-view images, which are 2D. If they're using images (a single modality) to create 3D models, maybe they're using different views or some other data? Hmm, but the title says \"single-view,\" so maybe it's just images. Not sure if that's multimodal. Maybe not.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate text, like in some NLP models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about 3D vehicle prototypes, which doesn't seem related to building or using knowledge graphs. So probably not KG.\n\nWait, maybe multimodal is possible if they're combining different types of data. For example, if they're using images and some other data like LiDAR or text. But the title says \"single-view and unconstrained driving scene images.\" Single-view implies just one image per input. Unconstrained might mean varying conditions, but not necessarily multiple modalities. Unless the model is using both images and some other data sources. But the title doesn't specify that. So maybe it's not multimodal either.\n\nSo none of the four topics seem to fit. The paper is about 3D reconstruction from images, which is more computer vision. The given options don't include computer vision topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32581@AAAI"},
{"title": "PEIE: Physics Embedded Illumination Estimation for Adaptive Dehazing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PEIE: Physics Embedded Illumination Estimation for Adaptive Dehazing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Physics Embedded\" suggests that they're incorporating physical principles into their model. \"Illumination Estimation\" is about figuring out the lighting conditions, which is common in image processing. \"Adaptive Dehazing\" refers to removing haze from images, which is a computer vision task. \n\nNow, the four options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal would involve combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus seems to be on image processing, specifically dehazing using physical models. None of the four topics directly relate to image processing or computer vision tasks. Time-series is about temporal data, which isn't mentioned here. Multimodal would require multiple data types, but the title doesn't indicate that. RAG and KG are more about information retrieval and knowledge representation, which don't seem relevant here. \n\nSo, the answer should be \"none\" because the paper's topic doesn't fit into any of the given categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32582@AAAI"},
{"title": "TCPFormer: Learning Temporal Correlation with Implicit Pose Proxy for 3D Human Pose Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TCPFormer: Learning Temporal Correlation with Implicit Pose Proxy for 3D Human Pose Estimation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Correlation\" immediately makes me think of time-series data because temporal refers to time. The paper is about learning correlations over time, which is a key aspect of time-series analysis. The method is called TCPFormer, which might be a Transformer model adapted for temporal data. \n\n3D Human Pose Estimation is the application area here. The paper is using some form of temporal modeling to improve pose estimation. The mention of \"Implicit Pose Proxy\" might be a technique they're using, but the key part for categorization is the temporal aspect. \n\nMultimodal would involve combining different types of data, like text and images, but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generation tasks, which doesn't seem relevant here. KG (Knowledge Graphs) involve structured data and relationships, which also isn't mentioned. \n\nSo the main focus is on temporal correlation, which fits under time-series. The answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32583@AAAI"},
{"title": "Union Is Strength! Unite the Power of LLMs and MLLMs for Chart Question Answering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Union Is Strength! Unite the Power of LLMs and MLLMs for Chart Question Answering.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. It mentions LLMs (Large Language Models) and MLLMs (Multimodal Large Language Models). The key part here is \"Multimodal,\" which refers to handling multiple types of data, like text and images. Since MLLMs are a type of multimodal model, the research is likely about combining different modalities. \n\nThe task is \"Chart Question Answering,\" which involves interpreting charts (visual data) and answering questions about them (text). This requires processing both visual and textual information, which is a classic example of multimodal tasks. \n\nLooking at the options, \"multimodal\" is one of the topics. The other options are time-series (which deals with sequential data over time), RAG (Retrieval-Augmented Generation, which uses external data for answering), and KG (Knowledge Graphs, which are structured data representations). None of these seem to fit the title as directly as multimodal. The paper is about combining different data types (text and charts), so multimodal is the right choice.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32584@AAAI"},
{"title": "D&M: Enriching E-commerce Videos with Sound Effects by Key Moment Detection and SFX Matching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"D&M: Enriching E-commerce Videos with Sound Effects by Key Moment Detection and SFX Matching.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main idea is about adding sound effects to e-commerce videos. The methods mentioned are Key Moment Detection and SFX Matching. So, they're probably analyzing the video to find important moments and then matching appropriate sound effects to those moments.\n\nTime-series usually involves data that's sequential over time, like stock prices or sensor data. If the paper is about analyzing video over time, maybe that's time-series. But the key here is combining different modalities—video and sound effects. So, video is visual, and sound is audio. That sounds like multimodal because it's using multiple types of data (visual and auditory) together.\n\nMultimodal research deals with integrating different data types, like text, images, audio, etc. Since the paper is about enriching videos (which are visual) with sound effects (audio), that's combining two modalities. So multimodal seems like a good fit.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation tasks, like in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention anything about building or using a knowledge graph, so that's probably not it either.\n\nSo the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32585@AAAI"},
{"title": "Attend and Enrich: Enhanced Visual Prompt for Zero-Shot Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Attend and Enrich: Enhanced Visual Prompt for Zero-Shot Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Attend and Enrich\" suggests some kind of attention mechanism, maybe in a neural network. \"Enhanced Visual Prompt\" implies that there's a visual component, so images or something related to vision. \"Zero-Shot Learning\" is a machine learning concept where the model can recognize classes not seen during training. \n\nNow, the topics given are time-series, multimodal, RAG, KG. Let's go through each. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. \n\nMultimodal usually refers to combining different types of data, like text and images. The paper mentions a visual prompt, which is one modality, but does it combine with others? The title doesn't specify another modality, but \"visual prompt\" might be part of a multimodal approach. However, zero-shot learning can be done with a single modality too. Hmm.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so likely not KG.\n\nSo, the remaining options are multimodal or none. The paper is about a visual prompt for zero-shot learning. If the method involves combining visual data with another modality (like text), then it's multimodal. But the title only mentions \"visual prompt,\" which could be part of a multimodal system. However, zero-shot learning can be unimodal. For example, using only images with some kind of prompt engineering. \n\nWait, \"visual prompt\" might be a way to enhance the model's ability to generalize to unseen classes. If the prompt is generated using attention mechanisms, maybe it's using some multimodal elements. But without explicit mention of combining different modalities, it's a bit unclear. \n\nAlternatively, maybe the paper is about improving the visual modality itself through attention and enrichment, which is part of multimodal if it's integrating with another modality. But if it's just enhancing the visual input, it might not be multimodal. \n\nSince the title doesn't explicitly state combining multiple modalities, maybe it's not multimodal. Then, the answer would be none. But I'm a bit uncertain. Let me think again. Zero-shot learning often uses attributes or semantic information, which could be a form of multimodal if combining visual and textual attributes. If the \"visual prompt\" is being enriched with semantic information, that could be multimodal. But the title doesn't specify that. \n\nGiven the information provided, the safest answer is \"none\" because the title doesn't clearly indicate time-series, RAG, or KG, and the multimodal aspect isn't explicitly stated. However, if the paper is about combining visual and textual information for zero-shot learning, then it would be multimodal. But based solely on the title, I can't confirm that. So, I'll go with \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32586@AAAI"},
{"title": "UP-Restorer: When Unrolling Meets Prompts for Unified Image Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UP-Restorer: When Unrolling Meets Prompts for Unified Image Restoration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Unified Image Restoration\" suggests that the paper is about restoring images, which is a computer vision task. The methods mentioned are \"Unrolling\" and \"Prompts.\" Unrolling might refer to unrolling a neural network, like in iterative methods, which is common in image restoration tasks. Prompts could be related to prompting techniques, maybe similar to how prompts are used in language models, but applied to images here.\n\nNow, looking at the four options. Time-series is about data over time, which doesn't seem relevant here. Multimodal involves combining different data types like text and images. RAG (Retrieval-Augmented Generation) is a method that uses retrieval to augment generation, typically in NLP. KG (Knowledge Graph) is about structured data and relationships. \n\nThe paper is about image restoration using unrolling and prompts. The term \"prompts\" might be a hint. In recent AI, prompts are often associated with models like GPT, but in image tasks, maybe they're using some form of prompt-based learning. However, RAG specifically refers to retrieval-augmented generation, which is more about retrieving information to aid in generating text. Since the paper is about image restoration, which is a vision task, and there's no mention of combining different modalities (like text and images), it's probably not multimodal. The use of \"prompts\" here might be a novel approach in image restoration, but it doesn't fit into RAG or KG. So the answer might be none. Wait, but maybe \"prompts\" here refers to something else. Alternatively, could it be multimodal if they're using text prompts for image restoration? Like, using text to guide the restoration process. If that's the case, then it would be multimodal. But the title doesn't explicitly mention combining modalities. The term \"Unified\" might imply handling different types of restoration tasks, but not necessarily different data modalities. So I'm leaning towards \"none\" because it doesn't clearly fit into any of the four categories. The main focus is on image restoration techniques using unrolling and prompts, which might be a new method but doesn't align with the listed topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32587@AAAI"},
{"title": "LLM4GEN: Leveraging Semantic Representation of LLMs for Text-to-Image Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LLM4GEN: Leveraging Semantic Representation of LLMs for Text-to-Image Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nNext, multimodal. That refers to models that handle multiple types of data, like text and images. The title mentions text-to-image generation, which is definitely combining text (input) and images (output). So that's a strong candidate for multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text. The title doesn't mention retrieval or augmenting with external data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title talks about semantic representations of LLMs but doesn't specify knowledge graphs. So probably not KG.\n\nSo the answer should be multimodal because it's about generating images from text, which combines two modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32588@AAAI"},
{"title": "Path-Adaptive Matting for Efficient Inference Under Various Computational Cost Constraints", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Path-Adaptive Matting for Efficient Inference Under Various Computational Cost Constraints.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Matting\" usually refers to image matting, which is about separating an object from its background in an image. \"Path-Adaptive\" suggests some kind of adaptive method that changes based on the path or conditions. \"Efficient Inference\" implies optimizing the model for performance, maybe reducing computational resources. \"Computational Cost Constraints\" means they're considering how much resources (like CPU/GPU time) the model uses.\n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is a method where a model uses retrieved information to generate responses. KG (Knowledge Graph) is about structured data representing entities and their relationships.\n\nThe paper's focus seems to be on image processing (matting) with efficiency in terms of computational resources. None of the four topics directly relate to image matting or computational efficiency. Time-series is about temporal data, which isn't mentioned here. Multimodal would involve multiple data types, but the title doesn't indicate that. RAG and KG are more about information retrieval and knowledge representation, which don't seem relevant here. The paper is about optimizing a specific image processing task under computational constraints, which doesn't fit any of the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32589@AAAI"},
{"title": "Bridge Diffusion Model: Bridge Chinese Text-to-Image Diffusion Model with English Communities", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bridge Diffusion Model: Bridge Chinese Text-to-Image Diffusion Model with English Communities.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nNext, multimodal. That's when the model handles multiple types of data, like text and images. The title says \"Chinese Text-to-Image,\" which combines text (Chinese) and images. So that's two modalities: text and image. That fits multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title doesn't mention anything about retrieval or augmenting generation with retrieved data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so likely not KG.\n\nSo the answer should be multimodal because it's combining text and image data in a diffusion model.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32590@AAAI"}
{"title": "Efficient Deformable Convolutional Prompt for Continual Test-Time Adaptation in Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Efficient Deformable Convolutional Prompt for Continual Test-Time Adaptation in Medical Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on medical image segmentation. The key terms here are \"Deformable Convolutional Prompt\" and \"Continual Test-Time Adaptation.\" \n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about sequences or time, so probably not time-series.\n\nMultimodal would involve combining different data types, like text and images. The title is about image segmentation, but there's no mention of combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on a convolutional neural network technique for image adaptation, not on building or using knowledge graphs. So KG is probably not it either.\n\nThe paper is about improving a model's ability to adapt during testing, using deformable convolutions. This seems more related to model adaptation techniques in computer vision, specifically for medical images. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32591@AAAI"},
{"title": "DeRainGS: Gaussian Splatting for Enhanced Scene Reconstruction in Rainy Environments", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DeRainGS: Gaussian Splatting for Enhanced Scene Reconstruction in Rainy Environments.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"DeRainGS\" probably refers to a method for removing rain from scenes. \"Gaussian Splatting\" is a technique used in 3D rendering and scene reconstruction, where points are rendered as Gaussian-shaped splats to create images. The goal here is enhancing scene reconstruction when it's raining. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data over time. Multimodal would involve combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to augment their responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on scene reconstruction in rainy environments using Gaussian Splatting. This seems more related to computer vision and 3D reconstruction techniques. None of the four topics listed (time-series, multimodal, RAG, KG) directly relate to this. The methods mentioned don't involve time-based data, multiple modalities, retrieval-augmented generation, or knowledge graphs. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32592@AAAI"},
{"title": "FaceMe: Robust Blind Face Restoration with Personal Identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FaceMe: Robust Blind Face Restoration with Personal Identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about face restoration and personal identification, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about face restoration, which is image processing, but does it use multiple modalities? The title mentions \"blind face restoration,\" which might mean restoring faces without prior information, but I'm not sure if it's multimodal. Maybe it uses different data sources, but the title doesn't specify that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. This paper seems focused on image restoration and identification, not on generating text with retrieval. So probably not RAG.\n\nKG is Knowledge Graph, which involves structured data and relationships. The paper's title doesn't mention anything about knowledge graphs or structured data relationships.\n\nSo, the options left are multimodal or none. The paper is about face restoration and personal identification. If it uses multiple modalities (like combining facial data with other data types for identification), then it's multimodal. But the title doesn't explicitly state that. \"Blind\" might refer to not having ground truth during restoration, but not necessarily multimodal. Since the title doesn't mention multiple data types, maybe it's just image processing. Therefore, it might not fit any of the four categories. So the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32593@AAAI"},
{"title": "Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Relation-aware\" suggests something about relationships between entities. \"Hierarchical Prompt\" might refer to a structure in the model's prompting mechanism. \"Open-vocabulary Scene Graph Generation\" – scene graphs are typically used in computer vision to represent objects and their relationships in an image. So generating a scene graph would involve identifying objects and the relations between them.\n\nNow, the four options. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is a method that uses retrieval to augment model responses. KG (Knowledge Graph) is a structured representation of entities and their relationships, often used in semantic networks.\n\nThe paper's focus is on generating scene graphs, which are a form of structured data representing entities (objects) and their relations. Scene graphs are similar to knowledge graphs in structure, as both represent entities and their relationships. The term \"relation-aware\" directly points to the importance of relationships, which is a key aspect of knowledge graphs. The hierarchical prompt might be a method to better capture these relationships in the generation process. Since the task is about generating a structured graph of relations, this seems closely related to Knowledge Graphs (KG). \n\nMultimodal could be a possibility if the paper combines different modalities like text and images, but the title doesn't mention that. RAG is about retrieval, which isn't indicated here. Time-series is unrelated. So the most likely answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32594@AAAI"},
{"title": "VQTalker: Towards Multilingual Talking Avatars Through Facial Motion Tokenization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VQTalker: Towards Multilingual Talking Avatars Through Facial Motion Tokenization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multilingual Talking Avatars\" suggests that the work involves creating avatars that can speak multiple languages. \"Facial Motion Tokenization\" probably refers to converting facial movements into tokens, maybe for generating animations or expressions. \n\nNow, the four options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. KG is Knowledge Graph, which is a structured representation of knowledge.\n\nThe paper's focus seems to be on creating avatars that can talk in multiple languages, using facial motion. Since it's about combining different modalities (like text for language and visual for facial expressions), that sounds like multimodal. The tokenization part might be about encoding facial movements into tokens, which could be part of a multimodal approach where different data types are processed together. \n\nI don't see any mention of time-series data here. RAG and KG are more about information retrieval and structured knowledge, which don't seem to fit. So the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32595@AAAI"},
{"title": "HC-LLM: Historical-Constrained Large Language Models for Radiology Report Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HC-LLM: Historical-Constrained Large Language Models for Radiology Report Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Historical-Constrained\" suggests that the model uses historical data or constraints based on past information. \"Large Language Models\" points to LLMs, which are typically used in NLP tasks. The application here is \"Radiology Report Generation,\" which involves creating reports based on medical imaging data, possibly combining text and images.\n\nNow, looking at the options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to models that handle multiple data types, like text and images. RAG (Retrieval-Augmented Generation) combines retrieval of information with generation, often used in question-answering. KG (Knowledge Graph) involves structured data and relationships between entities.\n\nThe key part here is \"Historical-Constrained.\" If the model is using historical data to constrain the generation, maybe it's retrieving past reports or data to inform the current report. That sounds like RAG, where the model retrieves relevant information from a database before generating a response. However, the term \"constrained\" might imply some form of structured data or rules, which could relate to a Knowledge Graph. But RAG is more about retrieving and using external information during generation. \n\nAlternatively, if the model is integrating different modalities like text and images (since radiology reports involve imaging data), it could be multimodal. But the title doesn't explicitly mention multiple data types. The focus seems more on using historical data to guide the generation process. \n\nSo, between RAG and multimodal. Since the task is report generation, which often involves retrieving past data to inform the current output, RAG might be the fit. The \"historical-constrained\" part suggests that the model is using retrieved historical information to structure the report, which aligns with RAG's approach of retrieving relevant documents and then generating a response based on them. Therefore, the answer is likely RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32596@AAAI"},
{"title": "Training Matting Models Without Alpha Labels", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Training Matting Models Without Alpha Labels.\" Hmm. I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. Matting models are typically used in image processing, like separating an object from its background. Alpha labels refer to the alpha channel in images, which is used for transparency. So the paper is about training these models without needing alpha labels, which are usually required for matting tasks. \n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. That doesn't seem related to image matting. Multimodal usually involves combining different types of data, like text and images. But the title doesn't mention multiple modalities. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where models use external information during generation. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on training a model without certain labels (alpha), which is more about the learning approach or data efficiency. But none of the four topics directly relate to this. RAG and KG are more about specific techniques in NLP or knowledge representation. Multimodal is about combining data types, which isn't the case here. Time-series is unrelated. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32597@AAAI"},
{"title": "Multi-view Consistent 3D Panoptic Scene Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-view Consistent 3D Panoptic Scene Understanding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-view\" suggests that the research uses multiple perspectives or data sources. \"Consistent\" might imply some form of integration or alignment. \"3D Panoptic Scene Understanding\" refers to understanding scenes in 3D, combining both objects and the environment. \n\nNow, looking at the options. Time-series usually involves data over time, like sequences. The title doesn't mention time or sequences, so probably not time-series. \n\nMultimodal research deals with combining different types of data, like text and images. \"Multi-view\" could mean different modalities, but \"multi-view\" often refers to different perspectives or viewpoints in the same modality, like multiple camera angles. However, if they're using different data types (e.g., RGB and depth), that would be multimodal. The title doesn't specify different modalities, just multiple views, so maybe not multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, typically in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graphs) involve structured data and relationships. The title doesn't mention knowledge graphs or structured data, so that's unlikely.\n\nSo, the options left are multimodal or none. Since \"multi-view\" could be a form of multimodal if the views are different modalities, but more likely, it's about different viewpoints in the same modality (like multiple camera angles). Therefore, it might not fit into any of the given topics. The answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32598@AAAI"},
{"title": "Interacted Object Grounding in Spatio-Temporal Human-Object Interactions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Interacted Object Grounding in Spatio-Temporal Human-Object Interactions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Interacted Object Grounding\" probably refers to identifying or locating objects that have interacted with humans. \"Spatio-Temporal\" suggests that both spatial (location) and temporal (time) aspects are involved. \"Human-Object Interactions\" implies studying how humans interact with objects, which could involve video or sequences over time.\n\nLooking at the options: time-series deals with data over time, like sequences. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus on spatio-temporal interactions suggests it's dealing with data that has both spatial and temporal dimensions. That's common in time-series analysis, especially if they're tracking movements or interactions over time. However, multimodal could also be a possibility if they're using different modalities (like video and text), but the title doesn't mention multiple data types. RAG and KG don't seem relevant here. The key term is \"spatio-temporal,\" which is a strong indicator for time-series. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32599@AAAI"},
{"title": "Generalized Debiased Semi-Supervised Hashing for Large-Scale Image Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generalized Debiased Semi-Supervised Hashing for Large-Scale Image Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Hashing\" usually refers to methods that convert data into hash codes for efficient retrieval. \"Semi-supervised\" suggests that the method uses both labeled and unlabeled data. \"Debiased\" might be about reducing bias in the model. \"Large-scale image retrieval\" indicates that the application is in image search, probably dealing with a lot of images.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to enhance its responses, often used in NLP. KG (Knowledge Graph) is about structured data representing entities and their relationships.\n\nThe paper's focus is on image retrieval using hashing. Hashing here is a technique for efficient similarity search, which is common in large-scale image retrieval. The terms \"semi-supervised\" and \"debiased\" are about the learning method, but the core application is image retrieval. RAG is more about augmenting generation with retrieval, typically in text models. KGs are structured knowledge bases. Multimodal would involve combining different modalities, but the title only mentions image retrieval. Time-series is unrelated here.\n\nSo, none of the four topics (time-series, multimodal, RAG, KG) directly apply. The paper is about hashing for image retrieval, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32600@AAAI"}
{"title": "Unlocking the Potential of Reverse Distillation for Anomaly Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unlocking the Potential of Reverse Distillation for Anomaly Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, reverse distillation. Distillation in machine learning usually refers to knowledge distillation, where a smaller model is trained to mimic a larger, more complex model. Reverse distillation might be the opposite, maybe transferring knowledge from a smaller model to a larger one? Not sure, but the key here is anomaly detection. Anomaly detection can be applied in various domains. \n\nTime-series anomaly detection is common, like detecting unusual patterns in stock prices or sensor data. But the title doesn't mention time-series specifically. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe title doesn't mention anything about multiple data modalities, so probably not multimodal. RAG and KG are more about data retrieval and structured knowledge, which doesn't directly relate to reverse distillation for anomaly detection. Unless the paper uses a knowledge graph in the process, but the title doesn't indicate that. So maybe it's none of the four? Wait, but the user says if it doesn't belong to any, respond with \"none.\" \n\nAlternatively, maybe reverse distillation is a technique used in one of these areas. For example, in time-series, maybe they use distillation methods. But the title doesn't specify time-series. Without more context, it's hard to say. Since the title doesn't mention time-series, multimodal, RAG, or KG explicitly, the answer might be \"none.\" But I need to be careful. Reverse distillation could be a method applied in any of these areas. However, the title is about anomaly detection, which is a general task. Unless the paper is specifically about using reverse distillation in a time-series context, but the title doesn't state that. So I think the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32601@AAAI"},
{"title": "Unveiling the Knowledge of CLIP for Training-Free Open-Vocabulary Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unveiling the Knowledge of CLIP for Training-Free Open-Vocabulary Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. CLIP is a model that's known for being multimodal because it connects text and images. The term \"Training-Free\" suggests that they're using a pre-trained model without additional training. \"Open-Vocabulary Semantic Segmentation\" implies that the model can handle segmentation tasks for objects not seen during training, which is a common challenge in vision tasks.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. Multimodal is about combining different data types, like text and images. Since CLIP is a multimodal model, this seems relevant. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, often in NLP. The title doesn't mention retrieval or generation. KG (Knowledge Graph) involves structured data and relationships. The title mentions \"knowledge,\" but it's about CLIP's knowledge, not a graph structure. So the most likely is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32602@AAAI"},
{"title": "DoGA: Enhancing Grounded Object Detection via Grouped Pre-Training with Attributes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DoGA: Enhancing Grounded Object Detection via Grouped Pre-Training with Attributes.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Grounded Object Detection\" probably refers to detecting objects in images or videos, maybe using some kind of grounding, like linking text to visual elements. \"Grouped Pre-Training with Attributes\" suggests that the model is pre-trained in groups, possibly using attributes which could be textual descriptions or other features. \n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on object detection, which is a computer vision task. If they're using attributes (maybe textual) along with images, that could be multimodal. Grounded object detection might involve using text to ground the objects, so combining text and images. So multimodal makes sense here. \n\nDoGA isn't an acronym I recognize for RAG or KG. RAG is more about retrieval in generation models, and KG is about structured knowledge. The title doesn't mention retrieval or knowledge graphs. So the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32603@AAAI"},
{"title": "Learning Dynamic Similarity by Bidirectional Hierarchical Sliding Semantic Probe for Efficient Text Video Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning Dynamic Similarity by Bidirectional Hierarchical Sliding Semantic Probe for Efficient Text Video Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main goal here is \"Efficient Text Video Retrieval.\" So they're trying to retrieve videos based on text queries. That immediately makes me think of multimodal because it's combining text and video data. Multimodal research often deals with integrating different types of data like text, images, audio, or video. \n\nThe methods mentioned are \"Learning Dynamic Similarity\" and \"Bidirectional Hierarchical Sliding Semantic Probe.\" The dynamic similarity part might involve how the model adapts the similarity measure between text and video over time or different contexts. The bidirectional and hierarchical aspects suggest that the model is processing information in both directions (like encoder-decoder structures) and has multiple levels of abstraction. The sliding semantic probe could be a way to analyze or extract features at different time steps or segments, which might be relevant for handling sequences, but that's more time-series. However, since the application is text-video retrieval, it's more about combining modalities than time series analysis.\n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves relevant documents and uses them to generate answers. But the title doesn't mention generation; it's about retrieval efficiency. So RAG might not be the right fit here. KG (Knowledge Graphs) involve structured data and relationships, which isn't indicated in the title. \n\nTime-series would involve data points indexed in time order, like stock prices over time. The title mentions \"sliding,\" which could imply a sliding window approach, common in time-series analysis. However, in this case, the sliding is part of a semantic probe for video and text, which are modalities. The primary focus is on combining text and video, making it multimodal. The sliding aspect might be a technique to handle temporal aspects within the video, but the core problem is multimodal retrieval. \n\nTherefore, the most fitting category here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32604@AAAI"},
{"title": "Asymmetric Visual Semantic Embedding Framework for Efficient Vision-Language Alignment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Asymmetric Visual Semantic Embedding Framework for Efficient Vision-Language Alignment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Asymmetric Visual Semantic Embedding\" suggests that there's some kind of embedding model that deals with visual and semantic aspects. \"Efficient Vision-Language Alignment\" points to aligning visual data (like images) with language (text). So, combining vision and language is a key part here. \n\nMultimodal research typically involves integrating multiple types of data, such as text and images. Since the title mentions both vision (visual) and language, that's a strong indicator of multimodal. Time-series usually deals with data over time, like stock prices or sensor data, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation models, often in text-based tasks. KG (Knowledge Graphs) involve structured data and relationships between entities, which isn't mentioned here. \n\nThe framework is about aligning vision and language, which is a classic multimodal problem. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32605@AAAI"},
{"title": "MUN: Image Forgery Localization Based on M³ Encoder and UN Decoder", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MUN: Image Forgery Localization Based on M³ Encoder and UN Decoder.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on image forgery localization. That's about detecting where in an image the forgery is. The methods mentioned are M³ Encoder and UN Decoder. The UN probably refers to U-Net, which is a common architecture for image segmentation. \n\nNow, looking at the topics. Time-series is about data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. \n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention anything about combining different modalities, just image processing. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The paper's title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about image forgery detection, which doesn't seem related to building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about image processing using specific neural network architectures, but the given options don't include computer vision or image processing. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32606@AAAI"},
{"title": "CLIP-PCQA: Exploring Subjective-Aligned Vision-Language Modeling for Point Cloud Quality Assessment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CLIP-PCQA: Exploring Subjective-Aligned Vision-Language Modeling for Point Cloud Quality Assessment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. CLIP is a well-known model in vision-language tasks, right? So \"Vision-Language Modeling\" suggests that it's combining visual and language data, which points towards multimodal. Multimodal typically involves integrating different types of data like images and text. The paper is about assessing the quality of point clouds, which are 3D data structures. But the key part here is the \"Vision-Language\" aspect, which is a classic multimodal setup. \n\nTime-series would involve data over time, like stock prices or sensor data over time. The title doesn't mention anything about time, so probably not that. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in NLP. The title doesn't mention retrieval or generation, so maybe not RAG. KG (Knowledge Graphs) involve structured data and relationships between entities. Again, the title doesn't mention knowledge graphs or structured data relationships. \n\nSo the main clue here is \"Vision-Language Modeling,\" which is a multimodal approach. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32607@AAAI"},
{"title": "DreamUHD: Frequency Enhanced Variational Autoencoder for Ultra-High-Definition Image Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DreamUHD: Frequency Enhanced Variational Autoencoder for Ultra-High-Definition Image Restoration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data over time, like stock prices or weather data. The title mentions image restoration, which is more about images, so maybe not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The paper here is about image restoration using a variational autoencoder. It doesn't mention combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP tasks. The title doesn't mention anything about retrieval or generation in that context, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about image processing using a VAE, which doesn't seem related to knowledge graphs.\n\nSo, the paper is about enhancing images using a specific type of autoencoder with frequency components. None of the given topics (time-series, multimodal, RAG, KG) directly apply here. The focus is on image restoration techniques, which is more related to computer vision or machine learning models for images, but not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32609@AAAI"},
{"title": "Towards Robust Visual Question Answering via Prompt-Driven Geometric Harmonization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Robust Visual Question Answering via Prompt-Driven Geometric Harmonization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual Question Answering\" (VQA) is a task where a model answers questions about an image. That usually involves both visual and textual data, so that's a hint towards multimodal. The term \"multimodal\" refers to models that process multiple types of data, like images and text together. \n\nThe other parts of the title mention \"Prompt-Driven Geometric Harmonization.\" Prompts are often used in models like those in RAG (Retrieval-Augmented Generation) or in prompting techniques for models. However, RAG specifically involves retrieving information from a database to augment the model's knowledge. The geometric harmonization part might relate to aligning or adjusting visual and textual features, which is common in multimodal tasks to ensure they work well together.\n\nNow, checking the options. Time-series is about data over time, which doesn't fit here. RAG is about retrieval and generation, which isn't the focus here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem to be the case. The paper is about combining visual and textual data (images and questions) to answer questions, which is a classic multimodal problem. The methods mentioned (prompt-driven and geometric harmonization) are techniques to improve multimodal models. So the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32610@AAAI"},
{"title": "See Through Their Minds: Learning Transferable Brain Decoding Models from Cross-Subject fMRI", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"See Through Their Minds: Learning Transferable Brain Decoding Models from Cross-Subject fMRI.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Brain decoding models\" probably refers to interpreting brain activity data, like fMRI. The key part here is \"cross-subject,\" which suggests that the model is trained on data from multiple subjects and can transfer knowledge between them. \n\nTime-series usually involves data points indexed in time order. fMRI data is inherently time-series because it captures brain activity over time. So maybe it's time-series? But the title mentions \"transferable models,\" which might be about generalization across subjects rather than the temporal aspect.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention multiple data types, just fMRI. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving relevant documents. Doesn't seem related to brain decoding.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using knowledge graphs.\n\nSo, the main focus here is on fMRI data, which is time-series. The cross-subject aspect is about transfer learning, but the core data type is time-series. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32611@AAAI"}
{"title": "See Through Their Minds: Learning Transferable Brain Decoding Models from Cross-Subject fMRI", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"See Through Their Minds: Learning Transferable Brain Decoding Models from Cross-Subject fMRI.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Brain decoding models\" probably refers to interpreting brain activity data, like fMRI. The key part here is \"cross-subject,\" which suggests that the model is trained on data from multiple subjects and can transfer knowledge between them. \n\nTime-series usually involves data points indexed in time order. fMRI data is inherently time-series because it captures brain activity over time. So maybe it's time-series? But the title mentions \"transferable models,\" which might be about generalization across subjects rather than the temporal aspect.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention multiple data types, just fMRI. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving relevant documents. Doesn't seem related to brain decoding.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using knowledge graphs.\n\nSo, the main focus here is on fMRI data, which is time-series. The cross-subject aspect is about transfer learning, but the core data type is time-series. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32611@AAAI"},
{"title": "SCOPE: Sign Language Contextual Processing with Embedding from LLMs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SCOPE: Sign Language Contextual Processing with Embedding from LLMs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Sign Language Contextual Processing\" suggests they're working with sign language, which is a form of communication using gestures, facial expressions, and body language. Processing sign language would likely involve video or visual data, maybe even audio if they're using voiceovers or other sounds. So that's a hint towards multimodal, since multimodal systems handle multiple types of data like text, images, audio, etc.\n\nThen there's \"Embedding from LLMs.\" LLMs are large language models, which typically process text. But here, they're using embeddings from LLMs for sign language processing. Wait, sign language isn't text, so how does that work? Maybe they're using the LLMs to generate embeddings for the contextual information, but the input data itself is non-textual. So combining different modalities (like video of signs and text embeddings) would be multimodal.\n\nTime-series usually refers to data that's sequential over time, like stock prices or sensor data. While sign language does involve sequences over time (since signs are performed in a sequence), the key here is whether the paper is focused on time-series analysis. The title doesn't explicitly mention time-series techniques, so maybe that's not the main focus.\n\nRAG (Retrieval-Augmented Generation) involves using a retrieval system to fetch relevant information and then generating a response. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) is about structured data representations, like entities and relationships. The title doesn't mention knowledge graphs either.\n\nSo putting it all together: the paper is about processing sign language, which is a visual modality, possibly combining it with embeddings from LLMs (text-based). That combination of different data types (visual and text embeddings) points to multimodal. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32612@AAAI"},
{"title": "Advancing Comprehensive Aesthetic Insight with Multi-Scale Text-Guided Self-Supervised Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Advancing Comprehensive Aesthetic Insight with Multi-Scale Text-Guided Self-Supervised Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Scale Text-Guided\" suggests that text is involved, so maybe multimodal since it combines text with something else. \"Self-Supervised Learning\" is a type of machine learning, but that's a method rather than the topic. The main focus here seems to be using text to guide the learning process, which could imply combining different modalities like text and images or other data types. \n\nTime-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time, so probably not that. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. The title doesn't mention retrieval or generation specifically. KG (Knowledge Graphs) involve structured data and relationships, which also isn't mentioned here. \n\nSo, the key part is \"Multi-Scale Text-Guided.\" If the model is using text as a guide, it's likely combining text with another modality, like images or audio, making it multimodal. The term \"multi-scale\" might refer to different levels of analysis or data scales, but the main clue is the combination of text with another modality. Therefore, the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32613@AAAI"},
{"title": "Training Verification-Friendly Neural Networks via Neuron Behavior Consistency", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Training Verification-Friendly Neural Networks via Neuron Behavior Consistency.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining different data types, like text and images. The title is about neural networks and verification, not about combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like some chatbots. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't talk about graphs or knowledge representation either.\n\nThe paper is about making neural networks more verification-friendly by ensuring neuron behavior consistency. Verification here might relate to formal methods or ensuring the network behaves as expected. None of the given topics directly relate to this. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32614@AAAI"},
{"title": "SAUGE: Taming SAM for Uncertainty-Aligned Multi-Granularity Edge Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SAUGE: Taming SAM for Uncertainty-Aligned Multi-Granularity Edge Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"SAM\" probably refers to Segment Anything Model, which is a vision model for image segmentation. \"Uncertainty-Aligned Multi-Granularity Edge Detection\" suggests they're working on edge detection with varying levels of detail and considering uncertainty. The term \"multi-granularity\" might imply handling different scales or resolutions, which could relate to multimodal if they're combining different data types. But wait, multimodal usually refers to combining multiple modalities like text and images. \n\nRAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks, often in NLP. KG is Knowledge Graphs, which involve structured data and relationships. Time-series is about data over time. \n\nThe paper seems focused on image processing (edge detection) with a model like SAM. The mention of \"multi-granularity\" might mean different levels of detail in the same modality (images), not different modalities. So maybe it's not multimodal. The other topics don't seem to fit. Time-series is about temporal data, which isn't mentioned here. RAG and KG are unrelated to image edge detection. So the answer might be \"none.\" But wait, could \"multi-granularity\" imply using different data types? Maybe not. I think it's about different scales in the same data. So the correct answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32615@AAAI"},
{"title": "Robust SAM: On the Adversarial Robustness of Vision Foundation Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Robust SAM: On the Adversarial Robustness of Vision Foundation Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Robust SAM\" probably refers to making the Segment Anything Model (SAM) more robust against adversarial attacks. The key part here is \"Vision Foundation Models,\" which are typically models like SAM that handle visual data. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. The title doesn't mention anything about time, so probably not that. \n\nMultimodal usually refers to models that handle multiple types of data, like both text and images. The paper is about vision models, but does it combine different modalities? The title doesn't specify that, so maybe not. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation, often in text-based models. The title doesn't mention retrieval or generation, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on adversarial robustness in vision models, which doesn't seem related to knowledge graphs. \n\nSo, none of the four topics seem to fit. The paper is about adversarial robustness in vision models, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32616@AAAI"},
{"title": "Enhancing Low-Light Images: A Synthetic Data Perspective on Practical and Generalizable Solutions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Low-Light Images: A Synthetic Data Perspective on Practical and Generalizable Solutions.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The paper here is about image enhancement, specifically low-light images. Images are more about spatial data, not time, so probably not time-series.\n\nNext, multimodal refers to using multiple types of data, like combining text and images or audio and video. The title mentions synthetic data but doesn't specify combining different modalities. It's focused on generating or using synthetic data for image enhancement, which is a single modality. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves relevant information from a database to aid in generating responses. The paper's title doesn't mention anything about retrieval or generation in that context. It's about enhancing images using synthetic data, which might involve generating data but not in the RAG framework.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using knowledge graphs. It's more about data generation for image processing.\n\nSo, the paper is about using synthetic data to improve low-light image enhancement. None of the four topics (time-series, multimodal, RAG, KG) directly apply here. The focus is on synthetic data generation for a specific image processing task, which doesn't fit into any of the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32617@AAAI"},
{"title": "RGBT Tracking via All-layer Multimodal Interactions with Progressive Fusion Mamba", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RGBT Tracking via All-layer Multimodal Interactions with Progressive Fusion Mamba.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"RGBT Tracking\" probably refers to tracking using both RGB (color) and thermal (T) images. So that's combining different modalities—like visual and thermal data. Then \"All-layer Multimodal Interactions\" definitely mentions multimodal, which is one of the options. The term \"multimodal\" here is key. The rest of the title talks about a method called Progressive Fusion Mamba, but the main clue is the mention of multimodal interactions. \n\nTime-series would involve data over time, like sequences. RAG is Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about time sequences, retrieval, or knowledge graphs. So the most fitting topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32618@AAAI"},
{"title": "Privacy-Preserving V2X Collaborative Perception Integrating Unknown Collaborators", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Privacy-Preserving V2X Collaborative Perception Integrating Unknown Collaborators.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. V2X stands for Vehicle-to-Everything, which is part of autonomous driving and connected vehicles. Collaborative perception probably means that multiple vehicles or entities are sharing data to improve perception, like object detection or environment understanding. The \"Privacy-Preserving\" part suggests they're handling data in a way that protects user privacy. \"Integrating Unknown Collaborators\" might mean they're dealing with dynamic or untrusted participants in the collaboration.\n\nNow, the four topics. Time-series would involve data over time, like stock prices or sensor data over time. Multimodal refers to using multiple types of data (e.g., text, images, audio). RAG is Retrieval-Augmented Generation, which combines retrieval of information with generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on collaborative systems (V2X) where privacy is a concern. It's about integrating data from unknown collaborators, which might involve techniques to handle untrusted data sources. But does this relate to any of the four topics? \n\nTime-series: Maybe if they're using temporal data, but the title doesn't mention time explicitly. Multimodal: If they're combining different data types (like camera, radar, lidar), but the title doesn't specify that. RAG: That's more about using retrieved information to generate responses, which doesn't seem to fit. KG: If they're building a knowledge graph to represent the collaborative data, but again, the title doesn't mention that.\n\nThe key terms here are privacy-preserving and integrating unknown collaborators. This might involve techniques like federated learning, secure multi-party computation, or differential privacy. These are more about data privacy and security rather than the four listed topics. Since none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32619@AAAI"},
{"title": "GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Text-to-Texture Generation\" suggests converting text into some kind of texture, probably for images or 3D models. The adjectives like stable, consistent, and high-quality are about the quality of the output. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather data. That doesn't seem related here. Multimodal refers to combining multiple data types, like text and images. Since this is text-to-texture, which is text to a visual element, that might fit multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge structures, so probably not KG. \n\nSo, the main thing here is converting text into texture, which is a form of generating a visual output from text. That's a multimodal task because it's combining text (modal) with another modality, which is the texture (visual). So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32621@AAAI"}
{"title": "GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GenesisTex2: Stable, Consistent and High-Quality Text-to-Texture Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Text-to-Texture Generation\" suggests converting text into some kind of texture, probably for images or 3D models. The adjectives like stable, consistent, and high-quality are about the quality of the output. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather data. That doesn't seem related here. Multimodal refers to combining multiple data types, like text and images. Since this is text-to-texture, which is text to a visual element, that might fit multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge structures, so probably not KG. \n\nSo, the main thing here is converting text into texture, which is a form of generating a visual output from text. That's a multimodal task because it's combining text (modal) with another modality, which is the texture (visual). So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32621@AAAI"},
{"title": "DeMo: Deep Motion Field Consensus with Learnable Kernels for Two-view Correspondence Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DeMo: Deep Motion Field Consensus with Learnable Kernels for Two-view Correspondence Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Deep Motion Field Consensus\" suggests something related to motion, maybe in images or videos. \"Learnable Kernels\" might refer to using neural networks where kernels are learned, which is common in deep learning. \"Two-view Correspondence Learning\" probably means matching points between two images or views, which is a common problem in computer vision, like in stereo vision or structure from motion.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper seems focused on correspondence between two views, which is more about computer vision tasks, specifically in areas like image matching or 3D reconstruction. None of the four topics listed directly relate to this. Time-series is about temporal data, which isn't the focus here. Multimodal would require combining different modalities, but the title doesn't mention that. RAG and KG are unrelated to correspondence learning. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32622@AAAI"},
{"title": "Can LVLMs Obtain a Driver’s License? A Benchmark Towards Reliable AGI for Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Can LVLMs Obtain a Driver’s License? A Benchmark Towards Reliable AGI for Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. LVLMs probably stands for Large Vision-Language Models. The question is whether these models can pass a driver's license test, which is about autonomous driving. The benchmark is for reliable AGI (Artificial General Intelligence) in this context.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data over time. Multimodal refers to models that handle multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external information retrieval to enhance model responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about LVLMs, which are multimodal because they process both visual (vision) and textual (language) data. Autonomous driving would require understanding images/videos (vision) and possibly text instructions or signs, so multimodal makes sense here. The other topics don't fit as well. Time-series might be involved in sensor data, but the focus here is on the model's ability to handle different modalities. RAG and KG aren't mentioned in the title, so probably not those. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32623@AAAI"},
{"title": "Generative Video Diffusion for Unseen Novel Semantic Video Moment Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generative Video Diffusion for Unseen Novel Semantic Video Moment Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Generative Video Diffusion\" sounds like it's using a diffusion model for generating video. \"Unseen Novel Semantic Video Moment Retrieval\" suggests they're trying to retrieve specific video moments that are new or unseen, based on semantic content. \n\nTime-series usually involves data over time, like stock prices or sensor data. Video is a time-series in a way, but the key here is the retrieval aspect. Multimodal would involve combining different data types, like text and video. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, often in NLP. KG (Knowledge Graph) involves structured data and relationships.\n\nThe paper's focus seems to be on retrieving specific video moments using generative models. The term \"retrieval\" is key here. RAG is about using retrieval to assist in generation, so if the paper is using retrieval to help generate or retrieve video moments, maybe RAG? But the title mentions \"Generative Video Diffusion,\" which is a type of model. However, the main task is retrieval of video moments. \n\nWait, RAG typically involves retrieving information from a database to augment the generation process. In this case, the retrieval is part of the task itself, not augmenting generation. The paper is about retrieving specific video moments, which might be more about multimodal retrieval since video involves both visual and possibly textual data. But the title doesn't mention combining different modalities explicitly. \n\nAlternatively, if the retrieval is based on semantic understanding, maybe it's multimodal because it's combining video (visual) with semantic (textual) information. But the problem is about retrieving moments, which could be a time-series aspect. However, time-series is more about analyzing sequences over time rather than retrieval. \n\nI'm a bit confused. Let me think again. The main components are generative models (diffusion), video, and retrieval. The task is to retrieve specific video moments. If the retrieval is done using a knowledge graph, that would be KG. But the title doesn't mention knowledge graphs. RAG is about using retrieval to enhance generation. If the paper is generating video moments based on retrieved information, maybe RAG. But the title says \"for Unseen Novel Semantic Video Moment Retrieval,\" which sounds like the retrieval is the main goal, not the generation. \n\nHmm. Maybe it's multimodal because video is a combination of visual and audio, and the retrieval is based on semantic (textual) queries. So combining different modalities (video and text) for retrieval. That would make it multimodal. But the title doesn't explicitly mention text, but \"semantic\" implies some form of meaning, which could be from text. \n\nAlternatively, if the retrieval is done using a knowledge graph, but again, the title doesn't mention that. So between multimodal and RAG. Since the task is about retrieving video moments, which could involve multiple modalities (like text and video), I think it's multimodal. But I'm not 100% sure. Wait, the problem is about generating video using diffusion, but the main task is retrieval. Maybe it's not RAG because RAG is about using retrieval to help in generation. Here, the generation is part of the method, but the retrieval is the task. So maybe it's multimodal because it's combining different data types (video and semantic information) for retrieval. So the answer would be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32624@AAAI"},
{"title": "Diff-Shadow: Global-guided Diffusion Model for Shadow Removal", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Diff-Shadow: Global-guided Diffusion Model for Shadow Removal.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The paper is about shadow removal in images, but the title doesn't mention multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on a diffusion model for image processing, not on building or using knowledge graphs. So KG is probably not it either.\n\nThe paper uses a diffusion model, which is a type of generative model. Diffusion models are often used in image generation or editing tasks. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to diffusion models or image processing, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32625@AAAI"},
{"title": "Beyond Pixel and Object: Part Feature as Reference for Few-Shot Video Object Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Beyond Pixel and Object: Part Feature as Reference for Few-Shot Video Object Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Few-Shot Video Object Segmentation\" suggests that the paper is about segmenting objects in videos with limited examples. Video data is inherently time-series because it's a sequence of frames over time. So maybe time-series is a candidate. \n\nBut wait, the title mentions \"Part Feature as Reference.\" That makes me think about how the model uses part features. In few-shot learning, you often use some form of reference or prior knowledge. RAG (Retrieval-Augmented Generation) is a method that uses external knowledge retrieval, but I'm not sure if that's directly related here. \n\nMultimodal usually refers to combining different data types like text and images. The title doesn't mention multiple modalities, so maybe not. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem to fit. \n\nThe key part is \"Video Object Segmentation.\" Since video is a time-series of images, the research is likely dealing with temporal data. So the topic would be time-series. The mention of \"few-shot\" might relate to how the model handles limited data over time, but the core aspect here is the video, which is time-based. \n\nI don't see any indication of multimodal data, RAG, or knowledge graphs in the title. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32626@AAAI"},
{"title": "Rethinking U-Net: Task-Adaptive Mixture of Skip Connections for Enhanced Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Rethinking U-Net: Task-Adaptive Mixture of Skip Connections for Enhanced Medical Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. U-Net is a type of neural network architecture commonly used in image segmentation, especially in medical imaging. The paper is about rethinking or modifying the U-Net structure by introducing a task-adaptive mixture of skip connections. The goal is to enhance the performance in medical image segmentation.\n\nNow, the possible topics are time-series, multimodal, RAG, or KG. Let's consider each one. \n\nTime-series analysis involves data points indexed in time order, like stock prices over time. This paper is about image segmentation, which is more about spatial data rather than temporal, so probably not time-series.\n\nMultimodal refers to combining multiple data modalities, such as text and images, or different types of data. The title doesn't mention anything about combining different data types; it's focused on improving the U-Net architecture for a specific task (medical image segmentation). So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method used in natural language processing where a model retrieves relevant information from a database to aid in generating responses. This doesn't seem related to image segmentation or U-Net modifications.\n\nKG stands for Knowledge Graph, which is a structured representation of knowledge, often used to model relationships between entities. Again, the paper's focus is on neural network architecture for image processing, not on knowledge graphs.\n\nSo, the paper is about improving a neural network model (U-Net) for a specific image segmentation task. None of the listed topics (time-series, multimodal, RAG, KG) directly apply here. The paper is about model architecture adaptation, which doesn't fall under any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32627@AAAI"},
{"title": "Privacy-Preserving Low-Rank Adaptation Against Membership Inference Attacks for Latent Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Privacy-Preserving Low-Rank Adaptation Against Membership Inference Attacks for Latent Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on privacy preservation, specifically against membership inference attacks. The method mentioned is low-rank adaptation applied to latent diffusion models. \n\nTime-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so maybe not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. The paper here is about adapting models to prevent privacy attacks, not about retrieval, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nSo, the paper is about improving privacy in latent diffusion models through low-rank adaptation. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The focus is on privacy and model adaptation, which doesn't fit into any of the four categories listed. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32628@AAAI"},
{"title": "Revisiting Change Captioning from Self-supervised Global-Part Alignment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Revisiting Change Captioning from Self-supervised Global-Part Alignment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Change Captioning\" probably refers to generating descriptions of changes in something. \"Self-supervised Global-Part Alignment\" suggests that the method uses self-supervised learning to align global and part-level features. \n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge sources. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title mentions \"captioning,\" which is often in the context of images or videos, so maybe multimodal? But \"change captioning\" could be about describing changes in a sequence, which might relate to time-series. However, the key part here is \"Global-Part Alignment.\" That sounds like aligning different parts of a model, perhaps in a multimodal setup where different modalities (like visual and textual) are aligned. Self-supervised learning is common in multimodal tasks, like aligning text and images without explicit labels. \n\nRAG and KG are more about using external knowledge or structured data. The title doesn't mention retrieval or knowledge graphs specifically. So it's probably not RAG or KG. Between time-series and multimodal. Since \"change captioning\" could involve describing changes over time, but the method's focus on global-part alignment makes me think it's about integrating different parts of data, which is a common issue in multimodal learning. For example, aligning different parts of an image with text descriptions. \n\nSo I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32629@AAAI"},
{"title": "Infer the Whole from a Glimpse of a Part: Keypoint-Based Knowledge Graph for Vehicle Re-Identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Infer the Whole from a Glimpse of a Part: Keypoint-Based Knowledge Graph for Vehicle Re-Identification.\" I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main part here is \"Keypoint-Based Knowledge Graph for Vehicle Re-Identification.\" The key term here is \"Knowledge Graph,\" which is one of the options given (KG). The other parts mention using keypoints, which are specific points in an image, perhaps for identifying features of a vehicle. Vehicle re-identification is about recognizing the same vehicle across different camera views, which is a common problem in computer vision.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval. The paper's focus on a knowledge graph suggests it's using structured data to represent relationships, which aligns with KG. The mention of keypoint-based might relate to how the knowledge graph is constructed using specific features, but the core is the knowledge graph itself. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32630@AAAI"}
{"title": "ScaleMatch: Multi-scale Consistency Enhancement for Semi-supervised Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ScaleMatch: Multi-scale Consistency Enhancement for Semi-supervised Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-scale Consistency Enhancement\" suggests that the method involves handling different scales, maybe in images or data. \"Semi-supervised Semantic Segmentation\" refers to a machine learning task where the model is trained with both labeled and unlabeled data to segment images into meaningful parts. \n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. Multimodal would involve combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on improving consistency across different scales in a semi-supervised setting for segmentation. This seems more related to computer vision techniques, particularly in handling different spatial scales in images. None of the four topics directly relate to this. Time-series is about temporal data, which isn't mentioned. Multimodal would require combining different data types, which isn't the case here. RAG and KG are about retrieval and knowledge graphs, which also don't fit. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32631@AAAI"},
{"title": "Arbitrary Reading Order Scene Text Spotter with Local Semantics Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Arbitrary Reading Order Scene Text Spotter with Local Semantics Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Scene Text Spotter\" suggests it's about detecting text in images, maybe like OCR. \"Arbitrary Reading Order\" might mean the model can handle text in any order, not just left-to-right or top-to-bottom. \"Local Semantics Guidance\" probably refers to using local context or meaning to guide the spotting process.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. That doesn't seem relevant here. Multimodal involves combining different data types, like text and images. Since this is about text in images, maybe multimodal? But the main focus here is on the text detection and reading order, not necessarily combining modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks, like in chatbots. That doesn't fit. KG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using a knowledge graph.\n\nSo, the paper is about text detection in images with a specific reading order approach. The key here is that it's handling text in scenes, which is a computer vision task. But the options given are time-series, multimodal, RAG, KG. Since it's dealing with images (visual data) and text (linguistic data), maybe multimodal? But multimodal typically refers to integrating different modalities for a task, like using both image and text inputs. However, in this case, the task is text spotting in images, which is more about computer vision with text recognition. The \"local semantics guidance\" might involve some language understanding, but I'm not sure if that's enough to classify it as multimodal. \n\nAlternatively, maybe it's not any of the four. The paper's focus is on the reading order and text spotting, which might not fit into the given categories. So the answer could be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32632@AAAI"},
{"title": "HVIS: A Human-like Vision and Inference System for Human Motion Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HVIS: A Human-like Vision and Inference System for Human Motion Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Human-like Vision and Inference System\" suggests that the system is using visual data, maybe from videos or images, to make inferences. \"Human Motion Prediction\" implies that the system is trying to predict how a person will move next, which is a sequence of movements over time. \n\nTime-series analysis involves data points indexed in time order. Since motion prediction is about predicting future movements based on past data, that's a time-series problem. But wait, the system uses vision, which is visual data. So maybe it's combining different data types? But multimodal is about using multiple types of data (like text, images, audio) together. The title mentions vision, which is one modality, but does it combine with others? The title doesn't specify other modalities, so maybe it's not multimodal. \n\nRAG (Retrieval-Augmented Generation) is a method that uses retrieval of documents to aid in generating answers, typically in NLP. This paper is about motion prediction, so RAG doesn't seem relevant here. \n\nKG (Knowledge Graph) involves structured data representations, often for relationships between entities. The title doesn't mention anything about knowledge graphs or structured data, so probably not that either. \n\nSo the main focus here is predicting human motion, which is a sequence over time. Even though the system uses vision (a modality), the core task is time-series prediction. Unless the system is combining vision with other modalities, but the title doesn't indicate that. Therefore, the topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32633@AAAI"},
{"title": "MVREC: A General Few-shot Defect Classification Model Using Multi-View Region-Context", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MVREC: A General Few-shot Defect Classification Model Using Multi-View Region-Context.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View\" suggests that the model uses multiple perspectives or views of the data. \"Region-Context\" might refer to analyzing different regions within an image or data structure. The term \"Multi-View\" makes me think of multimodal, which involves combining different types of data or modalities. But wait, multimodal usually refers to different data types like text, image, audio, etc. Here, \"Multi-View\" could be about different views of the same modality, like multiple images from different angles. That might still be multimodal if each view is a different modality, but maybe not. Alternatively, it could be a different approach.\n\nThe other options: time-series is about data over time, which doesn't seem to fit here. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in NLP. KG is Knowledge Graphs, which involve structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval-augmented methods. \n\nSo, the key term is \"Multi-View.\" If \"Multi-View\" refers to using multiple different data sources or modalities, then it's multimodal. If it's just multiple perspectives within the same modality (like multiple images), it might not be multimodal. But in machine learning, multi-view learning is a subfield that deals with data from multiple views, which can be considered a type of multimodal approach. So I think the correct answer here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32634@AAAI"},
{"title": "Step-Calibrated Diffusion for Biomedical Optical Image Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Step-Calibrated Diffusion for Biomedical Optical Image Restoration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or sensor data. The title mentions image restoration, which is more about images, so maybe not time-series. \n\nMultimodal refers to combining different types of data, like text and images. The title is about biomedical optical images, but there's no mention of combining different data types. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks, like in NLP. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image restoration using a diffusion method, which is a type of generative model. Diffusion models are used in image generation and restoration, but the title doesn't mention knowledge graphs. \n\nSo, none of the four topics seem to fit. The paper is about a specific image restoration technique using diffusion, which isn't directly related to time-series, multimodal data, RAG, or knowledge graphs. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32635@AAAI"},
{"title": "GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nNext, multimodal. That refers to combining multiple types of data, like text and images. The paper uses both diffusion models (which are image-related) and large language models (text). So generating posters with both text and images would be multimodal. That seems possible.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text. The title doesn't mention retrieval or augmenting generation with external data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about graphs or structured knowledge, so probably not KG.\n\nSo the most likely answer is multimodal because it combines text and image generation using both types of models.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32636@AAAI"},
{"title": "Aligning and Prompting Anything for Zero-Shot Generalized Anomaly Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Aligning and Prompting Anything for Zero-Shot Generalized Anomaly Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Aligning and Prompting Anything\" suggests that the method involves aligning different components or data types and using prompting techniques. \"Zero-Shot Generalized Anomaly Detection\" means the model can detect anomalies without prior examples of those anomalies, and it's generalized, so it's not limited to specific types.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention time or sequences, so maybe not time-series. Multimodal usually refers to combining different data types like text, images, audio. The title says \"anything,\" which might imply multiple modalities, but I'm not sure. RAG stands for Retrieval-Augmented Generation, which uses retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe key terms here are \"aligning\" and \"prompting.\" Aligning could relate to aligning different modalities (multimodal) or aligning data with knowledge (KG). Prompting is often used in RAG for generating responses. However, the focus here is on anomaly detection. Zero-shot learning often uses prompting techniques, like in RAG where you prompt the model with retrieved information. But generalized anomaly detection might not be directly tied to RAG. Alternatively, if they're using knowledge graphs to detect anomalies, it could be KG. But the title doesn't mention knowledge graphs. \n\nWait, \"aligning anything\" might be about aligning different data sources or modalities. If it's about combining different data types, then multimodal. But the title doesn't specify modalities. Alternatively, if they're using a knowledge graph to align different entities, that would be KG. However, the title doesn't mention knowledge graphs. \n\nRAG involves using retrieval to augment generation. If the method uses retrieved information to prompt the model for anomaly detection, maybe RAG. But the title doesn't explicitly mention retrieval. \n\nHmm. The title is a bit vague. Since it's about zero-shot anomaly detection using aligning and prompting, and none of the terms directly point to time-series, multimodal, RAG, or KG, maybe it's none. But I need to be careful. \n\nWait, \"prompting\" is a key term in RAG. RAG models use prompts to generate answers based on retrieved documents. If the paper is using prompting techniques for anomaly detection, maybe it's RAG. But generalized anomaly detection might not be the typical use case for RAG. \n\nAlternatively, if they're using a knowledge graph to detect anomalies, that would be KG. But again, the title doesn't mention knowledge graphs. \n\nGiven the ambiguity, maybe the answer is none. But I'm not entirely sure. Let me think again. The options are time-series, multimodal, RAG, KG. The title doesn't mention any of these explicitly. So perhaps it's none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32637@AAAI"},
{"title": "Does VLM Classification Benefit from LLM Description Semantics?", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Does VLM Classification Benefit from LLM Description Semantics?\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. VLM stands for Vision-Language Model, right? And LLM is Large Language Model. The question is whether using the semantics from an LLM's description helps in the classification task of a VLM. \n\nSo, VLMs are models that handle both visual and textual data, which makes me think of multimodal learning. Multimodal refers to combining different types of data, like images and text. Since the paper is about how an LLM (text-based) can influence a VLM's classification (which uses both vision and language), this seems like it's dealing with integrating different modalities. \n\nTime-series is about data over time, which doesn't seem relevant here. RAG is Retrieval-Augmented Generation, which involves using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about retrieval, generation, or structured knowledge graphs. \n\nTherefore, the most fitting topic here is multimodal because it's about combining vision and language models, leveraging the semantics from LLMs in a VLM's task. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32638@AAAI"},
{"title": "CAKE: Category Aware Knowledge Extraction for Open-Vocabulary Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CAKE: Category Aware Knowledge Extraction for Open-Vocabulary Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Category Aware Knowledge Extraction\" sounds like it's about extracting knowledge related to categories. \"Open-Vocabulary Object Detection\" suggests that the model can detect objects even if they weren't in the training data, which might involve some kind of knowledge base or external information.\n\nLooking at the options: time-series is about data over time, which doesn't seem relevant here. Multimodal usually involves combining different data types like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance model outputs. KG stands for Knowledge Graph, which is structured data representing entities and relationships.\n\nThe paper's focus on knowledge extraction for object detection makes me think it might be using a Knowledge Graph (KG) to incorporate structured knowledge about categories. The term \"knowledge extraction\" is often associated with building or utilizing knowledge graphs. So, the answer is likely KG. It doesn't seem to fit RAG because RAG is more about retrieval during generation, and multimodal would involve multiple data modalities. Time-series is unrelated here.\n</think>\n\nKG", "url": "https://papers.cool/venue/32639@AAAI"},
{"title": "Instruct Where the Model Fails: Generative Data Augmentation via Guided Self-contrastive Fine-tuning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Instruct Where the Model Fails: Generative Data Augmentation via Guided Self-contrastive Fine-tuning.\" I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main idea seems to be about data augmentation using a method called guided self-contrastive fine-tuning. The phrase \"generative data augmentation\" suggests they're creating new data samples to improve model training. \n\nNow, looking at the options. Time-series would involve data that's sequential over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal typically refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so probably not multimodal. \n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information before generating a response. The title talks about data augmentation through generative methods, but I'm not sure if retrieval is involved here. The method mentioned is \"guided self-contrastive fine-tuning,\" which sounds more like a training technique rather than retrieval-based. \n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about graphs or structured knowledge, so probably not KG. \n\nSo, none of the four topics seem to fit. The paper is about data augmentation using a specific fine-tuning method, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32640@AAAI"}
{"title": "Novel View Synthesis Under Large-Deviation Viewpoint for Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Novel View Synthesis Under Large-Deviation Viewpoint for Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Novel View Synthesis\" sounds like generating new views or images, maybe from different angles. \"Large-Deviation Viewpoint\" might refer to significant changes in perspective. \"Autonomous Driving\" is the application area. \n\nNow, the possible topics. Time-series usually involves data over time, like sequences. Multimodal deals with combining different data types, like images and text. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about generating new views for autonomous driving. That seems more related to computer vision or 3D reconstruction. Novel view synthesis is a term I've heard in computer graphics and vision, where you generate images from new viewpoints. This might involve techniques like neural rendering or using multiple modalities (like cameras, LiDAR) to create the views. If they're using multiple data sources (e.g., combining camera images with other sensors), that would be multimodal. But if it's just about generating views from existing data without combining different modalities, maybe not. \n\nRAG and KG don't seem relevant here. RAG is about using retrieval to augment generation, which is more for text-based models. KGs are structured knowledge bases, which might be used for something else. Time-series is about temporal data, but the title doesn't mention time. \n\nSo, the key is whether multimodal is involved. If the synthesis uses multiple data types (like images and depth maps, or different sensors), then it's multimodal. If it's just about generating views from a single modality (like images), then maybe not. The title doesn't specify, but \"novel view synthesis\" in autonomous driving often uses multiple sensors (cameras, LiDAR, etc.), which are different modalities. So I think it's multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32641@AAAI"},
{"title": "A Trusted Lesion-assessment Network for Interpretable Diagnosis of Coronary Artery Disease in Coronary CT Angiography", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Trusted Lesion-assessment Network for Interpretable Diagnosis of Coronary Artery Disease in Coronary CT Angiography.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data collected over time, like stock prices or sensor data. The title mentions CT angiography, which is a medical imaging technique. So maybe it's image data, but not necessarily time-series unless they're looking at changes over time. The title doesn't specify time-based analysis, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about diagnosing using CT angiography, which is a single modality (images). Unless they're integrating other data types, but the title doesn't mention that. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and relationships. The title talks about a network for lesion assessment, which sounds more like a neural network model rather than building or using a knowledge graph. Unless the model incorporates a KG, but the title doesn't indicate that.\n\nThe key terms here are \"Lesion-assessment Network\" and \"Coronary CT Angiography.\" This seems to be a deep learning model for medical image analysis. The topics given don't include medical imaging or deep learning models in general. Since none of the four topics (time-series, multimodal, RAG, KG) are clearly indicated in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32642@AAAI"},
{"title": "Follow-Your-Click: Open-domain Regional Image Animation via Motion Prompts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Follow-Your-Click: Open-domain Regional Image Animation via Motion Prompts.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Open-domain Regional Image Animation\" suggests that the paper is about creating animations from images, possibly in different regions or areas. \"Motion Prompts\" might refer to using motion-related inputs or instructions to generate the animation. \n\nTime-series usually involves data points indexed in time order, like stock prices over time. This paper seems more about image animation, which is a sequence of images over time, but the focus here might not be on the time-series analysis itself but rather on generating the animation. So maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images, or audio and video. The title mentions \"Motion Prompts,\" which could be a form of input modality (like text prompts for motion) combined with images. If they're using different modalities (text and images) to create animation, that might be multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or augmenting with external data, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The title doesn't seem to relate to knowledge graphs either.\n\nSo the most likely candidate is multimodal. The paper uses motion prompts (which could be a different modality) along with images to create animations. Therefore, it's combining different data types (image and motion instructions), making it multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32643@AAAI"},
{"title": "Storynizor: Consistent Story Generation via Inter-Frame Synchronized and Shuffled ID Injection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Storynizor: Consistent Story Generation via Inter-Frame Synchronized and Shuffled ID Injection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Consistent Story Generation\" suggests it's about creating stories that are coherent. The methods mentioned are \"Inter-Frame Synchronized and Shuffled ID Injection.\" Hmm. \"Inter-Frame\" might relate to frames in a video or sequence, which could be time-series data. But \"ID Injection\" sounds like inserting identifiers, maybe to maintain consistency across frames. \n\nTime-series usually involves data points indexed in time order. If the story is generated over a sequence of frames (like in a video), that could be time-series. But the key here is \"consistent story generation.\" Maybe they're ensuring that the story elements remain consistent across different frames, which are time-ordered. So maybe time-series?\n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention different modalities, so probably not that. RAG is Retrieval-Augmented Generation, which uses external knowledge during generation. The title doesn't mention retrieval or external data, so maybe not RAG. KG is Knowledge Graphs, which are structured data representations. Again, the title doesn't mention knowledge graphs.\n\nSo the most likely is time-series, as it's dealing with sequences (frames) and maintaining consistency over time. The \"inter-frame\" part suggests temporal relationships. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32644@AAAI"},
{"title": "Few-Shot Fine-Grained Image Classification with Progressively Feature Refinement and Continuous Relationship Modeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Few-Shot Fine-Grained Image Classification with Progressively Feature Refinement and Continuous Relationship Modeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Few-Shot\" refers to machine learning where the model is trained with very few examples. \"Fine-Grained Image Classification\" suggests it's about classifying images into very specific categories, like different species of birds or models of cars. The methods mentioned are \"Progressively Feature Refinement\" and \"Continuous Relationship Modeling.\" \n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on image classification, which is a computer vision task. The methods mentioned don't seem to involve time-based data, so time-series is out. There's no mention of combining different data modalities (like text and images together), so multimodal might not fit. RAG and KG are more about using external knowledge or retrieval. The title doesn't mention anything about retrieval or knowledge graphs. The terms \"feature refinement\" and \"relationship modeling\" are more about improving the model's features and understanding relationships within the data, which is common in computer vision tasks. \n\nSo, none of the four topics (time-series, multimodal, RAG, KG) seem to directly apply here. The paper is about image classification techniques, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32645@AAAI"},
{"title": "Relaxed Class-consensus Consistency for Semi-supervised Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Relaxed Class-consensus Consistency for Semi-supervised Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Semi-supervised\" usually refers to machine learning methods that use both labeled and unlabeled data. \"Semantic segmentation\" is a computer vision task where each pixel in an image is classified into a category. So the paper is about improving semantic segmentation using semi-supervised learning.\n\nNow, the key part is \"Relaxed Class-consensus Consistency.\" That sounds like a method to enforce consistency in predictions, maybe using some form of regularization or agreement between different models or different parts of the model. \n\nLooking at the options: time-series deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. Multimodal would involve combining different types of data, like text and images. The paper is about semantic segmentation, which is image data, but there's no mention of combining modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to enhance their responses, often in NLP. The paper's focus is on segmentation, not generation or retrieval. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo, none of the four topics seem to fit. The paper is about a semi-supervised method for semantic segmentation, which is a computer vision task. The techniques used might involve consistency regularization, which is common in semi-supervised learning, but the specific topics listed don't align here. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32646@AAAI"},
{"title": "OUS: Bridging Scene Context and Facial Features to Overcome the Rigid Cognitive Problem", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OUS: Bridging Scene Context and Facial Features to Overcome the Rigid Cognitive Problem.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Bridging Scene Context and Facial Features\" suggests combining different types of data. Scene context might be like the environment or background, and facial features are visual data. So combining different modalities, like visual and contextual information. That makes me think of multimodal, which deals with integrating multiple data types (e.g., text, images, audio).\n\nThe other parts mention overcoming a rigid cognitive problem. Not sure exactly what that refers to, but the key part here is the combination of scene and facial features. Time-series would involve data over time, like sequences. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured data representations. \n\nSince the paper is about integrating different data sources (scene and facial), it's likely multimodal. The other options don't fit as well. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32647@AAAI"},
{"title": "DMF-Net: Image-Guided Point Cloud Completion with Dual-Channel Modality Fusion and Shape-Aware Upsampling Transformer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DMF-Net: Image-Guided Point Cloud Completion with Dual-Channel Modality Fusion and Shape-Aware Upsampling Transformer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components here are \"Image-Guided Point Cloud Completion,\" \"Dual-Channel Modality Fusion,\" and \"Shape-Aware Upsampling Transformer.\" \n\n\"Image-Guided\" suggests that images are being used to guide the process. \"Point Cloud Completion\" refers to completing or reconstructing a point cloud, which is a set of data points in space, often used in 3D modeling. \n\n\"Modality Fusion\" is a key term here. Modality refers to different types of data, like images, text, audio, etc. So \"Dual-Channel Modality Fusion\" probably means combining two different data modalities, in this case, images and point clouds. That points towards multimodal research because it's about integrating multiple data types.\n\nThe other part, \"Shape-Aware Upsampling Transformer,\" might be about the architecture used for processing, but the key part is the fusion of different modalities. \n\nLooking at the options: time-series deals with data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation, which isn't mentioned. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo the most fitting category here is multimodal because the paper is about fusing image and point cloud data, which are different modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32648@AAAI"},
{"title": "CREST: An Efficient Conjointly-trained Spike-driven Framework for Event-based Object Detection Exploiting Spatiotemporal Dynamics", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CREST: An Efficient Conjointly-trained Spike-driven Framework for Event-based Object Detection Exploiting Spatiotemporal Dynamics.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Event-based Object Detection\" suggests that the data is coming from events, which might be time-stamped. \"Spatiotemporal Dynamics\" definitely implies both spatial and temporal aspects. So, time-series could be a possibility here because time-series data involves sequences over time. But wait, event-based data is a bit different. Events are asynchronous and can be sparse, but they still have a temporal component. So maybe time-series is relevant.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, like in NLP. The title doesn't mention anything about retrieval or generation, so RAG is out.\n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so that's not it either.\n\nSo the main clue is \"Spatiotemporal Dynamics\" and \"Event-based.\" Spatiotemporal implies both space and time, which is a key aspect of time-series analysis. Even though event-based data isn't a traditional time-series, the temporal aspect is there. Therefore, the paper likely falls under the time-series topic.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32649@AAAI"},
{"title": "Image Regeneration: Evaluating Text-to-Image Model via Generating Identical Image with Multimodal Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Image Regeneration: Evaluating Text-to-Image Model via Generating Identical Image with Multimodal Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on image regeneration, which involves creating images from text. The key part here is \"Multimodal Large Language Models.\" Multimodal typically refers to models that handle multiple types of data, like text and images. So that's a hint towards the \"multimodal\" category. \n\nThe paper is evaluating a text-to-image model by generating identical images. The use of \"Multimodal Large Language Models\" suggests that the model is processing both text and images, which aligns with multimodal research. Time-series would involve data over time, like stock prices or weather data, which isn't mentioned here. RAG (Retrieval-Augmented Generation) usually involves using a retrieval system to augment the generation process, but the title doesn't mention retrieval. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't seem relevant here. \n\nSo the most fitting category is multimodal. The paper is about models that handle multiple modalities (text and images), so the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32651@AAAI"}
{"title": "Image Regeneration: Evaluating Text-to-Image Model via Generating Identical Image with Multimodal Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Image Regeneration: Evaluating Text-to-Image Model via Generating Identical Image with Multimodal Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on image regeneration, which involves creating images from text. The key part here is \"Multimodal Large Language Models.\" Multimodal typically refers to models that handle multiple types of data, like text and images. So that's a hint towards the \"multimodal\" category. \n\nThe paper is evaluating a text-to-image model by generating identical images. The use of \"Multimodal Large Language Models\" suggests that the model is processing both text and images, which aligns with multimodal research. Time-series would involve data over time, like stock prices or weather data, which isn't mentioned here. RAG (Retrieval-Augmented Generation) usually involves using a retrieval system to augment the generation process, but the title doesn't mention retrieval. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't seem relevant here. \n\nSo the most fitting category is multimodal. The paper is about models that handle multiple modalities (text and images), so the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32651@AAAI"},
{"title": "Black-Box Test-Time Prompt Tuning for Vision-Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Black-Box Test-Time Prompt Tuning for Vision-Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Black-Box Test-Time Prompt Tuning\" suggests some kind of method for adjusting prompts during testing, without knowing the internal workings (black-box). \"Vision-Language Models\" implies that the model deals with both visual and language data. So, vision and language are two different modalities. That makes me think of multimodal, since multimodal refers to models that handle multiple types of data, like images and text together.\n\nTime-series would be about data that's sequential over time, like stock prices or weather data. RAG is Retrieval-Augmented Generation, which involves using a retrieval system to get information and then generating a response. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on vision and language, which are two different modalities. So the topic here is multimodal. The other options don't fit. Time-series isn't relevant here. RAG and KG are more about specific techniques or structures, not the combination of different data types. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32652@AAAI"},
{"title": "Sp3ctralMamba: Physics-Driven Joint State Space Model for Hyperspectral Image Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sp3ctralMamba: Physics-Driven Joint State Space Model for Hyperspectral Image Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order. The title mentions \"state space model,\" which can be used in time-series analysis, but the main focus here seems to be on hyperspectral image reconstruction. Hyperspectral images are multi-dimensional, capturing data across different wavelengths. So maybe that's related to multimodal? Wait, multimodal typically refers to combining different types of data, like text and images. Hyperspectral images are more about multiple spectral bands, which is a type of data modality, but not necessarily combining different modalities. Hmm.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's title doesn't mention knowledge graphs or structured data, so that's probably out.\n\nThe key part here is \"Physics-Driven Joint State Space Model.\" State space models are often used in time-series, but the application here is for hyperspectral image reconstruction. Hyperspectral images are a type of multi-dimensional data, but the term \"joint\" might imply combining different aspects or modalities. However, the main focus is on the reconstruction using a physics-driven model. Since the options are time-series, multimodal, RAG, or KG, and none of the other terms fit, maybe it's none? Wait, but the state space model could be part of time-series. However, the problem is image reconstruction, which is more about spatial data. Unless the model is processing the image over time, but the title doesn't specify that. So maybe it's not time-series either. Therefore, the answer might be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32653@AAAI"},
{"title": "Accelerated Diffusion via High-Low Frequency Decomposition for Pan-Sharpening", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Accelerated Diffusion via High-Low Frequency Decomposition for Pan-Sharpening.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Pan-Sharpening\" refers to a technique in remote sensing where a high-resolution panchromatic image is combined with a lower-resolution multispectral image to create a high-resolution color image. So that's image processing, specifically dealing with combining different types of images. \n\nNow, the methods mentioned are \"Accelerated Diffusion\" and \"High-Low Frequency Decomposition.\" Diffusion methods are often used in image processing for tasks like denoising or sharpening. High-low frequency decomposition might involve separating image components into different frequency bands, which is a common technique in signal processing. \n\nLooking at the possible topics: time-series deals with data over time, which doesn't seem to fit here. Multimodal refers to combining different types of data (like images and text), but in this case, it's about combining different spectral images (panchromatic and multispectral), which could be considered multimodal. However, the main focus here is on the image processing technique rather than integrating multiple modalities. \n\nRAG (Retrieval-Augmented Generation) is about using retrieved information to enhance generation tasks, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo, the paper is about image processing techniques for pan-sharpening. The key here is whether combining different image types (panchromatic and multispectral) falls under multimodal. Since multimodal typically refers to different data types (e.g., text and images), but in this case, it's different spectral bands of images, maybe it's a stretch. However, some might argue that different spectral images are different modalities. But the primary focus is on the diffusion method and frequency decomposition, which are more about the algorithm rather than the modality integration. \n\nAlternatively, maybe it's not any of the four topics. The options are time-series, multimodal, RAG, KG. Since the paper is about image processing for pan-sharpening using specific algorithms, and none of the four topics directly relate to that, the answer might be \"none.\" But I need to be careful. If multimodal is considered as combining different data types (even if they are different spectral images), then maybe it's multimodal. But I'm not entirely sure. Let me think again. \n\nMultimodal usually refers to integrating data from different sources or types, like combining text and images, or audio and video. In pan-sharpening, it's combining two images with different resolutions and spectral characteristics. So, in the context of machine learning, that could be considered multimodal because you're using different types of data (panchromatic and multispectral) to produce a better image. Therefore, the topic might be multimodal. \n\nBut wait, the question is whether the paper belongs to one of the four topics. If the paper's main contribution is the diffusion method and frequency decomposition, then maybe it's not about the modality itself but the technique. However, the application is in pan-sharpening, which is a multimodal task. So perhaps the correct answer is multimodal. \n\nAlternatively, if the paper is just about the algorithm (diffusion and frequency decomposition) without focusing on the multimodal aspect, then it might not fit any of the four. But given the options, the closest would be multimodal. \n\nI think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32654@AAAI"},
{"title": "EvdCLIP: Improving Vision-Language Retrieval with Entity Visual Descriptions from Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EvdCLIP: Improving Vision-Language Retrieval with Entity Visual Descriptions from Large Language Models.\" I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language Retrieval\" suggests that the paper deals with tasks that involve both visual (images) and language (text) data. That immediately makes me think of multimodal learning, since multimodal refers to combining different types of data like vision and language. \n\nThen, the part about \"Entity Visual Descriptions from Large Language Models\" – they're using LLMs to generate descriptions of entities, which are probably objects or concepts in images. So, they're enhancing the retrieval by incorporating these descriptions. \n\nNow, checking the options. Time-series is about data over time, which doesn't fit here. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to augment its responses, but the title doesn't mention generation or augmenting with retrieved data in that way. KG (Knowledge Graphs) involve structured data and relationships, which isn't directly mentioned here. \n\nMultimodal is about combining multiple modalities, like vision and language, which aligns with the vision-language retrieval part. The paper is improving how these two modalities are used together for retrieval, so multimodal seems right. \n\nI don't see any mention of time-series data, knowledge graphs, or retrieval-augmented generation beyond the retrieval aspect. The key here is the combination of vision and language, which is a classic multimodal problem. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32655@AAAI"},
{"title": "Boosting ViT-based MRI Reconstruction from the Perspectives of Frequency Modulation, Spatial Purification, and Scale Diversification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Boosting ViT-based MRI Reconstruction from the Perspectives of Frequency Modulation, Spatial Purification, and Scale Diversification.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. ViT stands for Vision Transformer, which is a type of neural network used in image processing. MRI reconstruction is about improving the quality of MRI images, probably using machine learning techniques. The methods mentioned are frequency modulation, spatial purification, and scale diversification. These seem like technical approaches to enhance the reconstruction process.\n\nNow, the four possible topics. Time-series would involve data that changes over time, like stock prices or sensor data over time. The paper here is about MRI images, which are static images, so time-series might not fit unless they're dealing with dynamic MRI, but the title doesn't mention time. \n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention combining different data types, just improving MRI reconstruction using ViT. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to generate responses. That's more common in NLP tasks, like question-answering systems. The paper here is about image reconstruction, so RAG doesn't seem relevant.\n\nKG is Knowledge Graph, which involves structured data representations. The paper doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, the paper is about improving MRI image reconstruction using Vision Transformers with specific techniques. None of the four topics (time-series, multimodal, RAG, KG) directly apply here. The focus is on image processing methods rather than any of those specific areas. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32656@AAAI"},
{"title": "Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Autonomous\" suggests it's self-operating. \"LLM-Enhanced\" means it uses a Large Language Model. \"Adversarial Attack\" refers to methods that try to fool machine learning models. \"Text-to-Motion\" implies converting text into motion, which could be related to generating animations or robotic movements based on text.\n\nNow, the topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data retrieval to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on adversarial attacks in a text-to-motion system. Adversarial attacks are a security concern in machine learning. Text-to-motion is a multimodal task because it combines text (language) and motion (which could be video or animation). So, the system likely uses both text and motion data, making it multimodal. The use of LLMs might be part of the attack method, but the core task is converting text to motion, which is multimodal. The adversarial aspect is about attacking the model, but the primary research area here is the combination of text and motion data. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32657@AAAI"},
{"title": "Qua2SeDiMo: Quantifiable Quantization Sensitivity of Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Qua2SeDiMo: Quantifiable Quantization Sensitivity of Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Quantifiable Quantization Sensitivity\" suggests they're looking at how sensitive diffusion models are to quantization, which is about reducing the precision of numbers in a model, maybe for efficiency. \"Diffusion Models\" are a type of generative model, often used in image or audio generation. \n\nNow, the four options. Time-series would involve data over time, like stock prices or weather. Multimodal refers to models that handle multiple types of data, like text and images. RAG is Retrieval-Augmented Generation, which combines retrieval of information with generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on quantization sensitivity in diffusion models. Quantization is a technique used in model optimization, but the core of the research here is about how diffusion models react to quantization. Diffusion models are typically used in generative tasks, which can be part of multimodal systems if they handle different data types. However, the title doesn't mention multiple modalities. It's about the sensitivity of the model's quantization, which is more about model efficiency or compression. \n\nNone of the four topics directly relate to quantization sensitivity or diffusion models. Time-series is unrelated. Multimodal might be a stretch if the diffusion model is multimodal, but the title doesn't specify that. RAG and KG are about retrieval and knowledge graphs, which aren't mentioned here. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32658@AAAI"},
{"title": "Energy vs. Noise: Towards Robust Temporal Action Localization in Open-World", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Energy vs. Noise: Towards Robust Temporal Action Localization in Open-World.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Action Localization\" suggests something related to time, since \"temporal\" refers to time. So that's a hint towards time-series. Time-series analysis often deals with data points indexed in time order, like sequences or time-based patterns. Action localization in videos, for example, is a common time-series problem where you identify when actions occur in a video.\n\nThe other part of the title mentions \"Energy vs. Noise,\" which might be about distinguishing between meaningful signals (energy) and background noise in the data. But that's more about the methodology or the problem being addressed rather than the type of data or model.\n\nNow, looking at the options. Time-series is a strong candidate here because of the temporal aspect. Multimodal would involve combining different types of data (like text and images), but the title doesn't mention that. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem related. KG (Knowledge Graph) involves structured data and relationships, which also isn't indicated here.\n\nSo the key term is \"Temporal Action Localization,\" which is a time-series problem. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32659@AAAI"},
{"title": "Extract Free Dense Misalignment from CLIP", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Extract Free Dense Misalignment from CLIP.\" Hmm. First, I need to break down the title to understand what it's about. CLIP is a well-known multimodal model developed by OpenAI. It's designed to understand both images and text, so it's used for tasks like image-text matching. The term \"misalignment\" here probably refers to discrepancies between the image and text modalities. \n\nThe phrase \"Free Dense Misalignment\" might be a specific technique or method they're using. \"Dense\" could mean that they're looking at detailed, pixel-level or token-level misalignments rather than a more general or sparse approach. \"Extract\" suggests they're developing a method to identify or extract these misalignments.\n\nNow, the research topics in question are time-series, multimodal, RAG, or KG. Time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which combines retrieval of documents with generation models. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nGiven that CLIP is a multimodal model, and the paper is about misalignment in CLIP, which deals with both images and text, this seems to fall under the multimodal category. The other topics don't fit here. There's no mention of time-series data, retrieval-augmented generation, or knowledge graphs in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32660@AAAI"}
{"title": "SegFace: Face Segmentation of Long-Tail Classes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SegFace: Face Segmentation of Long-Tail Classes.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. Face segmentation doesn't seem to be about time-based data. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions face segmentation, which is an image processing task. But does it involve multiple modalities? The title doesn't mention anything else like text or audio, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate a response, often in NLP. Face segmentation doesn't seem related to retrieval or generation. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about building or using a knowledge graph. So that's probably not it either.\n\nThe task here is face segmentation, which is a computer vision problem. The mention of \"long-tail classes\" suggests dealing with rare or less common categories in the data. But none of the given topics directly relate to computer vision or handling class imbalance. The four options provided don't include computer vision or class distribution topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32661@AAAI"},
{"title": "HiGDA: Hierarchical Graph of Nodes to Learn Local-to-Global Topology for Semi-Supervised Domain Adaptation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HiGDA: Hierarchical Graph of Nodes to Learn Local-to-Global Topology for Semi-Supervised Domain Adaptation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Hierarchical Graph of Nodes\" suggests some kind of graph structure. \"Local-to-Global Topology\" might be about how local structures in the graph relate to the overall structure. The main application here is \"Semi-Supervised Domain Adaptation,\" which is a machine learning technique where you adapt a model from a source domain to a target domain with limited labeled data.\n\nNow, looking at the options. Time-series would involve data over time, like sequences. The title doesn't mention anything about time, so probably not that. Multimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple modalities, so maybe not. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. That doesn't seem to fit here either. \n\nKG stands for Knowledge Graph, which is a structured representation of knowledge, often in the form of a graph. The paper's title mentions a \"Hierarchical Graph of Nodes,\" which sounds like a graph structure, possibly a knowledge graph. The focus on topology and domain adaptation might involve using a graph to represent relationships between data points. So, the most likely answer here is KG. \n\nI should double-check if there's any mention of retrieval or generation, which would point to RAG, but the title doesn't indicate that. The key terms are graph and domain adaptation, which aligns more with knowledge graphs. So, the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32662@AAAI"},
{"title": "SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SwiftTry: Fast and Consistent Video Virtual Try-On with Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Video Virtual Try-On\" suggests that the paper is about trying on clothes or items virtually using video. The term \"video\" implies that there's a sequence of frames over time, which might relate to time-series data. But wait, time-series usually refers to data points indexed in chronological order, like stock prices over time. However, video processing can involve time-series analysis because each frame is a time step. But maybe there's more to it.\n\n\"Diffusion Models\" are a type of generative model, often used in image and video generation. They might be used here to generate the virtual try-on results. Now, the options given are time-series, multimodal, RAG, or KG. Let's consider each:\n\n- Time-series: If the paper is about analyzing sequences over time, maybe. But virtual try-on with video could involve processing each frame, but the main focus might not be on time-series analysis per se. It's more about generating realistic try-ons across video frames, which could involve temporal consistency. However, the term \"time-series\" is usually more about statistical analysis of time-based data rather than video generation.\n\n- Multimodal: This refers to combining multiple types of data, like text and images, or audio and video. The paper's title doesn't mention combining different modalities. It's about video virtual try-on, which might involve images (clothing) and video (the person trying on), but unless they're integrating different data types beyond that, it might not be multimodal.\n\n- RAG (Retrieval-Augmented Generation): This is a method where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or augmenting generation with retrieved data, so probably not RAG.\n\n- KG (Knowledge Graph): This involves structured data representations, like graphs of entities and relationships. The title doesn't suggest the use of knowledge graphs, so likely not KG.\n\nSo, the main contenders are time-series and multimodal. The paper uses diffusion models for video, which is a sequence of frames. If the model is ensuring consistency across frames (as the title says \"Consistent Video\"), that might involve temporal modeling, which is part of time-series. However, in machine learning, video processing often falls under computer vision tasks, and while there's a temporal aspect, it's not always categorized strictly as time-series. The term \"time-series\" is more commonly used in contexts like financial data, sensor data, etc. \n\nAlternatively, if the model is generating frames in a sequence and maintaining consistency, that's more about temporal coherence in video generation, which is a part of computer vision rather than traditional time-series analysis. So maybe it's not strictly a time-series topic. The multimodal aspect is also questionable unless they're combining different data types. Since the title doesn't mention anything about combining modalities, it's probably not that either.\n\nGiven the options, the closest might be time-series, but I'm not entirely sure. However, since the paper is about video (a sequence of frames) and ensuring consistency across them, which is a temporal aspect, maybe it's considered time-series. But I'm a bit uncertain because in ML, video tasks are often under computer vision, not time-series. The other options don't fit. So perhaps the answer is time-series, but I'm not 100% confident. Alternatively, maybe none of the options fit. Wait, the options are time-series, multimodal, RAG, KG. If none of these are correct, then the answer is \"none\". \n\nBut the paper is about video virtual try-on using diffusion models. The key here is whether the research topic aligns with any of the four. Since the paper is about generating video (which is a sequence) and ensuring consistency, maybe time-series is the closest. However, in academic terms, video processing is often under computer vision or multimedia, not necessarily time-series. So perhaps the answer is \"none\". But the user wants me to choose from the four. Hmm. Alternatively, maybe multimodal if they're combining different data types. For example, if the try-on involves both images (clothing) and video (person), but that's still within the same modality (visual). Unless they're combining text and video, which isn't mentioned. So probably not multimodal. \n\nGiven that, the best fit might be time-series, but I'm not entirely sure. Alternatively, maybe the answer is none. But the user wants me to pick from the four. Let me check again. The title mentions \"video virtual try-on with diffusion models.\" Diffusion models are a type of generative model, but that's not one of the options. The options are time-series, multimodal, RAG, KG. Since none of these seem to directly fit, maybe the answer is \"none\". But the user might expect time-series because of the video aspect. However, I'm not certain. Maybe the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32663@AAAI"},
{"title": "iMoT: Inertial Motion Transformer for Inertial Navigation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"iMoT: Inertial Motion Transformer for Inertial Navigation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Inertial Motion Transformer\" suggests they're using a Transformer model, which is a type of neural network architecture. The application is \"Inertial Navigation,\" which typically involves using data from inertial measurement units (IMUs) like accelerometers and gyroscopes. These sensors provide time-dependent data, so the input is likely a time-series. \n\nTransformers are often used in time-series analysis because they can handle sequential data effectively. So maybe this is a time-series topic. But wait, could it be multimodal? Multimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data types, just inertial data. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is unlikely. KG is Knowledge Graphs, which involve structured data and relationships. Again, the title doesn't suggest that.\n\nSo the main clue is \"Inertial Navigation\" using a Transformer. Since inertial data is collected over time, it's a time-series problem. The Transformer is being applied to sequential data here. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32664@AAAI"},
{"title": "Motion-aware Contrastive Learning for Temporal Panoptic Scene Graph Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Motion-aware Contrastive Learning for Temporal Panoptic Scene Graph Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Motion-aware\" suggests something related to movement over time, which might tie into time-series data. \"Contrastive Learning\" is a method often used in machine learning, but that's more about the technique rather than the topic. \"Temporal\" definitely points to time, so that's a strong indicator for time-series. \"Panoptic Scene Graph Generation\" involves creating graphs that represent scenes, which could be related to knowledge graphs (KG) since they structure information. But wait, scene graphs are more about representing objects and their relationships in a scene, which is a type of knowledge graph. However, the \"temporal\" aspect here is key. The combination of temporal and scene graphs might mean it's about modeling over time, which is time-series. But scene graphs themselves are structured data, so maybe KG? Hmm.\n\nWait, the options are time-series, multimodal, RAG, or KG. Let me think again. Time-series is about data over time, like sequences. Multimodal would involve multiple data types (text, image, etc.). RAG is Retrieval-Augmented Generation, which is a specific method in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on generating scene graphs that are temporal, meaning they change over time. Scene graphs are a form of knowledge graph, but the temporal aspect here might be more about the time-series aspect. However, the primary output is a scene graph, which is a structured representation. But the problem is generating these graphs over time, which could involve time-series modeling. But the core of the topic is the generation of the graph structure, which is a knowledge graph. However, the title mentions \"Temporal,\" which is a time aspect. So maybe it's time-series? Or is the main contribution the generation of the scene graph, making it a knowledge graph topic? \n\nAlternatively, maybe it's neither. If the paper is about creating a scene graph that evolves over time, it's combining time-series data with knowledge graphs. But the question is which of the four topics it belongs to. Since the options are time-series, multimodal, RAG, or KG. The most direct would be KG because scene graphs are a type of knowledge graph. However, the temporal aspect might make it time-series. But time-series is about the data being a sequence over time, whereas the scene graph is the structure. So maybe the primary topic is KG, but the temporal aspect is a modifier. Alternatively, if the method uses time-series techniques to generate the scene graph, then it's time-series. But the title says \"Temporal Panoptic Scene Graph Generation,\" which is about generating a scene graph that's temporal. So the main focus is on the scene graph (KG) with a temporal component. Therefore, the topic would be KG. But I'm a bit confused. Let me check again. The four options are time-series, multimodal, RAG, KG. The paper is about generating a scene graph that's temporal. Scene graphs are knowledge graphs. So the answer is KG. But wait, maybe the temporal aspect is part of the time-series. For example, if the input is a time-series of images and the output is a scene graph over time, then it's time-series. But the title doesn't specify the input. The key is the output: a temporal scene graph. So the structure is a knowledge graph that's temporal. Therefore, the topic is KG. Alternatively, if the process of generating it uses time-series methods, then it's time-series. But the title doesn't mention time-series methods. It mentions contrastive learning, which is a technique, but the topic is about the data structure. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32665@AAAI"},
{"title": "Multi-Scale Contrastive Learning for Video Temporal Grounding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Scale Contrastive Learning for Video Temporal Grounding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video Temporal Grounding\" sounds like it's about understanding the timing or sequence in videos. Temporal usually relates to time, so maybe time-series? But wait, time-series is more about data that's sequential over time, like stock prices or sensor data. Video is a form of time-series data, but the term \"temporal grounding\" might be more about aligning or identifying specific time points in the video with some context. \n\nThen there's \"Multi-Scale Contrastive Learning.\" Contrastive learning is a method used in machine learning, often in self-supervised learning, where the model learns by contrasting positive and negative examples. Multi-scale could mean looking at different levels of detail or different time scales. \n\nNow, the options are time-series, multimodal, RAG, or KG. Let's consider each. \n\nTime-series: If the paper is about analyzing video data over time, maybe. But video is a type of time-series data, but the specific task here is temporal grounding, which might involve aligning video segments with text or other modalities. \n\nMultimodal: That's when the model uses multiple types of data, like text and video. The title doesn't mention text or other modalities explicitly, but \"temporal grounding\" could involve aligning video with another modality, like text descriptions. However, the title doesn't specify that. \n\nRAG (Retrieval-Augmented Generation): That's a method where a model retrieves information from a database and uses it to generate responses. Doesn't seem related here. \n\nKG (Knowledge Graph): Involves structured data and relationships. The title doesn't mention anything about knowledge graphs. \n\nSo, the main question is whether this is time-series or multimodal. The key term is \"temporal grounding.\" Temporal grounding in video could be about aligning video segments with temporal information, which might be part of a time-series analysis. However, if the paper is using contrastive learning across different scales in the video's time dimension, that's more about the time aspect. But if it's combining video with another modality (like text) for grounding, then it's multimodal. \n\nThe title doesn't mention text or other modalities, just video. So maybe it's time-series. But I'm a bit unsure. Alternatively, maybe it's multimodal if the grounding is between video and another modality. But the title doesn't specify. \n\nWait, \"temporal grounding\" in video could mean mapping video content to specific time points or intervals, which is a time-series task. So perhaps the answer is time-series. But I'm not 100% sure. Alternatively, if the paper is about combining different modalities (like video and text) for grounding, then it's multimodal. But the title doesn't mention text. \n\nHmm. The title is \"Multi-Scale Contrastive Learning for Video Temporal Grounding.\" The key here is that the task is temporal grounding in video. Temporal grounding is about aligning temporal information, which is time-based. So maybe time-series. But I'm still a bit conflicted. Let me think again. \n\nTime-series analysis typically involves sequences of data points over time. Video is a sequence of frames, so it's inherently time-series. Temporal grounding in video would involve understanding the temporal aspects, so this could fall under time-series. \n\nAlternatively, if the paper is using multimodal data (like video and text) for grounding, then it's multimodal. But the title doesn't mention text. The term \"temporal grounding\" could be part of a multimodal task, but without explicit mention, it's hard to say. \n\nGiven the options, I think the best fit is time-series. So the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32666@AAAI"},
{"title": "SPU-IMR: Self-supervised Arbitrary-scale Point Cloud Upsampling via Iterative Mask-recovery Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SPU-IMR: Self-supervised Arbitrary-scale Point Cloud Upsampling via Iterative Mask-recovery Network.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on point cloud upsampling. Point clouds are 3D data points, often used in computer vision or robotics. The method is self-supervised, which is a type of machine learning, and it uses an iterative mask-recovery network. \n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. This paper is about point clouds, which are spatial data, not time-based. So probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention combining different modalities, just working on point clouds. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses, often in NLP. The paper's title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on upsampling point clouds, which is more about data processing or computer vision, not knowledge representation. \n\nSo none of the four topics seem to fit. The paper is about point cloud upsampling using a specific neural network approach, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32667@AAAI"},
{"title": "Exploring Semantic Consistency and Style Diversity for Domain Generalized Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring Semantic Consistency and Style Diversity for Domain Generalized Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on semantic segmentation, which is a computer vision task where each pixel in an image is classified into a category. The terms \"Semantic Consistency\" and \"Style Diversity\" suggest they're looking at how the model maintains consistent understanding across different domains (like different datasets or environments) while also handling variations in style. \"Domain Generalized\" implies that the model is being trained to perform well on unseen domains, which is a common challenge in machine learning when data distributions vary.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The title is about semantic segmentation, which is image-based, but there's no mention of combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on domain generalization in semantic segmentation, which doesn't directly relate to building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about improving domain generalization in a computer vision task, which is more about model robustness and adaptation rather than the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32668@AAAI"},
{"title": "EOV-Seg: Efficient Open-Vocabulary Panoptic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EOV-Seg: Efficient Open-Vocabulary Panoptic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Panoptic Segmentation\" refers to a task in computer vision where the goal is to segment an image into both objects and stuff (like background). Open-vocabulary here probably means the model can recognize objects beyond a fixed set of classes, maybe using some kind of knowledge base or external information. But wait, RAG (Retrieval-Augmented Generation) is about using external documents to enhance model responses, which is more common in NLP. KG (Knowledge Graph) involves structured data and relationships between entities. \n\nMultimodal would involve combining different data types like text and images. Time-series is about sequential data over time. The title doesn't mention anything about time, so probably not time-series. \n\nOpen-vocabulary segmentation might use a knowledge graph to map the vocabulary to the segmentation classes. Alternatively, if it's using retrieval to get additional information for segmentation, that could be RAG. But RAG is more about augmenting generation with retrieved documents. \n\nPanoptic segmentation is a computer vision task, and open-vocabulary might involve using a knowledge graph to link the vocabulary to the segmentation labels. So maybe KG? Or is it multimodal if combining different modalities? The title doesn't specify combining modalities, just segmentation with open vocabulary. \n\nAlternatively, maybe it's using a knowledge graph to handle the open vocabulary aspect. So the answer could be KG. But I'm not entirely sure. Let me think again. If the model is using a knowledge graph to understand the vocabulary for segmentation, then KG. If it's using retrieval from a database to augment the model's knowledge, then RAG. But RAG is typically for text generation. \n\nSince the task is segmentation, which is more about image data, and open-vocabulary might involve linking to a knowledge base, I think the answer is KG. So the topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32669@AAAI"},
{"title": "Efficient Robustness Evaluation via Constraint Relaxation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Efficient Robustness Evaluation via Constraint Relaxation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining different data types, like text and images. The title doesn't talk about multiple modalities, so probably not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generative models. The title mentions robustness evaluation, but not retrieval or generation. Doesn't seem to fit RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title's focus is on constraint relaxation for robustness. I don't see a direct link to knowledge graphs here.\n\nThe paper seems to be about evaluating robustness through relaxing constraints, which might be a methodological approach rather than a specific topic like the ones listed. Since none of the four topics clearly apply, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32670@AAAI"}
{"title": "Dual-calibrated Co-training Framework for Personalized Federated Semi-Supervised Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dual-calibrated Co-training Framework for Personalized Federated Semi-Supervised Medical Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on a framework for medical image segmentation. The terms \"Federated\" and \"Semi-Supervised\" are mentioned, which are more about the learning approach and data handling. \"Dual-calibrated Co-training\" suggests a method involving two models or components working together, possibly in a semi-supervised setup. \n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. Multimodal usually refers to combining different types of data, like text and images. The paper is about medical image segmentation, which is a single modality (images), so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely. KG is Knowledge Graphs, which involve structured data and relationships. Again, the title is about image segmentation, not structured knowledge. \n\nSo, none of the four topics seem to fit. The paper is about a specific framework for medical image segmentation in a federated learning setting, which is more related to machine learning methods in medical imaging rather than the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32671@AAAI"},
{"title": "Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for Remote Sensing Community", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Locate Anything on Earth: Advancing Open-Vocabulary Object Detection for Remote Sensing Community.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about object detection in remote sensing, which might involve images, but the title doesn't specify combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on object detection in remote sensing, which is more about computer vision and geospatial data. Unless they're integrating a knowledge graph into their model, which isn't indicated here, KG might not be the right fit.\n\nThe paper is about open-vocabulary object detection, which is a computer vision task. The topics given don't include computer vision or object detection specifically. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to the main focus of the paper, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32672@AAAI"},
{"title": "Learning with Open-world Noisy Data via Class-independent Margin in Dual Representation Space", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning with Open-world Noisy Data via Class-independent Margin in Dual Representation Space.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on learning with noisy data in an open-world setting. The methods mentioned are class-independent margin and dual representation space. \n\nTime-series usually involves data over time, like sequences or temporal data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't talk about multiple modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation models, often in NLP. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't reference knowledge graphs or structured data, so that's probably not it.\n\nThe paper seems to be about handling noisy data in a dual representation space, which might relate to robust learning or data cleaning, but none of the given topics fit. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32673@AAAI"},
{"title": "DuSSS: Dual Semantic Similarity-Supervised Vision-Language Model for Semi-Supervised Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DuSSS: Dual Semantic Similarity-Supervised Vision-Language Model for Semi-Supervised Medical Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language Model\" immediately makes me think of multimodal because it combines visual (images) and language (text) data. Multimodal models typically handle multiple types of data, like images and text together. The term \"semi-supervised\" refers to the learning approach, using both labeled and unlabeled data, but that's more about the methodology rather than the topic category here. \n\nThe other parts of the title mention \"Dual Semantic Similarity-Supervised,\" which might relate to how the model uses semantic information from both vision and language. The application is in \"Medical Image Segmentation,\" which is a specific use case but doesn't directly point to one of the four topics. \n\nLooking at the options: time-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships. None of these seem to fit here. The key part is \"Vision-Language Model,\" which is a classic example of a multimodal approach. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32674@AAAI"},
{"title": "Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Label-Efficient Data Augmentation with Video Diffusion Models for Guidewire Segmentation in Cardiac Fluoroscopy.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Label-Efficient Data Augmentation\" suggests they're working with data that's maybe scarce or expensive to label, so they're using techniques to generate more data without needing lots of labels. \"Video Diffusion Models\" – diffusion models are a type of generative model, and video implies time-series data since videos are sequences over time. \"Guidewire Segmentation in Cardiac Fluoroscopy\" – this is about medical imaging, specifically fluoroscopy, which is a type of X-ray imaging that shows real-time moving images. So the data here is likely a sequence of images over time, making it time-series.\n\nNow, checking the options. Time-series would fit because the data is video (a sequence of frames over time). Multimodal usually refers to combining different types of data, like text and images, but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, which isn't mentioned here. KG (Knowledge Graphs) involve structured data representations, which also don't seem relevant. The focus is on generating video data for segmentation, so time-series is the best fit.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32675@AAAI"},
{"title": "Fair Training with Zero Inputs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Fair Training with Zero Inputs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't talk about multiple data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title mentions \"training,\" but RAG is more about the generation phase using retrieval. Not sure if training with zero inputs relates to RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nThe title says \"Fair Training with Zero Inputs.\" \"Zero Inputs\" might refer to training without using any input data, or maybe using a minimal input. Fair training could relate to fairness in machine learning, ensuring models don't have biases. But none of the four topics directly relate to fairness or zero inputs. The four options are time-series, multimodal, RAG, KG. Since none of these seem to fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32676@AAAI"},
{"title": "Procedure Knowledge Decoupled Distillation Strategy for Procedure Planning in Instructional Videos", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Procedure Knowledge Decoupled Distillation Strategy for Procedure Planning in Instructional Videos.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Procedure Knowledge Decoupled Distillation Strategy\" sounds like a method or approach. \"Procedure Planning in Instructional Videos\" suggests that the application is about planning steps in videos that teach procedures, like how to do something step-by-step.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to using multiple types of data, like text and images or video. RAG is Retrieval-Augmented Generation, which combines retrieval of information with generating responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on procedure planning in instructional videos. Instructional videos typically involve both visual and textual information, maybe even audio. So, if the method uses multiple modalities (like video and text), it might be multimodal. The term \"decoupled distillation\" might refer to separating different aspects of knowledge during training, but I'm not sure. However, the key part here is \"instructional videos,\" which are inherently multimodal. The procedure planning would require understanding both the visual steps and the accompanying instructions, which are different modalities. So this seems like a multimodal task. \n\nI don't see any mention of time-series data here. RAG and KG are more about knowledge retrieval or structured knowledge, which doesn't directly fit the title. The main application is in handling instructional videos, which are multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32677@AAAI"},
{"title": "S2S2: Semantic Stacking for Robust Semantic Segmentation in Medical Imaging", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"S2S2: Semantic Stacking for Robust Semantic Segmentation in Medical Imaging.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Semantic Segmentation\" is a common term in computer vision, especially in medical imaging, where the goal is to classify each pixel in an image into a category. The term \"Semantic Stacking\" might refer to a method that combines different models or layers to improve segmentation. \n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order, like stock prices or sensor data over time. This paper is about medical imaging, which is more about images (2D or 3D) rather than sequences over time. So probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images, or different sensor data. The title doesn't mention anything about combining different data types. It's focused on semantic segmentation in medical imaging, which is a single modality (images). So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method used in natural language processing where a model retrieves information from a database to enhance its responses. This seems unrelated to image segmentation. The paper's title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on segmentation techniques, not on building or using knowledge graphs. So likely not KG.\n\nSo, none of the four topics seem to fit. The paper is about a new method for semantic segmentation in medical imaging, which is a computer vision task. The topics provided don't include computer vision or segmentation-specific methods. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32678@AAAI"},
{"title": "Planning from Imagination: Episodic Simulation and Episodic Memory for Vision-and-Language Navigation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Planning from Imagination: Episodic Simulation and Episodic Memory for Vision-and-Language Navigation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Vision-and-Language Navigation\" immediately makes me think of multimodal because it combines visual and language data. Multimodal research deals with integrating different types of data, like images and text. So that's a strong hint towards multimodal.\n\nNext, the terms \"episodic simulation\" and \"episodic memory\" might relate to how the model processes sequences of events or memories over time. But time-series typically refers to data that is sequential and time-dependent, like stock prices or sensor data. While episodic memory could involve sequences, the key here is the combination of vision and language, which is more about modalities than just time.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, like in question-answering. The paper's focus on planning and memory doesn't immediately suggest retrieval-augmented methods. KG (Knowledge Graphs) involve structured data and relationships, which doesn't seem to be the case here either.\n\nSo putting it all together, the main elements are vision and language working together for navigation, which is a classic multimodal problem. The other terms like episodic simulation might be part of the methodology but don't point to the other topics. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32679@AAAI"},
{"title": "Point Cloud Semantic Segmentation with Sparse and Inhomogeneous Annotations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Point Cloud Semantic Segmentation with Sparse and Inhomogeneous Annotations.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. This title mentions point clouds, which are 3D data points, but there's no mention of time here. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title is about point cloud segmentation, which is a single data modality (3D points), so maybe not multimodal unless they're combining different modalities, but the title doesn't say that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and relationships. The paper's focus is on semantic segmentation of point clouds, which is more about labeling data points rather than building a knowledge graph. So KG doesn't fit here either.\n\nThe paper is about semantic segmentation with sparse annotations. That sounds more like a computer vision or machine learning problem, specifically in 3D data processing. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32680@AAAI"}
{"title": "Modular-Cam: Modular Dynamic Camera-view Video Generation with LLM", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Modular-Cam: Modular Dynamic Camera-view Video Generation with LLM\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Modular Dynamic Camera-view Video Generation\" suggests they're creating videos from dynamic camera views, probably using some modular approach. The \"with LLM\" part means they're using a Large Language Model. \n\nNow, the possible topics. Time-series usually deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data retrieval to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about video generation, which is a form of multimodal data since videos combine visual and possibly auditory elements. Using an LLM might imply they're integrating text (language) with visual data, making it multimodal. The \"Modular\" aspect might refer to combining different components or data types. \n\nRAG and KG are more about knowledge retrieval or structured data, which doesn't seem directly related here. Time-series is about sequential data over time, but video generation is more about combining different modalities (like text and video) rather than just time-based sequences. \n\nSo, the most likely topic here is multimodal because it's generating video (visual) using an LLM (text), combining different modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32681@AAAI"},
{"title": "Partially Blinded Unlearning: Class Unlearning for Deep Networks from Bayesian Perspective", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Partially Blinded Unlearning: Class Unlearning for Deep Networks from Bayesian Perspective.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Unlearning\" here probably refers to the concept of removing or forgetting certain information from a model. The paper is about class unlearning in deep networks, approached from a Bayesian perspective. \n\nTime-series analysis deals with data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't talk about multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on unlearning in deep networks, not on building or using knowledge graphs. \n\nThe paper is about unlearning, which is a concept in machine learning where a model is modified to forget certain data. This is more related to model training and data privacy, but none of the given topics (time-series, multimodal, RAG, KG) directly cover unlearning. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32682@AAAI"},
{"title": "VHM: Versatile and Honest Vision Language Model for Remote Sensing Image Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VHM: Versatile and Honest Vision Language Model for Remote Sensing Image Analysis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision Language Model\" suggests that it's dealing with both visual data (images) and language. That makes me think of multimodal because multimodal models typically handle multiple types of data, like combining images and text. \n\nThen, \"Remote Sensing Image Analysis\" refers to analyzing images from remote sources, like satellites. But the key part here is the combination of vision and language. So the model is probably using both visual and textual information, which is a hallmark of multimodal approaches. \n\nTime-series would involve data over time, like sequences or temporal data. The title doesn't mention anything about time or sequences, so probably not that. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in NLP tasks. The title doesn't mention retrieval or generation in that context. \n\nKG (Knowledge Graphs) involve structured data and relationships. Again, the title doesn't mention anything about knowledge graphs or structured data. \n\nSo putting it all together, the model is a Vision Language Model, which is multimodal. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32683@AAAI"},
{"title": "Beyond Text: Fine-Grained Multi-Modal Fact Verification with Hypergraph Transformers", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Beyond Text: Fine-Grained Multi-Modal Fact Verification with Hypergraph Transformers.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Beyond Text\" suggests they're using more than just text. \"Multi-Modal\" is right there in the title, which makes me think it's about combining different data types like text, images, audio, etc. The task is \"Fact Verification,\" which is checking if a statement is true using evidence. \n\nNow, the options. Time-series would involve data over time, like stock prices or weather. RAG is Retrieval-Augmented Generation, which uses a retriever to get documents and then generates answers. KG is Knowledge Graphs, which are structured data representations. \n\nThe paper uses \"Hypergraph Transformers,\" which might be a type of model for handling complex relationships. But the key part here is \"Multi-Modal,\" which directly matches one of the options. The fact verification part is about combining different modalities (text, maybe images or other data) to verify facts. So even though there's mention of hypergraphs, the main category here is multimodal. The other terms like RAG or KG aren't mentioned in the title, and time-series doesn't fit. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32684@AAAI"},
{"title": "Spectral Motion Alignment for Video Motion Transfer Using Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spectral Motion Alignment for Video Motion Transfer Using Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spectral Motion Alignment\" suggests some kind of alignment technique using spectral methods. \"Video Motion Transfer\" implies that the research is about transferring motion from one video to another. \"Diffusion Models\" are a type of generative model, often used in image and video generation.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about video motion transfer, which involves video data. Video is a sequence of frames over time, so it's inherently time-series data. However, the main focus here seems to be on aligning motion using spectral methods and diffusion models. The key term here is \"motion transfer,\" which is a specific application in computer vision, often involving generating new videos with transferred motion. \n\nBut does this fit into the given categories? Time-series could be a possible fit because video is a time-series of images. However, the other categories like multimodal might not apply here unless the paper combines different modalities (e.g., text and video). The title doesn't mention anything about combining different data types, so multimodal might not be right. RAG and KG are about retrieval and knowledge graphs, which don't seem related to motion transfer in videos. \n\nSo, the most plausible category here is time-series, since video is a time-series of frames. The motion transfer process would involve analyzing and generating sequences over time. Even though the paper uses diffusion models, which are a type of generative model, the core data being handled is time-series data. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32685@AAAI"},
{"title": "SeeDiff: Off-the-Shelf Seeded Mask Generation from Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SeeDiff: Off-the-Shelf Seeded Mask Generation from Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"SeeDiff\" probably refers to the method or model. \"Seeded Mask Generation\" suggests creating masks, maybe for images, using some kind of seeding. \"Diffusion Models\" are a type of generative model, right? They're used in image generation, like how DALL-E or Stable Diffusion works. \n\nNow, the topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper's title mentions diffusion models, which are typically used in image generation. Generating masks could be part of image processing. But none of the topics listed directly relate to image generation or diffusion models. The options are time-series, multimodal, RAG, or KG. \n\nWait, multimodal could involve images and text, but the title doesn't mention combining different modalities. It's about generating masks from diffusion models. RAG is about retrieval, which isn't mentioned here. KG is about knowledge graphs, which also doesn't fit. Time-series is unrelated. So maybe it doesn't fit any of the given topics. \n\nTherefore, the answer should be \"none\" because the paper's topic is about diffusion models and mask generation, which isn't covered by the four listed categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32686@AAAI"},
{"title": "Efficient Attention-Sharing Information Distillation Transformer for Lightweight Single Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Efficient Attention-Sharing Information Distillation Transformer for Lightweight Single Image Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on a Transformer model designed for image super-resolution. The key terms here are \"Information Distillation,\" \"Attention-Sharing,\" and \"Lightweight Single Image Super-Resolution.\" \n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image super-resolution, which is a single modality (images), so maybe not multimodal unless they're using other data types, but the title doesn't indicate that.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using external knowledge retrieval in models, often in NLP tasks. The title doesn't mention retrieval or generation, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on a Transformer architecture for image processing, not on building or using knowledge graphs. \n\nSo, none of the four topics seem to fit. The paper is about a specific type of Transformer model for image super-resolution, which is a computer vision task. The topics provided don't cover this area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32687@AAAI"},
{"title": "Foreground-Covering Prototype Generation and Matching for SAM-Aided Few-Shot Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Foreground-Covering Prototype Generation and Matching for SAM-Aided Few-Shot Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Few-Shot Segmentation\" suggests it's about image segmentation with limited examples, which is a common problem in computer vision. The mention of \"SAM\" probably refers to Segment Anything Model, a pre-trained model for image segmentation. \n\n\"Prototype Generation and Matching\" might be about creating prototypes (like representative examples) and matching them to new instances. This is a technique used in few-shot learning where you generate a prototype from the few examples you have and then match new data to these prototypes.\n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem relevant here. Multimodal would involve combining different data types like text and images, but the title doesn't mention that. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, often in NLP. KG (Knowledge Graph) involves structured data and relationships. \n\nThe paper seems focused on improving segmentation using prototypes, which is more about model architecture or learning methods rather than the listed topics. Since none of the four topics directly relate to prototype generation in the context of few-shot segmentation, the answer might be \"none.\" But wait, maybe RAG? RAG uses retrieval, but the paper's title doesn't mention retrieval or generation. It's more about prototype matching. So probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32688@AAAI"},
{"title": "ConVis: Contrastive Decoding with Hallucination Visualization for Mitigating Hallucinations in Multimodal Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ConVis: Contrastive Decoding with Hallucination Visualization for Mitigating Hallucinations in Multimodal Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Multimodal Large Language Models.\" That immediately makes me think the topic is multimodal. But I should check the rest to be sure. The main focus here is on mitigating hallucinations in these models using contrastive decoding and visualization. \n\nTime-series usually involves data over time, like stock prices or weather data. This doesn't seem related. RAG (Retrieval-Augmented Generation) is about using external data retrieval to enhance model outputs, but the title doesn't mention retrieval. KG (Knowledge Graphs) involve structured data representations, which also isn't mentioned here. \n\nThe key term here is \"Multimodal,\" which refers to models that process multiple types of data, like text and images. The paper is addressing a problem in multimodal models, so the topic should be multimodal. The other parts of the title are about methods to reduce hallucinations, but the primary research area is multimodal models. So the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32689@AAAI"},
{"title": "EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"EfficientVMamba\" sounds like a model or architecture. \"Atrous Selective Scan\" might refer to a specific technique used in the model. \"Light Weight Visual Mamba\" suggests it's related to vision tasks and is optimized for efficiency.\n\nNow, the four options. Time-series usually deals with sequential data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generative models, often in NLP. KG (Knowledge Graph) involves structured data representations, often for relationships between entities.\n\nThe title mentions \"Visual Mamba,\" which makes me think of vision models. Mamba is a type of model that uses state space methods, which are different from transformers. The \"Atrous Selective Scan\" part might be a technique to make the model more efficient. Since it's a visual model, maybe it's used in computer vision tasks. But does that relate to any of the four topics?\n\nTime-series could be a stretch if the model processes sequences, but the focus here is on visual data. Multimodal would require combining multiple modalities, but the title doesn't mention that. RAG and KG are more about text-based models and knowledge representation. The paper seems to be about improving a vision model's efficiency, which doesn't directly fit any of the four categories. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32690@AAAI"}
{"title": "CDE-Learning: Camera Deviation Elimination Learning for Unsupervised Person Re-identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CDE-Learning: Camera Deviation Elimination Learning for Unsupervised Person Re-identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Camera Deviation Elimination\" probably refers to handling differences in camera angles or positions. \"Unsupervised Person Re-identification\" suggests that the task is to recognize the same person across different camera views without labeled data. So, the main focus is on person re-id, which is a computer vision problem. \n\nNow, the four options. Time-series usually involves data over time, like stock prices or sensor data. This paper doesn't mention anything about time sequences, so probably not time-series. \n\nMultimodal would involve combining different types of data, like text and images. The title mentions camera data, but it's about eliminating camera deviations, not combining different modalities. So maybe not multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. This paper is about person re-id, which is more about image processing and not generation, so RAG seems unlikely.\n\nKG (Knowledge Graph) involves structured data and relationships. The paper doesn't mention anything about building or using a knowledge graph. \n\nSo, the paper is about eliminating camera deviations in unsupervised person re-id. None of the four topics (time-series, multimodal, RAG, KG) directly apply here. The main focus is on a specific computer vision technique for re-identification, which doesn't fit into the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32691@AAAI"},
{"title": "Adaptive Dual-domain Learning for Underwater Image Enhancement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adaptive Dual-domain Learning for Underwater Image Enhancement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title here is about image enhancement, which is more about spatial data, not time. So probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images or audio and video. The title mentions \"dual-domain,\" which might mean using two different domains (like spatial and frequency domains in image processing). But does that count as multimodal? Hmm. Multimodal typically involves different modalities (e.g., text, image, audio), whereas dual-domain might be different representations of the same modality. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on image enhancement techniques, not on building or using knowledge graphs. So likely not KG.\n\nSo the answer might be \"none\" since it doesn't fit any of the four categories. The paper is about image processing using dual-domain learning, which is a specific technique in computer vision, but none of the listed topics (time-series, multimodal, RAG, KG) directly apply here.\n</think>\n\nnone", "url": "https://papers.cool/venue/32692@AAAI"},
{"title": "Boosting Image De-Raining via Central-Surrounding Synergistic Convolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Boosting Image De-Raining via Central-Surrounding Synergistic Convolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image de-raining, which is about removing rain from images. That's image processing, not time-series data. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about image de-raining, which is a single modality (images). Unless they're using other data types, but the title doesn't mention that. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically in NLP, where a model retrieves information from a database to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image processing using a specific convolution method. No mention of knowledge graphs here.\n\nSo the paper is about improving image de-raining using a specific convolution technique. None of the listed topics (time-series, multimodal, RAG, KG) seem to fit. The main focus is on the convolution method for image processing, which doesn't align with any of the four categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32693@AAAI"},
{"title": "3D-aware Select, Expand, and Squeeze Token for Aerial Action Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"3D-aware Select, Expand, and Squeeze Token for Aerial Action Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"3D-aware\" suggests something related to three-dimensional data, maybe spatial information. \"Select, Expand, and Squeeze Token\" sounds like a method or architecture component. \"Aerial Action Recognition\" refers to recognizing actions in aerial (like drone or airborne) videos. \n\nTime-series usually involves data over time, like stock prices or sensor data. This paper is about action recognition, which does involve sequences over time, so maybe time-series? But the title doesn't explicitly mention time-series terms. However, action recognition in videos is inherently time-series because it's about sequences of frames.\n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention combining modalities, so probably not multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention knowledge graphs or structured data, so that's out.\n\nSo the most likely is time-series, because action recognition in videos is a time-series problem. Even though the title doesn't use the term, the context of action recognition implies temporal data. The 3D-aware part might relate to spatial dimensions, but the core of action recognition is temporal. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32694@AAAI"},
{"title": "SAM-Aware Graph Prompt Reasoning Network for Cross-Domain Few-Shot Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SAM-Aware Graph Prompt Reasoning Network for Cross-Domain Few-Shot Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"SAM-Aware\" probably refers to Segment Anything Model, which is a pre-trained model for image segmentation. \"Graph Prompt Reasoning Network\" suggests the use of graph structures in the model. \"Cross-Domain Few-Shot Segmentation\" means the model is designed to work across different domains with limited examples.\n\nLooking at the options: time-series deals with sequential data over time. Multimodal involves combining different data types like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge retrieval. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on segmentation, which is an image processing task. The mention of \"Graph\" in the title might relate to Knowledge Graphs (KG), but in this context, it's more likely referring to a graph neural network structure used in the model. Since the problem is about cross-domain few-shot learning in segmentation, it's using a graph-based approach for reasoning. However, none of the four topics (time-series, multimodal, RAG, KG) directly align with this. The graph here is part of the model architecture, not a Knowledge Graph. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32695@AAAI"},
{"title": "OAMaskFlow: Occlusion-Aware Motion Mask for Scene Flow", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OAMaskFlow: Occlusion-Aware Motion Mask for Scene Flow.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Occlusion-Aware Motion Mask\" suggests that the paper deals with motion in scenes, specifically handling occlusions. Scene flow is a term I've heard in computer vision, which refers to the 3D motion of objects in a scene over time. So, this is probably related to video or dynamic scenes where objects move and might block each other (occlusion).\n\nNow, looking at the possible topics. Time-series analysis involves data points indexed in time order, often used in forecasting or analyzing temporal data. Multimodal refers to combining multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where models retrieve information from a database to enhance their responses. KG is Knowledge Graph, which structures information as entities and relationships.\n\nThe paper's focus is on motion masks and scene flow, which are part of computer vision, particularly in processing video sequences. Scene flow involves understanding how objects move between consecutive frames, which is inherently temporal. However, time-series typically refers to numerical data over time, not visual data. But maybe there's a connection here. However, the key term here is \"motion mask,\" which is more about spatial and temporal information in video processing. \n\nMultimodal would require combining different modalities like text and images, but the title doesn't mention that. RAG and KG are more about information retrieval and knowledge representation, which don't seem relevant here. \n\nSo, even though scene flow involves time, the primary focus here is on motion and occlusion in visual data, which might not fit neatly into the given categories. The options are time-series, multimodal, RAG, or KG. Since none of these exactly match the topic of motion masks and scene flow in computer vision, the answer might be \"none.\" But wait, maybe time-series is a stretch? Scene flow does involve sequences of frames over time, so maybe it's considered time-series. However, in academic contexts, time-series is usually numerical data, not video. So I think the correct answer here is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32696@AAAI"},
{"title": "HVDualformer: Histogram-Vision Dual Transformer for White Balance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HVDualformer: Histogram-Vision Dual Transformer for White Balance\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Histogram-Vision Dual Transformer\" suggests that the model uses both histogram data and vision (image) data. The term \"Dual\" might imply combining two different modalities. White Balance is an image processing task, so the application is in computer vision.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. This doesn't seem to fit because the focus is on images and histograms, not sequences over time.\n\nMultimodal refers to models that use multiple types of data, like combining text and images, or audio and video. Here, the model uses both histogram (which is a statistical representation of image data) and vision (the actual image pixels). So combining these two different data types for the same task (white balance) would be multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in NLP. This doesn't seem relevant here.\n\nKG is Knowledge Graphs, which involve structured data and relationships between entities. The title doesn't mention anything about knowledge graphs or structured data, so probably not this one.\n\nSo the most likely answer is multimodal. The model uses two different data modalities (histogram and vision) to perform white balance, which is a computer vision task. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32697@AAAI"},
{"title": "Semi-supervised 3D Semantic Scene Completion with 2D Vision Foundation Model Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Semi-supervised 3D Semantic Scene Completion with 2D Vision Foundation Model Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"3D Semantic Scene Completion\" suggests working with 3D data, maybe like point clouds or volumetric data, to complete or reconstruct scenes. \"2D Vision Foundation Model Guidance\" implies using a 2D model, perhaps something like a pre-trained image model, to guide the 3D task. So combining 2D and 3D data here. \n\nNow, the options. Time-series would involve data over time, like sequences. The title doesn't mention anything about time or sequences, so probably not that. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in NLP. KG is Knowledge Graphs, which are structured data representations. The paper seems to be about combining different modalities (2D and 3D) for a scene completion task. \n\nMultimodal research involves integrating multiple types of data, like combining images (2D) with 3D data. The use of a 2D vision model to guide a 3D task fits into multimodal learning. So the answer should be multimodal. The other options don't fit here. The paper isn't about time-series data, nor does it mention RAG or KG. So the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32698@AAAI"},
{"title": "Anatomical Knowledge Mining and Matching for Semi-supervised Medical Multi-structure Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Anatomical Knowledge Mining and Matching for Semi-supervised Medical Multi-structure Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Anatomical Knowledge Mining\" suggests they're extracting knowledge related to anatomy. \"Matching\" might imply some kind of alignment or comparison. \"Semi-supervised\" refers to a machine learning approach that uses both labeled and unlabeled data. \"Medical Multi-structure Detection\" probably means identifying multiple anatomical structures in medical images.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time, so probably not time-series. \n\nMultimodal would involve combining different data types, like images and text. The paper is about medical structures, which could be images, but the title doesn't explicitly mention combining multiple modalities. Maybe, but not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graph, which is a structured representation of knowledge. The title mentions \"Knowledge Mining,\" which could relate to building or using a knowledge graph. \"Anatomical Knowledge\" might be structured in a graph to represent relationships between different anatomical structures. The \"Matching\" part could involve aligning or mapping this knowledge to detect structures in medical data. \n\nSo, the key terms here are \"Knowledge Mining\" and possibly \"Matching,\" which aligns with Knowledge Graphs. The semi-supervised approach might use the knowledge graph to enhance the detection without needing full labels. \n\nMultimodal could be a possibility if they're using different data types, but the title doesn't specify that. The focus seems more on the knowledge aspect rather than combining modalities. Therefore, the most likely topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32699@AAAI"},
{"title": "Leveraging Anatomical Consistency for Multi-Object Detection in Ultrasound Images via Source-free Unsupervised Domain Adaptation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Leveraging Anatomical Consistency for Multi-Object Detection in Ultrasound Images via Source-free Unsupervised Domain Adaptation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title here is about ultrasound images and multi-object detection, which seems more like image processing. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about ultrasound images, but does it mention using other modalities? The title doesn't specify combining different data types, just focusing on images. Hmm, maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The title talks about anatomical consistency and domain adaptation, which might relate to knowledge in anatomy, but the methods described don't seem to involve building or using a knowledge graph. \n\nThe paper uses source-free unsupervised domain adaptation. That's a machine learning technique for adapting models to a new domain without access to the source data. The focus is on domain adaptation in the context of medical imaging (ultrasound). None of the four topics (time-series, multimodal, RAG, KG) directly relate to domain adaptation. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32700@AAAI"}
{"title": "Dive into Aerial Remote Sensing Underwater Depth Estimation with Hyperspectral Imagery", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dive into Aerial Remote Sensing Underwater Depth Estimation with Hyperspectral Imagery.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Aerial remote sensing involves using aircraft or satellites to collect data. Underwater depth estimation suggests they're trying to determine how deep the water is using some method. Hyperspectral imagery refers to capturing data across many narrow spectral bands, which is different from regular multispectral. \n\nNow, the four options. Time-series would involve data collected over time, like tracking changes. Multimodal usually means combining different types of data, like images and text. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information to generate answers. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper uses hyperspectral imagery, which is a type of data modality. But does it combine multiple modalities? The title mentions aerial remote sensing and hyperspectral imagery. If they're using just hyperspectral data, maybe it's not multimodal. But if they're combining different data types (like hyperspectral with other sensors), then it could be multimodal. However, the title doesn't explicitly mention combining different modalities. It's focused on using hyperspectral imagery for depth estimation. \n\nTime-series would require data collected at different times. The title doesn't mention time, so probably not. RAG and KG are more about information retrieval and knowledge representation, which don't seem directly related to using hyperspectral images for depth estimation. \n\nSo, the most likely answer is multimodal if they are using multiple data types. But the title only mentions hyperspectral imagery. Wait, maybe hyperspectral is a modality, but if they're using it alone, it's not multimodal. However, sometimes hyperspectral is considered a modality in itself. But multimodal typically refers to combining different types, like images and text, or images and LiDAR. Since the title doesn't mention combining different data types, maybe it's not multimodal. \n\nAlternatively, maybe the aerial remote sensing involves different modalities. For example, using both aerial images and other data. But the title specifies hyperspectral imagery, which is a specific type of data. Without explicit mention of combining different modalities, I'm leaning towards it not being multimodal. \n\nSo, none of the four topics seem to fit. The paper is about using hyperspectral imagery for underwater depth estimation, which is a specific application in remote sensing. The topics given don't include remote sensing, computer vision, or specific imaging techniques. Therefore, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32701@AAAI"},
{"title": "Unsupervised Domain Adaptive Person Search via Dual Self-Calibration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unsupervised Domain Adaptive Person Search via Dual Self-Calibration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Unsupervised Domain Adaptive\" suggests that the research is about adapting models between different domains without labeled data. \"Person Search\" probably refers to identifying or searching for people in images or videos. \"Dual Self-Calibration\" might be a method they're using to improve the model's performance.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal would involve combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus seems to be on domain adaptation for person search. Domain adaptation is a common problem in machine learning where a model trained on one domain (source) needs to perform well on another domain (target) without labeled data. This is often seen in computer vision tasks, like adapting a model trained on synthetic data to real-world data. \n\nPerson search would typically involve image or video data, which could be part of a multimodal approach if combining different data types. However, the title doesn't explicitly mention combining multiple modalities. The key terms here are \"domain adaptive\" and \"self-calibration.\" Since the options given don't include domain adaptation directly, I need to see if any of the listed topics align with this.\n\nMultimodal could be a stretch if the method uses different data types, but the title doesn't specify that. RAG and KG are about retrieval and knowledge graphs, which don't seem related. Time-series is about temporal data, which isn't indicated here. So, none of the four topics (time-series, multimodal, RAG, KG) directly match the domain adaptation aspect. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32702@AAAI"},
{"title": "TGBFormer: Transformer-GraphFormer Blender Network for Video Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TGBFormer: Transformer-GraphFormer Blender Network for Video Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The model is called TGBFormer, which combines Transformer and GraphFormer. The application is Video Object Detection. \n\nVideo object detection involves processing video frames over time, so there's a temporal aspect here. Time-series typically deals with sequential data over time. Since video is a sequence of frames, this might relate to time-series. But wait, the other components are Transformer and GraphFormer. Transformers are often used in multimodal tasks, but here it's combined with a graph-based model. GraphFormer suggests a graph neural network component. \n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. RAG is Retrieval-Augmented Generation, which is more about using retrieved information during generation. The title doesn't mention anything about knowledge graphs or retrieval-augmented generation. \n\nMultimodal usually refers to combining different types of data, like text and images. However, the title is about video object detection, which is more about processing video (a sequence of images) rather than combining different modalities. \n\nThe key here is the \"blender network\" combining Transformer and GraphFormer. GraphFormer is a graph-based model, so maybe this relates to Knowledge Graphs (KG)? But the application is video detection, not structured knowledge. Alternatively, the use of a graph could be for modeling relationships between objects in the video frames. \n\nWait, the problem is video object detection. So each frame is processed, and the model needs to track objects over time. The Transformer part might handle the temporal aspect (time-series), while the GraphFormer could model relationships between objects in each frame. But the main application isn't about time-series data in the traditional sense (like stock prices or sensor data), but rather video, which is a time-series of images. \n\nHowever, the question is about the research topic. Time-series is a possible fit here because video is a time-based sequence. But the model uses both Transformer (which is good for sequences) and GraphFormer (for graph structures). But the primary research area might be multimodal if combining different data types, but video is a single modality (visual). \n\nAlternatively, since the model is a blend of Transformer and Graph networks, maybe it's more about the architecture rather than the research topic. The research topics given are time-series, multimodal, RAG, KG. \n\nGiven that video is a time-series of frames, and the model is designed for video object detection, which inherently involves temporal data, the topic might be time-series. However, I'm not entirely sure. Another angle: if the paper is about combining different modalities (like text and video), then it's multimodal. But the title doesn't mention other modalities. \n\nSo, considering all this, the most likely answer is time-series because video is a time-based sequence. But I need to check if there's a better fit. Since the other options (RAG, KG) don't seem relevant, and multimodal isn't indicated, the answer is probably time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32703@AAAI"},
{"title": "PhysDiff: Physiology-based Dynamicity Disentangled Diffusion Model for Remote Physiological Measurement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PhysDiff: Physiology-based Dynamicity Disentangled Diffusion Model for Remote Physiological Measurement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"PhysDiff\" is the model's name. \"Physiology-based\" suggests it's related to biological processes, maybe involving data over time. \"Dynamicity Disentangled Diffusion Model\" – diffusion models are a type of generative model, often used in image generation, but here it's modified to handle dynamic aspects. \"Remote Physiological Measurement\" implies measuring things like heart rate, respiration from a distance, probably using sensors or cameras.\n\nNow, the possible topics. Time-series would involve data points indexed in time order. Since physiological measurements like heart rate are inherently time-series data, this could be a candidate. The model might process time-series data to disentangle dynamic aspects.\n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not this one.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in NLP. The title doesn't mention retrieval or generation in that context, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data representations. The title doesn't mention knowledge graphs or structured data, so likely not KG.\n\nSo the most plausible is time-series. The model is for physiological measurements, which are time-dependent. The diffusion model here is adapted to handle dynamic (time-varying) aspects. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32704@AAAI"},
{"title": "UCF-Crime-DVS: A Novel Event-Based Dataset for Video Anomaly Detection with Spiking Neural Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UCF-Crime-DVS: A Novel Event-Based Dataset for Video Anomaly Detection with Spiking Neural Networks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The dataset is called UCF-Crime-DVS. The key parts here are \"event-based dataset,\" \"video anomaly detection,\" and \"spiking neural networks.\" \n\nEvent-based datasets are typically related to data that's generated by events, which in this case might be video data. Video anomaly detection involves identifying unusual events in video footage. Spiking neural networks are a type of neural network that processes information in the form of spikes, which is more akin to how biological neurons work. These networks are often used in neuromorphic computing and can handle temporal data efficiently.\n\nNow, looking at the four options. Time-series analysis deals with data points indexed in time order. Since the dataset is event-based and used for video (which is inherently temporal), this could be a candidate. However, the mention of spiking neural networks might lean more towards a specific type of time-series processing, but I'm not sure if the main focus is on time-series analysis itself.\n\nMultimodal refers to combining multiple types of data (like text, images, audio). The title doesn't mention multiple modalities, so probably not this one.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation tasks, like in language models. The title doesn't mention anything about retrieval or generation, so this is unlikely.\n\nKG (Knowledge Graph) involves structured data representations. The paper is about a dataset for video anomaly detection, not about building or using knowledge graphs. So that's probably not it either.\n\nSo, the main contenders are time-series and multimodal. Since the dataset is event-based and used for video (which is a time-series of frames), and spiking neural networks are good for temporal data, the topic might be time-series. However, the term \"event-based\" could imply that each event is a data point, which is more about the data format rather than the analysis type. But given the options, time-series seems the closest fit. Alternatively, if the paper is about the dataset itself without focusing on time-series analysis, maybe it's none. But the question is about the research topic the paper belongs to. Since the dataset is for video anomaly detection using spiking neural networks, which process temporal data, I think the correct answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32705@AAAI"},
{"title": "Holistic Correction with Object Prototype for Video Object Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Holistic Correction with Object Prototype for Video Object Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The paper is about video object segmentation, which does involve sequences of frames over time. So maybe time-series? But wait, video processing can be considered a time-series problem because each frame is a time step. However, sometimes video tasks are categorized under computer vision or multimodal if they combine different data types.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention anything about combining different modalities, just video (which is visual) and object segmentation. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is probably not it.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo the main contenders are time-series and multimodal. Since video is a sequence of frames over time, it's a time-series problem. But sometimes video tasks are considered under computer vision. However, the options given are time-series, multimodal, RAG, KG. Since the paper is about video (time-based data) and segmentation, which involves processing each frame in sequence, I think it's time-series. The \"holistic correction\" might involve temporal consistency across frames. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32706@AAAI"},
{"title": "Detail Matters: Mamba-Inspired Joint Unfolding Network for Snapshot Spectral Compressive Imaging", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Detail Matters: Mamba-Inspired Joint Unfolding Network for Snapshot Spectral Compressive Imaging.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Mamba-Inspired\" probably refers to a specific model or architecture, maybe related to neural networks. \"Joint Unfolding Network\" suggests a method that combines different processes or data sources. \"Snapshot Spectral Compressive Imaging\" is the application area. Spectral imaging involves capturing data across different wavelengths, which might involve multiple modalities. \n\nNow, the four options. Time-series deals with data over time. Multimodal involves combining different types of data (like images and text). RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on a network for compressive imaging, which is about reconstructing images from compressed data. The term \"joint unfolding\" might imply integrating different data aspects, but not necessarily different modalities. \"Mamba\" could be a model, but I'm not sure if it's related to any of the four topics. Since the application is in spectral imaging, which could involve multiple spectral bands, maybe multimodal? But spectral imaging is often considered a single modality with multiple channels. \n\nAlternatively, if the method uses a joint approach that combines different data types, it might be multimodal. However, without more context, it's hard to say. The title doesn't mention anything about time-series data, RAG, or knowledge graphs. So the most plausible is multimodal if the network integrates different data sources. But if it's just a single modality (spectral data) processed in a new way, then maybe none. \n\nGiven the options, I think the answer is \"none\" because the title doesn't clearly indicate time-series, multimodal, RAG, or KG. The key terms are about a specific imaging technique and a network architecture, which don't align with the four topics listed.\n</think>\n\nnone", "url": "https://papers.cool/venue/32707@AAAI"},
{"title": "Integrating Low-Level Visual Cues for Enhanced Unsupervised Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Integrating Low-Level Visual Cues for Enhanced Unsupervised Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title talks about integrating low-level visual cues, which are part of image data. But does it combine with another modality? The title doesn't mention other data types, just visual cues. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generation tasks, often in NLP. The title is about semantic segmentation, which is a computer vision task. Doesn't seem related to RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nThe paper is about improving unsupervised semantic segmentation by integrating low-level visual cues. Semantic segmentation is a computer vision task, and integrating visual cues could be part of multimodal if combining different modalities, but here it's all within visual data. So maybe none of the listed topics. The answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32708@AAAI"},
{"title": "PC-BEV: An Efficient Polar-Cartesian BEV Fusion Framework for LiDAR Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PC-BEV: An Efficient Polar-Cartesian BEV Fusion Framework for LiDAR Semantic Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. PC-BEV refers to a framework that combines Polar and Cartesian representations in a Bird's Eye View (BEV) for LiDAR semantic segmentation. LiDAR is a sensor that captures 3D data, often used in autonomous vehicles. The key terms here are \"fusion framework\" and \"LiDAR semantic segmentation.\"\n\nNow, looking at the possible topics. Time-series would involve data over time, like sequences or temporal analysis. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal refers to combining different types of data, like text and images, or different sensor data. Here, the paper is about fusing Polar and Cartesian representations of LiDAR data. Wait, Polar and Cartesian are just different coordinate systems for the same data (LiDAR), not different modalities. So maybe it's not multimodal. Unless the fusion is between different sensor modalities, but the title specifies LiDAR, so it's the same modality but different representations. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to augment its responses. This doesn't seem related to LiDAR segmentation. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data representation. \n\nSo, the paper is about a fusion framework for LiDAR data using different coordinate systems. Since the options are time-series, multimodal, RAG, or KG, and none of these seem to fit, the answer might be \"none.\" But wait, maybe I'm missing something. The fusion of Polar and Cartesian could be considered a form of multimodal if the different representations are treated as different modalities. But typically, multimodal refers to different types of data (like text and images), not different coordinate systems of the same data type. So I think it's \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32709@AAAI"},
{"title": "High-Fidelity Polarimetric Implicit 3D Reconstruction with View-Dependent Physical Representation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"High-Fidelity Polarimetric Implicit 3D Reconstruction with View-Dependent Physical Representation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"High-Fidelity\" probably refers to the quality or accuracy. \"Polarimetric\" relates to polarization, which is a property of light. \"Implicit 3D Reconstruction\" suggests creating a 3D model from data without explicit meshing. \"View-Dependent Physical Representation\" implies that the model's appearance depends on the viewing angle, which is common in computer graphics for realistic rendering.\n\nNow, the four options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on 3D reconstruction using polarimetric data. Polarimetric data is a type of sensor data, but the key here is the method of reconstruction. The terms don't mention anything about time, so time-series is out. It's not combining multiple modalities (like text and image), so multimodal might not fit. RAG and KG are more about information retrieval and knowledge representation, which don't seem related to 3D reconstruction techniques. \n\nTherefore, the paper doesn't fit into any of the four categories. The main topics here are 3D reconstruction and physical representation, which aren't listed among the options. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32710@AAAI"}
{"title": "HSOD-BIT-V2: A Challenging Benchmark for Hyperspectral Salient Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HSOD-BIT-V2: A Challenging Benchmark for Hyperspectral Salient Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Hyperspectral\" refers to hyperspectral imaging, which involves data across many wavelengths. \"Salient Object Detection\" is about identifying the most noticeable objects in an image. The term \"Benchmark\" suggests it's a dataset or evaluation framework for testing algorithms.\n\nNow, the four options. Time-series deals with data over time, like stock prices or weather data. Multimodal involves combining different data types, such as text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where models use external information during generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on hyperspectral imaging for object detection. Hyperspectral data is a type of image data with many spectral bands. Salient object detection is a computer vision task. Since the paper introduces a benchmark for this specific task, it's about creating a dataset or evaluation framework. None of the four topics directly relate to hyperspectral imaging or salient object detection. Time-series is about temporal data, which isn't the case here. Multimodal would involve combining different modalities (like text and images), but the paper is about a single modality (hyperspectral images). RAG and KG are unrelated to this context. Therefore, the paper doesn't fit into any of the given topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32711@AAAI"},
{"title": "HOGSA: Bimanual Hand-Object Interaction Understanding with 3D Gaussian Splatting Based Data Augmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HOGSA: Bimanual Hand-Object Interaction Understanding with 3D Gaussian Splatting Based Data Augmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Bimanual Hand-Object Interaction Understanding\" suggests that the research is about understanding interactions between hands and objects, probably using some kind of data. The method mentioned is \"3D Gaussian Splatting Based Data Augmentation.\" \n\nTime-series usually involves data points indexed in time order, like stock prices over time. This title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, audio, etc. The paper is about hand-object interactions, which might involve visual data (images or 3D models) and possibly other modalities. But the title specifically mentions data augmentation using 3D Gaussian Splatting. If they're combining different data types, it could be multimodal. However, the key term here is \"data augmentation,\" which is a technique to improve model training by generating more data. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This doesn't seem related to the title, which is about data augmentation in a different context.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data representation.\n\nSo, the main focus here is on data augmentation using 3D Gaussian Splatting for understanding hand-object interactions. Data augmentation is a technique, but the question is about the research topic. The paper is about understanding interactions, which might involve multimodal data (like combining visual and motion data), but the title doesn't explicitly state multiple modalities. However, \"bimanual hand-object interaction\" could imply using different types of data (e.g., 3D data, possibly RGB-D, etc.), making it multimodal. Alternatively, if the data augmentation is just a method within a single modality, it might not be multimodal. But given the options, the closest fit might be multimodal. Alternatively, if the data augmentation is part of a time-series approach, but the title doesn't mention time. So, I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32712@AAAI"},
{"title": "Universal Features Guided Zero-Shot Category-Level Object Pose Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Universal Features Guided Zero-Shot Category-Level Object Pose Estimation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Universal Features Guided\" suggests that the method uses some kind of universal features, maybe something like pre-trained models or generalizable features. \"Zero-Shot Category-Level Object Pose Estimation\" means they're estimating the pose of objects in categories that weren't seen during training. So it's about generalizing to new categories without prior examples.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. That doesn't seem related here. Multimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities. RAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation in models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper is about object pose estimation, which is a computer vision task. The zero-shot aspect implies using some form of prior knowledge or external information to generalize. If they're using a knowledge graph to provide category information, that would be KG. Alternatively, if they're retrieving examples from a database to augment the model, that might be RAG. But the title mentions \"Universal Features,\" which could be a pre-trained model or a knowledge base. However, without more details, it's hard to tell. But since the options are RAG or KG, and the task is about category-level generalization, it's more likely to be KG. Knowledge graphs often store hierarchical or categorical information that can be used for zero-shot learning. RAG is more about combining retrieval with generation, which isn't the focus here. So the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32713@AAAI"},
{"title": "Multi-Focus Image Fusion via Explicit Defocus Blur Modelling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Focus Image Fusion via Explicit Defocus Blur Modelling.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-Focus Image Fusion\" suggests combining images taken with different focus settings. So, it's about merging images where each image has different parts in focus. The method mentioned is \"Explicit Defocus Blur Modelling,\" which probably involves modeling how out-of-focus areas look to better combine them.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather data. This doesn't seem related to images over time, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. But here, it's about fusing multiple images (all visual data) with different focus. So maybe not multimodal, unless the images are considered different modalities, but I think multimodal is more about different data types, not different focus levels.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. That's more about text generation with retrieval, so not related to image fusion.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. This paper doesn't mention anything about knowledge graphs or structured data, so probably not KG.\n\nSo, none of the given topics seem to fit. The paper is about image processing, specifically fusing images with different focus using blur modeling. The options provided don't cover image fusion or computer vision topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32714@AAAI"},
{"title": "GHOST: Gaussian Hypothesis Open-Set Technique", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GHOST: Gaussian Hypothesis Open-Set Technique.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"GHOST\" is the acronym, probably standing for something. The key parts here are \"Gaussian Hypothesis\" and \"Open-Set Technique.\" \n\nGaussian Hypothesis might relate to statistical methods using Gaussian distributions. Open-Set Technique sounds like it's about handling open-set problems, which in machine learning refers to scenarios where the model encounters data from classes not seen during training. So maybe it's about classification with unknown classes.\n\nNow, looking at the four options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title doesn't mention anything about time, sequences, or temporal data, so probably not time-series. There's no indication of combining multiple modalities, so not multimodal. RAG and KG are both related to knowledge and retrieval, but the title's focus seems to be on statistical hypothesis testing and open-set classification. \n\nOpen-set techniques are more about machine learning models handling unknown classes, which is a classification problem. The Gaussian part suggests using Gaussian distributions for hypothesis testing. This doesn't directly relate to RAG or KG. RAG is about using retrieved information to generate answers, and KG is about structured knowledge. \n\nSo, the paper's topic doesn't fit into any of the four categories listed. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32715@AAAI"},
{"title": "AWRaCLe: All-Weather Image Restoration Using Visual In-Context Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AWRaCLe: All-Weather Image Restoration Using Visual In-Context Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. The title mentions image restoration, which is more about images, so maybe not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about image restoration using visual in-context learning. The term \"visual\" suggests it's image-based, but does it use multiple modalities? The title doesn't mention text or other data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get relevant information and then generate a response. The title mentions \"in-context learning,\" which sounds similar to using context from retrieved examples. But the paper is about image restoration, not text generation. However, \"in-context learning\" might be a method similar to RAG's approach, where the model uses examples from the context to improve performance. So maybe RAG?\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nSo the options are between RAG and multimodal. Since the paper is about image restoration using in-context learning, which could be a form of retrieval-based method, similar to RAG. Even though RAG is typically for text, the concept of using retrieved examples (in this case, visual contexts) might fit under RAG. Alternatively, if \"in-context learning\" here refers to using multiple modalities, but the title doesn't specify that. So I think the answer is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32716@AAAI"},
{"title": "CDTR: Semantic Alignment for Video Moment Retrieval Using Concept Decomposition Transformer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CDTR: Semantic Alignment for Video Moment Retrieval Using Concept Decomposition Transformer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video Moment Retrieval\" suggests that the paper is about finding specific moments in videos. That usually involves both visual and auditory data, so maybe multimodal? Because multimodal research deals with combining different types of data like text, images, audio, etc. \n\n\"Semantic Alignment\" might refer to aligning different modalities, like matching text descriptions with video content. That's a common task in multimodal studies. The \"Concept Decomposition Transformer\" part sounds like a model that breaks down concepts, perhaps to better align different modalities. \n\nTime-series usually deals with data points indexed in time order, like stock prices or sensor data. While video is a time-series in a way, the key here is the retrieval aspect and semantic alignment, which is more about combining different data types. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval-augmented generation specifically. \n\nSo putting it all together, the main focus seems to be on aligning different modalities (video and text, perhaps) for retrieval, which points to multimodal. The other topics don't fit as well. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32717@AAAI"},
{"title": "Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Vision Language Models\" immediately stands out. Multimodal usually refers to models that handle multiple types of data, like text and images. So that's a hint. The term \"vision language\" also suggests combining visual and textual information, which is a classic multimodal setup. \n\nThe other parts of the title mention \"Elastic Visual Experts,\" which might relate to how the model processes visual data efficiently. But the key part here is \"multimodal.\" The other options are time-series (which deals with sequential data over time), RAG (Retrieval-Augmented Generation, which uses external data retrieval), and KG (Knowledge Graphs, which are structured representations of knowledge). \n\nSince the title explicitly uses \"multimodal,\" and the context is about combining vision and language, this definitely fits the multimodal category. The other topics don't seem relevant here. There's no mention of time-series data, retrieval, or knowledge graphs. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32718@AAAI"},
{"title": "ISPDiffuser: Learning RAW-to-sRGB Mappings with Texture-Aware Diffusion Models and Histogram-Guided Color Consistency", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ISPDiffuser: Learning RAW-to-sRGB Mappings with Texture-Aware Diffusion Models and Histogram-Guided Color Consistency.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title mentions RAW-to-sRGB mappings, which sounds like image processing. So probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper is about converting RAW images to sRGB, which is a color space conversion. It uses diffusion models and color consistency. I don't see mention of multiple data types here, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper seems focused on image processing techniques, not on building or using knowledge graphs. So likely not KG either.\n\nSo the answer might be none. But wait, let me check again. The paper uses diffusion models, which are a type of generative model. However, the four options given are time-series, multimodal, RAG, KG. None of these directly relate to diffusion models or image processing unless there's a hidden category. Since the options don't include computer vision or image processing, the correct answer here would be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32721@AAAI"},
{"title": "Improving Integrated Gradient-based Transferable Adversarial Examples by Refining the Integration Path", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Improving Integrated Gradient-based Transferable Adversarial Examples by Refining the Integration Path.\" Hmm. I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Integrated Gradient-based\" probably refers to a method in machine learning, maybe related to explainability or adversarial examples. Transferable adversarial examples are those that can fool different models, right? So the paper is about making adversarial examples more transferable by improving the integration path in the gradient-based method.\n\nNow, looking at the topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generative models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on adversarial examples and improving a specific method (integrated gradients) for generating them. None of the topics listed directly relate to adversarial examples or gradient-based methods. Time-series, multimodal, RAG, and KG are all different areas. The paper doesn't mention anything about time-dependent data, multiple modalities, retrieval-augmented generation, or knowledge graphs. So it probably doesn't fit into any of these categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32722@AAAI"}
{"title": "ISPDiffuser: Learning RAW-to-sRGB Mappings with Texture-Aware Diffusion Models and Histogram-Guided Color Consistency", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ISPDiffuser: Learning RAW-to-sRGB Mappings with Texture-Aware Diffusion Models and Histogram-Guided Color Consistency.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title mentions RAW-to-sRGB mappings, which sounds like image processing. So probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper is about converting RAW images to sRGB, which is a color space conversion. It uses diffusion models and color consistency. I don't see mention of multiple data types here, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper seems focused on image processing techniques, not on building or using knowledge graphs. So likely not KG either.\n\nSo the answer might be none. But wait, let me check again. The paper uses diffusion models, which are a type of generative model. However, the four options given are time-series, multimodal, RAG, KG. None of these directly relate to diffusion models or image processing unless there's a hidden category. Since the options don't include computer vision or image processing, the correct answer here would be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32721@AAAI"},
{"title": "Improving Integrated Gradient-based Transferable Adversarial Examples by Refining the Integration Path", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Improving Integrated Gradient-based Transferable Adversarial Examples by Refining the Integration Path.\" Hmm. I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Integrated Gradient-based\" probably refers to a method in machine learning, maybe related to explainability or adversarial examples. Transferable adversarial examples are those that can fool different models, right? So the paper is about making adversarial examples more transferable by improving the integration path in the gradient-based method.\n\nNow, looking at the topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generative models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on adversarial examples and improving a specific method (integrated gradients) for generating them. None of the topics listed directly relate to adversarial examples or gradient-based methods. Time-series, multimodal, RAG, and KG are all different areas. The paper doesn't mention anything about time-dependent data, multiple modalities, retrieval-augmented generation, or knowledge graphs. So it probably doesn't fit into any of these categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32722@AAAI"},
{"title": "MM-CamObj: A Comprehensive Multimodal Dataset for Camouflaged Object Scenarios", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MM-CamObj: A Comprehensive Multimodal Dataset for Camouflaged Object Scenarios.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"MM-CamObj\" probably stands for Multimodal Camouflaged Object. The key part here is \"Multimodal Dataset.\" The term \"multimodal\" refers to using multiple types of data, like combining images, text, audio, etc. So the dataset is designed for scenarios where different data modalities are involved. The application here is for camouflaged object detection, which is a computer vision problem. \n\nNow, looking at the options. The topic \"multimodal\" is directly mentioned in the title. The other options are time-series (which deals with data over time), RAG (Retrieval-Augmented Generation, a method in NLP), and KG (Knowledge Graphs, which are structured representations of knowledge). The paper is about a dataset, specifically a multimodal one. Since the title explicitly states \"Multimodal Dataset,\" the correct category here is \"multimodal.\" There's no mention of time-series data, RAG techniques, or knowledge graphs in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32723@AAAI"},
{"title": "GenHMR: Generative Human Mesh Recovery", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GenHMR: Generative Human Mesh Recovery.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Generative\" might hint at a model type, like a generative model. \"Human Mesh Recovery\" suggests it's about reconstructing 3D human body meshes from data. So, the task is probably related to generating 3D models of humans, maybe from images or videos.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nGenHMR is about generating human meshes. If it's using generative models like GANs or VAEs, that's a method, but the topic here is the application. Since the task is about recovering a 3D mesh, which is a structured output, maybe it's related to multimodal if it uses multiple data sources (like images and depth sensors). But the title doesn't mention combining different modalities. It just says \"Generative Human Mesh Recovery.\" \n\nRAG and KG don't seem relevant here. The paper isn't about retrieving information to augment generation (RAG) or building knowledge graphs (KG). Time-series also doesn't fit because there's no indication of temporal data. So the most plausible is multimodal if the method uses multiple input types. However, without more details, it's hard to be certain. But given the options, maybe it's multimodal. Alternatively, if it's just generating from images, maybe not. But since the answer options are limited, and the other three don't fit, perhaps it's none. Wait, but the user says if it doesn't belong to any, respond with \"none.\" Let me think again. The task is human mesh recovery, which is a computer vision task. The topics given are time-series, multimodal, RAG, KG. None of these directly relate to 3D mesh generation from images. So maybe the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32724@AAAI"},
{"title": "FunEditor: Achieving Complex Image Edits via Function Aggregation with Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FunEditor: Achieving Complex Image Edits via Function Aggregation with Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image edits, which are more about visual data, so maybe not time-series. \n\nMultimodal refers to combining different types of data, like text and images. The paper is about image editing using diffusion models. If it's using multiple modalities, like text and images together, then it would be multimodal. But the title doesn't mention text or other data types, just image edits. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically when a model uses a retrieval system to pull information and then generates text, like in some NLP tasks. The title doesn't mention retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image editing with diffusion models, which doesn't seem related to knowledge graphs.\n\nSo, the paper is about image editing using diffusion models. The key here is \"Function Aggregation with Diffusion Models.\" Diffusion models are a type of generative model used in image generation and editing. The topic here is about a method for complex image edits, which is a computer vision task. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The paper doesn't combine multiple modalities, use retrieval, or involve knowledge graphs. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32725@AAAI"},
{"title": "PVTree: Realistic and Controllable Palm Vein Generation for Recognition Tasks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PVTree: Realistic and Controllable Palm Vein Generation for Recognition Tasks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Palm Vein Generation\" suggests it's about creating synthetic palm vein images, probably for biometric recognition. The goal is to generate realistic and controllable data. \n\nTime-series usually involves data points indexed in time order, like stock prices over time. This doesn't seem related to time-based data. \n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about generating palm vein images, which is a single modality (image), so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information before generating a response. The title doesn't mention anything about retrieval or combining it with generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using a knowledge graph, so probably not KG.\n\nSo, the paper is about generating synthetic palm vein images. That sounds like a generative model, maybe using techniques like GANs or VAEs. But the options given don't include generative models directly. The four topics are time-series, multimodal, RAG, KG. None of these directly fit. The closest might be RAG if they're using retrieval to generate, but the title doesn't indicate that. So the answer is \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32726@AAAI"},
{"title": "Video Summarization Using Denoising Diffusion Probabilistic Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Video Summarization Using Denoising Diffusion Probabilistic Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, video summarization. That's about creating a shorter version of a video, right? So, video is a sequence of frames over time, which might relate to time-series. But wait, time-series usually refers to data points indexed in time order, like stock prices or weather data. Video is a form of time-series data because it's a sequence over time. So maybe time-series is a possibility.\n\nBut then, video is also multimodal. It includes both visual (frames) and auditory (audio) information. So if the paper is using both modalities, it could be multimodal. However, the title doesn't explicitly mention multiple modalities. It just says \"video,\" which is inherently multimodal, but the method used here is a denoising diffusion model. \n\nDenoising diffusion models are a type of generative model, often used in image and video generation. They work by gradually denoising data through a series of steps. So the technique here is about generating a summary, which might involve processing the video's frames. But does that tie into any of the listed topics?\n\nRAG (Retrieval-Augmented Generation) is a method that combines retrieval of information with generation, often used in NLP. KG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention anything about retrieval or knowledge graphs, so probably not RAG or KG.\n\nSo between time-series and multimodal. The video is a time-series of frames, but the main focus here is on summarization using a specific model. The key is whether the research topic is about the time-series aspect or the multimodal aspect. Since video inherently combines visual and audio data, it's multimodal. However, the method used (denoising diffusion) is more about the model architecture rather than the modality. But the task of video summarization is a multimodal task because it involves processing both visual and audio elements. \n\nWait, but the title doesn't specify using multiple modalities. It just says \"video,\" which is a single modality (though video itself is a combination of frames and audio). However, in academic terms, video processing is often considered multimodal because it's more than just images. So maybe the correct answer is multimodal. \n\nAlternatively, if the paper is focusing on the temporal aspect of the video (since it's a sequence over time), it could be time-series. But time-series typically refers to numerical data over time, not video. So I think the better fit here is multimodal because video is a combination of different modalities (visual and auditory), and the task is about summarizing it, which is a multimodal processing task. The model used (diffusion) is the method, but the topic is the nature of the data. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32727@AAAI"},
{"title": "Boosting Consistency in Story Visualization with Rich-Contextual Conditional Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Boosting Consistency in Story Visualization with Rich-Contextual Conditional Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Story Visualization\" probably involves generating images or videos based on a story, which is a narrative. So that's about creating visual content from textual input. The method mentioned is \"Rich-Contextual Conditional Diffusion Models.\" Diffusion models are a type of generative model, often used in image generation. The \"conditional\" part suggests that the model is conditioned on some input, which in this case is the story context.\n\nNow, the key part is \"Rich-Contextual.\" That implies the model uses multiple types of information or modalities. Since the input is a story (text) and the output is a visualization (image or video), this seems like a multimodal task. Multimodal research deals with combining different data types, like text and images. \n\nTime-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation, often in NLP. KG (Knowledge Graphs) involves structured data and relationships. The title doesn't mention anything about time, retrieval, or structured knowledge graphs. So the most likely topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32728@AAAI"},
{"title": "IMAGDressing-v1: Customizable Virtual Dressing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"IMAGDressing-v1: Customizable Virtual Dressing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. Virtual dressing might involve images or videos of clothing and maybe user inputs, so that's a possibility. But I'm not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and then generates a response. The title doesn't mention anything about retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graph, which is a structured representation of knowledge. If the paper is about building a graph of clothing items or user preferences, it might be KG. But the title says \"Customizable Virtual Dressing,\" which sounds more like an application rather than a knowledge graph.\n\nPutting it together: Virtual dressing could involve using different modalities like images and user inputs (multimodal). For example, a system that takes a user's image and suggests outfits, combining visual and maybe textual data. So the answer might be multimodal. I don't see any indication of time-series, RAG, or KG here. So the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32729@AAAI"},
{"title": "LDP: Generalizing to Multilingual Visual Information Extraction by Language Decoupled Pretraining", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LDP: Generalizing to Multilingual Visual Information Extraction by Language Decoupled Pretraining.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multilingual Visual Information Extraction\" suggests that the paper deals with extracting information from visual data (like images) and handling multiple languages. So, combining visual and textual data across different languages. That makes me think of multimodal because multimodal typically involves integrating different types of data, such as text and images. \n\nThen there's \"Language Decoupled Pretraining.\" Pretraining is a common technique in machine learning, especially in NLP. Decoupling language might mean separating the language-specific components from the model during pretraining, which could help in generalizing across different languages. But how does that tie into the topics? \n\nLooking at the options: time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) involves using retrieval mechanisms to augment generation models, which isn't mentioned. KG (Knowledge Graphs) are structured representations of knowledge, which also don't seem to be the focus here. \n\nMultimodal is about combining multiple modalities, like text and images. The paper's focus on visual information extraction (images) and multilingual (text) suggests a combination of different data types. So, multimodal seems like the right fit. \n\nI don't see any mention of knowledge graphs or retrieval-augmented generation. Time-series is unrelated. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32730@AAAI"}
{"title": "In2NeCT: Inter-class and Intra-class Neural Collapse Tuning for Semantic Segmentation of Imbalanced Remote Sensing Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"In2NeCT: Inter-class and Intra-class Neural Collapse Tuning for Semantic Segmentation of Imbalanced Remote Sensing Images.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on neural collapse tuning for semantic segmentation. The key terms here are \"inter-class\" and \"intra-class,\" which relate to how different classes (categories) are separated in the model's output. The application is in remote sensing images, which are typically images from satellites or aerial sources. The problem mentioned is imbalanced data, meaning some classes have more samples than others.\n\nNow, looking at the four options. Time-series research deals with data points indexed in time order, like stock prices over time. This paper is about images, so probably not time-series. Multimodal refers to combining multiple data types, like text and images. The title doesn't mention combining different modalities, just working with remote sensing images. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This paper is about image segmentation, not text generation or retrieval, so RAG seems unlikely. KG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using knowledge graphs, so that's probably not it either.\n\nThe paper is focused on improving neural network performance for semantic segmentation in imbalanced datasets. The techniques mentioned (inter-class and intra-class neural collapse tuning) are about adjusting the model's learning process to handle class imbalance. None of the four topics directly relate to this. Time-series is about temporal data, multimodal about multiple data types, RAG about retrieval in generation, and KG about structured knowledge. Since the paper is about a specific problem in image segmentation and neural network tuning, it doesn't fit into any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32731@AAAI"},
{"title": "Topology-Aware 3D Gaussian Splatting: Leveraging Persistent Homology for Optimized Structural Integrity", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Topology-Aware 3D Gaussian Splatting: Leveraging Persistent Homology for Optimized Structural Integrity.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Topology-Aware\" suggests something related to topological data analysis, maybe using methods like persistent homology, which is a concept from computational topology. \"3D Gaussian Splatting\" sounds like a rendering or visualization technique, perhaps in computer graphics or 3D modeling. \"Persistent Homology\" is definitely a term from topological data analysis, used to study the shape of data. The goal here is \"Optimized Structural Integrity,\" which might relate to ensuring the structural soundness of a 3D model or some physical structure.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, which doesn't seem to fit here. Multimodal refers to combining multiple data types (like text and images), but the title doesn't mention different modalities. RAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval, typically in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus on topology and persistent homology doesn't directly align with any of these four topics. Time-series is about temporal data, multimodal about multiple data types, RAG and KG about information retrieval and knowledge representation. The use of topological methods here is more about data structure and shape analysis, which isn't one of the listed topics. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32732@AAAI"},
{"title": "Fast Omni-Directional Image Super-Resolution: Adapting the Implicit Image Function with Pixel and Semantic-Wise Spherical Geometric Priors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Fast Omni-Directional Image Super-Resolution: Adapting the Implicit Image Function with Pixel and Semantic-Wise Spherical Geometric Priors.\" I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. This title is about image super-resolution, which is image processing, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions image super-resolution, but I don't see any indication of combining different modalities. It's focused on images, specifically omni-directional images, which might be 360-degree images. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title talks about geometric priors and image functions, which seems more related to computer vision techniques rather than knowledge graphs.\n\nSo the options are none of the above. The paper is about image super-resolution using spherical geometric priors, which is a computer vision topic. None of the given categories (time-series, multimodal, RAG, KG) fit here. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32733@AAAI"},
{"title": "Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Medical\" probably refers to the application domain, so that's the context. \"Multimodal\" is right there in the title. That suggests the model uses multiple types of data, like images and text. Then \"Model Stealing Attacks\" implies it's about security, specifically attacking machine learning models to steal them. \"Adversarial Domain Alignment\" sounds like a method used in adversarial machine learning, where they might be aligning different domains, perhaps to transfer knowledge or attack the model.\n\nNow, the options are time-series, multimodal, RAG, or KG. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. Multimodal is directly mentioned, so that's a strong candidate. RAG (Retrieval-Augmented Generation) is a technique in NLP where models use external information during generation. KG (Knowledge Graphs) involve structured data representations. The title doesn't mention retrieval or knowledge graphs. The focus here is on multimodal data and adversarial attacks. So the main topic here is multimodal. The model stealing attack is the specific problem, but the broader category is multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32734@AAAI"},
{"title": "ProcTag: Process Tagging for Assessing the Efficacy of Document Instruction Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ProcTag: Process Tagging for Assessing the Efficacy of Document Instruction Data.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Process Tagging\" probably refers to some kind of tagging system for processes. \"Assessing the Efficacy of Document Instruction Data\" suggests they're evaluating how well document instructions work. \n\nTime-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal would involve multiple data types, like text and images. The title is about document instruction data, which is text-based, but there's no mention of combining different modalities. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate answers. The paper's focus on assessing document instruction data might relate to how retrieval is used, but the title doesn't explicitly mention retrieval or generation. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper is about creating or using a knowledge graph from document instructions, that could fit. However, the title mentions \"Process Tagging,\" which sounds more like categorizing or labeling processes rather than building a graph structure. \n\nWait, maybe RAG? If they're using document instruction data to enhance retrieval for a model, but the title doesn't specify that. The key part is \"Assessing the Efficacy,\" which might be about evaluating how well the data works for some purpose. \n\nAlternatively, if the process tagging is part of structuring the data into a knowledge graph, then KG could be the topic. But the title doesn't mention graphs. \n\nHmm. The options are time-series, multimodal, RAG, KG. The title doesn't clearly align with any of these. It's about process tagging and evaluating document instruction data. None of the four topics seem to fit directly. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32735@AAAI"},
{"title": "Free-Moving Object Reconstruction and Pose Estimation with Virtual Camera", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Free-Moving Object Reconstruction and Pose Estimation with Virtual Camera.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or sensor data. The title mentions reconstruction and pose estimation, which might involve sequences, but \"free-moving\" could imply movement over time. However, the key part here is \"virtual camera.\" \n\nMultimodal research deals with combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. That's more common in NLP tasks, so probably not here. \n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about knowledge or structured data. \n\nThe main focus seems to be on reconstructing objects and estimating their pose using a virtual camera. This sounds like computer vision, maybe 3D reconstruction or robotics. None of the given topics directly relate to this. The closest might be time-series if there's a temporal aspect, but the title doesn't explicitly state that. Since the options are time-series, multimodal, RAG, KG, and none, I think it's \"none\" because it doesn't fit any of the listed categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32736@AAAI"},
{"title": "Normal-NeRF: Ambiguity-Robust Normal Estimation for Highly Reflective Scenes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Normal-NeRF: Ambiguity-Robust Normal Estimation for Highly Reflective Scenes.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Normal-NeRF\" probably refers to a method or model, maybe an extension of NeRF (Neural Radiance Fields), which is used in 3D scene reconstruction. The key part here is \"Normal Estimation,\" which relates to estimating surface normals in a scene. The focus is on highly reflective scenes, which might be challenging for traditional methods due to reflections causing ambiguities.\n\nNow, looking at the possible topics. Time-series would involve data over time, like sequences or temporal data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal usually refers to combining multiple data modalities, like text and images, or different types of data. The title doesn't mention combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to augment its responses. This seems unrelated to normal estimation in 3D scenes.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about knowledge graphs or structured data.\n\nSo, none of the four topics (time-series, multimodal, RAG, KG) seem to fit. The paper is about normal estimation in 3D scenes, which is more related to computer vision or graphics, not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32737@AAAI"},
{"title": "Neural Block Compression: Variable Bitrates Feature Blocks for Texture Representation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Neural Block Compression: Variable Bitrates Feature Blocks for Texture Representation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data points indexed in time order, like stock prices over time or sensor data. The title here mentions compression and texture representation, which sounds more like image processing or data compression techniques. So maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't seem related to retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus on compression and texture blocks doesn't hint at knowledge graphs.\n\nSo, none of the four topics seem to fit. The paper is about a specific compression technique for texture representation using neural networks, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32738@AAAI"},
{"title": "ResMaster: Mastering High-Resolution Image Generation via Structural and Fine-Grained Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ResMaster: Mastering High-Resolution Image Generation via Structural and Fine-Grained Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title here is about image generation, so time-series doesn't seem relevant. \n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about generating images, but the title doesn't mention combining different modalities. It's focused on high-resolution image generation with specific guidance methods. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses retrieved information to enhance its generation, often in text. The title doesn't mention retrieval or augmentation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's title doesn't mention anything about knowledge graphs or structured data. \n\nThe paper is about image generation techniques, specifically structural and fine-grained guidance. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32739@AAAI"},
{"title": "SdalsNet: Self-Distilled Attention Localization and Shift Network for Unsupervised Camouflaged Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SdalsNet: Self-Distilled Attention Localization and Shift Network for Unsupervised Camouflaged Object Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on an unsupervised method for detecting camouflaged objects. The network uses self-distilled attention localization and shift. \n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't mention anything about time, so probably not time-series.\n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. The paper here is about object detection, which is computer vision, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo none of the four topics seem to fit. The paper is about a specific neural network architecture for object detection, which doesn't align with the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32742@AAAI"}
{"title": "Pixel Is Not a Barrier: An Effective Evasion Attack for Pixel-Domain Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Pixel Is Not a Barrier: An Effective Evasion Attack for Pixel-Domain Diffusion Models.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions pixel-domain diffusion models, which are more about images, so maybe not time-series. \n\nMultimodal refers to combining different data types, like text and images. The paper is about attacking diffusion models, which are image-based, but the title doesn't mention combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. The paper is about evasion attacks in diffusion models, which are generative models for images. Not sure if RAG is involved here.\n\nKG is Knowledge Graphs, which are structured data representations. The paper doesn't mention anything about knowledge graphs or structured data. \n\nThe paper is about an evasion attack in the pixel domain for diffusion models. Diffusion models are a type of generative model used in image generation. The attack is in the pixel domain, which relates to manipulating pixels to evade detection. None of the four topics (time-series, multimodal, RAG, KG) seem to directly relate to this. The attack is more about adversarial examples or security in machine learning, which isn't listed here. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32741@AAAI"},
{"title": "SdalsNet: Self-Distilled Attention Localization and Shift Network for Unsupervised Camouflaged Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SdalsNet: Self-Distilled Attention Localization and Shift Network for Unsupervised Camouflaged Object Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on an unsupervised method for detecting camouflaged objects. The network uses self-distilled attention localization and shift. \n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't mention anything about time, so probably not time-series.\n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. The paper here is about object detection, which is computer vision, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo none of the four topics seem to fit. The paper is about a specific neural network architecture for object detection, which doesn't align with the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32742@AAAI"},
{"title": "OGP-Net: Optical Guidance Meets Pixel-Level Contrastive Distillation for Robust Multi-Modal and Missing Modality Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OGP-Net: Optical Guidance Meets Pixel-Level Contrastive Distillation for Robust Multi-Modal and Missing Modality Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That immediately makes me think of the \"multimodal\" topic. The paper is about segmentation, which is a computer vision task, but the key part here is \"Multi-Modal and Missing Modality.\" So multimodal definitely seems relevant. \n\nBut wait, are there other possibilities? Let's check the other options. Time-series usually involves data over time, like sequences. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is unlikely. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything related to knowledge graphs. \n\nSo the main clue here is \"Multi-Modal,\" which directly corresponds to the multimodal topic. The paper is addressing segmentation in a multi-modal context, handling cases where some modalities might be missing. That fits under multimodal research. \n\nI don't see any indication that it's about time-series data, RAG, or knowledge graphs. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32743@AAAI"},
{"title": "SKI Models: Skeleton Induced Vision-Language Embeddings for Understanding Activities of Daily Living", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SKI Models: Skeleton Induced Vision-Language Embeddings for Understanding Activities of Daily Living.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Skeleton Induced Vision-Language Embeddings\" suggests that they're combining visual data (like images or videos) with language, which points towards multimodal learning. The skeleton part might refer to using skeletal data from, say, motion capture, which is often used in activity recognition. But the key here is the combination of vision and language, which are two different modalities. \n\nTime-series usually involves data points indexed in time order, like stock prices over time. While activities of daily living could involve time-series data (like tracking movements over time), the title doesn't explicitly mention time-series analysis. The focus here seems more on the integration of different data types (vision and language) rather than temporal sequences.\n\nRAG (Retrieval-Augmented Generation) is a method that combines retrieval of information with generation, often used in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graphs) involve structured data representations, often linking entities and their relationships. The title doesn't indicate the use of a knowledge graph structure either.\n\nSo, putting it all together, the main elements are vision and language, which are two different modalities. The use of skeleton data might be part of the vision modality, but the key aspect is combining vision with language. Therefore, the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32744@AAAI"},
{"title": "JoVALE: Detecting Human Actions in Video Using Audiovisual and Language Contexts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"JoVALE: Detecting Human Actions in Video Using Audiovisual and Language Contexts.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main task is detecting human actions in video. The key part here is \"using audiovisual and language contexts.\" So they're combining different modalities—audio, visual, and language. That sounds like multimodal because multimodal research typically involves integrating information from multiple sensory inputs or data types, like combining text, images, audio, etc. \n\nTime-series usually refers to data that is sequential over time, like stock prices or sensor data. While video is a time-series in a way, the title doesn't specifically mention time-series analysis or modeling. The focus here is more on combining different modalities (audio, visual, language) rather than temporal sequences.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves relevant documents and uses them to generate answers. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about building or using a knowledge graph, so that's probably not it either.\n\nSo the main clue is the use of \"audiovisual and language contexts,\" which are different modalities. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32745@AAAI"},
{"title": "Fine-Grained Perception in Panoramic Scenes: A Novel Task, Dataset, and Method for Object Importance Ranking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Fine-Grained Perception in Panoramic Scenes: A Novel Task, Dataset, and Method for Object Importance Ranking.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper talks about panoramic scenes, which are visual, but there's no mention of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper introduces a new task and dataset for object importance ranking in panoramic scenes. If they're building a knowledge graph to represent the relationships or importance of objects, maybe. But the title doesn't explicitly mention a knowledge graph. It's more about perception and ranking objects in images.\n\nSince none of the four topics seem to fit perfectly, the answer might be \"none.\" The paper is about computer vision, specifically object ranking in panoramic images, which doesn't directly relate to time-series, multimodal data, RAG, or KG.\n</think>\n\nnone", "url": "https://papers.cool/venue/32746@AAAI"},
{"title": "CtrlAvatar: Controllable Avatars Generation via Disentangled Invertible Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CtrlAvatar: Controllable Avatars Generation via Disentangled Invertible Networks.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about generating avatars, which might involve images or 3D models, but the title doesn't specify using multiple modalities. It's about controllable generation, so maybe it's using a specific model rather than combining data types.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generation tasks, like in chatbots. The title doesn't mention retrieval or combining retrieved information with generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on generating avatars using invertible networks, which doesn't seem related to knowledge graphs.\n\nSo, none of the four topics seem to fit. The paper is about controllable avatar generation using a specific type of neural network (disentangled invertible networks), which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32747@AAAI"},
{"title": "ERL-MPP: Evolutionary Reinforcement Learning with Multi-head Puzzle Perception for Solving Large-scale Jigsaw Puzzles of Eroded Gaps", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ERL-MPP: Evolutionary Reinforcement Learning with Multi-head Puzzle Perception for Solving Large-scale Jigsaw Puzzles of Eroded Gaps.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are Evolutionary Reinforcement Learning (ERL), Multi-head Puzzle Perception (MPP), and the application to solving large-scale jigsaw puzzles with eroded gaps. \n\nTime-series usually involves data over time, like stock prices or weather data. This paper seems to be about solving jigsaw puzzles, which is more of a spatial or image-based problem. So time-series might not be relevant here.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper mentions \"Multi-head Puzzle Perception,\" which could imply using different aspects or features of the puzzle, but I'm not sure if that's multimodal in the traditional sense. It might be more about the model architecture rather than combining different data modalities.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about solving puzzles using reinforcement learning, which doesn't seem to involve building or using a knowledge graph.\n\nSo, none of the four topics seem to directly fit. The paper is about reinforcement learning and puzzle solving, which might be a different area altogether. The multi-head part could relate to multimodal if it's using different data types, but since it's about puzzle perception, it's more likely about the model's attention mechanisms rather than combining modalities. Therefore, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32748@AAAI"},
{"title": "Temporal Coherent Object Flow for Multi-Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Temporal Coherent Object Flow for Multi-Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Coherent\" suggests something related to time, right? Temporal usually refers to time-based data. \"Object Flow\" might be about how objects move over time. \"Multi-Object Tracking\" is the task of tracking multiple objects in a sequence, like in videos. \n\nTime-series analysis deals with data points indexed in time order. Since the title mentions temporal coherence, which is about maintaining consistency over time, this seems related to time-series. Multi-object tracking in videos is a classic time-series problem because each frame is a time step, and you're analyzing sequences of frames.\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention anything about combining different data types, so probably not multimodal.\n\nRAG (Retrieval-Augmented Generation) is a method that uses external knowledge during generation, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG (Knowledge Graph) involves structured data representations. Again, the title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nSo the most likely topic here is time-series. The focus on temporal coherence and tracking over time fits well with time-series analysis.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32749@AAAI"},
{"title": "Enhancing Noise-Robust Losses for Large-Scale Noisy Data Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Noise-Robust Losses for Large-Scale Noisy Data Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key parts are \"noise-robust losses\" and \"noisy data learning.\" So the focus is on making loss functions more robust to noise in large datasets. \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't talk about multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title is about loss functions and noise, which doesn't directly relate to retrieval or generation. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data. \n\nSo none of the four topics seem to fit. The paper is about improving loss functions for noisy data, which is more related to machine learning optimization or robust learning, but not the specific topics listed. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32752@AAAI"}
{"title": "Hierarchical Vector Quantization for Unsupervised Action Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hierarchical Vector Quantization for Unsupervised Action Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Hierarchical Vector Quantization\" sounds like a method or technique. \"Unsupervised Action Segmentation\" refers to the task of segmenting actions without labeled data. Action segmentation is often related to video or time-based data, so maybe time-series? But wait, time-series typically refers to data points indexed in time order, like stock prices or sensor data. Action segmentation in videos could involve time-series analysis, but the key here is the method used.\n\nVector quantization is a technique used in data compression and clustering. Hierarchical might mean it's using multiple levels of quantization. Now, the options are time-series, multimodal, RAG, or KG. \n\nMultimodal usually involves combining different types of data, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval. That doesn't seem related to action segmentation. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nTime-series could be a possibility if the action segmentation is based on temporal data. However, the main focus here is on the method (hierarchical vector quantization) rather than the temporal aspect. The task is unsupervised action segmentation, which is more about clustering or segmenting actions in sequences, possibly video frames. But the core of the paper is the quantization method. \n\nWait, but the problem is about action segmentation, which is a time-based task. However, the question is about the research topic the paper belongs to. The options are time-series, multimodal, RAG, or KG. Since the method is hierarchical vector quantization, which is a clustering technique, but none of the options directly relate to clustering. The task is action segmentation, which could be part of time-series analysis if the data is temporal. But the paper's title doesn't mention time-series explicitly. \n\nAlternatively, maybe it's not any of the four. The four options are time-series, multimodal, RAG, KG. The paper's focus is on a specific method for action segmentation, which is a computer vision or machine learning task. Since none of the four topics directly match the method or the task described, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32751@AAAI"},
{"title": "Enhancing Noise-Robust Losses for Large-Scale Noisy Data Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Noise-Robust Losses for Large-Scale Noisy Data Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key parts are \"noise-robust losses\" and \"noisy data learning.\" So the focus is on making loss functions more robust to noise in large datasets. \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't talk about multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title is about loss functions and noise, which doesn't directly relate to retrieval or generation. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data. \n\nSo none of the four topics seem to fit. The paper is about improving loss functions for noisy data, which is more related to machine learning optimization or robust learning, but not the specific topics listed. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32752@AAAI"},
{"title": "RI-MAE: Rotation-Invariant Masked AutoEncoders for Self-Supervised Point Cloud Representation Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RI-MAE: Rotation-Invariant Masked AutoEncoders for Self-Supervised Point Cloud Representation Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Rotation-Invariant Masked AutoEncoders\" and \"Point Cloud Representation Learning.\" Masked AutoEncoders (MAE) are a type of self-supervised learning method, right? They work by masking parts of the input and then reconstructing them. So MAE is a technique used in self-supervised learning, which is a broader area. But the question is about the specific topics listed.\n\nTime-series would involve data that's sequential over time, like stock prices or sensor data over time. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple modalities, like text and images. The paper here is about point clouds, which are a type of 3D data. But the title doesn't mention combining different data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models like those that retrieve information from a database to enhance generation tasks. That's more about combining retrieval with generation, which doesn't seem related to point cloud representation learning.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on learning representations from point clouds, not on building or using knowledge graphs.\n\nSo the paper is about developing a specific type of autoencoder (RI-MAE) for point clouds, focusing on rotation invariance. None of the listed topics (time-series, multimodal, RAG, KG) directly apply here. The techniques used (like MAE) are part of self-supervised learning, but the given options don't include self-supervised learning or representation learning. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32753@AAAI"},
{"title": "Can We Get Rid of Handcrafted Feature Extractors? SparseViT: Nonsemantics-Centered, Parameter-Efficient Image Manipulation Localization Through Spare-Coding Transformer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Can We Get Rid of Handcrafted Feature Extractors? SparseViT: Nonsemantics-Centered, Parameter-Efficient Image Manipulation Localization Through Spare-Coding Transformer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on image manipulation localization. The term \"SparseViT\" suggests it's a Vision Transformer (ViT) variant. The key parts here are \"nonsemantics-centered,\" \"parameter-efficient,\" and \"spare-coding transformer.\" \n\nHandcrafted feature extractors are traditional methods in computer vision, like SIFT or HOG. The paper is proposing to eliminate these in favor of a sparse coding approach using a transformer. The goal is to detect image manipulations, which is a computer vision task. \n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. Multimodal refers to combining different data types, like text and images. The title doesn't mention combining modalities, so maybe not multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, often in NLP. The paper doesn't mention retrieval or generation, so RAG is unlikely. KG (Knowledge Graph) involves structured data and relationships. The paper is about image processing, not structured knowledge, so KG is probably not it either.\n\nThe paper is focused on improving image manipulation detection using a transformer model that's parameter-efficient and sparse. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The closest might be multimodal if it involved multiple data types, but since it's purely image-based, it doesn't fit. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32754@AAAI"},
{"title": "EigenSR: Eigenimage-Bridged Pre-Trained RGB Learners for Single Hyperspectral Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EigenSR: Eigenimage-Bridged Pre-Trained RGB Learners for Single Hyperspectral Image Super-Resolution.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"EigenSR\" probably refers to a method or model. \"Eigenimage\" might be related to some kind of image processing or feature extraction. \"Bridged Pre-Trained RGB Learners\" suggests that they're using pre-trained models on RGB images. \"Single Hyperspectral Image Super-Resolution\" is the task: enhancing the resolution of a hyperspectral image using a single input.\n\nHyperspectral images have multiple spectral bands, so they're more complex than regular RGB images. The paper is about super-resolution, which is a common task in image processing. Now, the key here is whether this falls under any of the given topics. \n\nTime-series usually involves data over time, like stock prices or weather data. This paper is about images, not sequences over time, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images, or audio and video. Here, the paper is using RGB learners (which are standard color images) to process hyperspectral images. Hyperspectral data is a different modality compared to RGB, so combining them might be multimodal. But wait, the task is to generate a high-resolution hyperspectral image from a single one. If they're using pre-trained RGB models, maybe they're leveraging the RGB modality to enhance the hyperspectral data. That could be considered multimodal because it's using information from different modalities (RGB and hyperspectral) to achieve the task. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, typically in NLP tasks. This paper is about image super-resolution, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which involve structured data and relationships between entities. The paper doesn't mention anything about knowledge graphs or structured data, so that's probably not it.\n\nSo, the most likely answer is multimodal because it's using pre-trained RGB models (a different modality) to improve hyperspectral image resolution. The bridging of eigenimages might be a technique to combine these modalities. Therefore, the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32755@AAAI"},
{"title": "Prior-guided Hierarchical Harmonization Network for Efficient Image Dehazing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Prior-guided Hierarchical Harmonization Network for Efficient Image Dehazing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image dehazing, which is about images, not time-based data. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper's title is about image dehazing, which is a single modality (images). Unless there's mention of combining different data types, but the title doesn't indicate that. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The title doesn't mention knowledge graphs or structured data. The focus is on a neural network for image processing.\n\nThe paper is about an image dehazing network using a hierarchical approach with prior guidance. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The main focus is on image processing techniques, not the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32756@AAAI"},
{"title": "Dual-branch Graph Feature Learning for NLOS Imaging", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dual-branch Graph Feature Learning for NLOS Imaging.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Dual-branch\" suggests there are two separate branches or pathways in the model. \"Graph Feature Learning\" makes me think of graph structures, which might relate to Knowledge Graphs (KG). \"NLOS Imaging\" stands for Non-Line-of-Sight Imaging, which is a technique in computer vision where you reconstruct images of objects that aren't directly visible. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of information using graphs.\n\nThe key part here is \"Graph Feature Learning.\" If they're using graph structures to learn features, that's likely related to Knowledge Graphs. The dual-branch approach might be a method to process different aspects of the graph data. NLOS Imaging is the application area, but the core method seems to be about graph-based feature learning. So I think this falls under the KG topic. I don't see time-series elements, it's not about combining multiple modalities, and it's not retrieval-augmented generation. Therefore, the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32757@AAAI"},
{"title": "Learning Fine-Grained Alignment for Aerial Vision-Dialog Navigation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning Fine-Grained Alignment for Aerial Vision-Dialog Navigation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Aerial Vision-Dialog Navigation\" suggests that there's a combination of visual data (vision) and dialogue (text) involved in navigation. So, that's using multiple modalities—vision and text. The term \"Fine-Grained Alignment\" probably refers to aligning these different modalities at a detailed level. \n\nMultimodal research deals with integrating different types of data, like combining images and text. Since the paper mentions both vision (images from aerial views) and dialog (textual instructions or conversations), this seems like a multimodal problem. \n\nTime-series would involve data over time, like sequences. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about time sequences, retrieval, or knowledge graphs. \n\nSo the most likely topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32758@AAAI"},
{"title": "Explicit Relational Reasoning Network for Scene Text Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Explicit Relational Reasoning Network for Scene Text Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about scene text detection, which might involve images and text, but the title doesn't explicitly say it's combining different modalities. Hmm, maybe, but not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which involve structured data and relationships between entities. The title mentions \"Relational Reasoning,\" which could relate to relationships in a knowledge graph. But the context here is scene text detection, which is more about computer vision. So maybe the relational reasoning is about how elements in the scene relate to each other, not a knowledge graph. \n\nWait, \"Explicit Relational Reasoning\" might be about modeling relationships between objects in the scene, like how text elements are positioned relative to each other. That's more about spatial reasoning in computer vision rather than a knowledge graph. So maybe it's not KG either. \n\nMultimodal could be a stretch if they're combining visual and textual data, but the title doesn't specify that. The main focus seems to be on the relational reasoning aspect for detecting text in scenes. Since none of the four topics (time-series, multimodal, RAG, KG) directly fit, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32759@AAAI"},
{"title": "3D Annotation-Free Learning by Distilling 2D Open-Vocabulary Segmentation Models for Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"3D Annotation-Free Learning by Distilling 2D Open-Vocabulary Segmentation Models for Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components are 3D annotation-free learning, distilling 2D models, open-vocabulary segmentation, and autonomous driving. \n\nTime-series usually involves data over time, like stock prices or sensor data over time. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining images and text. The paper talks about 3D and 2D models, but it's about distilling a 2D model into a 3D one. It's more about model architecture and learning methods rather than combining different data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on segmentation models for autonomous driving, which is more about computer vision and machine learning techniques. No mention of knowledge graphs here.\n\nSo none of the four topics seem to fit. The paper is about model distillation in the context of autonomous driving, using 2D and 3D models for segmentation. The key terms here are model distillation, segmentation, autonomous driving, which don't align with the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32760@AAAI"}
{"title": "Ultra-High Resolution Segmentation via Boundary-Enhanced Patch-Merging Transformer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Ultra-High Resolution Segmentation via Boundary-Enhanced Patch-Merging Transformer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Ultra-High Resolution Segmentation\" suggests that the paper is about image segmentation, probably in computer vision. The method mentioned is a \"Boundary-Enhanced Patch-Merging Transformer.\" Transformers are a type of neural network architecture, often used in vision tasks now with models like Vision Transformers (ViT). The term \"patch-merging\" might refer to how the model processes image patches, combining them in some way. The \"boundary-enhanced\" part could mean they're focusing on improving the segmentation around object boundaries.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on image segmentation using a transformer-based model. None of the four topics directly relate to image segmentation or computer vision models unless there's a specific mention of multimodal data. But the title doesn't mention combining different modalities (like text and images), so multimodal might not fit. The other topics (time-series, RAG, KG) don't seem relevant here. The paper is about a specific architecture for segmentation, which doesn't fall under the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32761@AAAI"},
{"title": "NeuralFlix: A Simple While Effective Framework for Semantic Decoding of Videos from Non-invasive Brain Recordings", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"NeuralFlix: A Simple While Effective Framework for Semantic Decoding of Videos from Non-invasive Brain Recordings.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Semantic Decoding of Videos\" and \"Non-invasive Brain Recordings.\" So, the research is about decoding videos from brain recordings. That sounds like it's taking data from the brain (which could be time-series data, since brain signals are recorded over time) and using that to generate or decode videos. \n\nNow, the options. Time-series usually refers to data that is sequential over time, like stock prices or sensor data. Since brain recordings are likely time-series data, maybe that's a possibility. But the main focus here is on decoding videos, which is a different modality. So maybe it's about combining different types of data (brain signals and video), which would be multimodal. \n\nMultimodal research involves integrating multiple types of data, like text and images, or in this case, brain signals and video. The paper is taking brain recordings (which could be time-series) and using them to decode videos, which are another modality. So this seems like a multimodal approach because it's combining different data types to achieve a task. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, typically in NLP. KG (Knowledge Graphs) involve structured data representations. The title doesn't mention anything about retrieval or knowledge graphs, so those can probably be ruled out. \n\nSo the main contenders are time-series and multimodal. The brain recordings are time-series, but the decoding into videos involves another modality. The framework is for semantic decoding, which implies understanding the meaning (semantics) from the brain data to generate videos. Since it's combining brain data (time-series) with video output, the primary research topic here is likely multimodal because it's integrating different modalities (brain signals and video) for a decoding task. Time-series is a component, but the main focus is on the multimodal aspect of decoding one modality (video) from another (brain signals).\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32762@AAAI"},
{"title": "VE-Bench: Subjective-Aligned Benchmark Suite for Text-Driven Video Editing Quality Assessment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VE-Bench: Subjective-Aligned Benchmark Suite for Text-Driven Video Editing Quality Assessment.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Text-Driven Video Editing\" suggests that there's some interaction between text and video. So, multimodal might be a candidate because it involves combining different modalities like text and video. \n\nThe term \"Benchmark Suite\" indicates it's about evaluating models or systems. But the key part here is \"Subjective-Aligned\" and \"Quality Assessment.\" The focus is on how well the video editing aligns with the text input, probably using human judgment or subjective metrics. \n\nNow, looking at the options. Time-series usually deals with data over time, like stock prices or sensor data. This doesn't seem to fit. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, often in text-based models. KG (Knowledge Graphs) involve structured data and relationships. Neither of these seem directly related to video editing based on text. \n\nMultimodal is about integrating multiple data types, like text and video here. The paper is assessing how well text-driven video editing works, which involves both text and video modalities. So, the topic should be multimodal. \n\nI don't see any mention of time-series analysis, knowledge graphs, or retrieval-augmented generation in the title. The main elements are text and video, making multimodal the correct category.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32763@AAAI"},
{"title": "Guided and Variance-Corrected Fusion with One-shot Style Alignment for Large-Content Image Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Guided and Variance-Corrected Fusion with One-shot Style Alignment for Large-Content Image Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Large-Content Image Generation\" suggests it's about generating images, maybe using some kind of fusion or alignment techniques. The terms \"Guided\" and \"Variance-Corrected Fusion\" might refer to combining different data sources or modalities. \"One-shot Style Alignment\" could imply that they're aligning styles from different sources, perhaps using a single example. \n\nMultimodal research typically involves combining multiple types of data, like text and images, or different sensory inputs. If this paper is about fusing different modalities to generate images, it might be multimodal. The \"fusion\" part in the title supports that idea. \n\nRAG (Retrieval-Augmented Generation) usually involves using a retrieval system to pull relevant information and then generating text based on that. The title doesn't mention retrieval or text generation, so maybe not RAG. \n\nKG (Knowledge Graphs) are structured representations of knowledge, often used for reasoning or information retrieval. The title doesn't seem to relate to knowledge graphs either. \n\nTime-series analysis deals with data points indexed in time order. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nSo, the most likely candidate is multimodal, as it's about fusing different elements (maybe style and content) for image generation. The \"one-shot style alignment\" might involve aligning different styles, which could be considered different modalities. The fusion aspect is key here. I don't see elements that point to RAG, KG, or time-series. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32764@AAAI"},
{"title": "Hierarchically-Structured Open-Vocabulary Indoor Scene Synthesis with Pre-trained Large Language Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hierarchically-Structured Open-Vocabulary Indoor Scene Synthesis with Pre-trained Large Language Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Hierarchically-Structured\" suggests some kind of structured approach, maybe layers or levels. \"Open-Vocabulary\" usually relates to models that can handle a wide range of words, not just a fixed set. \"Indoor Scene Synthesis\" sounds like generating scenes, maybe in a 3D environment or something visual. \"Pre-trained Large Language Model\" is a big hint here. Large language models (LLMs) are typically used in NLP tasks, but when combined with scene synthesis, it might involve generating text and images together.\n\nNow, the options. Time-series is about data over time, like stock prices or weather. That doesn't seem to fit. Multimodal refers to models that handle multiple types of data, like text and images. Since the paper is about scene synthesis (which could be visual) using a language model, that might be multimodal. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database and then generates text. The title doesn't mention retrieval, so maybe not RAG. KG (Knowledge Graph) involves structured data and relationships between entities. The title mentions \"hierarchically-structured,\" which could relate to a knowledge graph, but the main focus seems to be on synthesis using a pre-trained language model.\n\nPutting it together: The key part is \"Pre-trained Large Language Model\" used for \"Indoor Scene Synthesis.\" If the model is generating scenes (which could be images or 3D models) based on text, that's combining text and visual data, which is multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32765@AAAI"},
{"title": "Diversifying Query: Region-Guided Transformer for Temporal Sentence Grounding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Diversifying Query: Region-Guided Transformer for Temporal Sentence Grounding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Sentence Grounding\" suggests something related to time, maybe time-series data. But \"Region-Guided Transformer\" makes me think of models that process different regions, perhaps in images or video. \"Query Diversifying\" might relate to how the model handles different queries, maybe in a multimodal context where text and visual data are combined.\n\nTime-series usually deals with data points indexed in time order, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved documents to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus on temporal aspects (time) and sentence grounding (linking text to time-based data) might point to time-series. However, \"Region-Guided\" could imply working with visual regions, which is common in multimodal tasks where text and images are involved. Temporal sentence grounding is often seen in video captioning or aligning text with video segments, which is a multimodal problem. So maybe it's multimodal. But I'm not entirely sure. Let me check again. The key terms are \"temporal\" and \"sentence grounding.\" If it's about aligning text with time-based data (like video), that's multimodal. If it's purely about time-series data analysis without combining different modalities, then time-series. But given the mention of \"sentence,\" which is text, and \"region,\" which could be visual, it's likely multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32766@AAAI"},
{"title": "M2Flow: A Motion Information Fusion Framework for Enhanced Unsupervised Optical Flow Estimation in Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"M2Flow: A Motion Information Fusion Framework for Enhanced Unsupervised Optical Flow Estimation in Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Motion Information Fusion Framework\" suggests combining different types of data or information. \"Multimodal\" usually refers to using multiple types of data, like combining images with text or sensor data. So if they're fusing different motion information, maybe that's multimodal. \n\n\"Unsupervised Optical Flow Estimation\" – optical flow is about estimating motion between consecutive frames in a video, which is a time-series aspect because it's dealing with sequences over time. But the question is whether the main topic is time-series. However, the key here might be the fusion part. If they're combining different modalities (like different sensors or different types of motion data), then it's multimodal. \n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to fit here. The paper is about autonomous driving and optical flow, which is more about computer vision and sensor data. \n\nSo, the main question is between time-series and multimodal. Time-series is about data over time, but multimodal is about combining different data types. The title mentions \"fusion framework,\" which points towards multimodal. So I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32767@AAAI"},
{"title": "Leveraging Large Vision-Language Model as User Intent-Aware Encoder for Composed Image Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Leveraging Large Vision-Language Model as User Intent-Aware Encoder for Composed Image Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Large Vision-Language Model\" – that sounds like combining vision (images) and language (text), so that's multimodal. Then \"User Intent-Aware Encoder\" suggests understanding user intent, which might involve natural language processing. \"Composed Image Retrieval\" probably means retrieving images based on some composed queries, maybe combining text and images.\n\nTime-series is about data over time, like stock prices or weather. Doesn't seem related here. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation tasks. The title mentions image retrieval, but RAG is more about text generation with retrieved data. KG is Knowledge Graphs, which are structured data representations. The paper doesn't mention knowledge graphs explicitly.\n\nMultimodal is definitely a possibility because it's using both vision and language models. The key term here is \"Vision-Language Model,\" which is a classic multimodal setup. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32768@AAAI"},
{"title": "RealisID: Scale-Robust and Fine-Controllable Identity Customization via Local and Global Complementation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RealisID: Scale-Robust and Fine-Controllable Identity Customization via Local and Global Complementation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Scale-Robust\" suggests it's handling different scales, maybe in images or data. \"Fine-Controllable Identity Customization\" makes me think of generating or modifying identities, like in images or avatars. \"Local and Global Complementation\" might refer to combining local details with global structure, which is common in image processing or generative models.\n\nLooking at the options: time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper seems focused on identity customization, which is likely in the realm of image generation or editing. That doesn't directly align with time-series, RAG, or KG. Multimodal could be a possibility if it combines different modalities, but the title doesn't mention text, audio, or other data types. It's more about generating or modifying identities, which might be part of computer vision or generative models, but none of the given options fit perfectly. Since the options are limited, and the paper doesn't clearly relate to any of the four, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32769@AAAI"},
{"title": "SoundBrush: Sound as a Brush for Visual Scene Editing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SoundBrush: Sound as a Brush for Visual Scene Editing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. The paper's title mentions sound and visual editing, which might involve sequences, but I'm not sure if it's the main focus.\n\nMultimodal refers to combining multiple types of data, like text, images, and sound. The title uses \"sound\" and \"visual scene,\" which are two different modalities. So this could be multimodal because it's using sound to edit visual scenes. That seems likely.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't seem to relate to knowledge graphs either.\n\nSo the most probable answer is multimodal since it combines sound (audio) and visual elements for scene editing.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32770@AAAI"}
{"title": "First Line of Defense: A Robust First Layer Mitigates Adversarial Attacks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"First Line of Defense: A Robust First Layer Mitigates Adversarial Attacks.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"First Line of Defense\" suggests a security or robustness approach. \"Robust First Layer\" probably refers to a model's initial layer being made resilient. \"Mitigates Adversarial Attacks\" is about defending against attacks that try to fool machine learning models. Adversarial attacks are a common issue in AI security, especially in areas like image recognition or NLP.\n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like some chatbots. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on making a model's first layer robust against adversarial attacks. This seems more related to model robustness and security rather than the specific data types or structures mentioned in the four topics. None of the four topics directly address adversarial attacks or model robustness. Time-series, multimodal, RAG, and KG are all about the type of data or methods used, not about security defenses. So the paper doesn't fit into any of these categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32771@AAAI"},
{"title": "C2P-CLIP: Injecting Category Common Prompt in CLIP to Enhance Generalization in Deepfake Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"C2P-CLIP: Injecting Category Common Prompt in CLIP to Enhance Generalization in Deepfake Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. CLIP is a model known for multimodal tasks, combining text and images. The paper is about modifying CLIP by adding a \"Category Common Prompt\" to improve generalization in detecting deepfakes. \n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time-based data, so probably not time-series.\n\nMultimodal refers to models that handle multiple data types, like text and images. CLIP is a multimodal model, so if the paper is about enhancing CLIP, it might be multimodal. But the key here is whether the modification is about the multimodal aspect or something else.\n\nRAG stands for Retrieval-Augmented Generation, which combines retrieval of information with generation models. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nSo, the main components are CLIP (multimodal) and enhancing generalization. The modification involves prompts, which could be related to prompting techniques in multimodal models. Since CLIP is inherently multimodal, and the paper is about improving it, the topic is likely multimodal. The other options don't fit. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32772@AAAI"},
{"title": "Modality-Aware Shot Relating and Comparing for Video Scene Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Modality-Aware Shot Relating and Comparing for Video Scene Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Modality-Aware\" suggests that the research is considering different data modalities, like combining visual and audio data. \"Shot Relating and Comparing\" might refer to analyzing different shots in a video. \"Video Scene Detection\" is about identifying scenes in a video, which is a common task in video processing.\n\nNow, the possible topics. Time-series usually involves data points indexed in time order, like stock prices over time. Multimodal refers to using multiple types of data (e.g., text, images, audio) together. RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. KG stands for Knowledge Graph, which is structured data representing entities and their relationships.\n\nThe key term here is \"Modality-Aware,\" which directly points to multimodal research. The paper is likely dealing with integrating different modalities (like visual and auditory) for video scene detection. So, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32773@AAAI"},
{"title": "Beyond Human Data: Aligning Multimodal Large Language Models by Iterative Self-Evolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Beyond Human Data: Aligning Multimodal Large Language Models by Iterative Self-Evolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multimodal Large Language Models\" directly mentions \"multimodal,\" which is one of the options. The rest of the title talks about aligning these models through iterative self-evolution. So the key term here is \"multimodal.\" The other parts of the title don't seem to relate to time-series data, which is about sequences over time. RAG stands for Retrieval-Augmented Generation, which involves using external data sources for generating responses. KG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about retrieval, generation, or knowledge graphs. So the most fitting category here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32774@AAAI"},
{"title": "ALLVB: All-in-One Long Video Understanding Benchmark", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ALLVB: All-in-One Long Video Understanding Benchmark.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Long Video Understanding\" suggests that the paper is about analyzing videos, which are sequences over time. But the key part here is \"Benchmark.\" A benchmark usually refers to a standard or set of tests used to evaluate systems. So this is a benchmark for long video understanding.\n\nNow, the options are time-series, multimodal, RAG, or KG. Time-series analysis deals with data points indexed in time order, which could be relevant for video since videos are sequences of frames over time. However, video understanding often involves more than just time-series data. It might also involve processing visual and audio data together, which would be multimodal. \n\nMultimodal refers to combining multiple types of data, like text, images, audio, etc. Since a video contains both visual and auditory information, a video understanding task would typically be multimodal. The term \"All-in-One\" in the title might imply that the benchmark covers various aspects or modalities of video analysis.\n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generation models. That's more about enhancing models with external knowledge retrieval, which doesn't seem directly related to a video understanding benchmark unless the benchmark specifically involves retrieval tasks. But the title doesn't mention anything about retrieval or generation.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. If the benchmark involved building or using knowledge graphs for video understanding, that would be relevant. But again, the title doesn't indicate that.\n\nSo, the main contenders are time-series and multimodal. Time-series is about temporal data, which is part of video analysis, but video understanding is more than just time-series; it's about combining different modalities (like visual and audio) over time. Therefore, the benchmark is likely multimodal. The \"All-in-One\" part might suggest that it's testing multiple modalities or aspects, making it a multimodal benchmark. \n\nTherefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32775@AAAI"},
{"title": "Neighbor Does Matter: Density-Aware Contrastive Learning for Medical Semi-supervised Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Neighbor Does Matter: Density-Aware Contrastive Learning for Medical Semi-supervised Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Density-Aware Contrastive Learning\" and \"Medical Semi-supervised Segmentation.\" The main focus seems to be on a machine learning method for medical image segmentation, using a semi-supervised approach. The term \"contrastive learning\" suggests it's about learning representations by contrasting different data points, which is common in self-supervised learning. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. Multimodal usually refers to combining different types of data, like text and images. The paper here is about medical segmentation, which is image data, but there's no mention of combining multiple modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so that's probably not it. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about graphs or knowledge structures. \n\nThe paper is about a specific learning method for segmentation in medical imaging, using contrastive learning with density awareness. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The methods used here are more about machine learning techniques for image segmentation, which might fall under computer vision or medical imaging, but those aren't the listed options. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32776@AAAI"},
{"title": "A Training-free Synthetic Data Selection Method for Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Training-free Synthetic Data Selection Method for Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Training-free\" suggests that the method doesn't require training a model, which might be relevant in some contexts. \"Synthetic Data Selection\" implies they're working with generated data, maybe for training models. \"Semantic Segmentation\" is a computer vision task where each pixel in an image is classified into a category. So the paper is about selecting synthetic data to improve semantic segmentation without training.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. Multimodal refers to using multiple data types, like combining text and images. The paper is about synthetic data selection for a vision task, but it doesn't mention combining different modalities. RAG stands for Retrieval-Augmented Generation, which is used in NLP for enhancing models with external information. The title doesn't mention retrieval or generation. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about knowledge graphs.\n\nSo none of the four topics seem to fit. The paper is about synthetic data selection for a specific computer vision task, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32777@AAAI"},
{"title": "MUSE: Mamba Is Efficient Multi-scale Learner for Text-video Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MUSE: Mamba Is Efficient Multi-scale Learner for Text-video Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-video Retrieval\" suggests that the paper deals with retrieving information that involves both text and video. That immediately makes me think of multimodal learning because multimodal refers to combining different types of data, like text and video here. \n\nThen there's \"Mamba Is Efficient Multi-scale Learner.\" Mamba might be a model or framework. The term \"multi-scale\" could relate to handling different levels of detail or different modalities. But the key part here is the combination of text and video, which are two different modalities. \n\nTime-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nSince the title specifically mentions text-video retrieval, which is about integrating two different data types (text and video), the most fitting category here is multimodal. The other options don't seem to fit. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32778@AAAI"},
{"title": "Promptable Representation Distribution Learning and Data Augmentation for Gigapixel Histopathology WSI Analysis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Promptable Representation Distribution Learning and Data Augmentation for Gigapixel Histopathology WSI Analysis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Promptable Representation Distribution Learning\" sounds like it's about learning representations, maybe using prompts. \"Data Augmentation\" is a common technique in machine learning to improve model performance by generating more training data. \"Gigapixel Histopathology WSI Analysis\" refers to analyzing very high-resolution whole slide images in histopathology, which is a medical imaging field.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on histopathology images, which are images. The mention of \"promptable\" might relate to prompting techniques, but RAG typically involves retrieval from a knowledge base. Since the paper is about image analysis and data augmentation for medical images, it doesn't seem to involve time-series data. There's no mention of combining different modalities (like text and images), so multimodal might not fit. RAG and KG are more about text-based models and knowledge structures. The paper is about image processing and learning representations for medical images, so it doesn't fit any of the four categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32779@AAAI"},
{"title": "Compressing Streamable Free-Viewpoint Videos to 0.1 MB per Frame", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Compressing Streamable Free-Viewpoint Videos to 0.1 MB per Frame.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. This paper is about video compression, which is a sequence of frames, but the key aspect here is the compression technique, not the temporal analysis. So maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images or audio and video. The title mentions \"free-viewpoint videos,\" which might involve different viewpoints or angles, but the main focus is on compression. Unless the compression method uses multiple modalities, but the title doesn't specify that. Hmm.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This doesn't seem related to video compression. \n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. Again, not directly related to video compression techniques.\n\nThe paper is about compressing videos to a very small size per frame. The main topic here is video compression, which is more about data compression algorithms, maybe using techniques like neural networks or specific encoding methods. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to video compression, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32780@AAAI"}
{"title": "Sign-IDD: Iconicity Disentangled Diffusion for Sign Language Production", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sign-IDD: Iconicity Disentangled Diffusion for Sign Language Production.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Sign-IDD\" probably refers to a model or method. \"Iconicity Disentangled Diffusion\" sounds like a technique, maybe in machine learning. The application is \"Sign Language Production,\" which involves generating sign language, possibly using video or gestures.\n\nNow, the possible topics. Time-series usually deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured data representations.\n\nSign language production likely involves video (visual) and maybe text or audio, so multimodal makes sense. The diffusion model might be part of generating the sign language, which could be a sequence over time, but the key here is the combination of different modalities. The paper's focus on disentangling iconicity might relate to separating different aspects of the sign language, which could be part of multimodal processing. Since it's about producing sign language, which is a combination of visual and linguistic elements, multimodal is the most fitting. Time-series could be a component, but the primary classification here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32781@AAAI"},
{"title": "BEV-TSR: Text-Scene Retrieval in BEV Space for Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BEV-TSR: Text-Scene Retrieval in BEV Space for Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. BEV stands for Bird's Eye View, which is a common term in autonomous driving for representing the environment from a top-down perspective. TSR is Text-Scene Retrieval. So the paper is about retrieving scenes based on text in the BEV space.\n\nNow, the four options. Time-series would involve data over time, like sequences. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe key here is \"Text-Scene Retrieval.\" That sounds like a task where you take a text query and retrieve a corresponding scene. That's a retrieval task. RAG is about using retrieval to augment generation, but the title doesn't mention generation. It's just retrieval. So maybe RAG? Wait, but RAG typically involves retrieving information to help generate a response. If the paper is about retrieving scenes based on text, that's more of a retrieval system, but not necessarily RAG. Unless they're using a RAG framework for this retrieval. But the title doesn't specify that. \n\nAlternatively, multimodal could be a fit because it's combining text (modal) with scene data (another modality, like images or BEV maps). So if the system uses both text and visual/scene data, that's multimodal. The BEV space is a type of visual representation. So the retrieval is between text and a scene (which is a modality). So multimodal makes sense here. \n\nTime-series doesn't seem relevant unless the scenes are over time, but the title doesn't mention time. KG is about knowledge graphs, which isn't indicated here. \n\nSo the answer is either multimodal or RAG. But RAG is more about retrieval to aid in generation. Since the title is about retrieval itself, not generation, I think multimodal is the right choice. The system is using text (one modality) to retrieve scenes (another modality), so it's multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32782@AAAI"},
{"title": "More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"More Text, Less Point: Towards 3D Data-Efficient Point-Language Understanding.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"More Text, Less Point\" suggests that the research is using more textual information and less point data. The phrase \"3D Data-Efficient\" might refer to 3D point clouds, which are common in areas like robotics or computer vision. \"Point-Language Understanding\" implies combining point data (like 3D points) with language. So, this seems like a multimodal approach because it's integrating two different data types: text and 3D points. \n\nMultimodal research typically involves combining different modalities like text, images, audio, etc. Here, the modalities are text and 3D points. Time-series would involve data over time, which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which doesn't seem to fit. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't align with the title. \n\nSo the most likely topic is multimodal. The paper is about integrating text and 3D point data for understanding, which is a classic multimodal problem.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32783@AAAI"},
{"title": "Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Empowering LLMs with Pseudo-Untrimmed Videos for Audio-Visual Temporal Understanding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Empowering LLMs\" suggests they're enhancing large language models. \"Pseudo-Untrimmed Videos\" probably means they're using videos that aren't cut into segments, so maybe full-length or unprocessed. \"Audio-Visual Temporal Understanding\" implies they're dealing with both audio and visual data over time. \n\nTime-series usually refers to data points indexed in time order, like stock prices over days. But here, the focus is on audio and video, which are inherently temporal but also involve multiple modalities (audio and visual). \n\nMultimodal research deals with combining different types of data, like text, images, audio, etc. Since the title mentions both audio and visual, that's a strong indicator of multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance model outputs, typically in text-based tasks. The title doesn't mention retrieval or generation in that context. \n\nKG (Knowledge Graphs) involve structured data representations, which isn't directly mentioned here. \n\nSo the key elements are combining audio and visual data (multimodal) and temporal aspects (time-series). But the primary focus here is on integrating different modalities (audio and video) for understanding over time. The term \"temporal\" might relate to time-series, but the main aspect is the combination of modalities. Therefore, the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32784@AAAI"},
{"title": "CaRDiff: Video Salient Object Ranking Chain of Thought Reasoning for Saliency Prediction with Diffusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CaRDiff: Video Salient Object Ranking Chain of Thought Reasoning for Saliency Prediction with Diffusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video Salient Object Ranking\" suggests that the paper is dealing with video data, which is a sequence of frames over time. So video is a time-dependent data type, which might relate to time-series. But wait, time-series usually refers to data points indexed in time order, like stock prices or weather data. However, video processing can involve time-series analysis because each frame is a time step. But there's also the aspect of \"salient object ranking,\" which is about identifying important objects in each frame. \n\nThen there's \"Chain of Thought Reasoning,\" which might relate to reasoning processes in AI models, but I'm not sure how that connects to the four topics. The \"Diffusion\" part probably refers to diffusion models, which are a type of generative model. But the main focus here is on saliency prediction in videos. \n\nLooking at the four options: time-series, multimodal, RAG, KG. \n\nTime-series: If the paper is about analyzing sequences of data over time, like video frames, then maybe time-series. But video is a type of time-series data, but the primary focus here is on saliency detection, which is more about computer vision. \n\nMultimodal: That would involve combining different types of data, like text and images. The title doesn't mention combining different modalities, just video. So probably not multimodal. \n\nRAG (Retrieval-Augmented Generation): That's about using retrieval methods to enhance generation tasks, like in language models. The title doesn't mention retrieval or generation in that context. \n\nKG (Knowledge Graph): That's about structured data and relationships. The title doesn't mention knowledge graphs. \n\nSo the closest might be time-series because video is a time-based data type. But I'm not entirely sure. The main task is saliency prediction, which is a computer vision task, but the temporal aspect of video could fall under time-series. However, sometimes video processing is considered a separate domain. The options given are time-series, multimodal, RAG, KG. Since the paper is about video (time-based) and saliency prediction, maybe time-series is the right choice. But I'm a bit uncertain because time-series is more about numerical data over time. Alternatively, maybe it's none of them. Wait, the user said if it doesn't belong to any, respond with \"none.\" \n\nBut the title mentions \"video,\" which is a time-series of images. So maybe time-series is the correct category here. Alternatively, if the primary focus is on the saliency prediction method using diffusion models, perhaps it's not fitting into any of the four. Hmm. The four topics are time-series, multimodal, RAG, KG. Since the paper is about video (time-based) and uses a diffusion model for saliency, but the key topics listed don't include computer vision or diffusion models. So maybe it's time-series because of the video aspect. I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32785@AAAI"},
{"title": "RAGG: Retrieval-Augmented Grasp Generation Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RAGG: Retrieval-Augmented Grasp Generation Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"RAGG\" probably stands for Retrieval-Augmented Grasp Generation. The key term here is \"Retrieval-Augmented,\" which makes me think of RAG, which stands for Retrieval-Augmented Generation. RAG is a technique where a model uses retrieved information to enhance its responses, often used in NLP tasks. So the paper's title mentions \"Retrieval-Augmented,\" which directly points to RAG. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or weather. Multimodal would involve multiple data types, like text and images. KG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about time, multiple modalities, or knowledge graphs. The focus is on retrieval-augmented generation for grasp generation, which is likely in robotics or computer vision, but the key part here is the RAG component. \n\nSo the answer should be RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32786@AAAI"},
{"title": "Cycle3D: High-quality and Consistent Image-to-3D Generation via Generation-Reconstruction Cycle", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cycle3D: High-quality and Consistent Image-to-3D Generation via Generation-Reconstruction Cycle.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about generating 3D models from images, so probably not time-series.\n\nMultimodal refers to using multiple data types, like combining text and images. The paper is converting images to 3D, which is a different modality, so maybe multimodal? But I'm not sure if that's the main focus here. The key part is \"Generation-Reconstruction Cycle,\" which sounds like a process involving generating and then reconstructing, maybe using a cycle-consistency approach, like CycleGAN. But CycleGAN is typically for image-to-image translation. However, the question is about the research topic, not the method. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation, often in NLP. This paper doesn't mention retrieval, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured data representations. The paper is about 3D generation, not knowledge graphs.\n\nSo, the main question is whether this is multimodal. Image-to-3D generation involves converting one modality (image) to another (3D model), which is a form of multimodal processing. So I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32787@AAAI"},
{"title": "From Representation Space to Prognostic Insights: Whole Slide Image Generation with Hierarchical Diffusion Model for Survival Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"From Representation Space to Prognostic Insights: Whole Slide Image Generation with Hierarchical Diffusion Model for Survival Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Whole Slide Image Generation\" suggests that the work involves images, probably in a medical context since \"prognostic insights\" and \"survival prediction\" are mentioned. The term \"Hierarchical Diffusion Model\" might be a type of generative model used here. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The paper is about generating images, but there's no mention of combining multiple modalities. Unless the hierarchical model uses different data types, but the title doesn't specify that. \n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP. The title doesn't mention retrieval or combining retrieved data with generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so that's unlikely.\n\nSo the remaining possibility is none. The paper seems to focus on image generation using a diffusion model for medical prognosis, which doesn't fit into the given categories. The key elements here are image generation and survival prediction, which aren't covered by time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32788@AAAI"},
{"title": "3D²-Actor: Learning Pose-Conditioned 3D-Aware Denoiser for Realistic Gaussian Avatar Modeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"3D²-Actor: Learning Pose-Conditioned 3D-Aware Denoiser for Realistic Gaussian Avatar Modeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are \"3D²-Actor,\" \"Pose-Conditioned,\" \"3D-Aware Denoiser,\" and \"Realistic Gaussian Avatar Modeling.\" \n\nTime-series usually involves data over time, like sequences or temporal data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about 3D modeling and denoising, but I don't see any indication of combining different modalities here. It's focused on 3D data and pose conditioning, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about 3D avatars and denoising, which doesn't seem related to knowledge graphs.\n\nSo, none of the four topics seem to fit. The paper is about 3D modeling and denoising, which is more related to computer graphics or machine learning in 3D space, but not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32789@AAAI"},
{"title": "Stitch, Contrast, and Segment: Learning a Human Action Segmentation Model Using Trimmed Skeleton Videos", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Stitch, Contrast, and Segment: Learning a Human Action Segmentation Model Using Trimmed Skeleton Videos.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on human action segmentation using trimmed skeleton videos. Action segmentation is about dividing a video into segments where each segment corresponds to a specific action. Skeleton videos probably refer to using joint positions or pose data over time, which is a common approach in action recognition.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order. Since the skeleton data is a sequence of poses over time, this could be a time-series problem. The model is learning to segment actions, which involves temporal data.\n\nMultimodal would involve combining different types of data, like text and images, but the title mentions only skeleton videos, so maybe not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit.\n\nSo the most likely topic here is time-series because the model processes sequential data over time for action segmentation. The key is the temporal aspect of the skeleton data. The other topics don't align with the description given in the title.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32792@AAAI"}
{"title": "Relieving Universal Label Noise for Unsupervised Visible-Infrared Person Re-Identification by Inferring from Neighbors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Relieving Universal Label Noise for Unsupervised Visible-Infrared Person Re-Identification by Inferring from Neighbors.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main task here is \"Visible-Infrared Person Re-Identification.\" That sounds like a computer vision problem where you're trying to match a person across different images, specifically visible (like regular photos) and infrared (like thermal images). So, using two different modalities: visible and infrared. That immediately makes me think of multimodal learning because it's combining data from different sources or types. \n\nThen, the method mentioned is \"Inferring from Neighbors.\" That might relate to using neighboring data points, maybe in a graph structure where each node is connected to its neighbors. But wait, RAG (Retrieval-Augmented Generation) is more about using retrieved information to augment the generation process, typically in NLP. KG (Knowledge Graph) involves structured data and relationships between entities. Time-series is about data over time, which doesn't seem to fit here.\n\nThe problem is about label noise in an unsupervised setting. The key part here is that they're dealing with visible and infrared images, which are different modalities. So, multimodal makes sense. The other parts of the title don't seem to point to RAG, KG, or time-series. RAG is more about retrieval in generation tasks, and KG is about structured knowledge. Time-series would involve sequences over time, which isn't the case here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32791@AAAI"},
{"title": "Stitch, Contrast, and Segment: Learning a Human Action Segmentation Model Using Trimmed Skeleton Videos", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Stitch, Contrast, and Segment: Learning a Human Action Segmentation Model Using Trimmed Skeleton Videos.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on human action segmentation using trimmed skeleton videos. Action segmentation is about dividing a video into segments where each segment corresponds to a specific action. Skeleton videos probably refer to using joint positions or pose data over time, which is a common approach in action recognition.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order. Since the skeleton data is a sequence of poses over time, this could be a time-series problem. The model is learning to segment actions, which involves temporal data.\n\nMultimodal would involve combining different types of data, like text and images, but the title mentions only skeleton videos, so maybe not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit.\n\nSo the most likely topic here is time-series because the model processes sequential data over time for action segmentation. The key is the temporal aspect of the skeleton data. The other topics don't align with the description given in the title.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32792@AAAI"},
{"title": "DrivingForward: Feed-forward 3D Gaussian Splatting for Driving Scene Reconstruction from Flexible Surround-view Input", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DrivingForward: Feed-forward 3D Gaussian Splatting for Driving Scene Reconstruction from Flexible Surround-view Input.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Driving Scene Reconstruction\" suggests it's about creating 3D models of driving environments. \"Flexible Surround-view Input\" probably means using data from multiple cameras around the vehicle, like a 360-degree view. \"Feed-forward 3D Gaussian Splatting\" is a technique for rendering or reconstructing 3D scenes, maybe using Gaussian distributions to represent points in space.\n\nNow, the possible topics. Time-series usually involves data over time, like sequences. Multimodal refers to using multiple types of data (e.g., images, text, audio). RAG is Retrieval-Augmented Generation, which combines retrieval of information with generation models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper seems to be about reconstructing 3D scenes from surround-view inputs. If they're using data from multiple cameras (like different modalities—images from different angles), that might be multimodal. But \"surround-view input\" could just be multiple camera feeds, which are all visual data. So maybe it's not multimodal in the sense of combining different data types, but rather multiple inputs of the same type. \n\nTime-series would involve temporal data, but the title doesn't mention anything about time or sequences. RAG and KG are more about information retrieval and knowledge representation, which don't seem directly related to 3D scene reconstruction. \n\nSo the most likely candidate is multimodal if they are combining different types of data. But wait, the input is \"flexible surround-view,\" which might mean different camera angles but all visual. Unless they are combining other sensors like LiDAR or radar, but the title doesn't specify. The term \"multimodal\" usually refers to different modalities like text, image, audio. If it's just multiple images, maybe it's not multimodal. \n\nAlternatively, maybe the method uses different data sources. But the title doesn't mention that. The key part is \"Feed-forward 3D Gaussian Splatting,\" which is a rendering technique. So perhaps it's none of the listed topics. But I need to check again. \n\nWait, the options are time-series, multimodal, RAG, KG. If the paper is about using multiple input sources (like multiple cameras) to reconstruct a scene, that could be considered multimodal. Even if they are all visual, if they are different viewpoints, maybe that's considered multimodal in this context. But I'm not entirely sure. Alternatively, if the paper is about the technical method (Gaussian splatting) without combining different data types, it might not fit any of the four. \n\nHmm. The user wants to know if it belongs to one of these four. Since the title mentions \"surround-view input,\" which could imply multiple modalities (like different camera feeds), but I'm not certain. If the answer is none, but maybe it's multimodal. Alternatively, maybe it's none. Let me think again. \n\nMultimodal typically refers to combining different types of data (e.g., text and images). If the input is multiple images from different angles, that's more about multi-view rather than multimodal. So perhaps it's not multimodal. Then, none of the four topics apply. So the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32793@AAAI"},
{"title": "Unsupervised Self-Prior Embedding Neural Representation for Iterative Sparse-View CT Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unsupervised Self-Prior Embedding Neural Representation for Iterative Sparse-View CT Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on CT reconstruction, specifically sparse-view CT. The method mentioned is an unsupervised self-prior embedding neural representation. So, they're using a neural network approach for reconstructing CT images from sparse data, which is a common problem in medical imaging where you want to get good images with fewer X-ray projections to reduce patient exposure.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data over time. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention multiple modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This paper is about CT reconstruction, which is more about image processing and inverse problems, not about generating text with retrieved information. So RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using a knowledge graph. The focus is on neural representations for reconstruction, not on structured data or knowledge.\n\nSo none of the four topics seem to fit. The paper is about a neural network method for CT image reconstruction, which is a specific application in medical imaging. The key terms here are \"neural representation,\" \"iterative reconstruction,\" and \"sparse-view CT,\" which don't align with the given topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32794@AAAI"},
{"title": "AI-generated Image Quality Assessment in Visual Communication", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AI-generated Image Quality Assessment in Visual Communication.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title here is about image quality assessment, which is more about static images rather than sequences over time. So probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title mentions AI-generated images in visual communication. Visual communication could involve images, but the focus here is on assessing the quality of those images. It doesn't explicitly mention combining different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation processes, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's title doesn't indicate the use of a knowledge graph for organizing information or relationships between concepts. It's about assessing image quality, which is more of a computer vision task.\n\nSo, none of the four topics seem to fit. The paper is about evaluating the quality of AI-generated images, which is a computer vision or image processing task. The given options don't cover that, so the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32795@AAAI"},
{"title": "ChatterBox: Multimodal Referring and Grounding with Chain-of-Questions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ChatterBox: Multimodal Referring and Grounding with Chain-of-Questions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the word \"Multimodal\" is right there in the title. That's a big hint. Multimodal usually refers to combining multiple types of data, like text and images or audio. The paper's title mentions \"Multimodal Referring and Grounding,\" which sounds like it's about understanding references across different modalities. So that points towards the multimodal topic.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not that. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation models. The title doesn't mention retrieval or generation, so maybe not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention graphs or knowledge structures either.\n\nThe key term here is \"Multimodal,\" so the answer should be multimodal. The other parts of the title, like \"Chain-of-Questions,\" might relate to the methodology, but the main topic is clearly multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32796@AAAI"},
{"title": "Anywhere: A Multi-Agent Framework for User-Guided, Reliable, and Diverse Foreground-Conditioned Image Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Anywhere: A Multi-Agent Framework for User-Guided, Reliable, and Diverse Foreground-Conditioned Image Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts are \"Multi-Agent Framework,\" \"User-Guided,\" \"Reliable,\" \"Diverse,\" and \"Foreground-Conditioned Image Generation.\" The main focus here is on generating images, specifically conditioned on the foreground. The term \"multi-agent\" might refer to using multiple agents in the framework, but I'm not sure how that ties into the given topics.\n\nLooking at the options: time-series deals with data over time, like sequences. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about image generation, which is a type of generative model. The mention of \"foreground-conditioned\" suggests that the model uses some form of conditioning, possibly from user input or other modalities. However, the title doesn't explicitly mention combining different data modalities (like text and images), which is key for multimodal. It's focused on image generation with certain qualities (reliable, diverse), but not necessarily integrating multiple data types. \n\nRAG involves using retrieved data to inform generation, but the title doesn't mention retrieval. KG would involve using a knowledge graph structure, which isn't indicated here. Time-series is about temporal data, which isn't the case here either. \n\nSo, the closest might be multimodal if the conditioning involves multiple modalities, but the title doesn't specify that. The term \"user-guided\" could imply some interaction with text or other inputs, but without explicit mention of combining modalities, it's not a clear fit. Therefore, it might not belong to any of the listed topics. The answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32797@AAAI"},
{"title": "G-VEval: A Versatile Metric for Evaluating Image and Video Captions Using GPT-4o", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"G-VEval: A Versatile Metric for Evaluating Image and Video Captions Using GPT-4o\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus is on evaluating image and video captions. So, image and video are both visual modalities, and captions are text. That suggests combining different types of data—images/videos (visual) and text (linguistic). That sounds like multimodal because it's using multiple modalities (vision and language). \n\nThe metric is called G-VEval, and it uses GPT-4o. GPT models are typically used for text generation and understanding, but when applied to image and video captions, it's likely processing both the visual content and the text. So the evaluation here is about how well the captions (text) match the images or videos (visual), which is a classic multimodal task. \n\nTime-series usually involves data over time, like stock prices or sensor data. This doesn't seem to fit here. RAG (Retrieval-Augmented Generation) is about combining retrieval of documents with generation, which isn't mentioned here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem relevant. \n\nSo the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32798@AAAI"},
{"title": "Improving Transformer Based Line Segment Detection with Matched Predicting and Re-ranking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Improving Transformer Based Line Segment Detection with Matched Predicting and Re-ranking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on improving a Transformer-based model for line segment detection. The methods mentioned are \"Matched Predicting\" and \"Re-ranking.\" \n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequential data beyond the Transformer, which is often used in NLP but not necessarily time-series here.\n\nMultimodal would involve combining different data types, like text and images. The title talks about line segment detection, which is image-related, but there's no mention of combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on improving detection with specific techniques, not on building or using a knowledge graph. \n\nSo none of the four topics seem to fit. The paper is about improving a specific computer vision task (line segment detection) using Transformer models with new methods. Since it doesn't align with time-series, multimodal, RAG, or KG, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32799@AAAI"},
{"title": "TextToucher: Fine-Grained Text-to-Touch Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TextToucher: Fine-Grained Text-to-Touch Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-to-Touch\" suggests converting text into some form of touch data. Touch could be like haptic feedback or gestures. So maybe it's about generating touch signals based on text input. \n\nNow, the options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on generating touch from text. That seems like a task where two different modalities (text and touch) are involved. So it's probably multimodal because it's dealing with text input and generating touch output. \n\nI don't think it's time-series because there's no mention of temporal data. RAG and KG are more about using external knowledge or retrieval, which doesn't seem to be the case here. The main thing is converting one modality to another, so multimodal makes sense.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32802@AAAI"}
{"title": "Memory-Augmented Re-Completion for 3D Semantic Scene Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Memory-Augmented Re-Completion for 3D Semantic Scene Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Memory-Augmented\" suggests that there's some kind of memory component involved. \"Re-Completion\" might refer to refining or redoing a completion task. The main task here is \"3D Semantic Scene Completion,\" which is about reconstructing a 3D scene with semantic information. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like sequences. Multimodal deals with combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which uses external knowledge retrieval during generation. KG is Knowledge Graphs, which are structured representations of information.\n\nThe key term here is \"Memory-Augmented.\" RAG is a type of memory-augmented model where the model retrieves information from a database to enhance its responses. So if the paper is using a memory-augmented approach for scene completion, it might be related to RAG. However, RAG typically refers to using retrieval mechanisms in natural language processing tasks. In this case, the application is 3D scene completion, which is more about computer vision. But the term \"Memory-Augmented\" could still align with RAG if they're using retrieval methods. \n\nAlternatively, maybe it's not RAG. If the memory is part of the model's architecture, like an external memory module, it might not be RAG. RAG specifically involves retrieving from a knowledge base. Without more details, it's a bit tricky. But given the options, \"Memory-Augmented\" is a strong indicator of RAG. The other options don't fit. Time-series isn't mentioned. Multimodal would involve combining different modalities, which isn't clear here. KG is about structured knowledge, which isn't directly indicated. So the most likely answer is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32801@AAAI"},
{"title": "TextToucher: Fine-Grained Text-to-Touch Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TextToucher: Fine-Grained Text-to-Touch Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-to-Touch\" suggests converting text into some form of touch data. Touch could be like haptic feedback or gestures. So maybe it's about generating touch signals based on text input. \n\nNow, the options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on generating touch from text. That seems like a task where two different modalities (text and touch) are involved. So it's probably multimodal because it's dealing with text input and generating touch output. \n\nI don't think it's time-series because there's no mention of temporal data. RAG and KG are more about using external knowledge or retrieval, which doesn't seem to be the case here. The main thing is converting one modality to another, so multimodal makes sense.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32802@AAAI"},
{"title": "Query-centric Audio-Visual Cognition Network for Moment Retrieval, Segmentation and Step-Captioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Query-centric Audio-Visual Cognition Network for Moment Retrieval, Segmentation and Step-Captioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Audio-Visual\" suggests that the research involves both audio and visual data. That makes me think of multimodal because multimodal typically refers to combining different types of data like text, images, audio, etc. So that's a hint towards the multimodal category.\n\nThen, the tasks mentioned are moment retrieval, segmentation, and step-captions. Moment retrieval in videos usually involves finding specific time intervals based on a query. Segmentation would be dividing the video into parts, and step-captions might involve generating descriptions for each step. These tasks often require integrating different modalities, like text queries with audio-visual content. \n\nTime-series could be a possibility if the focus was on temporal data analysis, but the key here is the combination of audio and visual, which points more to multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, but the title doesn't mention anything about retrieval in the context of augmenting generation. KG (Knowledge Graphs) involve structured data and relationships, which isn't indicated here. \n\nSo putting it all together, the main elements are combining audio and visual data (multimodal) for specific tasks. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32803@AAAI"},
{"title": "Watch Video, Catch Keyword: Context-aware Keyword Attention for Moment Retrieval and Highlight Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Watch Video, Catch Keyword: Context-aware Keyword Attention for Moment Retrieval and Highlight Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. The paper's title mentions video and keywords, which might involve temporal data, but the main focus here seems to be on retrieving specific moments in a video based on keywords. That could be time-series, but maybe not the primary aspect.\n\nMultimodal refers to combining multiple data types, like text and video. The title mentions \"Watch Video\" and \"Keyword,\" which are different modalities. The task is about retrieving moments in a video using keywords, so it's likely using both visual and textual information. That points towards multimodal.\n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database and uses it to generate responses. The paper's focus is on moment retrieval and highlight detection, which is more about retrieving specific parts of a video rather than generating text based on retrieved information. So probably not RAG.\n\nKG (Knowledge Graph) involves structured data representing entities and their relationships. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it.\n\nPutting it all together, the paper is about using keywords (text) to find specific moments in a video (visual), which is a multimodal task. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32804@AAAI"},
{"title": "VOILA: Complexity-Aware Universal Segmentation of CT Images by Voxel Interacting with Language", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VOILA: Complexity-Aware Universal Segmentation of CT Images by Voxel Interacting with Language.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"VOILA\" is probably the model name. \"Complexity-Aware Universal Segmentation of CT Images\" suggests it's about medical imaging, specifically CT scans. The key part here is \"Voxel Interacting with Language.\" Voxel refers to 3D pixels in imaging, and \"interacting with language\" implies that the model uses some form of language processing. So, combining visual data (from CT images) with language. That sounds like multimodal because it's using two different modalities: visual (voxels) and textual (language). \n\nTime-series usually involves data over time, like stock prices or sensor data over time. This doesn't mention anything about time, so probably not time-series. RAG (Retrieval-Augmented Generation) is about using retrieval systems to augment generation models, often in NLP. The title doesn't mention retrieval or generation, so maybe not RAG. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem to fit here. \n\nSo the main clue is the interaction between voxels (visual) and language (textual), which is a multimodal approach. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32805@AAAI"},
{"title": "ParGo: Bridging Vision-Language with Partial and Global Views", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ParGo: Bridging Vision-Language with Partial and Global Views.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Bridging Vision-Language\" suggests that it's combining visual and language data. That immediately makes me think of multimodal learning because multimodal typically involves integrating different types of data, like images and text. \n\nThen there's \"Partial and Global Views.\" Partial might refer to parts of an image or text, and global would be the overall context. This could be about how the model processes both local and global information in the data. \n\nTime-series usually deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate answers. The title doesn't mention retrieval or generation, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG. \n\nPutting it all together, the key part is \"Vision-Language,\" which is a classic multimodal problem. The paper is likely about combining visual and textual information, which fits under multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32806@AAAI"},
{"title": "Overcoming Heterogeneous Data in Federated Medical Vision-Language Pre-training: A Triple-Embedding Model Selector Approach", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Overcoming Heterogeneous Data in Federated Medical Vision-Language Pre-training: A Triple-Embedding Model Selector Approach.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key parts are \"Federated Medical Vision-Language Pre-training\" and \"Triple-Embedding Model Selector.\" \n\nFederated learning is a method where models are trained across decentralized data sources, but that's more about the training approach rather than the data type. The main focus here is on \"Vision-Language Pre-training.\" Vision and language are two different modalities, so that suggests multimodal data. Vision would be images or visual data, and language is text. So combining these two modalities points towards multimodal research.\n\nThe problem mentioned is \"Heterogeneous Data,\" which in this context likely refers to different types of data (like images and text) being used together. The solution proposed is a \"Triple-Embedding Model Selector,\" which probably involves handling multiple embeddings from different modalities. \n\nNow, looking at the options: time-series deals with sequential data over time, which doesn't seem to be the case here. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which isn't mentioned. KG (Knowledge Graphs) involve structured data representations, which also isn't indicated here. \n\nMultimodal is about combining multiple data types, like vision and language. The title clearly mentions both vision and language, so this fits the multimodal category. The other terms like federated learning and heterogeneous data are challenges addressed, but the core topic is multimodal pre-training. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32807@AAAI"},
{"title": "RealisHuman: A Two-Stage Approach for Refining Malformed Human Parts in Generated Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RealisHuman: A Two-Stage Approach for Refining Malformed Human Parts in Generated Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This paper is about images, so probably not time-series. \n\nMultimodal refers to using multiple data types, like combining text and images. The title mentions generated images but doesn't talk about combining different modalities. It's about refining parts of images, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate a response. The paper's title doesn't mention anything about retrieval or augmenting generation with retrieved data. It's about refining images, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using knowledge graphs. \n\nSo the paper is about improving generated images by refining human parts. It's a two-stage approach, but none of the given topics seem to fit. The main focus is on image generation and refinement, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32808@AAAI"},
{"title": "FakeDiffer: Distributional Disparity Learning on Differentiated Reconstruction for Face Forgery Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FakeDiffer: Distributional Disparity Learning on Differentiated Reconstruction for Face Forgery Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on face forgery detection. The methods mentioned are \"Distributional Disparity Learning\" and \"Differentiated Reconstruction.\" I'm not super familiar with all the acronyms, but RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generative models, often in NLP. KG is Knowledge Graphs, which are structured representations of information. Time-series is about data over time, like stock prices or sensor data. Multimodal refers to using multiple types of data, like text and images together.\n\nThe paper's title doesn't mention anything about time or temporal data, so time-series is probably out. It's about face forgery, which is an image or video problem. RAG and KG don't seem relevant here either. The methods mentioned are about learning disparities in distributions and reconstruction, which sounds like it's using some kind of model to detect anomalies in images. Since it's dealing with images (face forgery), maybe multimodal? But multimodal usually refers to combining different data types. If the paper is using only images, then maybe not. However, if they're using different modalities (like combining images with other data types), then it could be multimodal. But the title doesn't specify that. The key terms here are \"distributional disparity\" and \"reconstruction,\" which might relate to generative models or autoencoders. But none of the given options are generative models. RAG is a type of model, but it's more for text. Since the options are limited, and the paper is about face forgery detection using reconstruction and distributional learning, it might not fit into any of the four categories. So the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32809@AAAI"},
{"title": "Taylor Series-Inspired Local Structure Fitting Network for Few-shot Point Cloud Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Taylor Series-Inspired Local Structure Fitting Network for Few-shot Point Cloud Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Taylor Series-Inspired\" suggests they're using a mathematical concept from Taylor series, which is a way to approximate functions. \"Local Structure Fitting Network\" might refer to a neural network that fits local structures, maybe in data. \"Few-shot Point Cloud Semantic Segmentation\" indicates the application area: point clouds (like 3D data) and semantic segmentation with few examples.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data over time. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal usually refers to combining different data types, like text and images. The paper here is about point cloud segmentation, which is a single modality (3D data), so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, common in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper seems focused on a neural network architecture for segmentation, not on building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about a novel neural network approach for point cloud segmentation using Taylor series concepts. Since the topics given don't include computer vision, neural networks, or point cloud processing, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32810@AAAI"}
{"title": "Focus on Local: Finding Reliable Discriminative Regions for Visual Place Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Focus on Local: Finding Reliable Discriminative Regions for Visual Place Recognition.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Visual Place Recognition\" sounds like it's about identifying locations using visual data, probably images or videos. The key terms here are \"local,\" \"reliable discriminative regions,\" and \"visual.\" \n\nTime-series usually involves data points indexed in time order, like stock prices over time or sensor data. This title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The title is focused on visual data specifically, so unless they're combining it with another modality, it might not be multimodal. But the title doesn't mention other modalities, so probably not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on finding regions in visual data for place recognition, which doesn't seem to involve building or using a knowledge graph.\n\nSo, the paper is about analyzing visual data to find specific regions that help in recognizing places. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32811@AAAI"},
{"title": "Explore In-Context Segmentation via Latent Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Explore In-Context Segmentation via Latent Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"In-Context Segmentation\" probably refers to segmenting something within a context, maybe images or text. \"Latent Diffusion Models\" sounds like a type of generative model, maybe related to diffusion processes in machine learning. \n\nTime-series analysis deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal research involves combining different data types, like text and images. The title doesn't specify multiple modalities, so that might not fit.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generation tasks. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data, so that's unlikely.\n\nSo, the paper is about using latent diffusion models for segmentation. Diffusion models are a type of generative model, often used in image generation. Segmentation is a computer vision task. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to diffusion models or segmentation, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32812@AAAI"},
{"title": "Geometry-Aware 3D Salient Object Detection Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Geometry-Aware 3D Salient Object Detection Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title mentions 3D and geometry, which doesn't seem time-related. So probably not time-series.\n\nMultimodal refers to using multiple data types, like combining text and images. The title is about 3D object detection, but it doesn't mention combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on a detection network with geometry awareness, not on building or using a knowledge graph. So KG probably isn't it either.\n\nThe paper is about a 3D object detection network that's geometry-aware. None of the given topics directly relate to 3D geometry or object detection. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32813@AAAI"},
{"title": "QCS:Feature Refining from Quadruplet Cross Similarity for Facial Expression Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"QCS: Feature Refining from Quadruplet Cross Similarity for Facial Expression Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about facial expression recognition, which is typically image-based. But the title doesn't mention combining different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't seem related to retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on feature refining for facial expressions, which doesn't seem to involve building or using a knowledge graph.\n\nThe paper's main contribution is about refining features using Quadruplet Cross Similarity. That sounds like a method for improving feature representations, perhaps in a machine learning model. Since none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32814@AAAI"},
{"title": "RHanDS: Refining Malformed Hands for Generated Images with Decoupled Structure and Style Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RHanDS: Refining Malformed Hands for Generated Images with Decoupled Structure and Style Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about refining hands in images, so probably not time-series.\n\nMultimodal refers to using multiple data types, like combining text and images. The paper is about generated images, but the title doesn't mention combining different modalities. It's more about improving the structure and style of hands in images, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate text based on that. The title doesn't mention anything about retrieval or augmenting generation with retrieved data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on refining image generation, not on building or using knowledge graphs. So that's probably not it either.\n\nSo the answer should be none. The paper is about image generation techniques, specifically refining hands in generated images using structure and style guidance. It doesn't fit any of the four categories listed.\n</think>\n\nnone", "url": "https://papers.cool/venue/32815@AAAI"},
{"title": "Multi-clue Consistency Learning to Bridge Gaps Between General and Oriented Object in Semi-supervised Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-clue Consistency Learning to Bridge Gaps Between General and Oriented Object in Semi-supervised Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-clue Consistency Learning\" suggests that the method uses multiple clues or features to maintain consistency. \"Bridging gaps between general and oriented object\" might refer to handling different types of objects, maybe in detection tasks. \"Semi-supervised Detection\" implies that the model uses both labeled and unlabeled data, which is common in semi-supervised learning.\n\nLooking at the options:\n\n- Time-series: Typically involves data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not this one.\n- Multimodal: Involves combining different data types (e.g., text, images, audio). The term \"multi-clue\" might hint at using multiple data sources, but \"clues\" here could be features rather than modalities. Not sure yet.\n- RAG (Retrieval-Augmented Generation): Usually related to models that retrieve information to augment generation, like in NLP. The title doesn't mention retrieval or generation, so maybe not.\n- KG (Knowledge Graph): Involves structured data and relationships. The title doesn't mention knowledge graphs or structured data, so probably not.\n\nThe paper seems to focus on object detection, specifically in a semi-supervised setting. The \"multi-clue\" part might refer to using multiple features or cues within the same modality (like images) to improve consistency. Since multimodal would require different data types (e.g., text and images), and there's no mention of that, it's less likely. The other topics don't fit either. So the answer might be \"none\" because it's about semi-supervised learning in object detection, which isn't one of the listed topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32816@AAAI"},
{"title": "RA-GAR: A Richly Annotated Benchmark for Gait Attribute Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RA-GAR: A Richly Annotated Benchmark for Gait Attribute Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Gait Attribute Recognition\" sounds like it's about analyzing how people walk, maybe using video or motion data. The term \"benchmark\" suggests it's a dataset or a standard for evaluating models. \"Richly Annotated\" probably means the dataset has detailed labels or metadata.\n\nNow, the possible topics. Time-series analysis involves data points indexed in time order, like stock prices or sensor data over time. Gait analysis could involve time-series data since walking is a temporal process. But I'm not sure if the paper is about the time-series aspect specifically.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. If the dataset includes different modalities (e.g., video and text annotations), it might be multimodal. However, the title doesn't explicitly mention multiple modalities, just \"richly annotated,\" which could be detailed labels within a single modality.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which structures information as entities and relationships. If the paper is about building a knowledge graph for gait attributes, that would fit. But the title mentions a \"benchmark,\" which is more about a dataset than a knowledge graph structure.\n\nPutting it together: The paper introduces a benchmark (dataset) for gait attribute recognition. Gait analysis often uses time-series data from sensors or video frames over time. However, the key here is whether the research topic is about the time-series aspect. Since the title doesn't specify time-series methods or analysis, but rather a benchmark for recognition, it might not fall under time-series. The \"richly annotated\" part could imply multimodal if it combines different data types, but without explicit mention, it's uncertain. RAG and KG don't seem relevant here. The most plausible is time-series if the dataset is for temporal data analysis, but the title doesn't explicitly state that. Alternatively, if the dataset is just a benchmark without focusing on the method, maybe it's none. Hmm. Wait, the question is about the research topic the paper belongs to. If the paper is about creating a benchmark for gait attribute recognition, which is a task that could involve time-series data, but the paper itself is about the benchmark, not the time-series method. So maybe it doesn't fit into any of the four topics. The four options are time-series, multimodal, RAG, KG. Since the paper is about a benchmark (dataset) for a specific task, but the task isn't one of the listed topics, the answer might be \"none.\" Alternatively, if the dataset is multimodal (e.g., combining video and text), then it's multimodal. But the title doesn't specify that. The term \"richly annotated\" could mean detailed labels, not necessarily multiple modalities. So I think the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32817@AAAI"},
{"title": "Towards Efficient Object Re-Identification with a Novel Cloud-Edge Collaborative Framework", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Efficient Object Re-Identification with a Novel Cloud-Edge Collaborative Framework.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Object re-identification is about identifying the same object across different images or videos, right? So that's typically in computer vision. The cloud-edge collaborative framework suggests a system where edge devices (like cameras) and the cloud work together to process data. The goal here is efficiency, maybe in terms of computation or latency.\n\nNow, looking at the options. Time-series usually involves data over time, like stock prices or sensor data. This paper's focus is on object re-ID, which is more about spatial data in images, so maybe not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention multiple data types, just object re-ID, which is usually image-based. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents and generating answers. The paper's title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's framework is about cloud-edge collaboration for object re-ID, which doesn't seem to involve building or using a knowledge graph. \n\nSo none of the four topics seem to fit. The paper is about a collaborative framework for object re-identification, which is a computer vision problem, possibly involving distributed computing. Since the given options don't cover this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32818@AAAI"},
{"title": "Intra and Inter Parser-Prompted Transformers for Effective Image Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Intra and Inter Parser-Prompted Transformers for Effective Image Restoration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image restoration, which is more about images, so maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper's title talks about image restoration, but does it involve multiple modalities? The term \"Parser-Prompted Transformers\" might be a method, but I'm not sure if it's combining different data types. Maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem to relate to knowledge graphs either.\n\nSo the paper is about using a specific type of transformer (Intra and Inter Parser-Prompted) for image restoration. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32819@AAAI"},
{"title": "Target-Driven Distillation: Consistency Distillation with Target Timestep Selection and Decoupled Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Target-Driven Distillation: Consistency Distillation with Target Timestep Selection and Decoupled Guidance.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Distillation\" here probably refers to knowledge distillation, a technique where a smaller model is trained using a larger, more complex model. The term \"Target-Driven\" suggests that there's a specific target involved. \"Consistency Distillation\" might mean ensuring consistency in the distillation process. \"Target Timestep Selection\" makes me think of time steps, which are common in time-series data. \"Decoupled Guidance\" could be about separating different aspects of the guidance during training.\n\nTime-series research often deals with data points indexed in time order, so if the paper is about selecting specific timesteps, that's a strong indicator. Multimodal would involve combining different data types like text and images, which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation models, which doesn't seem to fit. KG (Knowledge Graphs) involve structured data representations, which also don't appear in the title.\n\nThe mention of \"timestep\" and \"target timestep selection\" points towards time-series analysis. The methods described in the title are about distillation techniques that focus on specific time points, which is a common challenge in time-series modeling. So, the paper likely belongs to the time-series topic.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32820@AAAI"}
{"title": "ADBA: Approximation Decision Boundary Approach for Black-Box Adversarial Attacks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ADBA: Approximation Decision Boundary Approach for Black-Box Adversarial Attacks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Black-box adversarial attacks\" refers to a type of attack in machine learning where the attacker doesn't have access to the model's internal parameters, only the input and output. The method here is called ADBA, which approximates the decision boundary. Decision boundaries are concepts in machine learning that separate different classes in the feature space. \n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention different data modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model uses a retrieval system to get information before generating a response. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nSo, the paper is about adversarial attacks, specifically black-box ones, and the method involves approximating decision boundaries. None of the four topics (time-series, multimodal, RAG, KG) directly relate to adversarial attacks or decision boundary approximation. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32821@AAAI"},
{"title": "A Black-Box Evaluation Framework for Semantic Robustness in Bird’s Eye View Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Black-Box Evaluation Framework for Semantic Robustness in Bird’s Eye View Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Black-Box Evaluation Framework\" suggests they're testing a system without knowing its internal workings. \"Semantic Robustness\" probably refers to how well the system handles different semantic variations. \"Bird’s Eye View Detection\" is about detecting objects from a top-down perspective, like in autonomous vehicles or robotics.\n\nNow, the topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper's focus is on evaluating a detection system's robustness in a specific view. It doesn't mention time-based data, so time-series is out. There's no indication of combining multiple data modalities, so multimodal might not fit. RAG and KG are about data retrieval and knowledge structures, which don't seem related to the evaluation framework described. The paper is about testing a model's robustness in a specific detection task, which doesn't align with any of the four topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32822@AAAI"},
{"title": "Scene Graph-Grounded Image Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Scene Graph-Grounded Image Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Scene Graph-Grounded\" probably refers to using a scene graph as a basis. Scene graphs are structured representations of scenes, often used in computer vision to describe objects and their relationships. So that's a knowledge graph (KG) aspect because scene graphs are a type of structured data, similar to knowledge graphs. \n\nThen \"Image Generation\" suggests creating images, which is a computer vision task. But the key here is how the scene graph is used. If the paper is about generating images based on a scene graph, which is a structured representation, that might relate to knowledge graphs. \n\nLooking at the options: time-series is about data over time, which doesn't fit. Multimodal usually involves combining different data types like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation. KG is Knowledge Graphs, which aligns with scene graphs as structured data. \n\nSo the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32823@AAAI"},
{"title": "S³-Mamba: Small-Size-Sensitive Mamba for Lesion Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"S³-Mamba: Small-Size-Sensitive Mamba for Lesion Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Lesion Segmentation\" suggests it's related to medical imaging, probably using some kind of neural network for image analysis. The term \"Mamba\" might refer to a specific model or architecture. I remember that Mamba is a type of model designed for processing sequences, similar to transformers but with some differences. Wait, Mamba is actually a type of state space model, which is used for time-series data. So maybe this is related to time-series?\n\nBut the paper is about lesion segmentation, which is an image task. So how does Mamba fit in here? Maybe they're using a time-series approach for image segmentation? That seems a bit odd. Alternatively, perhaps the Mamba model is being adapted for image data. But the key part here is \"Small-Size-Sensitive,\" which might indicate that the model is optimized for handling small lesions, which are hard to detect. \n\nLooking at the four options: time-series, multimodal, RAG, KG. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships between entities.\n\nThe paper's focus is on lesion segmentation in images, which is a computer vision task. The Mamba model here is a variant for handling small lesions. Since Mamba is a state space model, which is used for time-series, but the application here is in image segmentation. However, the core model's architecture might still be related to time-series processing. But the problem domain is image segmentation, not time-series data. So does the topic belong to time-series because of the model used, or is it none because the application is image-based?\n\nWait, maybe the confusion is between the model's origin and the application. The model itself is a time-series model (Mamba), but the paper is applying it to an image task. The research topic here would be about the model's application, not the model's original domain. So if the paper is about adapting a time-series model for image segmentation, does that count as time-series research? Or is the topic determined by the problem being solved, not the model used?\n\nThe question is asking which research topic the paper belongs to. The options are time-series, multimodal, RAG, KG. Since the paper is about lesion segmentation (image task) using a modified Mamba model (originally for time-series), but the problem isn't time-series data. So the topic isn't time-series. It's about applying a certain model to an image task. None of the four options seem to fit. The paper isn't about multimodal data, RAG, or KG. So the answer would be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32824@AAAI"},
{"title": "SSC-VAE: Structured Sparse Coding Based Variational Autoencoder for Detail Preserved Image Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SSC-VAE: Structured Sparse Coding Based Variational Autoencoder for Detail Preserved Image Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components here are Variational Autoencoder (VAE), Structured Sparse Coding, and the goal is Detail Preserved Image Reconstruction. VAEs are a type of generative model used in machine learning, often for tasks like image generation or reconstruction. The mention of \"image reconstruction\" suggests that the paper is focused on generating or reconstructing images while preserving details. \n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or sensor data. This paper is about images, so time-series doesn't seem relevant here. \n\nMultimodal refers to combining multiple types of data, like text and images, or audio and video. The title doesn't mention anything about combining different data types, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method used in models like those for question-answering where they retrieve information from a database and then generate a response. The title doesn't mention anything about retrieval or generation in that context, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge, often used for semantic reasoning. The paper's focus is on image reconstruction using a VAE with structured sparse coding. There's no mention of knowledge graphs or structured knowledge representation here. \n\nSo, the paper is about a VAE model for image reconstruction with structured sparse coding. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The paper is more about generative models and image processing, which doesn't fit into any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32825@AAAI"},
{"title": "BLS-GAN: A Deep Layer Separation Framework for Eliminating Bone Overlap in Conventional Radiographs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BLS-GAN: A Deep Layer Separation Framework for Eliminating Bone Overlap in Conventional Radiographs.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. BLS-GAN probably refers to a Generative Adversarial Network (GAN) with some specific method called Deep Layer Separation. The goal is to eliminate bone overlap in radiographs, which are X-ray images. So the application is in medical imaging, specifically dealing with image processing to separate overlapping bones.\n\nNow, the possible topics: time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using external information in models. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper's focus is on image processing using a GAN to separate layers in radiographs. None of the topics directly relate to time-series data. It's not combining multiple data modalities, so not multimodal. RAG and KG are more about data retrieval and knowledge representation, which don't seem to apply here. The core is image generation/processing, which isn't listed in the options. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32826@AAAI"},
{"title": "MV-VTON: Multi-View Virtual Try-On with Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MV-VTON: Multi-View Virtual Try-On with Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View Virtual Try-On\" suggests that the research is about trying on clothes virtually from multiple views. The \"Multi-View\" part might imply using different perspectives or angles, which could involve multiple data sources or modalities. \"Diffusion Models\" refers to a type of generative model, but that's more about the method used rather than the topic category.\n\nLooking at the options: time-series deals with data over time, like stock prices or weather. That doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation, often in NLP tasks. KG (Knowledge Graphs) involve structured data and relationships. The paper's focus is on virtual try-on, which is more about generating images or videos of clothing on a person from different views. \n\n\"Multi-View\" could mean using multiple images or data types (like images and text) to generate the try-on. If it's using different modalities (e.g., images, text descriptions), then it might be multimodal. However, if it's just multiple camera angles or views of the same modality (images), it might not be multimodal. The term \"Multi-View\" in computer vision often refers to different perspectives of the same object, which is a spatial aspect rather than combining different data types. \n\nBut the key here is whether the research combines different modalities (like text and images) or just different views of the same modality. The title doesn't explicitly mention combining different data types, so maybe it's not multimodal. However, virtual try-on often involves both images of the clothing and the person, possibly with text descriptions, which could be multimodal. \n\nAlternatively, if the model uses multiple views (images) to generate the try-on, it's more about 3D or multi-view generation, which might not fall under the given categories. Since the options are time-series, multimodal, RAG, or KG, and the paper doesn't seem to involve any of those, maybe the answer is \"none.\" But wait, the user might consider \"Multi-View\" as multimodal if it's combining different data sources. However, in standard terminology, multimodal typically refers to combining different types of data (text, image, audio), not just multiple images. \n\nSo, given the options, the most plausible is \"multimodal\" if the model uses different modalities. But without more context, it's a bit ambiguous. However, the title mentions \"Multi-View,\" which is more about different perspectives rather than different modalities. Therefore, the correct answer might be \"none\" since it doesn't clearly fit any of the four categories. But I'm not entirely sure. Let me check again. The four options are time-series, multimodal, RAG, KG. The paper is about virtual try-on using diffusion models. If it's using multiple views (images) to generate the output, it's not necessarily multimodal. So the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32827@AAAI"},
{"title": "EMControl: Adding Conditional Control to Text-to-Image Diffusion Models via Expectation-Maximization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EMControl: Adding Conditional Control to Text-to-Image Diffusion Models via Expectation-Maximization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main subject is a method called EMControl, which adds conditional control to text-to-image diffusion models using the Expectation-Maximization algorithm. \n\nText-to-image models are typically multimodal because they process both text (language) and images (vision). So, multimodal usually refers to combining different types of data, like text and images. The paper is about enhancing these models with conditional control, which might involve integrating text inputs to guide image generation. That sounds like multimodal processing.\n\nTime-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which uses external information retrieval during generation. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about time, retrieval, or knowledge graphs. So the most likely topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32828@AAAI"},
{"title": "Dual Conditioned Motion Diffusion for Pose-Based Video Anomaly Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dual Conditioned Motion Diffusion for Pose-Based Video Anomaly Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Motion Diffusion\" suggests something related to modeling motion over time, maybe using diffusion models. \"Pose-Based\" implies that the input is based on pose data, which could be skeletal points or something similar. \"Video Anomaly Detection\" means the goal is to detect unusual events in videos. \n\nNow, the four options. Time-series analysis deals with data over time, which this might involve since video is a sequence of frames. But the question is whether the paper specifically focuses on time-series methods. Multimodal would involve combining different data types, like text and images, but the title mentions pose data, which is a single modality. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which doesn't seem directly related here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit.\n\nThe key part is \"Motion Diffusion.\" Diffusion models are a type of generative model, often used in time-series or sequential data. However, the paper's focus is on using motion (which is inherently time-dependent) for anomaly detection. Since video is a time-series of frames, and the method is about modeling motion over time, this might fall under time-series. But I need to check if the paper's primary contribution is about time-series analysis techniques. The term \"dual conditioned\" might refer to conditioning on two different aspects, but not necessarily multimodal. Since the main application is video (time-based) and the method involves motion (time-dependent), I think it's more aligned with time-series. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32829@AAAI"},
{"title": "M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics from Digital Pathology Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics from Digital Pathology Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order. The title mentions \"spatial transcriptomics\" and \"digital pathology images,\" which are more about spatial data rather than temporal. So probably not time-series.\n\nMultimodal refers to using multiple types of data or modalities. Here, the paper is predicting spatial transcriptomics from digital pathology images. That sounds like combining different data types—images (visual modality) and transcriptomics data (gene expression). So maybe multimodal?\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where models retrieve information from a database to enhance their responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representations. The paper's focus seems to be on regression models for prediction, not on building or using a knowledge graph. So likely not KG.\n\nPutting it all together: the paper uses digital pathology images (one modality) to predict spatial transcriptomics (another modality), which suggests a multimodal approach. The \"many-to-one regression\" part indicates combining multiple inputs into a single output, which is common in multimodal tasks. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32830@AAAI"}
{"title": "SpotActor: Training-Free Layout-Controlled Consistent Image Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SpotActor: Training-Free Layout-Controlled Consistent Image Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Training-Free\" suggests that the model doesn't require training, maybe using pre-trained models or some other method. \"Layout-Controlled\" implies that the image generation is guided by a layout, which could be a structure or arrangement of elements. \"Consistent Image Generation\" probably means generating images that maintain consistency in some aspect, maybe across different views or under certain constraints.\n\nNow, the four options. Time-series usually involves data over time, like stock prices or weather data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on generating images based on a layout without training. That doesn't seem to involve time-series data. It's about image generation, which could be multimodal if it combines different modalities, but the title doesn't mention text or other data types. \"Layout-Controlled\" might involve some structured input, but it's not a knowledge graph. RAG uses retrieval, but the title says \"training-free,\" which might not directly relate to retrieval. The key here is that the paper is about image generation controlled by a layout, which is a spatial structure. None of the four topics directly fit. Time-series is out. Multimodal would require combining different data types. RAG and KG are about retrieval and knowledge structures. Since the paper is about image generation with layout control, and none of the four topics match, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32831@AAAI"},
{"title": "RAP-SR: RestorAtion Prior Enhancement in Diffusion Models for Realistic Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RAP-SR: RestorAtion Prior Enhancement in Diffusion Models for Realistic Image Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Diffusion Models\" are a type of generative model, often used in image generation or restoration. \"Image Super-Resolution\" refers to enhancing the resolution of images, which is an image processing task. The term \"Restoration Prior Enhancement\" suggests they're improving some prior knowledge in the model for better image restoration.\n\nLooking at the options: time-series deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about enhancing diffusion models for image super-resolution. None of the topics directly relate to time-series data. It's focused on image processing, which isn't multimodal unless combining different modalities, but the title doesn't mention that. RAG and KG are more about knowledge retrieval or structured data, which don't seem to be the focus here. The paper is about improving a model's prior for image restoration, which doesn't fit RAG or KG. So the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32832@AAAI"},
{"title": "FaceA-Net: Facial Attribute-Driven ID Preserving Image Generation Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FaceA-Net: Facial Attribute-Driven ID Preserving Image Generation Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about facial attributes and image generation, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about generating images based on facial attributes, which might involve different modalities. But the key here is whether it's combining different data types. The title mentions \"Facial Attribute-Driven,\" which could be attributes like age, gender, etc., but if those attributes are part of the input to generate images, maybe it's using different modalities (text attributes and images). However, I'm not sure if that's considered multimodal. Sometimes, multimodal is more about integrating different sensory data, like text and vision together. But in this case, the network is generating images based on attributes, which might be text or numerical data. So maybe it's multimodal if it's combining text attributes with image generation.\n\nRAG stands for Retrieval-Augmented Generation. That's typically when a model uses a retrieval component to fetch relevant information and then generates text based on that. The title doesn't mention anything about retrieval, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data, so likely not KG.\n\nSo the options are between multimodal and none. If the paper uses facial attributes (which could be text or numerical) along with image data to generate images, that might be multimodal. But if the attributes are just parameters for the image generation without combining different data types, maybe it's not. However, \"attribute-driven\" could imply that the model takes in attributes (like text labels) and generates images, which would be a multimodal approach since it's combining text (attributes) with image generation. So I think it's multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32833@AAAI"},
{"title": "MM-Mixing: Multi-Modal Mixing Alignment for 3D Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MM-Mixing: Multi-Modal Mixing Alignment for 3D Understanding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That immediately makes me think of the \"multimodal\" category. The term \"multi-modal\" refers to combining different types of data, like text, images, audio, etc. The paper is about mixing alignment for 3D understanding, which probably involves integrating different modalities to better understand 3D data. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't reference knowledge graphs. \n\nSo the key term here is \"Multi-Modal,\" which directly points to the multimodal topic. The rest of the title supports that by talking about mixing alignment for 3D understanding, which is a specific application of multimodal data integration. Therefore, the correct category should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32834@AAAI"},
{"title": "OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and Open-World Unknown Objects Supervision", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and Open-World Unknown Objects Supervision.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Open-Vocabulary DETR\" suggests that it's related to object detection, maybe using a DETR model, which is a transformer-based model for detection. \"Denoising Text Query Training\" makes me think of using text queries, which could be part of a multimodal approach since it's combining text (language) with vision. \"Open-World Unknown Objects Supervision\" might relate to handling unknown classes, which is a common challenge in open-vocabulary tasks.\n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem to fit here. RAG (Retrieval-Augmented Generation) is typically for models that retrieve information from a database to generate answers, often in NLP. KG (Knowledge Graphs) involve structured data and relationships between entities. \n\nMultimodal, on the other hand, involves combining different modalities like text and images. The mention of \"text query training\" and \"open-vocabulary\" suggests that the model is integrating text (language) with visual data (object detection), which is a classic multimodal setup. The use of text queries to guide the detection process would require aligning different modalities, so this seems like a multimodal approach. \n\nI don't see any direct references to knowledge graphs or retrieval-augmented generation here. The focus is on training a detector with text queries, which is more about combining vision and language. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32836@AAAI"},
{"title": "InpDiffusion: Image Inpainting Localization via Conditional Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"InpDiffusion: Image Inpainting Localization via Conditional Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Image inpainting is about filling in missing parts of an image. Localization here probably refers to identifying where the missing parts are. Conditional diffusion models are a type of generative model used in image generation, right? So the paper is using these models for image inpainting with a focus on localization.\n\nNow, the possible topics. Time-series deals with data over time, like stock prices or weather. This paper is about images, so probably not time-series. Multimodal would involve combining different types of data, like text and images. The title doesn't mention anything about combining different data types, just image inpainting. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation, often in text. KG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or retrieval. \n\nSo, the paper is focused on image inpainting using diffusion models. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The main techniques here are diffusion models and image processing, which don't fall under the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32837@AAAI"},
{"title": "Alignment-Free RGB-T Salient Object Detection: A Large-Scale Dataset and Progressive Correlation Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Alignment-Free RGB-T Salient Object Detection: A Large-Scale Dataset and Progressive Correlation Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"RGB-T\" probably refers to combining RGB (visible light) and thermal (T) images. So that's two different modalities. Salient object detection is about identifying the most noticeable objects in an image. The term \"Alignment-Free\" might mean they don't need to align the two modalities, which is a common step in multimodal tasks. The dataset is large-scale, which is common in multimodal research because you need a lot of data to train models on different modalities. The Progressive Correlation Network sounds like a method to process these two modalities together, maybe finding correlations between them without alignment.\n\nTime-series is about data over time, like stock prices or sensor data. This doesn't seem to fit because the title is about images, not sequences over time. RAG (Retrieval-Augmented Generation) is more about using external knowledge in generation tasks, like in question-answering. KG (Knowledge Graph) involves structured data and relationships between entities. Neither of those seem relevant here. \n\nMultimodal research deals with combining different types of data, like images and text, or in this case, RGB and thermal images. The paper introduces a dataset and a network for this specific multimodal task. So the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32838@AAAI"},
{"title": "Tracking Everything Everywhere across Multiple Cameras", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Tracking Everything Everywhere across Multiple Cameras.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or sensor data. The title mentions tracking across multiple cameras, which might involve temporal data, but tracking itself is more about spatial and temporal analysis. However, time-series is a possible fit if the focus is on the sequence over time.\n\nMultimodal refers to combining different types of data, like text, images, audio. The title talks about multiple cameras, which are all visual data. Unless they're integrating other modalities, it might not be multimodal. But if it's just multiple cameras, maybe it's not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data and relationships. The title doesn't indicate building or using a knowledge graph, so likely not KG.\n\nSo, the main options are time-series or multimodal. Since the tracking is across multiple cameras, which could be considered different data sources (modalities), but all are visual. However, multimodal typically requires different types of data. If the paper is about integrating data from multiple cameras (same modality), it's not multimodal. But if it's about tracking over time, then time-series. Tracking across multiple cameras would involve temporal data as well as spatial, so maybe time-series. But I'm a bit confused. Let me think again. Tracking in multiple cameras is more about multi-camera tracking, which is a computer vision task. Time-series could be part of it, but the primary focus might be on the spatial aspects. However, the options given are time-series, multimodal, RAG, KG. Since the paper is about tracking across multiple cameras, which could involve temporal sequences (tracking over time), so time-series. Alternatively, if it's about combining data from different cameras (different sources), maybe multimodal. But multimodal usually implies different types of data. Since all cameras are visual, it's not multimodal. Therefore, the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32839@AAAI"},
{"title": "Debiased Distillation for Consistency Regularization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Debiased Distillation for Consistency Regularization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Debiased Distillation\" sounds like a method to reduce bias in some kind of model training. \"Consistency Regularization\" is a technique used in machine learning, especially in semi-supervised learning, where the model is encouraged to produce consistent predictions for different transformations of the same input. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather. Multimodal deals with combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title doesn't mention anything about time, different data modalities, retrieval, or knowledge graphs. It's more about a training method (distillation) and a regularization technique (consistency). So it doesn't fit into any of the four categories listed. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32840@AAAI"},
{"title": "VLScene: Vision-Language Guidance Distillation for Camera-Based 3D Semantic Scene Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VLScene: Vision-Language Guidance Distillation for Camera-Based 3D Semantic Scene Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language\" suggests combining visual and language data, which is a classic multimodal setup. \"Guidance Distillation\" might refer to a method where knowledge is transferred from a model that uses both modalities. \"Camera-Based 3D Semantic Scene Completion\" implies using camera inputs (visual) to complete 3D scenes with semantic information. \n\nTime-series usually involves data over time, like sequences. This title doesn't mention anything about time or sequences, so probably not time-series. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, often in NLP. The title doesn't mention retrieval or generation in that context. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem to fit here. \n\nSo the key terms are Vision-Language, which are two different modalities. That points to multimodal. The task is about scene completion using both visual and language guidance, which is a multimodal approach. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32841@AAAI"}
{"title": "VLScene: Vision-Language Guidance Distillation for Camera-Based 3D Semantic Scene Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VLScene: Vision-Language Guidance Distillation for Camera-Based 3D Semantic Scene Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language\" suggests combining visual and language data, which is a classic multimodal setup. \"Guidance Distillation\" might refer to a method where knowledge is transferred from a model that uses both modalities. \"Camera-Based 3D Semantic Scene Completion\" implies using camera inputs (visual) to complete 3D scenes with semantic information. \n\nTime-series usually involves data over time, like sequences. This title doesn't mention anything about time or sequences, so probably not time-series. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, often in NLP. The title doesn't mention retrieval or generation in that context. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem to fit here. \n\nSo the key terms are Vision-Language, which are two different modalities. That points to multimodal. The task is about scene completion using both visual and language guidance, which is a multimodal approach. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32841@AAAI"},
{"title": "Bright-NeRF: Brightening Neural Radiance Field with Color Restoration from Low-Light RAW Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bright-NeRF: Brightening Neural Radiance Field with Color Restoration from Low-Light RAW Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. \"Neural Radiance Field\" (NeRF) is a concept in computer vision, typically used for 3D scene reconstruction from 2D images. The paper is about enhancing NeRF by brightening low-light RAW images and restoring color. \n\nNow, looking at the topics. Time-series usually involves data over time, like stock prices or sensor data. This doesn't seem to fit because the focus is on image processing, not sequential data over time.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about improving image quality, but there's no mention of integrating different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. This paper is about image restoration, not text generation or retrieval, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo, the paper is about image processing techniques for NeRF, specifically color restoration in low-light conditions. None of the given topics (time-series, multimodal, RAG, KG) directly apply here. The main focus is on computer vision and image enhancement, which isn't covered by the listed options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32842@AAAI"},
{"title": "Thinking in Granularity: Dynamic Quantization for Image Super-Resolution by Intriguing Multi-Granularity Clues", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Thinking in Granularity: Dynamic Quantization for Image Super-Resolution by Intriguing Multi-Granularity Clues.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on image super-resolution, which is about enhancing the resolution of images. The key terms here are \"Dynamic Quantization\" and \"Multi-Granularity Clues.\" \n\nTime-series usually involves data points indexed in time order, like stock prices over time. This paper is about images, so time-series might not fit. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention combining different modalities, just image processing. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to aid in generating responses. The title doesn't mention anything about retrieval or generation, so RAG might not be relevant here.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nThe paper is about image super-resolution using dynamic quantization and multi-granularity clues. These terms relate to image processing techniques, which don't fall under the four listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32843@AAAI"},
{"title": "Deep Multi-modal Graph Clustering via Graph Transformer Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Deep Multi-modal Graph Clustering via Graph Transformer Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Deep Multi-modal\" suggests that the research involves multiple modalities, like combining different types of data (e.g., text, images, audio). So \"multimodal\" is a possible candidate. \n\nThen \"Graph Clustering\" implies that the work is about grouping data using graph structures. Graphs here could be related to knowledge graphs (KG), which are structured representations of information. But the term \"Graph Clustering\" might not necessarily be about knowledge graphs. It could just be about graph structures in general, like social networks or other graph-based data.\n\nThe method mentioned is \"Graph Transformer Network.\" Transformers are a type of neural network architecture, and combining them with graphs might relate to graph neural networks. However, RAG (Retrieval-Augmented Generation) is a specific technique that uses retrieval from a knowledge base to augment generation models, which doesn't seem directly related here.\n\nSo, \"multi-modal\" is definitely part of the title. The \"Graph\" part could be related to knowledge graphs (KG), but the clustering aspect might not be. However, the presence of \"multi-modal\" is a strong indicator. The other options: time-series is about sequential data over time, which isn't mentioned here. RAG is about retrieval and generation, which isn't the focus. So the most likely answer is \"multimodal.\"\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32844@AAAI"},
{"title": "Meme Trojan: Backdoor Attacks Against Hateful Meme Detection via Cross-Modal Triggers", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Meme Trojan: Backdoor Attacks Against Hateful Meme Detection via Cross-Modal Triggers.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Meme Trojan\" suggests some kind of attack method. \"Backdoor Attacks\" implies that they're introducing a hidden trigger to manipulate the model's behavior. \"Hateful Meme Detection\" is the target here, so the paper is about attacking systems that detect harmful memes. \n\nNow, the key part is \"Cross-Modal Triggers.\" The term \"cross-modal\" usually refers to combining different types of data, like text and images. Since memes typically combine both visual elements and text, this makes sense. So, the attack uses triggers that span multiple modalities. \n\nLooking at the options: time-series deals with data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which involves using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge. None of these seem to fit the cross-modal aspect. \n\nMultimodal, on the other hand, directly relates to handling multiple data types (like text and images) together. The paper's focus on cross-modal triggers in the context of meme detection (which is inherently multimodal) points to the multimodal topic. \n\nSo, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32845@AAAI"},
{"title": "The Parables of the Mustard Seed and the Yeast: Extremely Low-Budget, High-Performance Nighttime Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"The Parables of the Mustard Seed and the Yeast: Extremely Low-Budget, High-Performance Nighttime Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The first part mentions \"Parables of the Mustard Seed and the Yeast,\" which sounds like a metaphor, maybe from the Bible. But the main part is about \"Nighttime Semantic Segmentation\" with \"Extremely Low-Budget, High-Performance.\" So the focus is on a computer vision task—semantic segmentation, specifically at night, and they're doing it with a low budget but high performance.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks, common in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about semantic segmentation, which is an image processing task. The mention of \"nighttime\" might imply dealing with low-light conditions, but that's more about the domain rather than the method. The key here is whether the method uses any of the four topics. The title doesn't mention anything about time-series data, combining multiple modalities, retrieval-augmented generation, or knowledge graphs. It's focused on optimizing performance under budget constraints, which might relate to model efficiency or lightweight models, but those aren't the listed topics. So none of the four topics seem to fit. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32846@AAAI"},
{"title": "GFlow: Recovering 4D World from Monocular Video", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GFlow: Recovering 4D World from Monocular Video.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Monocular video\" suggests using a single camera feed, which is a type of visual data. \"Recovering 4D World\" probably refers to reconstructing a 3D environment over time, which adds the fourth dimension (time). So, 4D here likely means 3D space plus time. \n\nNow, the task is to determine the research topic. Time-series analysis deals with data points indexed in time order. Since the video is a sequence of frames over time, this could be related to time-series. But the main focus here is on reconstructing a 4D world, which involves spatial and temporal data. However, time-series is more about analyzing sequences, not necessarily reconstructing spatial structures. \n\nMultimodal refers to using multiple types of data (like text, images, audio). The title mentions monocular video, which is a single modality (visual), so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval of information with generation, often in NLP contexts. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't indicate building or using a knowledge graph, so that's unlikely. \n\nSo, the closest might be time-series, but I'm not entirely sure. The 4D aspect includes time, so maybe it's time-series. However, the primary focus is on reconstructing a 4D world from video, which is more about computer vision and 3D reconstruction. Since the options are limited to the four given, and time-series is the only one that involves temporal data, maybe it's time-series. But I'm a bit uncertain because the main task isn't just analyzing a time series but reconstructing a dynamic 3D scene. However, given the options, time-series might be the best fit here. Alternatively, if none of the options fit, the answer would be \"none.\" But I need to check again. \n\nWait, the problem says if it doesn't belong to any of these topics, respond with \"none.\" So, if the paper is about 4D reconstruction from monocular video, which is a computer vision task, and none of the four topics (time-series, multimodal, RAG, KG) directly apply, then the answer would be \"none.\" But maybe time-series is considered here because of the temporal aspect. However, time-series analysis is more about statistical analysis of time-ordered data, not necessarily 3D reconstruction. So perhaps \"none\" is the correct answer here.\n</think>\n\nnone", "url": "https://papers.cool/venue/32847@AAAI"},
{"title": "Autoregressive Sequence Modeling for 3D Medical Image Representation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Autoregressive Sequence Modeling for 3D Medical Image Representation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, autoregressive models are typically used in time-series data because they predict the next element based on previous ones. But the title mentions 3D medical images. Wait, 3D images could be a sequence in some way, like slices over time or spatial dimensions. But autoregressive models in images might be more about generating images pixel by pixel, which is a spatial sequence. However, time-series usually refers to temporal sequences. \n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention combining different modalities, just 3D images. RAG stands for Retrieval-Augmented Generation, which is more about using external information during generation, often in NLP. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about knowledge graphs or retrieval. \n\nSo, the key here is autoregressive sequence modeling. If the 3D images are being modeled as a sequence, maybe in a way that's autoregressive, but not necessarily time-based. However, the primary topics listed are time-series, multimodal, RAG, KG. Since the model is autoregressive and sequence-based, but applied to 3D images, which isn't time-series in the traditional sense. But maybe the paper is using autoregressive methods for spatial sequences. However, the given options don't include spatial sequence modeling. The closest might be time-series, but I'm not sure. Alternatively, maybe it's none of the listed topics. Wait, the options are time-series, multimodal, RAG, KG. Since the paper is about autoregressive models for 3D images, which isn't time-series (unless the 3D images are temporal), but the title doesn't specify that. So perhaps it's none. But I need to check again. Autoregressive models are a type of model, but the topics here are research areas. The paper's topic isn't directly listed. So the answer would be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32848@AAAI"},
{"title": "CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. CAD-GPT probably refers to a model related to Computer-Aided Design. The key parts here are \"Synthesising CAD Construction Sequence\" and \"Spatial Reasoning-Enhanced Multimodal LLMs.\" \n\n\"Multimodal LLMs\" directly mentions multimodal, which is one of the options. The term \"multimodal\" in machine learning typically refers to models that process multiple types of data, like text and images. Since the title explicitly states \"Multimodal LLMs,\" that's a strong indicator. \n\nNow, checking the other options. Time-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences in that context, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where models retrieve information from a database to enhance their responses. The title doesn't mention retrieval or augmentation, so RAG is unlikely. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't reference knowledge graphs either. \n\nSo, the main clue here is the \"Multimodal LLMs\" part. The paper is about using multimodal models enhanced with spatial reasoning for CAD sequences. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32849@AAAI"},
{"title": "Imagine: Image-Guided 3D Part Assembly with Structure Knowledge Graph", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Imagine: Image-Guided 3D Part Assembly with Structure Knowledge Graph.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Image-Guided\" suggests that images are involved. \"3D Part Assembly\" implies some kind of spatial or structural arrangement. Then \"Structure Knowledge Graph\" is right there. The term \"Knowledge Graph\" (KG) is one of the options. So that's a strong indicator. \n\nBut wait, could it be multimodal? Because it uses images and maybe other data types. Multimodal usually refers to combining different types of data like text, images, audio, etc. The title mentions image-guided, so maybe it's using images along with another modality. However, the key part here is \"Structure Knowledge Graph.\" The presence of \"Knowledge Graph\" in the title is pretty explicit. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval to augment generation models, which doesn't seem to be mentioned here. Time-series is about data over time, which isn't indicated in the title. \n\nSo the main clue is \"Structure Knowledge Graph.\" Even though there's an image component, the explicit mention of Knowledge Graph points to KG as the topic. The other elements like 3D assembly might be part of the application, but the core research topic here is the use of a knowledge graph. Therefore, the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32850@AAAI"}
{"title": "MVReward: Better Aligning and Evaluating Multi-View Diffusion Models with Human Preferences", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MVReward: Better Aligning and Evaluating Multi-View Diffusion Models with Human Preferences.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-View Diffusion Models\" suggests that the model uses multiple views or perspectives. The term \"multi-view\" might relate to multimodal, which involves combining different types of data like text, images, etc. But wait, \"multi-view\" could also mean different angles or representations of the same data, not necessarily different modalities. \n\nThen there's \"Human Preferences\" which is about aligning the model's outputs with what humans prefer. That part might relate to reward modeling or reinforcement learning, but RAG (Retrieval-Augmented Generation) is more about using external knowledge during generation. \n\nThe main focus here seems to be on aligning and evaluating diffusion models using multiple views and human feedback. Diffusion models are typically used in image generation, but the multi-view aspect could imply using different data sources or modalities. However, the key term here is \"multi-view,\" which might not be the same as multimodal. Multimodal usually refers to combining different types of data (like text and images), whereas multi-view could be different perspectives of the same modality, like multiple images of an object from different angles. \n\nRAG and KG (Knowledge Graphs) don't seem to be mentioned here. The paper isn't about retrieving information from a knowledge base or using a graph structure. Time-series is also not indicated. \n\nSo, the closest fit might be multimodal if \"multi-view\" is considered a form of multimodal data. But I'm not entirely sure. Alternatively, if \"multi-view\" refers to different data sources or modalities, then multimodal would be correct. If it's just different views within the same modality, maybe it's not. However, given the options, \"multimodal\" is the most likely answer here.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32851@AAAI"},
{"title": "Divide, Conquer and Combine: A Training-Free Framework for High-Resolution Image Perception in Multimodal Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Divide, Conquer and Combine: A Training-Free Framework for High-Resolution Image Perception in Multimodal Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Multimodal Large Language Models.\" The word \"multimodal\" is right there. That's one of the options. So that's a strong indicator. The paper is about combining different modalities, probably text and images, given the mention of \"High-Resolution Image Perception.\" \n\nThe other parts of the title talk about a training-free framework, which might relate to methods like RAG (Retrieval-Augmented Generation) since RAG often uses retrieval without training. But wait, RAG is more about using external knowledge during inference, whereas this paper is about a framework for image perception in multimodal models. The key term here is \"multimodal,\" which directly matches one of the options. \n\nTime-series is about data over time, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which isn't mentioned. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32852@AAAI"},
{"title": "FreeGen: Bridging Visual-Linguistic Discrepancies Towards Diffusion-based Pixel-level Data Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FreeGen: Bridging Visual-Linguistic Discrepancies Towards Diffusion-based Pixel-level Data Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual-Linguistic Discrepancies\" suggests that the paper deals with both visual (like images) and linguistic (text) data. That makes me think of multimodal, since multimodal research often combines different types of data, such as text and images. \n\nThen, \"Diffusion-based Pixel-level Data Synthesis\" refers to generating images (pixel-level) using diffusion models. Diffusion models are a type of generative model, but the key here is the combination of visual and linguistic aspects. \n\nTime-series is about data over time, like stock prices or weather data. That doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation, often in NLP. KG (Knowledge Graph) involves structured data and relationships. Neither of those seem to fit the title's focus on visual and linguistic data synthesis. \n\nSo, the main clue is \"Visual-Linguistic,\" which points to multimodal. The paper is likely about integrating vision and language, which is a classic multimodal problem. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32853@AAAI"},
{"title": "DCTMamba: Advancing JPEG Image Restoration Through Long-Sequence Modeling and Adaptive Frequency Strategy", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DCTMamba: Advancing JPEG Image Restoration Through Long-Sequence Modeling and Adaptive Frequency Strategy.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title mentions JPEG image restoration, which is about images, not time-based data. So probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about image restoration, but does it use multiple modalities? The title doesn't mention anything else like text or audio, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to aid in generating responses. The paper is about image restoration using JPEG, which is a different domain. Doesn't seem related to RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on image processing techniques, not on building or using knowledge graphs. So probably not KG.\n\nThe paper uses \"Long-Sequence Modeling\" and \"Adaptive Frequency Strategy.\" Long-sequence modeling might relate to handling sequences, but in the context of images, maybe they're processing image data as sequences. However, the main focus here is on JPEG restoration, which is image processing. None of the given topics (time-series, multimodal, RAG, KG) directly fit. The techniques mentioned don't align with any of the four categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32854@AAAI"},
{"title": "TokenMatcher: Diverse Tokens Matching for Unsupervised Visible-Infrared Person Re-Identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TokenMatcher: Diverse Tokens Matching for Unsupervised Visible-Infrared Person Re-Identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Visible-Infrared Person Re-Identification\" suggests that the research is about identifying people using both visible and infrared images. That immediately makes me think of multimodal data because it's combining two different types of data (visible and infrared). Multimodal usually refers to using multiple types of data, like images and text, or in this case, different imaging modalities.\n\nThe method mentioned is \"TokenMatcher\" with \"Diverse Tokens Matching.\" The term \"tokens\" might relate to something like tokenization in NLP, but in the context of person re-identification, it could be about matching features or representations. However, the key part here is the combination of visible and infrared data, which is a classic example of multimodal learning. The paper is probably trying to align or match features from these two different modalities without supervision.\n\nNow, checking the other options. Time-series would involve data over time, like sequences or temporal data. The title doesn't mention anything about time, so that's probably not it. RAG (Retrieval-Augmented Generation) is more about using retrieval mechanisms in generative models, which doesn't seem to fit here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't align with the problem described. \n\nSo, the most likely topic here is multimodal because it's dealing with integrating and matching data from two different modalities (visible and infrared) for person re-identification. The unsupervised aspect might relate to how they handle the matching without labeled data, but the core of the problem is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32855@AAAI"},
{"title": "CNC: Cross-modal Normality Constraint for Unsupervised Multi-class Anomaly Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CNC: Cross-modal Normality Constraint for Unsupervised Multi-class Anomaly Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-modal\" immediately makes me think of multimodal, since cross-modal usually refers to combining different types of data, like text and images. The term \"normality constraint\" might relate to how the model ensures normal patterns across these modalities. The goal is unsupervised anomaly detection, which is a common task in multimodal settings where you want to detect anomalies by leveraging multiple data sources.\n\nTime-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generation tasks, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also isn't mentioned. \n\nSo the key term here is \"cross-modal,\" which directly points to multimodal. The method is using constraints across different modalities for anomaly detection. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32856@AAAI"},
{"title": "HomoMatcher: Achieving Dense Feature Matching with Semi-Dense Efficiency by Homography Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HomoMatcher: Achieving Dense Feature Matching with Semi-Dense Efficiency by Homography Estimation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Dense feature matching\" sounds like it's about matching features in images, maybe in computer vision. Homography estimation is a technique used in image processing to find the transformation between two planes. So this paper is probably about improving feature matching using homography, making it more efficient.\n\nNow, the options. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in NLP for models that retrieve information to enhance their responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on feature matching in images using homography. None of the topics directly relate to time-series data. It's not combining different modalities, so not multimodal. RAG and KG are more about data retrieval and knowledge representation, which don't seem to connect here. The paper is about a specific computer vision technique, which doesn't fit into any of the four listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32857@AAAI"},
{"title": "From 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"From 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time, so probably not time-series.\n\nNext, multimodal. That refers to using multiple types of data, like combining text and images. The title mentions \"Vision-Language Approach,\" which sounds like combining visual data (CAD drawings) with language. So that's a strong indicator for multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about converting 2D to 3D models, which doesn't seem to involve building or using a knowledge graph. \n\nSo the most likely answer is multimodal because it's using both vision (CAD drawings) and language in the approach.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32858@AAAI"},
{"title": "MIMTrack: In-Context Tracking via Masked Image Modeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MIMTrack: In-Context Tracking via Masked Image Modeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"MIMTrack\" probably refers to the method or model. \"In-Context Tracking\" suggests that it's about tracking something within a context, maybe in images or videos. \"Masked Image Modeling\" makes me think of techniques like those used in vision transformers, where parts of the image are masked and the model has to predict them. That's similar to how BERT works with masked language modeling but for images.\n\nNow, the topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually combines different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses a retriever to get information and a generator to produce answers. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on image modeling with masking, which is a technique used in vision models. Tracking in this context might be about tracking objects in images or videos. But the key part here is \"Masked Image Modeling,\" which is a method, not necessarily tied to any of the four topics listed. The topics given are more about the application or structure of the model rather than the specific technique. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to masked image modeling or in-context tracking as described, the answer might be \"none.\" Unless there's an overlap I'm missing. For example, if multimodal involves combining different modalities, but the title doesn't mention combining text and images. It's focused on image modeling. So I think it's \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32860@AAAI"},
{"title": "TIV-Diffusion: Towards Object-Centric Movement for Text-driven Image to Video Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TIV-Diffusion: Towards Object-Centric Movement for Text-driven Image to Video Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-driven Image to Video Generation\" suggests that the input is text and the output is a video. So, the model takes text and generates a video. That sounds like a multimodal task because it's combining text (language) and video (visual) data. Multimodal typically involves integrating different types of data, like text and images or text and audio. \n\nThe other parts of the title mention \"Object-Centric Movement,\" which might relate to how objects move in the video, but that's more about the method or the focus of the research rather than the type of data. The term \"Diffusion\" here likely refers to a diffusion model, which is a type of generative model used in image and video generation. \n\nNow, checking the options. Time-series usually involves data points indexed in time order, like stock prices over time. This paper is about generating video from text, which is a sequence of images, so maybe time-series? But the main aspect here is the combination of text and video, which is multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in text-based models. KG (Knowledge Graph) involves structured data representations. The title doesn't mention anything about retrieval or knowledge graphs, so those can be ruled out. \n\nSo, the key factors are text and video, which are different modalities. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32861@AAAI"}
{"title": "TIV-Diffusion: Towards Object-Centric Movement for Text-driven Image to Video Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TIV-Diffusion: Towards Object-Centric Movement for Text-driven Image to Video Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-driven Image to Video Generation\" suggests that the input is text and the output is a video. So, the model takes text and generates a video. That sounds like a multimodal task because it's combining text (language) and video (visual) data. Multimodal typically involves integrating different types of data, like text and images or text and audio. \n\nThe other parts of the title mention \"Object-Centric Movement,\" which might relate to how objects move in the video, but that's more about the method or the focus of the research rather than the type of data. The term \"Diffusion\" here likely refers to a diffusion model, which is a type of generative model used in image and video generation. \n\nNow, checking the options. Time-series usually involves data points indexed in time order, like stock prices over time. This paper is about generating video from text, which is a sequence of images, so maybe time-series? But the main aspect here is the combination of text and video, which is multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in text-based models. KG (Knowledge Graph) involves structured data representations. The title doesn't mention anything about retrieval or knowledge graphs, so those can be ruled out. \n\nSo, the key factors are text and video, which are different modalities. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32861@AAAI"},
{"title": "Dehaze-RetinexGAN: Real-World Image Dehazing via Retinex-based Generative Adversarial Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dehaze-RetinexGAN: Real-World Image Dehazing via Retinex-based Generative Adversarial Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about image dehazing, which is image processing, so probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The paper here seems focused on images, specifically dehazing them. So maybe not multimodal unless they're using multiple modalities, but the title doesn't mention that.\n\nRAG stands for Retrieval-Augmented Generation. That's typically in NLP, where a model retrieves information from a database to enhance its responses. The title mentions a Generative Adversarial Network (GAN), which is a type of generative model. But RAG is more about combining retrieval with generation, not necessarily GANs. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data, so probably not KG.\n\nThe key part here is \"Retinex-based Generative Adversarial Network.\" Retinex is a theory related to human vision and image processing. GANs are generative models used for tasks like image generation or enhancement. The paper is about using a GAN for image dehazing. None of the four topics (time-series, multimodal, RAG, KG) directly relate to GANs used for image processing. So the answer might be \"none.\"\n\nWait, but RAG is a type of model architecture? Or is RAG specifically Retrieval-Augmented Generation? The user listed RAG as one of the options. Since the paper uses a GAN, which is a generative model, but RAG is a specific type of model that combines retrieval and generation. The title doesn't mention retrieval, so it's not RAG. Therefore, the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32862@AAAI"},
{"title": "AugRefer: Advancing 3D Visual Grounding via Cross-Modal Augmentation and Spatial Relation-based Referring", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AugRefer: Advancing 3D Visual Grounding via Cross-Modal Augmentation and Spatial Relation-based Referring.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"3D Visual Grounding\" suggests it's about understanding or locating objects in 3D space using visual data. \"Cross-Modal Augmentation\" implies combining different types of data, like text and images, which points towards multimodal approaches. \"Spatial Relation-based Referring\" might involve how objects relate spatially, which could be part of multimodal processing as well.\n\nTime-series usually involves data over time, like stock prices or weather data. This doesn't seem to fit here. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation tasks, often in NLP. The title doesn't mention retrieval or generation. KG (Knowledge Graphs) involve structured data and relationships between entities, but the title focuses more on visual and spatial aspects rather than structured knowledge.\n\nSo, the key terms here are \"cross-modal,\" which directly relates to multimodal research. The paper is likely combining different modalities (like vision and language) for 3D grounding. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32863@AAAI"},
{"title": "GCD: Advancing Vision-Language Models for Incremental Object Detection via Global Alignment and Correspondence Distillation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GCD: Advancing Vision-Language Models for Incremental Object Detection via Global Alignment and Correspondence Distillation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language Models\" immediately makes me think of multimodal learning because it combines visual (images) and language (text) data. So that's a hint towards the multimodal category. \n\nIncremental object detection suggests that the model is being updated or improved over time with new data, but I'm not sure if that's directly related to any of the four topics. The methods mentioned are Global Alignment and Correspondence Distillation. Global alignment might refer to aligning different modalities (like images and text), which again points to multimodal. Correspondence distillation could be about transferring knowledge between models, but I don't think that's RAG (Retrieval-Augmented Generation) or KG (Knowledge Graphs). \n\nRAG involves using external knowledge retrieval during generation, which isn't mentioned here. KG would involve structured knowledge bases, which also doesn't seem to fit. Time-series is about sequential data over time, which isn't the focus here. So the main clue is the combination of vision and language, which is multimodal. The answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32864@AAAI"},
{"title": "From Coarse to Fine: A Matching and Alignment Framework for Unsupervised Cross-View Geo-Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"From Coarse to Fine: A Matching and Alignment Framework for Unsupervised Cross-View Geo-Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-View Geo-Localization\" suggests that the paper is about determining geographic locations from different viewpoints. The \"matching and alignment\" part might involve aligning different data sources or views. \n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining images and text. If the paper uses different modalities (e.g., images from different angles or sources), it could be multimodal. The \"cross-view\" part might imply different views or modalities, so maybe multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships. The paper's focus seems to be on alignment and matching, which could relate to knowledge graphs if they're structuring geographic data. However, the term \"geo-localization\" is more about spatial data, which might not directly relate to knowledge graphs unless they're building a graph structure. But the title doesn't mention knowledge graphs explicitly.\n\nSo, the most likely is multimodal because cross-view could mean different modalities or different perspectives (like images from different angles or sources). The framework is for matching and aligning these different views, which is a common task in multimodal research where you need to align different data types or sources. Therefore, the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32865@AAAI"},
{"title": "RefDetector: A Simple Yet Effective Matching-based Method for Referring Expression Comprehension", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RefDetector: A Simple Yet Effective Matching-based Method for Referring Expression Comprehension.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Referring Expression Comprehension\" sounds like it's about understanding expressions that refer to something, maybe in a visual context. Like, if someone says \"the red car next to the tree,\" the model has to figure out which object that refers to. So that's probably related to vision and language tasks. \n\nMatching-based method suggests they're matching some elements, maybe between text and images. So if it's combining text and images, that's multimodal. Multimodal typically involves integrating different types of data, like text and images or audio and video. \n\nTime-series would be about data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generation in models. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus on referring expressions likely involves both visual and textual data, so multimodal makes sense here. The other topics don't fit. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32866@AAAI"},
{"title": "Hierarchical Alignment-enhanced Adaptive Grounding Network for Generalized Referring Expression Comprehension", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hierarchical Alignment-enhanced Adaptive Grounding Network for Generalized Referring Expression Comprehension.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Generalized Referring Expression Comprehension\" sounds like it's about understanding expressions that refer to something, maybe in a visual context. Referring expressions often involve both language and images, so that might hint at multimodal. \n\nThe \"Hierarchical Alignment-enhanced Adaptive Grounding Network\" part suggests that the model uses alignment between different modalities (like text and images) and adapts to grounding, which is about linking language to visual elements. Grounding is a common term in multimodal tasks where you need to connect text descriptions to parts of an image or video.\n\nTime-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about sequences over time, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieval systems to enhance generative models, often in NLP tasks. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't seem to involve building or using knowledge graphs, so probably not KG.\n\nPutting it all together, the focus on referring expressions and grounding suggests a multimodal approach, combining text and visual data. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32867@AAAI"},
{"title": "SigStyle: Signature Style Transfer via Personalized Text-to-Image Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SigStyle: Signature Style Transfer via Personalized Text-to-Image Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Signature Style Transfer\" suggests that the paper is about modifying or transferring a style, specifically a signature style. \"Personalized Text-to-Image Models\" indicates that the model takes text as input and generates images, tailored to a person's style. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather. This doesn't seem related. Multimodal refers to models that handle multiple data types, like text and images. Since the model here uses text to generate images, that's combining two modalities, so multimodal might be a fit. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generation tasks. The title doesn't mention anything about retrieval, so probably not RAG. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention knowledge graphs either. \n\nSo the most likely answer is multimodal because it's combining text and image data in a model. The key here is the text-to-image aspect, which is a classic example of a multimodal task. The other topics don't fit here. I don't see any mention of time-series data, retrieval, or knowledge graphs. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32868@AAAI"},
{"title": "Enhancing Fine-Grained Vision-Language Pretraining with Negative Augmented Samples", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Fine-Grained Vision-Language Pretraining with Negative Augmented Samples.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language Pretraining\" suggests that the model is working with both visual and language data. That immediately makes me think of multimodal learning because multimodal typically involves combining different types of data, like images and text. \n\nThen, \"Negative Augmented Samples\" might refer to data augmentation techniques, but I'm not sure if that's directly related to any of the listed topics. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, which is more about text and information retrieval. KG (Knowledge Graphs) involve structured data and relationships, which doesn't seem to fit here. Time-series is about sequential data over time, which isn't mentioned in the title. \n\nSo, the key part here is \"Vision-Language,\" which is a classic example of multimodal data. The paper is about improving pretraining models that use both vision and language, which is a multimodal approach. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32869@AAAI"},
{"title": "Aligning Composed Query with Image via Discriminative Perception from Negative Correspondences", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Aligning Composed Query with Image via Discriminative Perception from Negative Correspondences.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Aligning Composed Query with Image\" suggests that there's a query (maybe text) being matched with an image. So combining different data types like text and images. That sounds like multimodal because multimodal deals with multiple modalities, like text and vision. \n\nThen, \"via Discriminative Perception from Negative Correspondences.\" The term \"negative correspondences\" might refer to negative samples or examples where the alignment isn't correct. This could be part of a training process where the model learns to distinguish between correct and incorrect alignments. \n\nNow, checking the options. Time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieval to augment generation, often in text, but the title mentions images. KG (Knowledge Graph) involves structured data and relationships, which isn't directly mentioned. \n\nMultimodal is about combining different data types, like text and images. The paper seems to be about aligning a composed query (maybe text) with an image, which is a classic multimodal task. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32871@AAAI"}
{"title": "Aligning Composed Query with Image via Discriminative Perception from Negative Correspondences", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Aligning Composed Query with Image via Discriminative Perception from Negative Correspondences.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Aligning Composed Query with Image\" suggests that there's a query (maybe text) being matched with an image. So combining different data types like text and images. That sounds like multimodal because multimodal deals with multiple modalities, like text and vision. \n\nThen, \"via Discriminative Perception from Negative Correspondences.\" The term \"negative correspondences\" might refer to negative samples or examples where the alignment isn't correct. This could be part of a training process where the model learns to distinguish between correct and incorrect alignments. \n\nNow, checking the options. Time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieval to augment generation, often in text, but the title mentions images. KG (Knowledge Graph) involves structured data and relationships, which isn't directly mentioned. \n\nMultimodal is about combining different data types, like text and images. The paper seems to be about aligning a composed query (maybe text) with an image, which is a classic multimodal task. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32871@AAAI"},
{"title": "HoneypotNet: Backdoor Attacks Against Model Extraction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HoneypotNet: Backdoor Attacks Against Model Extraction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title is about backdoor attacks and model extraction, which doesn't seem to involve multiple data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses external information retrieval to enhance its responses. The paper's focus is on attacks against model extraction, which is more about security vulnerabilities rather than retrieval methods. So RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about knowledge graphs or structured data. \n\nThe paper is about backdoor attacks in the context of model extraction. Model extraction is a security issue where an attacker tries to steal a machine learning model. HoneypotNet sounds like a method or system designed to detect or exploit such attacks. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to model extraction attacks or backdoors, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32872@AAAI"},
{"title": "Capturing the Unseen: Vision-Free Facial Motion Capture Using Inertial Measurement Units", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Capturing the Unseen: Vision-Free Facial Motion Capture Using Inertial Measurement Units.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Vision-Free Facial Motion Capture\" suggests they're not using visual data like cameras. Instead, they're using Inertial Measurement Units (IMUs), which are sensors that measure acceleration and angular velocity. So, the data here is probably from these sensors over time. \n\nTime-series analysis involves data points indexed in time order. Since IMUs collect data over time, this might be a time-series topic. But wait, the paper is about motion capture, which often involves tracking movement over time, so time-series makes sense here. \n\nMultimodal refers to using multiple types of data, like combining text, images, audio, etc. But the title says \"vision-free,\" meaning they're not using visual data. They're using IMUs, which are a different modality. However, if the paper is using only IMU data without combining it with other modalities, maybe it's not multimodal. Unless the IMUs themselves are part of a multimodal setup, but the title doesn't mention combining with other data types. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This doesn't seem related to motion capture using IMUs. \n\nKG is Knowledge Graph, which involves structured data representation. The paper doesn't mention anything about building or using a knowledge graph. \n\nSo, the main focus is on capturing facial motion using IMUs, which generate time-series data. Therefore, the topic is likely time-series. The other options don't fit. The answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32873@AAAI"},
{"title": "AnyTalk: Multi-modal Driven Multi-domain Talking Head Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AnyTalk: Multi-modal Driven Multi-domain Talking Head Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal Driven\" suggests that the research uses multiple modalities, like combining text, images, audio, etc. \"Multi-domain\" might mean it works across different areas or types of data. \"Talking Head Generation\" is about creating animated or virtual heads that can talk, probably for applications like virtual assistants or avatars.\n\nLooking at the options: time-series is about data over time, like stock prices or weather. RAG is Retrieval-Augmented Generation, which combines retrieval of information with generating responses. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about time-based data, so time-series is probably out. It does mention \"multi-modal,\" which is one of the options. The other parts of the title don't seem to relate to RAG or KG. So the key term here is \"multi-modal,\" which matches the multimodal topic. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32874@AAAI"},
{"title": "LIBA: Language Instructed Multi-granularity Bridge Assistant for 3D Visual Grounding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LIBA: Language Instructed Multi-granularity Bridge Assistant for 3D Visual Grounding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Language Instructed\" suggests that language is involved, maybe natural language processing. \"Multi-granularity\" could mean handling different levels of detail or scales. \"Bridge Assistant\" might imply connecting different modalities or components. \"3D Visual Grounding\" refers to linking language to 3D visual data, like understanding where a described object is in a 3D scene.\n\nNow, the options. Time-series is about data over time, like stock prices or sensor data. That doesn't seem to fit here. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to generate answers. KG (Knowledge Graph) involves structured data representations. The title doesn't mention anything about retrieval or knowledge graphs specifically.\n\nMultimodal refers to combining multiple types of data, like text and images. Since the paper is about 3D visual grounding with language instructions, that's combining text (language) and 3D visual data. So multimodal makes sense here. The \"bridge assistant\" part might be about integrating different modalities. So I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32875@AAAI"},
{"title": "Re-Attentional Controllable Video Diffusion Editing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Re-Attentional Controllable Video Diffusion Editing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video Diffusion Editing\" suggests it's about video, which is a sequence of frames over time. So maybe time-series? But wait, time-series usually refers to data points indexed in time order, like stock prices or weather data. Video is a form of time-series data, but the term might be more specific here. \n\n\"Controllable\" might imply some kind of model that allows for manipulation or control, which could be related to RAG (Retrieval-Augmented Generation) if it's about generating content with retrieval. But RAG is more about combining retrieval with generation, often in text. \n\n\"Re-Attentional\" makes me think of attention mechanisms, which are common in models like transformers. But how does that tie into the topics? RAG uses retrieval, but the term \"Re-Attentional\" might be a specific technique. \n\nMultimodal usually involves combining different types of data, like text and images. The paper is about video editing, which is a type of visual data. If it's using both video and another modality (like text for editing instructions), then it could be multimodal. But the title doesn't mention another modality explicitly. \n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem to relate to that. \n\nSo, video is a time-series of frames. The editing process might involve processing each frame in sequence, which is time-dependent. However, video editing could also involve spatial and temporal aspects. But the primary categorization here might be time-series because it's dealing with sequences over time. \n\nAlternatively, if the paper uses multimodal inputs (e.g., text and video), then it would be multimodal. But the title doesn't mention text or other modalities. It's focused on video diffusion, which is a generative model. \n\nRAG is about retrieval and generation. If the editing process involves retrieving information to generate the video, maybe. But the term \"Re-Attentional\" might not directly relate to RAG. \n\nSo, the most likely answer is time-series, since video is a time-based sequence. But I'm not entirely sure. Let me double-check. The other options don't fit as well. The paper is about video editing using diffusion models, which are typically used in image and video generation. Diffusion models can handle time-series data, but the main categories here are time-series, multimodal, RAG, or KG. Since the paper is about video, which is a time-series, I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32876@AAAI"},
{"title": "InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"InstructAvatar: Text-Guided Emotion and Motion Control for Avatar Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-Guided\" suggests that text is involved as an input or instruction. \"Emotion and Motion Control\" implies that the system is managing both emotional expressions and physical movements of an avatar. \"Avatar Generation\" is the main task here, creating avatars based on these controls.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like sequences or temporal data. This title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal refers to using multiple types of data, like combining text, images, audio, etc. Here, the system uses text (instructions) to control avatars, which might involve generating visual elements (motion, emotion). So that's two modalities: text and visual (motion/emotion). That could be multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation tasks. The title doesn't mention anything about retrieving information or using a retrieval component, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't indicate the use of a knowledge graph or structured data in that way. So likely not KG.\n\nSo the most plausible is multimodal because it combines text input with generating motion and emotion in avatars. The system is using multiple modalities (text and visual/motion) to achieve the task. I don't see elements of time-series, RAG, or KG here. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32877@AAAI"},
{"title": "DeMo: Decoupled Feature-Based Mixture of Experts for Multi-Modal Object Re-Identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DeMo: Decoupled Feature-Based Mixture of Experts for Multi-Modal Object Re-Identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That suggests it's about combining different data modalities, like images and text or audio and video. The term \"multimodal\" is one of the options given. The other parts of the title mention \"Object Re-Identification,\" which is a common task in computer vision, especially when dealing with different modalities, such as matching objects across different types of data (e.g., infrared and visible light images). \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval from a database with generation models, often in NLP. The title doesn't mention retrieval or generation, so RAG is unlikely. KG is Knowledge Graphs, which involve structured data and relationships between entities. Again, the title doesn't mention knowledge graphs or structured data. \n\nSo the key term here is \"Multi-Modal,\" which directly matches one of the options. The paper is about combining different modalities for object re-identification, so the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32878@AAAI"},
{"title": "MambaPro: Multi-Modal Object Re-identification with Mamba Aggregation and Synergistic Prompt", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MambaPro: Multi-Modal Object Re-identification with Mamba Aggregation and Synergistic Prompt.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That immediately makes me think the topic is multimodal. But let me check the other parts to be sure. The paper is about object re-identification, which is a computer vision task. The methods mentioned are Mamba Aggregation and Synergistic Prompt. \n\nMamba might refer to a type of model or architecture. I know that in some contexts, Mamba could be related to state-space models, but the key part here is \"Multi-Modal.\" The other options are RAG (Retrieval-Augmented Generation), KG (Knowledge Graphs), and time-series. \n\nRAG is typically about combining retrieval with generation, often in NLP. KG involves structured data and knowledge bases. Time-series deals with sequential data over time. The paper's focus on multi-modal suggests it's using multiple data types (like images and text) for object re-identification. So the topic should be multimodal. The other parts of the title don't mention anything about time-series data, knowledge graphs, or retrieval-augmented generation. So I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32879@AAAI"},
{"title": "IteRPrimE: Zero-shot Referring Image Segmentation with Iterative Grad-CAM Refinement and Primary Word Emphasis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"IteRPrimE: Zero-shot Referring Image Segmentation with Iterative Grad-CAM Refinement and Primary Word Emphasis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Referring Image Segmentation\" suggests that the paper is about segmenting images based on referring expressions, which are typically natural language descriptions. So, this involves both images and text, which are different modalities. That makes me think it's multimodal because it combines visual and textual data.\n\nThe methods mentioned are \"Iterative Grad-CAM Refinement\" and \"Primary Word Emphasis.\" Grad-CAM is a technique used in computer vision to visualize the important regions in an image for a model's prediction. The iterative refinement suggests they're improving the segmentation through multiple steps. The primary word emphasis might relate to focusing on key words in the referring expression to guide the segmentation.\n\nNow, checking the possible topics. Time-series is about data over time, which doesn't fit here. RAG (Retrieval-Augmented Generation) is a method that combines retrieval with generation, often in NLP. KG (Knowledge Graph) involves structured data and relationships. The paper doesn't mention anything about knowledge graphs or retrieval-augmented generation. The main focus is on combining image and text for segmentation, which is a classic multimodal task. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32880@AAAI"}
{"title": "Target Scanpath-Guided 360-Degree Image Enhancement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Target Scanpath-Guided 360-Degree Image Enhancement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Target Scanpath-Guided\" suggests that there's a path or sequence of targets being followed, maybe in an image. \"360-Degree Image Enhancement\" implies working with images that cover a full 360-degree view, which is common in virtual reality or panoramic imaging. The enhancement part could involve improving the quality or certain aspects of the image.\n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices over time. Multimodal refers to combining multiple types of data, such as text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used for semantic queries.\n\nThe paper's title doesn't mention anything about time or sequences over time, so time-series might not fit. It's about image enhancement, which is a single modality (images), so multimodal might not be right unless they're combining different data types. RAG and KG are more about data retrieval and knowledge representation, which don't seem directly related to image enhancement. The key here is that the paper is about enhancing images using a scanpath, which is a sequence of visual fixations. That might relate to how the image is processed, but none of the listed topics directly address image processing techniques. Since the options are time-series, multimodal, RAG, or KG, and the paper doesn't fit any of these, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32881@AAAI"},
{"title": "DualNet: Robust Self-Supervised Stereo Matching with Pseudo-Label Supervision", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DualNet: Robust Self-Supervised Stereo Matching with Pseudo-Label Supervision.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"DualNet\" probably refers to a neural network architecture. \"Robust Self-Supervised Stereo Matching\" suggests it's about stereo vision, which is a common topic in computer vision for depth estimation. \"Pseudo-Label Supervision\" implies using pseudo-labels for training, which is a technique in semi-supervised learning.\n\nNow, the four options. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using external knowledge in models. KG is Knowledge Graphs, which are structured representations of information.\n\nStereo matching is about using two images (from different viewpoints) to compute depth. This is a computer vision task, typically involving image data. Since the paper is about stereo matching, which uses two images (modalities) to get depth, it might be multimodal. But wait, multimodal usually refers to combining different types of data, like text and images. Stereo matching uses two images, which are the same modality (visual), so maybe not multimodal. \n\nSelf-supervised learning is a training method, but the question is about the research topic. The paper's focus is on stereo matching, which is a specific computer vision problem. None of the four topics (time-series, multimodal, RAG, KG) directly relate to stereo matching. The closest might be multimodal if they're combining different data types, but stereo uses two images, same modality. So maybe it's none of the listed topics. The answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32882@AAAI"},
{"title": "Precision-Enhanced Human-Object Contact Detection via Depth-Aware Perspective Interaction and Object Texture Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Precision-Enhanced Human-Object Contact Detection via Depth-Aware Perspective Interaction and Object Texture Restoration.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining images and text. The title mentions depth-aware and object texture restoration. Depth is a type of data (like from a depth camera), and texture is visual. So maybe combining different modalities (depth and texture) for detection. That could be multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, common in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus seems to be on detection methods using specific techniques, not on building or using a knowledge graph. So likely not KG.\n\nSo the most plausible is multimodal because it's combining depth (a different modality) with texture (another modality) for contact detection. The methods mentioned involve integrating different data types, which fits the multimodal category.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32883@AAAI"},
{"title": "CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding Evaluation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding Evaluation.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Chinese Vision-Language Understanding Evaluation\" suggests that the dataset is for tasks involving both vision and language, specifically in Chinese. Vision and language together usually point to multimodal tasks because they involve combining different types of data—images and text. \n\nMultimodal research deals with integrating multiple modalities like text, images, audio, etc. So if the dataset is for vision and language, that's a classic multimodal setup. \n\nTime-series would involve data that's sequential over time, like stock prices or sensor data. That doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to generate answers, often used in question-answering. KG (Knowledge Graph) involves structured data representations, like entities and relationships. \n\nThe paper is about a benchmark dataset for understanding both vision and language, so it's about combining these two modalities. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32884@AAAI"},
{"title": "Mamba YOLO: A Simple Baseline for Object Detection with State Space Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Mamba YOLO: A Simple Baseline for Object Detection with State Space Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. YOLO is a well-known object detection model, right? So the paper is about object detection. The key part here is \"State Space Model.\" State Space Models (SSMs) are typically used in time-series analysis because they model the state of a system over time. For example, in time-series forecasting or sequence modeling, SSMs are common. The Mamba model mentioned here is probably a variant of SSMs, like the Mamba architecture introduced for efficient sequence modeling.\n\nNow, looking at the options. Time-series would be the most likely candidate here because of the State Space Model reference. Multimodal usually involves combining different data types like text and images, which doesn't seem to be the case here. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generative models, which isn't mentioned. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. The paper is focused on object detection using a specific model type (SSM), which is more aligned with time-series methods. Even though object detection is a computer vision task, the use of SSMs points towards time-series processing, especially if the model is handling sequential data or temporal aspects. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32885@AAAI"},
{"title": "Style Nursing with Spatial and Semantic Guidance for Zero-Shot Traffic Scene Style Transfer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Style Nursing with Spatial and Semantic Guidance for Zero-Shot Traffic Scene Style Transfer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Style Nursing\" might be a typo or a specific term, but maybe it's about style transfer. \"Spatial and Semantic Guidance\" suggests using both spatial information (like location or structure) and semantic meaning. \"Zero-Shot Traffic Scene Style Transfer\" implies applying style transfer to traffic scenes without prior examples of that style. \n\nStyle transfer is typically about generating images in a different style, often using neural networks. The mention of spatial and semantic guidance might involve using different types of data or features. Now, looking at the possible topics:\n\n- Time-series: Deals with data over time, like stock prices or sensor data. The title doesn't mention time or sequences, so probably not this.\n- Multimodal: Involves combining multiple data types, like text and images. The paper uses spatial (maybe images) and semantic (maybe text or labels) guidance. That sounds like combining different modalities, so multimodal could be a fit.\n- RAG (Retrieval-Augmented Generation): Combines retrieval of information with generation, often in NLP. The title doesn't mention retrieval or combining retrieved data with generation, so maybe not RAG.\n- KG (Knowledge Graphs): Structured data representing entities and relationships. The title doesn't mention knowledge graphs or structured data, so probably not KG.\n\nSo the most likely is multimodal because it's using both spatial (visual) and semantic (maybe textual or contextual) information for style transfer. The zero-shot aspect might involve generating styles without examples, but the key here is combining different data types. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32886@AAAI"},
{"title": "Thermal-Aware Low-Light Image Enhancement: A Real-World Benchmark and a New Light-Weight Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Thermal-Aware Low-Light Image Enhancement: A Real-World Benchmark and a New Light-Weight Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Thermal-Aware\" suggests that the model takes into account thermal data, maybe from a thermal camera. \"Low-Light Image Enhancement\" is about improving images taken in low-light conditions. The second part mentions a benchmark and a new lightweight model. \n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data over time. Multimodal usually refers to using multiple types of data, like combining images and text or images and audio. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used in semantic web or information retrieval.\n\nThe paper here is about image enhancement, specifically using thermal data. So thermal data is another modality (like infrared) combined with the visible light image. That sounds like multimodal because it's using two different types of data (thermal and low-light images) to enhance the image. The model is lightweight, but the key aspect here is the combination of different data types. So the topic would be multimodal. \n\nI don't think it's time-series because there's no mention of temporal data. RAG and KG are more about text-based models and knowledge representation, which doesn't fit here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32887@AAAI"},
{"title": "TdAttenMix: Top-Down Attention Guided Mixup", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TdAttenMix: Top-Down Attention Guided Mixup.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"TdAttenMix\" probably stands for Top-Down Attention Mixup. Mixup is a technique used in machine learning where you combine two training examples to create a new one, often used in image or data augmentation. The term \"attention\" here suggests that the model uses attention mechanisms, which are common in models like Transformers. \n\nTop-down attention might refer to a hierarchical attention mechanism where higher-level features influence lower-level processing. Now, the key is to see which of the four topics this relates to. \n\nTime-series analysis deals with data points indexed in time order. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal refers to combining multiple data modalities like text, images, audio. The title doesn't mention different modalities, so probably not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't mention retrieval or generation, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge, so probably not KG. \n\nSo, the paper seems to be about a mixup technique guided by attention mechanisms. Since none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32888@AAAI"},
{"title": "Attention-Imperceptible Backdoor Attacks on Vision Transformers", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Attention-Imperceptible Backdoor Attacks on Vision Transformers.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Backdoor attacks\" are a type of adversarial attack in machine learning, where an attacker injects a hidden trigger into a model to make it behave maliciously under certain conditions. \"Vision Transformers\" refers to models like ViT that process images using transformer architectures. \n\nNow, the term \"Attention-Imperceptible\" suggests that the attack is designed to be undetectable in the attention mechanisms of the transformer. Attention mechanisms are key in transformers, so this is about manipulating how the model focuses on parts of the input.\n\nLooking at the possible topics: time-series deals with sequential data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance model outputs, often in NLP. KG (Knowledge Graphs) are structured representations of knowledge, often used for reasoning tasks.\n\nThe paper is about attacking vision transformers, which are used in computer vision. The focus is on the model's attention mechanisms and backdoor attacks. None of the four topics directly relate to adversarial attacks or computer vision models. Time-series is about temporal data, which isn't the case here. Multimodal would involve combining modalities, but the paper is about a single modality (vision). RAG and KG are more about retrieval and knowledge representation, not attacks. \n\nSo, the paper doesn't fit into any of the listed topics. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32889@AAAI"},
{"title": "LLM-RG4: Flexible and Factual Radiology Report Generation Across Diverse Input Contexts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LLM-RG4: Flexible and Factual Radiology Report Generation Across Diverse Input Contexts.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on generating radiology reports using LLM-RG4. The key terms here are \"radiology report generation\" and \"diverse input contexts.\" \n\nTime-series usually involves data points indexed in time order, like stock prices over time. This doesn't seem related to radiology reports unless they're analyzing changes over time, but the title doesn't mention time aspects.\n\nMultimodal refers to using multiple types of data, such as text, images, audio, etc. Radiology reports often involve both medical images (like X-rays) and textual descriptions. If the model uses both images and text to generate reports, that would be multimodal. The title mentions \"diverse input contexts,\" which might imply different data types, so multimodal could be a possibility.\n\nRAG stands for Retrieval-Augmented Generation. This is when a model uses a retrieval system to fetch relevant information before generating a response. If the paper is about using retrieved information to enhance the report generation, it would fall under RAG. However, the title doesn't explicitly mention retrieval or augmentation, just generation.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the model uses a knowledge graph to inform the reports, that would be the case. The title doesn't mention knowledge graphs either.\n\nThe term \"LLM-RG4\" suggests it's a large language model-based system for report generation. The key here is \"diverse input contexts.\" If the inputs include different modalities (like images and text), then it's multimodal. If the model is retrieving information from a database to generate the report, it's RAG. The title emphasizes flexibility and factual accuracy, which could be achieved through multimodal inputs (combining images and text) to ensure the reports are accurate based on the provided data. \n\nSince radiology reports typically require analyzing medical images (visual data) and generating textual reports, the system likely uses both modalities. Therefore, the research topic would be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32890@AAAI"}
{"title": "WaveLoss: An Adaptive Dynamic Loss for Deep Gait Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"WaveLoss: An Adaptive Dynamic Loss for Deep Gait Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"WaveLoss\" sounds like a loss function, which is common in machine learning. \"Adaptive Dynamic Loss\" suggests it's a type of loss function that changes during training. \"Deep Gait Recognition\" refers to using deep learning for recognizing someone's walking pattern, which is a biometric. \n\nNow, the research topics. Time-series would involve data that's sequential over time, like stock prices or sensor data. Gait recognition does involve time-series data because walking patterns are sequences over time. So maybe time-series? But wait, the question is whether the paper's main topic is one of these four. The loss function itself isn't necessarily a time-series topic, but the application is. However, the loss function is designed for a time-series task. But the paper's title is about the loss function, not the time-series aspect. Hmm.\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention multiple modalities, so probably not that. RAG is Retrieval-Augmented Generation, which is about using retrieval in generative models. That's more for NLP tasks, so not relevant here. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about knowledge graphs.\n\nSo the main topic here is the loss function for gait recognition. Gait recognition is a time-series problem because it's analyzing sequences of movement. However, the paper's focus is on the loss function, not the time-series aspect itself. But the problem it's applied to is time-series. The question is whether the paper belongs to the time-series topic. Since the loss is designed for a time-series application, maybe the paper is categorized under time-series. Alternatively, maybe it's not one of the four topics. Wait, the four options are time-series, multimodal, RAG, KG. The paper is about a loss function for a time-series task. But does that make it a time-series research topic? Or is the loss function part of a different area? For example, if the loss is a novel method for time-series, then it's time-series. But if the loss is a general method applicable to any problem, then maybe not. However, the title specifies it's for \"Deep Gait Recognition,\" which is a time-series application. So the paper is addressing a time-series problem with a new loss function. Therefore, the topic would be time-series. Alternatively, if the loss is a general method, maybe it's not. But given the context, I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32891@AAAI"},
{"title": "MSV-PCT: Multi-Sparse-View Enhanced Transformer Framework for Salient Object Detection in Point Clouds", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MSV-PCT: Multi-Sparse-View Enhanced Transformer Framework for Salient Object Detection in Point Clouds.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Sparse-View\" suggests that the method uses multiple sparse views, which might relate to processing data from different perspectives or modalities. \"Transformer Framework\" points to using transformer models, which are common in various machine learning tasks. \"Salient Object Detection\" is about identifying important objects in the data. \"Point Clouds\" are 3D data points, often used in computer vision for 3D object detection.\n\nNow, looking at the topics. Time-series involves data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. Multimodal refers to using multiple types of data (like text and images). The paper uses point clouds, which are a type of data, but does it combine with other modalities? The title says \"Multi-Sparse-View,\" which might mean different views of the same data, not different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about combining retrieval with generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The paper is about object detection in point clouds, which doesn't seem related to knowledge graphs.\n\nSo, the paper is about a transformer-based method for detecting salient objects in point clouds. The key here is whether any of the four topics fit. Since none of the topics (time-series, multimodal, RAG, KG) are directly related to point cloud processing or the specific techniques mentioned, the answer might be \"none.\" But wait, \"Multi-Sparse-View\" could imply using multiple modalities if the sparse views are different data types. However, point clouds themselves are a single modality. So maybe it's not multimodal. Therefore, the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32892@AAAI"},
{"title": "GlyphSR: A Simple Glyph-Aware Framework for Scene Text Image Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GlyphSR: A Simple Glyph-Aware Framework for Scene Text Image Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"GlyphSR\" probably refers to a method for super-resolution (SR) of scene text images. The key terms here are \"Glyph-Aware,\" \"Scene Text,\" and \"Super-Resolution.\" Super-resolution in image processing is about enhancing the resolution of an image, making it clearer or higher quality. \n\nNow, the topics given are time-series, multimodal, RAG, and KG. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where models retrieve information from a database to enhance their responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used in semantic web or information retrieval.\n\nThe paper's focus is on improving the resolution of scene text images. The term \"Glyph-Aware\" suggests that it's considering the individual characters (glyphs) in the text. This seems to be a computer vision problem, specifically image processing. None of the given topics directly relate to image super-resolution. Time-series is about temporal data, multimodal involves multiple data types, RAG is about retrieval in NLP, and KG is about structured knowledge. \n\nSo, the paper is about image super-resolution for text, which doesn't fit into any of the four categories listed. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32893@AAAI"},
{"title": "VA-AR: Learning Velocity-Aware Action Representations with Mixture of Window Attention", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VA-AR: Learning Velocity-Aware Action Representations with Mixture of Window Attention.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Velocity-Aware Action Representations\" suggests that the model is considering velocity, which is a time-related concept. Velocity implies change over time, so maybe this is related to time-series data. The \"Mixture of Window Attention\" part might refer to how the model processes sequences of data over time, using different window sizes to capture temporal patterns. That sounds like time-series analysis, where you look at sequences of data points over time.\n\nMultimodal usually involves combining different types of data, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, often in NLP. The title doesn't mention retrieval or generation, so RAG is unlikely. KG (Knowledge Graph) involves structured data and relationships between entities. Again, the title doesn't mention knowledge graphs or structured data, so that's probably not it.\n\nPutting it all together, the focus on velocity and window attention for action representations points towards time-series analysis. The model is likely processing sequential data where the timing and changes over time (velocity) are important. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32894@AAAI"},
{"title": "GraphAvatar: Compact Head Avatars with GNN-Generated 3D Gaussians", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GraphAvatar: Compact Head Avatars with GNN-Generated 3D Gaussians.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"GraphAvatar\" suggests something related to graphs. \"GNN-Generated\" stands for Graph Neural Network, which is definitely related to graph structures. Then \"3D Gaussians\" might be part of the method used. The topic here is about creating compact head avatars using GNNs. \n\nNow, looking at the possible categories. Time-series is about data over time, which doesn't seem to fit here. Multimodal usually involves combining different types of data like text and images, but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which also doesn't seem relevant. KG stands for Knowledge Graph, which is a structured representation of knowledge. However, the paper here is about generating 3D avatars using GNNs, which are a type of model for graph-structured data. \n\nWait, GNNs are used for graph data, so maybe this is related to Knowledge Graphs (KG)? But KGs are more about representing entities and relationships, whereas GNNs are a method to process graph data. The paper's focus is on using GNNs to generate 3D Gaussians for avatars. So maybe it's not directly about KGs. The other options don't fit. Since the paper uses GNNs, which are part of graph-based models, but the main topic isn't one of the four listed. The four options are time-series, multimodal, RAG, KG. None of these seem to directly match the use of GNNs for generating 3D avatars. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32895@AAAI"},
{"title": "Power of Diversity: Enhancing Data-Free Black-Box Attack with Domain-Augmented Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Power of Diversity: Enhancing Data-Free Black-Box Attack with Domain-Augmented Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Data-Free Black-Box Attack\" sounds like it's related to machine learning security, specifically adversarial attacks. The term \"black-box attack\" refers to an attack where the attacker doesn't have access to the model's internal parameters, only the input and output. \"Data-Free\" might mean that the attack doesn't require any training data from the target model. \n\nThen there's \"Domain-Augmented Learning.\" Domain augmentation usually involves generating synthetic data from different domains to improve model performance. But in the context of an attack, it might be about making the attack more effective by using diverse domains. \n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so probably not that. \n\nMultimodal refers to using multiple types of data, like text and images. The title doesn't mention combining different data types, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP. The paper's title mentions \"Domain-Augmented Learning,\" but that's not the same as retrieval. So RAG might not be the right fit here. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge structures, so that's probably not it either. \n\nSo none of the four topics seem to directly fit. The paper is about adversarial attacks in machine learning, specifically data-free black-box attacks enhanced with domain augmentation. The topics provided don't cover security or adversarial machine learning. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32896@AAAI"},
{"title": "Achieving Lightweight Super-Resolution for Real-Time Computer Graphics", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Achieving Lightweight Super-Resolution for Real-Time Computer Graphics.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Super-resolution usually refers to enhancing the resolution of images or videos. Real-time computer graphics suggests it's about processing images quickly for applications like gaming or simulations. The term \"lightweight\" implies the method is optimized for efficiency, maybe using less computational resources.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or sensor data. This paper is about image processing, so maybe not time-series. Multimodal refers to combining different data types, like text and images. The title doesn't mention multiple data sources, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses, often in NLP. The paper's focus is on image super-resolution, which is more about image processing than generating text based on retrieved data. So RAG might not fit here.\n\nKG is Knowledge Graphs, which are structured representations of information, often used in semantic web or data integration. The title doesn't mention anything about knowledge representation or graphs, so KG is unlikely.\n\nSo, none of the four topics seem to fit. The paper is about image super-resolution in real-time, which is a computer graphics or image processing topic. Since the options given don't include those, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32897@AAAI"},
{"title": "Multi-axis Prompt and Multi-dimension Fusion Network for All-in-one Weather-degraded Image Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-axis Prompt and Multi-dimension Fusion Network for All-in-one Weather-degraded Image Restoration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-axis Prompt\" and \"Multi-dimension Fusion Network\" suggest that the paper is dealing with combining different types of data or features. The goal is \"All-in-one Weather-degraded Image Restoration,\" which is about restoring images that have been degraded by weather conditions like rain, fog, etc.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This paper is about image restoration, which is more about spatial data, so maybe not time-series. \n\nMultimodal refers to combining multiple types of data, like text and images, or different sensors. The \"Multi-axis\" and \"Multi-dimension Fusion\" might imply combining different modalities or data sources. However, the problem here is specifically about image restoration using different axes or dimensions, which could be different aspects of the image data itself rather than different modalities. But I'm not entirely sure. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This doesn't seem related to image restoration. \n\nKG is Knowledge Graph, which involves structured data representations. The paper doesn't mention anything about knowledge graphs or structured data, so probably not that.\n\nSo, the main contenders are multimodal and maybe none. The \"Multi-axis\" and \"Multi-dimension Fusion\" could be about combining different features or data types within the image processing context. However, multimodal typically refers to different modalities like text, image, audio. If the paper is using multiple types of data (e.g., combining different image channels, or integrating other data sources like weather data with images), then it might be multimodal. But if it's just processing the image in multiple dimensions (like spatial and frequency domains), that's more about the model's architecture rather than multimodal. \n\nThe title doesn't explicitly mention different modalities, so maybe it's not multimodal. The \"All-in-one\" part might refer to handling various weather conditions, not different data types. Therefore, the paper might not fit into any of the four categories. So the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32898@AAAI"},
{"title": "USDRL: Unified Skeleton-Based Dense Representation Learning with Multi-Grained Feature Decorrelation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"USDRL: Unified Skeleton-Based Dense Representation Learning with Multi-Grained Feature Decorrelation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Skeleton-Based\" probably refers to using skeleton data, which is common in areas like action recognition or pose estimation. \"Dense Representation Learning\" suggests they're creating detailed feature representations. \"Multi-Grained Feature Decorrelation\" might mean they're handling features at different levels of granularity and reducing redundancy between them.\n\nLooking at the options: time-series deals with sequential data over time. Multimodal involves combining different data types (like text and images). RAG is Retrieval-Augmented Generation, which is about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus on skeleton data could be time-series if they're analyzing sequences over time, which is typical in action recognition. Skeleton data often comes from motion capture, which is a time-series of joint positions. The \"Multi-Grained Feature Decorrelation\" part might be about handling different temporal scales, which is a time-series concern. The other terms like \"Representation Learning\" are general but in the context of skeleton data, it's likely time-series. There's no mention of combining different modalities (multimodal), or using retrieval (RAG), or building a knowledge graph (KG). So the most fitting topic here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32899@AAAI"},
{"title": "Spin: Diffusion-based Semantic Image Painting Through Independent Information Injection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spin: Diffusion-based Semantic Image Painting Through Independent Information Injection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image painting, which is a visual task. If it uses text or other modalities along with images, it might be multimodal. The title mentions \"Semantic Image Painting,\" which could involve text-based semantics, but the key part here is \"Independent Information Injection.\" Not sure yet.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title doesn't mention retrieval or augmentation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nBack to multimodal. The term \"Semantic\" in the title might imply using textual or semantic information to guide the image generation. Diffusion models are often used in image generation, and if they're incorporating semantic information (like text prompts), that would be multimodal. The \"Independent Information Injection\" part could refer to integrating different modalities (e.g., text and image) independently. So this might be a multimodal approach. \n\nI think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32901@AAAI"}
{"title": "Spin: Diffusion-based Semantic Image Painting Through Independent Information Injection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spin: Diffusion-based Semantic Image Painting Through Independent Information Injection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image painting, which is a visual task. If it uses text or other modalities along with images, it might be multimodal. The title mentions \"Semantic Image Painting,\" which could involve text-based semantics, but the key part here is \"Independent Information Injection.\" Not sure yet.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title doesn't mention retrieval or augmentation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nBack to multimodal. The term \"Semantic\" in the title might imply using textual or semantic information to guide the image generation. Diffusion models are often used in image generation, and if they're incorporating semantic information (like text prompts), that would be multimodal. The \"Independent Information Injection\" part could refer to integrating different modalities (e.g., text and image) independently. So this might be a multimodal approach. \n\nI think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32901@AAAI"},
{"title": "Language Prompt for Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Language Prompt for Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. Autonomous driving does use time-series data from sensors, but the title mentions \"language prompt,\" which might not be directly about time-series analysis.\n\nMultimodal refers to combining different data types, like text, images, and audio. Autonomous driving systems often use multiple modalities (cameras, lidar, radar, etc.), but the title specifically says \"language prompt,\" which is text-based. However, if the research is about integrating language with other modalities, maybe multimodal. But the title doesn't explicitly mention other modalities.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs either.\n\nSo, the main focus here is \"language prompt\" in the context of autonomous driving. Language prompts are text-based inputs, which could be part of a multimodal system if they're combined with other data types. But if the paper is solely about using language prompts without integrating other modalities, it might not be multimodal. However, autonomous driving typically involves multiple modalities, so using language prompts as part of that system would make it multimodal. The title is a bit ambiguous, but given the options, multimodal seems the most likely fit. Alternatively, if it's just about language without other modalities, maybe none. But since autonomous driving is inherently multimodal, I'll go with multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32902@AAAI"},
{"title": "Structural Pruning via Spatial-aware Information Redundancy for Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Structural Pruning via Spatial-aware Information Redundancy for Semantic Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. Structural pruning is a technique used to reduce the size of neural networks by removing unnecessary parts. The term \"spatial-aware\" suggests that the method is considering spatial information, which is common in tasks like image processing. Semantic segmentation is a computer vision task where each pixel in an image is classified into a category. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on pruning a model for semantic segmentation, which is a computer vision task. The methods mentioned (spatial-aware information redundancy) don't seem to relate to time-series data. There's no mention of combining different data modalities, so multimodal is probably not it. RAG and KG are more about information retrieval and knowledge representation, which don't directly relate to model pruning for segmentation. \n\nTherefore, the paper doesn't fit into any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32903@AAAI"},
{"title": "CoRe: Context-Regularized Text Embedding Learning for Text-to-Image Personalization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CoRe: Context-Regularized Text Embedding Learning for Text-to-Image Personalization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-to-Image Personalization\" suggests that the research is about generating images based on text, which is a common task in multimodal learning because it involves both text and images. Multimodal typically refers to models that handle multiple data types, like combining text and images. \n\nThe method mentioned is \"Context-Regularized Text Embedding Learning.\" The term \"embedding\" here is about representing text in a vector space, which is a common technique in NLP. The \"context-regularized\" part might imply that the model uses contextual information to regularize the embeddings, perhaps to better align text and image representations. \n\nNow, checking the options. Time-series would involve data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to augment generation models, but the title doesn't mention retrieval. KG (Knowledge Graph) involves structured data and relationships, which also isn't mentioned. \n\nMultimodal is the most likely fit because the task involves both text and images. The paper is about personalizing images based on text, which is a classic multimodal problem. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32904@AAAI"},
{"title": "Debiased All-in-one Image Restoration with Task Uncertainty Regularization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Debiased All-in-one Image Restoration with Task Uncertainty Regularization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image restoration, which is about images, not time-based data. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about image restoration, but the title doesn't mention combining different modalities. It's focused on a single task with images. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically in NLP, where a model retrieves information from a database to generate responses. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data. \n\nThe paper is about image restoration, which is a computer vision task. The topics given don't include computer vision or image processing. The four options are time-series, multimodal, RAG, KG. None of these directly relate to image restoration. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32905@AAAI"},
{"title": "LVPTrack: High Performance Domain Adaptive UAV Tracking with Label Aligned Visual Prompt Tuning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LVPTrack: High Performance Domain Adaptive UAV Tracking with Label Aligned Visual Prompt Tuning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"UAV Tracking\" refers to tracking Unmanned Aerial Vehicles, which is a computer vision task. \"Domain Adaptive\" suggests that the model is being adapted from one domain to another, which is common in transfer learning. \"Label Aligned Visual Prompt Tuning\" sounds like they're using some kind of prompt-based method, maybe similar to how prompts are used in NLP, but applied to visual data.\n\nNow, looking at the options. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time-series data, so probably not that. Multimodal would involve combining different types of data, like text and images. The title mentions \"Visual Prompt Tuning,\" which is about images, but there's no indication of combining multiple modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation, so RAG might not fit. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about building or using a knowledge graph.\n\nThe key part here is \"Visual Prompt Tuning.\" Prompt tuning is a technique used in models like those in the RAG framework, but more commonly in prompt-based learning where you adjust the prompts to adapt the model. However, RAG specifically involves retrieval. Since the paper is about domain adaptation in UAV tracking using visual prompts, it's more about adapting a model through prompt tuning rather than retrieval. But none of the given options exactly match this. The closest might be RAG if prompt tuning is considered part of it, but I'm not sure. Alternatively, maybe it's none of the listed topics. Let me double-check. The four options are time-series, multimodal, RAG, KG. The paper is about domain adaptation in visual tracking with prompt tuning. Since none of the options directly relate to domain adaptation or prompt tuning in this context, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32906@AAAI"},
{"title": "SVRMamba: Slice-to-Volume Reconstruction from Multiple MRI Stacks with Slice Sequence Guided Mamba", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SVRMamba: Slice-to-Volume Reconstruction from Multiple MRI Stacks with Slice Sequence Guided Mamba.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main task here is \"Slice-to-Volume Reconstruction,\" which involves taking multiple MRI slices and reconstructing a 3D volume. The method uses \"Slice Sequence Guided Mamba,\" which might be a model or technique. \n\nNow, looking at the options. Time-series usually involves data over time, like sequences of data points. Multimodal refers to combining different types of data, like images and text. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about reconstructing a volume from multiple MRI stacks. MRI stacks are different slices of the same area, so each stack is a sequence of slices. The term \"Slice Sequence\" might imply a sequence, but the key here is that they're using multiple stacks (different sequences) to build a volume. However, the main focus isn't on the temporal aspect (time) but rather on combining different slices. \n\nMultimodal could be a possibility if they're combining different modalities (like different types of MRI scans or other data types). But the title mentions \"Multiple MRI Stacks,\" which are different slices of the same modality (MRI). So it's not combining different data types, just multiple slices. \n\nRAG and KG don't seem relevant here. The paper is about image reconstruction, not retrieval or knowledge graphs. \n\nWait, but the term \"Slice Sequence Guided\" might imply that the model uses the sequence of slices in some way. However, time-series typically involves temporal data where the order over time is crucial. In this case, the slices are spatial sequences (different angles or positions) rather than temporal. So maybe it's not time-series. \n\nMultimodal is about combining different data sources. Since all the data here is MRI stacks (same modality), it's not multimodal. \n\nTherefore, the paper doesn't fit into any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32907@AAAI"},
{"title": "ICM-Assistant: Instruction-tuning Multimodal Large Language Models for Rule-based Explainable Image Content Moderation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ICM-Assistant: Instruction-tuning Multimodal Large Language Models for Rule-based Explainable Image Content Moderation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Multimodal Large Language Models.\" The term \"multimodal\" immediately stands out. Multimodal models are those that can process multiple types of data, like text and images. The paper is about using such models for image content moderation, which involves both text (instructions, maybe the model's responses) and images. So that points towards the multimodal category.\n\nNext, looking at the other parts. \"Instruction-tuning\" refers to training the model using instructions, which is a method in training LLMs, but that's more about the training approach rather than the topic classification here. \"Rule-based Explainable\" suggests that the model follows certain rules and provides explanations, but again, that's more about the application or methodology rather than the core research topic.\n\nThe other options: time-series would involve data over time, like stock prices or weather data. RAG (Retrieval-Augmented Generation) is about combining retrieval of information with generation, often used in question-answering systems. KG (Knowledge Graphs) involve structured data representations. None of these terms are present in the title. The focus is on handling multiple modalities (text and images), so the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32908@AAAI"},
{"title": "VarCMP: Adapting Cross-Modal Pre-Training Models for Video Anomaly Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VarCMP: Adapting Cross-Modal Pre-Training Models for Video Anomaly Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Modal Pre-Training Models\" suggests that the research involves multiple modalities, like combining different types of data such as text and video. The term \"cross-modal\" is a big hint here. Then, the application is \"Video Anomaly Retrieval,\" which is about finding anomalies in video data. \n\nLooking at the options: multimodal is definitely a candidate because cross-modal implies using multiple data types. Time-series could be related if the video is analyzed over time, but the key term here is cross-modal. RAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to fit. The paper is about adapting pre-trained models for a specific retrieval task in video, but the main focus is on the cross-modal aspect. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32909@AAAI"},
{"title": "Realistic Noise Synthesis with Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Realistic Noise Synthesis with Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title is about noise synthesis, which could be generating audio or images, but there's no mention of combining multiple modalities. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title doesn't talk about retrieval or combining it with generation, so RAG might not be it.\n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention anything about knowledge or graphs, so that's probably not it either.\n\nSo the paper is about using diffusion models to synthesize realistic noise. Diffusion models are a type of generative model, often used in image or audio generation. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to generative models or noise synthesis, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32910@AAAI"}
{"title": "DC-PCN: Point Cloud Completion Network with Dual-Codebook Guided Quantization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DC-PCN: Point Cloud Completion Network with Dual-Codebook Guided Quantization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Point cloud completion refers to generating or completing 3D point clouds, which is a task in computer vision or 3D data processing. The network uses a dual-codebook guided quantization method. Codebooks are often used in vector quantization, which is a technique in machine learning for data compression or representation. \n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, common in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on point cloud completion using a specific quantization method. None of the topics directly relate to time-series data. It's not combining multiple modalities, so not multimodal. RAG and KG are more about information retrieval and knowledge representation, which don't seem to connect here. The dual-codebook approach is a technical detail in the network's architecture but doesn't fall under the listed topics. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32911@AAAI"},
{"title": "PanAdapter: Two-Stage Fine-Tuning with Spatial-Spectral Priors Injecting for Pansharpening", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PanAdapter: Two-Stage Fine-Tuning with Spatial-Spectral Priors Injecting for Pansharpening.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. Pansharpening is a process in remote sensing where a high-resolution panchromatic image is combined with a lower-resolution multispectral image to produce a high-resolution color image. So, this is about image processing, specifically combining different types of images. \n\nThe terms \"spatial-spectral\" suggest that both spatial (related to the physical layout or structure of the image) and spectral (related to the different wavelengths or color bands) information are involved. That makes me think of multimodal data because it's combining different types of data (panchromatic and multispectral). Multimodal typically refers to integrating data from different sources or modalities, like combining images with text or different types of images.\n\nThe \"Two-Stage Fine-Tuning\" part might refer to a method where the model is first pre-trained and then fine-tuned in two stages. However, the key here is the combination of spatial and spectral data. RAG (Retrieval-Augmented Generation) is more about using external knowledge during generation, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem relevant. Time-series is about data over time, which isn't the case here. \n\nSo, the main focus is on integrating different data types (spatial and spectral) for pansharpening. That aligns with multimodal research, which deals with combining multiple data modalities. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32912@AAAI"},
{"title": "Combating Multimodal LLM Hallucination via Bottom-Up Holistic Reasoning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Combating Multimodal LLM Hallucination via Bottom-Up Holistic Reasoning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Multimodal LLM.\" Multimodal usually refers to models that handle multiple types of data, like text, images, audio, etc. So that's a hint. The problem here is \"hallucination,\" which is when a model generates false information. The approach is \"Bottom-Up Holistic Reasoning.\" \n\nNow, looking at the options. The topic could be multimodal because the title explicitly says \"Multimodal.\" The other options are time-series, RAG (Retrieval-Augmented Generation), and KG (Knowledge Graphs). Time-series is about data over time, which doesn't seem related here. RAG involves using retrieval to augment generation, maybe to prevent hallucinations by checking facts against a database. KGs are structured data that might help in reasoning. But the title specifically mentions multimodal, so that's a strong indicator. The paper is about addressing hallucinations in multimodal models, so the primary topic is multimodal. The other methods (like RAG or KG) might be part of the solution, but the main focus is on the multimodal aspect. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32913@AAAI"},
{"title": "CustomCrafter: Customized Video Generation with Preserving Motion and Concept Composition Abilities", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CustomCrafter: Customized Video Generation with Preserving Motion and Concept Composition Abilities.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. The paper is about video generation, which does involve sequences of frames over time. So maybe time-series? But wait, video generation could also involve multiple modalities, like combining text and video. The title mentions \"motion\" and \"concept composition,\" which might relate to different aspects of the video, such as movement and the concepts being depicted. That sounds like multimodal because it's handling different types of information (motion and concepts). \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title doesn't mention anything about retrieval or using external data for augmentation, so probably not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so that's out.\n\nSo the main contenders are time-series and multimodal. Video is inherently a time-series because it's a sequence of frames. However, the mention of \"concept composition\" might imply combining different modalities, like text and video. But the key here is whether the research focuses on the temporal aspect (time-series) or the integration of multiple data types (multimodal). Since the title emphasizes \"customized video generation\" with preserving motion (temporal) and concept composition (maybe combining different elements), it's possible that it's more about handling the temporal aspects of video. However, \"concept composition\" could also be about integrating different modalities. \n\nWait, the term \"multimodal\" typically refers to combining different types of data, like text, images, audio. If the paper is about generating videos that maintain both motion (which is a temporal aspect) and the composition of concepts (maybe combining different elements or modalities), it might be multimodal. But I'm a bit confused. Let me think again. Time-series is about sequences over time, which video is. But if the paper is about generating videos with specific motion and concepts, maybe it's using multimodal inputs (like text and video) to generate the output. However, the title doesn't explicitly mention other modalities. It just says \"customized video generation.\" \n\nHmm. Maybe the key is in the \"concept composition abilities.\" If the model is combining different concepts (like objects, actions) into the video, that could be multimodal in the sense of integrating different semantic elements. But I'm not entirely sure. Alternatively, since video is a time-series, maybe the focus is on the temporal modeling. However, the term \"multimodal\" is often used when combining different data types. Since the title doesn't mention other modalities, maybe it's not multimodal. \n\nWait, the title says \"preserving motion and concept composition.\" Motion is part of the video's temporal aspect. Concept composition might refer to combining different elements within the video, like different objects or actions. That could be part of the model's architecture, but not necessarily multimodal. So maybe the primary focus is on time-series (video as a sequence) but with customized generation. However, the answer options are time-series, multimodal, RAG, or KG. Since the paper is about video generation, which is a time-series, but the question is whether the research topic is time-series. But sometimes video generation can be considered multimodal if it uses text or other inputs. The title doesn't mention other modalities, though. \n\nI think the safest answer here is time-series because video is a time-series data. But I'm a bit uncertain because \"concept composition\" might imply something else. However, given the options, time-series seems the most likely.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32914@AAAI"},
{"title": "Deconfound Semantic Shift and Incompleteness in Incremental Few-shot Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Deconfound Semantic Shift and Incompleteness in Incremental Few-shot Semantic Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Incremental Few-shot Semantic Segmentation\" suggests that the paper is about improving semantic segmentation models in a few-shot learning scenario, where the model learns to recognize new classes with very few examples. The term \"incremental\" implies that the model is updated over time as new data comes in, which is common in continual learning. \n\nThe main problem addressed here is \"Semantic Shift and Incompleteness.\" Semantic shift refers to changes in the meaning or representation of classes over time, which can be a challenge in incremental learning. Incompleteness might relate to missing data or features when new classes are introduced. The paper's goal is to deconfound these issues, meaning to separate or address them effectively.\n\nNow, looking at the possible topics. Time-series typically involves data points indexed in time order, like stock prices or sensor data. This paper doesn't mention anything about temporal data, so probably not time-series.\n\nMultimodal refers to combining multiple data types (like text, images, audio). The title doesn't mention different modalities, so that's probably not it either.\n\nRAG (Retrieval-Augmented Generation) is a method that combines retrieval of documents with generation, often used in NLP. The paper's focus is on semantic segmentation, which is a computer vision task, so RAG doesn't seem relevant here.\n\nKG (Knowledge Graph) involves structured data representations, often for linking entities and their relationships. The paper's problem is about semantic shifts and incompleteness in segmentation, which doesn't directly relate to knowledge graphs.\n\nSince none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32915@AAAI"},
{"title": "Video Repurposing from User Generated Content: A Large-scale Dataset and Benchmark", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Video Repurposing from User Generated Content: A Large-scale Dataset and Benchmark.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or sensor data. The paper's about video repurposing, which is more about processing video content, so maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images or video and audio. Since the paper is about video (which is a combination of visual and audio elements), maybe it's multimodal. But the title doesn't explicitly mention combining different modalities, just repurposing video. Hmm.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The paper's about creating a dataset and benchmark for video repurposing. If they're using retrieval methods, maybe RAG? But the title doesn't mention retrieval or generation, just dataset and benchmark.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't seem to be about building or using knowledge graphs.\n\nSo, the main focus is on a dataset and benchmark for video repurposing. Video is a multimodal data type (combining video, audio, maybe text), so if the dataset includes multiple modalities, then it's multimodal. But the title doesn't specify that. However, video inherently involves multiple modalities. So maybe the answer is multimodal. Alternatively, if the dataset is just for video processing without combining different data types, maybe it's not. But given the options, multimodal seems the closest fit.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32916@AAAI"},
{"title": "Unlearning Concepts in Diffusion Model via Concept Domain Correction and Concept Preserving Gradient", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unlearning Concepts in Diffusion Model via Concept Domain Correction and Concept Preserving Gradient.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The title is about diffusion models and unlearning concepts, but there's no mention of multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title doesn't talk about retrieval or generation, so RAG might not fit here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title mentions \"Concept Domain Correction\" and \"Concept Preserving Gradient,\" which sounds like it's dealing with concepts and their relationships. Maybe they're modifying a model's understanding of certain concepts, which could relate to knowledge graphs. But I'm not entirely sure. The term \"unlearning\" might refer to removing or correcting certain knowledge, which could be part of a KG. However, the main focus here is on diffusion models and gradient methods. Diffusion models are typically used in generative tasks, like image generation. The paper is about unlearning concepts, which is more about modifying the model's knowledge rather than the structure of a knowledge graph. So maybe it's not KG either.\n\nWait, the options are time-series, multimodal, RAG, KG. If none of these fit, then the answer is \"none.\" The paper is about unlearning in diffusion models using specific techniques. Since none of the four topics directly relate to unlearning in diffusion models, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32917@AAAI"},
{"title": "MUCD: Unsupervised Point Cloud Change Detection via Masked Consistency", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MUCD: Unsupervised Point Cloud Change Detection via Masked Consistency.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Point Cloud Change Detection\" suggests it's about detecting changes in 3D point cloud data. The method is unsupervised and uses \"Masked Consistency.\" Now, the four options are time-series, multimodal, RAG (Retrieval-Augmented Generation), or KG (Knowledge Graphs).\n\nTime-series usually involves data over time, like stock prices or sensor data. This paper is about point clouds, which are 3D data points, but the title doesn't mention time explicitly. However, change detection could imply comparing data over time, so maybe time-series? But I'm not sure yet.\n\nMultimodal refers to combining different data types, like text and images. The title mentions point clouds, which are a type of data, but there's no indication of combining multiple modalities here. So probably not multimodal.\n\nRAG is about enhancing models with external knowledge retrieval, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG (Knowledge Graphs) involves structured data and relationships. The paper's focus is on point cloud change detection, which doesn't seem related to knowledge graphs.\n\nSo, the main question is whether this is time-series. Change detection in point clouds could be over time, but the term \"time-series\" is usually for sequential data. If the paper is about detecting changes between different time points in point clouds, then it might be time-series. However, the title doesn't explicitly state that. The method is unsupervised and uses masked consistency, which might be a technique for learning without labeled data. But the core topic here is the data type (point clouds) and the task (change detection). Since none of the other options fit, maybe it's none? But wait, the user wants to know if it belongs to any of the four. If the change detection is over time, then time-series. But if it's just detecting changes in the same time (like different views?), then maybe not. The title doesn't specify, so I'm a bit uncertain. However, given the options, the closest might be time-series if it's about temporal changes. But without explicit mention, maybe it's none. Hmm. Alternatively, maybe it's multimodal if point clouds are considered a modality, but the paper isn't combining multiple modalities. So I think the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32918@AAAI"},
{"title": "Sparis: Neural Implicit Surface Reconstruction of Indoor Scenes from Sparse Views", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sparis: Neural Implicit Surface Reconstruction of Indoor Scenes from Sparse Views.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Neural Implicit Surface Reconstruction\" suggests using neural networks to reconstruct surfaces. \"Indoor Scenes from Sparse Views\" means they're working with limited data points, maybe images or sensor data, to build a 3D model of an indoor environment. \n\nTime-series usually involves data over time, like stock prices or weather. This doesn't seem to mention anything about time, so probably not time-series. \n\nMultimodal would involve combining different types of data, like text and images. The title mentions \"sparse views,\" which could be images, but there's no indication of combining multiple modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The paper here is about 3D reconstruction, so RAG doesn't seem relevant. \n\nKG is Knowledge Graphs, which are structured representations of information. The paper is about reconstructing surfaces, not about building or using a knowledge graph. \n\nSo, none of the four topics seem to fit. The paper is about 3D reconstruction using neural networks, which is more related to computer vision or machine learning in general, but not specifically any of the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32919@AAAI"},
{"title": "FriendsQA: A New Large-Scale Deep Video Understanding Dataset with Fine-grained Topic Categorization for Story Videos", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FriendsQA: A New Large-Scale Deep Video Understanding Dataset with Fine-grained Topic Categorization for Story Videos.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Deep Video Understanding Dataset\" suggests that the dataset is related to video analysis. Video is a combination of visual and auditory elements, so that might point towards multimodal, since multimodal typically involves multiple data types like text, images, audio, etc. \n\nThe mention of \"Fine-grained Topic Categorization\" could imply some form of classification or knowledge organization. But \"KG\" stands for Knowledge Graph, which usually involves structured data and relationships between entities. However, the title doesn't explicitly mention knowledge graphs or structured data relationships. \n\nRAG is Retrieval-Augmented Generation, which is more about combining retrieval of information with generation models, often in text-based tasks. The title doesn't seem to focus on retrieval or generation, so probably not RAG.\n\nTime-series analysis deals with data points indexed in time order. While video can be considered a time-series of frames, the primary focus here seems to be on understanding the content of the video (like what's happening in the story) rather than temporal analysis. So maybe not time-series.\n\nMultimodal makes sense because video is inherently multimodal (combining visual and audio data). The dataset is for deep video understanding, which would require processing multiple modalities. The \"FriendsQA\" part might refer to a question-answering aspect, which is common in multimodal tasks where you have to understand both the video and textual questions.\n\nSo, putting it all together, the most likely topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32920@AAAI"}
{"title": "Hierarchically Controlled Deformable 3D Gaussians for Talking Head Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hierarchically Controlled Deformable 3D Gaussians for Talking Head Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Talking Head Synthesis\" suggests creating a talking head, which is probably a 3D model of a person's head that can speak. The method uses \"Deformable 3D Gaussians,\" which might be a way to model the head's shape and movements. \"Hierarchically Controlled\" implies there's a structure or layers in how the deformation is managed.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on generating 3D models for talking heads. The key terms here are 3D Gaussians and deformable models. This sounds more like computer graphics or 3D modeling, which isn't directly related to time-series data. There's no mention of combining different modalities like text and images, so multimodal might not fit. RAG and KG are about information retrieval and knowledge representation, which don't seem relevant here. The synthesis of a talking head using 3D models is more about generative models in computer vision or graphics, which isn't listed in the given topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32921@AAAI"},
{"title": "Relaxed Rotational Equivariance via G-Biases in Vision", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Relaxed Rotational Equivariance via G-Biases in Vision.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Relaxed Rotational Equivariance\" sounds like it's about making a model's behavior consistent under rotations, but in a relaxed way. \"G-Biases\" might refer to some kind of bias terms in the model that are related to group theory, maybe? \"In Vision\" suggests it's related to computer vision, like image processing or something.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using external information in models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper seems to be about improving a model's rotational equivariance in vision tasks. That's more about the model's architecture or properties, not about time-series data. It's not combining multiple modalities, so not multimodal. RAG and KG are about data retrieval or knowledge representation, which don't seem related here. The focus is on the model's symmetry properties in vision, which doesn't fit any of the four categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32922@AAAI"},
{"title": "Unified Knowledge Maintenance Pruning and Progressive Recovery with Weight Recalling for Large Vision-Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unified Knowledge Maintenance Pruning and Progressive Recovery with Weight Recalling for Large Vision-Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Large Vision-Language Models\" immediately makes me think of multimodal models because they combine vision (images) and language (text). Multimodal models are all about integrating different types of data, like images and text. So that's a strong hint towards the multimodal category.\n\nNext, the rest of the title talks about knowledge maintenance pruning and progressive recovery with weight recalling. These terms seem related to model optimization or training techniques. Pruning is a common method to reduce model size by removing unnecessary weights. Progressive recovery might involve retraining or adjusting the model after pruning. Weight recalling could be about retaining important weights during pruning. But these are more about model efficiency and training strategies rather than the core topic of the model itself.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time-based data, so probably not that. RAG (Retrieval-Augmented Generation) is a method where a model uses a retrieval system to fetch information and then generates a response. The title doesn't mention retrieval or generation in that context. KG (Knowledge Graph) involves structured data representations, often using graphs to represent entities and relationships. The title mentions \"knowledge maintenance,\" but that's more about preserving knowledge during pruning rather than building or using a knowledge graph.\n\nSo, the key part here is \"Vision-Language Models,\" which are inherently multimodal. The other parts of the title are about techniques applied to these models, but the primary research area is multimodal. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32923@AAAI"},
{"title": "GEONet: Global Enhancement and Optimization Network for Lane Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GEONet: Global Enhancement and Optimization Network for Lane Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This paper is about lane detection, which is more about images or video frames. But lane detection in video could involve time-series if it's tracking over time. However, the title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention using different data modalities, just a network for lane detection. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. This paper is about a network for lane detection, which is a computer vision task. RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data. It's about a neural network for lane detection, so maybe not KG.\n\nSo, the paper is about a neural network (GEONet) for lane detection, focusing on global enhancement and optimization. None of the given topics (time-series, multimodal, RAG, KG) seem to fit. The main focus is on a specific computer vision task using a neural network, which doesn't align with any of the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32924@AAAI"},
{"title": "Enhancing Close-up Novel View Synthesis via Pseudo-labeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Close-up Novel View Synthesis via Pseudo-labeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Close-up Novel View Synthesis\" sounds like it's about generating new views or perspectives, maybe in computer vision. \"Pseudo-labeling\" is a technique used in semi-supervised learning where models generate labels for unlabeled data. So the paper is probably about improving view synthesis using pseudo-labels.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on view synthesis, which is a computer vision task. Pseudo-labeling is a method to improve model training with unlabeled data. None of the four topics directly relate to view synthesis or pseudo-labeling. Time-series is about temporal data, which isn't mentioned here. Multimodal would require combining different modalities, but the title doesn't indicate that. RAG and KG are more about information retrieval and knowledge representation, which don't seem to fit. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32925@AAAI"},
{"title": "Multi-Shape Matching with Cycle Consistency Basis via Functional Maps", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Shape Matching with Cycle Consistency Basis via Functional Maps.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-Shape Matching\" suggests working with multiple shapes, maybe in 3D or some geometric data. \"Cycle Consistency Basis\" might refer to ensuring consistency in transformations, which is a concept I've heard in areas like image registration or graph matching. \"Functional Maps\" is a term I associate with methods for mapping between different shapes or manifolds, often used in computational geometry or computer graphics.\n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is in NLP for enhancing models with external information. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on geometric data and matching between shapes using functional maps. None of the four topics directly relate to time-series data. It's not about combining different data modalities, so not multimodal. RAG and KG are more about information retrieval and structured knowledge, which don't seem to fit here. The key terms like \"shape matching\" and \"functional maps\" are more aligned with computational geometry or computer vision tasks, which aren't covered in the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32926@AAAI"},
{"title": "PlaNet: Learning to Mitigate Atmospheric Turbulence in Planetary Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PlaNet: Learning to Mitigate Atmospheric Turbulence in Planetary Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or weather data. The title mentions planetary images, which might be images, but does it involve time? Maybe if they're analyzing changes over time, but the main focus here is on mitigating atmospheric turbulence, which is about image processing.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title only mentions planetary images, so unless they're using other data types alongside, it might not be multimodal. The problem here is about image processing, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and relationships. The paper's title doesn't suggest building or using a knowledge graph. It's about image processing for planetary images, so likely not KG.\n\nSo the options left are time-series or none. Since the main focus is on mitigating atmospheric turbulence in images, which is an image processing or computer vision task, and none of the four topics seem to fit perfectly. The problem isn't about time-series data, multimodal inputs, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32927@AAAI"},
{"title": "CA-Edit: Causality-Aware Condition Adapter for High-Fidelity Local Facial Attribute Editing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CA-Edit: Causality-Aware Condition Adapter for High-Fidelity Local Facial Attribute Editing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about facial attribute editing, which is image-related. But the title doesn't mention combining different modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically in NLP where a model retrieves information from a database to generate responses. The title here is about editing facial attributes, which seems more like image processing or computer vision. Doesn't look like RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on facial editing using a causality-aware condition adapter. I don't see any mention of knowledge graphs or structured data here.\n\nSo, none of the four topics seem to fit. The paper is about a specific method for facial attribute editing, which involves computer vision techniques, but it doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32928@AAAI"},
{"title": "POPoS: Improving Efficient and Robust Facial Landmark Detection with Parallel Optimal Position Search", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"POPoS: Improving Efficient and Robust Facial Landmark Detection with Parallel Optimal Position Search.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The paper here is about facial landmark detection, which is more image processing, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention combining different modalities, just facial landmarks, which are part of image data. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to enhance their responses. This paper is about detection methods, not retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data. \n\nThe paper's focus is on improving facial landmark detection using a specific algorithm (Parallel Optimal Position Search). Facial landmark detection is part of computer vision, which typically falls under multimodal if combined with other data types, but here it's just about the image processing aspect. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to the methods described in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32929@AAAI"},
{"title": "Wavelet-Driven Masked Image Modeling: A Path to Efficient Visual Representation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Wavelet-Driven Masked Image Modeling: A Path to Efficient Visual Representation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Wavelet-Driven\" probably refers to using wavelet transforms, which are mathematical tools for analyzing data in different scales. \"Masked Image Modeling\" sounds like a technique where parts of an image are masked and the model has to predict them, similar to how BERT works with text. \"Efficient Visual Representation\" suggests it's about creating better or more efficient ways to represent images, maybe for tasks like classification or object detection.\n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to generate responses. KG (Knowledge Graph) is about structured data representing entities and their relationships.\n\nThe paper's focus is on image modeling using wavelets and masking. That seems to be about improving visual representations, which is a part of computer vision. None of the four topics directly relate to this. Time-series is about temporal data, which isn't the case here. Multimodal would involve combining modalities, but the title doesn't mention that. RAG and KG are more about text generation and knowledge representation, not image processing. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32930@AAAI"}
{"title": "Cross-Modal Stealth: A Coarse-to-Fine Attack Framework for RGB-T Tracker", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cross-Modal Stealth: A Coarse-to-Fine Attack Framework for RGB-T Tracker.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Modal\" immediately stands out. That term usually refers to combining or interacting different types of data modalities, like text and images, or in this case, maybe RGB (visible light) and T (thermal) data. So \"cross-modal\" is a key part here. The paper is about an attack framework for an RGB-T tracker. RGB-T would be using both visible and thermal imaging, which are different modalities. So this seems like it's dealing with multiple data types, which points to multimodal.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data over time. The title doesn't mention time or sequences, so probably not that. RAG is Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks, like in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or retrieval-augmented generation. The focus here is on attacking a tracker that uses two different modalities (RGB and thermal), so the cross-modal aspect is central. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32931@AAAI"},
{"title": "ReMask-Animate: Refined Character Image Animation Using Mask-Guided Adapters", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ReMask-Animate: Refined Character Image Animation Using Mask-Guided Adapters.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about image animation, which might involve sequences, but the key here is the method using mask-guided adapters. Not sure if it's time-series.\n\nMultimodal refers to combining different data types, like text and images. The paper is about animating images, but the title doesn't mention combining different modalities. Maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title doesn't mention retrieval or generation in that context. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured data representations. The paper's focus is on image animation techniques, not on knowledge graphs. So that's out.\n\nThe main terms here are \"mask-guided adapters\" for refining character image animation. This seems more related to computer vision or image processing techniques, specifically in generating animations. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32932@AAAI"},
{"title": "SMR-Net: Semantic-Guided Mutually Reinforcing Network for Cross-Modal Image Fusion and Salient Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SMR-Net: Semantic-Guided Mutually Reinforcing Network for Cross-Modal Image Fusion and Salient Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Modal Image Fusion\" immediately makes me think of multimodal because cross-modal usually refers to combining different types of data, like images and text. But wait, image fusion could be combining different images, maybe from different sources or modalities. So cross-modal here might mean integrating different modalities, like infrared and visible images, which are different types of data. That would fit under multimodal.\n\nThen there's \"Salient Object Detection,\" which is about identifying the most noticeable objects in an image. But the key part here is the cross-modal aspect. The paper is using a network that's guided by semantics and mutually reinforcing, which suggests it's handling multiple data types. \n\nLooking at the options: time-series is about data over time, which doesn't seem to fit. RAG (Retrieval-Augmented Generation) is more about using retrieved information to augment generation, typically in NLP. KG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval-augmented generation. \n\nSo the main clue is \"Cross-Modal,\" which directly points to multimodal research. The network is designed to handle different modalities (like images from different sources) and fuse them, which is a classic multimodal problem. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32933@AAAI"},
{"title": "Boosting Vision State Space Model with Fractal Scanning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Boosting Vision State Space Model with Fractal Scanning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision State Space Model\" – state space models are often used in time-series analysis, like in Kalman filters or for sequential data. So maybe time-series? But the term \"vision\" here suggests it's related to computer vision, which is about images or videos. So combining vision with a state space model. State space models can handle sequences, so maybe time-series is part of it. But the main focus here is on improving the model with \"Fractal Scanning.\" \n\nFractal scanning might refer to a method of processing images in a fractal-like pattern, which could be a way to handle spatial data. But how does that tie into the four categories? Let's look at the options again. Time-series is about sequential data over time. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about combining different modalities (text, image, audio), so probably not multimodal. RAG and KG are about knowledge retrieval and structured data, which don't seem to fit here. The key terms are \"Vision\" and \"State Space Model.\" State space models are often used in time-series, but in vision, they might be applied to video sequences or image sequences. However, the mention of \"Fractal Scanning\" might be a novel method for processing the spatial structure of images, which could be part of improving the state space model for vision tasks. \n\nBut the question is whether it fits into one of the four topics. Since the state space model is a time-series method, but applied to vision, maybe it's still time-series? Or is the focus on the vision aspect making it multimodal? Wait, multimodal would require combining different data types. If it's just vision, even with a state space model, it's not multimodal. So perhaps the answer is time-series. Alternatively, if the state space model is being adapted for vision, maybe it's a new approach but still under time-series. \n\nAlternatively, maybe it's none of the four. Let me check the four options again. The options are time-series, multimodal, RAG, KG. The paper is about enhancing a vision model using a state space model with fractal scanning. If the state space model is for time-series, but applied to vision (like video frames), then it's time-series. But if it's for image processing without a temporal component, maybe not. However, state space models are inherently for sequences, so even if processing images in a certain order, it's still time-series. \n\nSo I think the answer is time-series. The other options don't fit. The paper isn't about combining modalities, RAG, or knowledge graphs. So the correct topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32934@AAAI"},
{"title": "Text Proxy: Decomposing Retrieval from a 1-to-N Relationship into N 1-to-1 Relationships for Text-Video Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Text Proxy: Decomposing Retrieval from a 1-to-N Relationship into N 1-to-1 Relationships for Text-Video Retrieval.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on retrieval, specifically text-video retrieval. The method involves decomposing a 1-to-N relationship into N 1-to-1 relationships. The term \"Text Proxy\" suggests using text as a proxy or intermediary in the retrieval process. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series. \n\nMultimodal refers to combining multiple data types, like text and video here. The paper is about text-video retrieval, which is a classic multimodal task. So that's a strong candidate. \n\nRAG stands for Retrieval-Augmented Generation, which typically involves using retrieved information to enhance a generative model. The title mentions retrieval but doesn't specify generation, so maybe not RAG. Unless the method is part of a RAG framework, but the title doesn't mention generation. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention graphs or structured data, so probably not KG. \n\nSo the most likely answer is multimodal. The paper deals with text and video, which are different modalities, and the retrieval between them. The decomposition method is a technique within multimodal retrieval. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32935@AAAI"},
{"title": "Radiology Report Generation via Multi-objective Preference Optimization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Radiology Report Generation via Multi-objective Preference Optimization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on generating radiology reports. That's probably about creating text, maybe using some kind of model. The method mentioned is \"Multi-objective Preference Optimization.\" Hmm, not sure what that exactly means, but the key part here is \"Report Generation.\" \n\nNow, looking at the options. RAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves relevant information from a database and then generates text based on that. Since the title is about generating reports, maybe RAG is involved here. But the paper's title doesn't explicitly mention retrieval, so I need to think if generating reports typically uses RAG. In some cases, report generation might involve retrieving medical data or images and then generating text, which would be RAG. \n\nMultimodal refers to using multiple types of data, like text and images. Radiology reports often involve interpreting medical images (like X-rays or MRIs) and then writing a report. So if the model uses both images and text, that would be multimodal. The title doesn't mention multimodal explicitly, but the process of generating a report from images could be multimodal. However, the title's focus is on the optimization method, not the data types. \n\nTime-series is about data that changes over time, like stock prices or sensor data. Radiology reports might involve time-series data if they track changes over time, but the title doesn't mention that. \n\nKG stands for Knowledge Graphs, which are structured representations of information. If the paper uses a knowledge graph to generate reports, that would be it. But again, the title doesn't mention knowledge graphs. \n\nSo, the main options are RAG and multimodal. The title is about report generation, which could be RAG if it uses retrieval. However, without explicit mention of retrieval, it's a bit uncertain. But given the options, RAG is a common approach for report generation tasks where external information is retrieved. Alternatively, if the model uses both images and text (multimodal), that's another possibility. \n\nBut the title doesn't specify using multiple modalities. The key term is \"Report Generation,\" which is a common application for RAG. So I think the answer is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/32936@AAAI"},
{"title": "FBRT-YOLO: Faster and Better for Real-Time Aerial Image Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FBRT-YOLO: Faster and Better for Real-Time Aerial Image Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. YOLO is a well-known object detection model, right? So this paper is probably improving upon YOLO for real-time detection in aerial images. The key parts here are \"real-time\" and \"aerial image detection.\" \n\nTime-series usually involves data over time, like stock prices or sensor data. This paper is about image detection, which is more about spatial data rather than temporal. So maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention anything about combining different data types, just aerial images. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like in some NLP tasks. This paper is about object detection in images, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo the paper is about improving YOLO for real-time detection in aerial images. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The focus is on object detection, which is a computer vision task, but the given options don't include computer vision or object detection. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32937@AAAI"},
{"title": "Cross-modulated Attention Transformer for RGBT Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cross-modulated Attention Transformer for RGBT Tracking\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"RGBT Tracking\" probably refers to tracking using both RGB (color) and thermal (T) images. So that's two different modalities. Then \"Cross-modulated Attention Transformer\" suggests that the model is using attention mechanisms that interact between these different modalities. \n\nMultimodal research typically involves combining data from multiple sources or types, like combining text and images, or in this case, RGB and thermal. The cross-modulated part implies that the model is integrating these different modalities. So this seems like a multimodal approach. \n\nTime-series would involve data over time, like stock prices or sensor data. While tracking could involve time-series data, the key here is the combination of RGB and thermal, which are different modalities. RAG (Retrieval-Augmented Generation) is more about using retrieval to enhance generation, like in language models. KG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval-augmented generation. \n\nSo the most likely topic here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32938@AAAI"},
{"title": "Spatial Annealing for Efficient Few-shot Neural Rendering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spatial Annealing for Efficient Few-shot Neural Rendering.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Spatial Annealing\" sounds like a technique related to spatial data or spatial transformations. \"Efficient Few-shot Neural Rendering\" suggests it's about rendering in a neural network context, especially with few examples. \n\nTime-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time, so maybe not time-series. \n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention multiple modalities, so probably not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably out.\n\nSo, the paper is about neural rendering with a specific method called spatial annealing. None of the given topics (time-series, multimodal, RAG, KG) seem to fit. The focus is on rendering techniques and efficiency in few-shot learning, which doesn't align with any of the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32939@AAAI"},
{"title": "Occlusion-Embedded Hybrid Transformer for Light Field Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Occlusion-Embedded Hybrid Transformer for Light Field Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Light Field Super-Resolution\" refers to enhancing the resolution of light field images. Light fields capture more information than regular images, including depth and perspective, so they're often used in 3D imaging. The \"Hybrid Transformer\" suggests they're using a transformer model, maybe combining different components. \"Occlusion-Embedded\" might mean they're handling occlusions, which are parts of the image that are blocked or missing.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about image super-resolution, specifically for light fields. That's image processing. The hybrid transformer might be using different modalities, but the title doesn't mention combining different data types. It's more about handling occlusions in the light field data. Since it's focused on image data and not combining different modalities, maybe it's not multimodal. The other topics don't seem to fit either. Time-series is unrelated. RAG and KG are more about data retrieval or structured knowledge, which isn't the focus here. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32940@AAAI"}
{"title": "Omni-Query Active Learning for Source-Free Domain Adaptive Cross-Modality 3D Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's tackle this. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If none fit, I should respond with \"none\".\n\nFirst, I'll break down the title: \"Omni-Query Active Learning for Source-Free Domain Adaptive Cross-Modality 3D Semantic Segmentation\". \n\nStarting with the key terms. \"Cross-Modality\" immediately stands out. The term \"modality\" refers to different types of data, like images, text, audio, etc. So cross-modality suggests the model is working with multiple data types, which points towards multimodal. \n\nNext, \"3D Semantic Segmentation\" is the task here. But the key part is \"Cross-Modality\". For example, maybe the model is trained on one type of data (like RGB images) and tested on another (like LiDAR data), which is common in multimodal research. \n\n\"Source-Free Domain Adaptive\" implies that the model adapts from a source domain to a target domain without access to the source data during adaptation. This is a domain adaptation problem, which can be part of multimodal learning if the domains involve different modalities. \n\n\"Active Learning\" is a technique where the model selects the most informative samples to learn from, but that's more about the learning strategy rather than the data type. \n\n\"Omni-Query\" might refer to handling various types of queries, but again, the main focus here is the cross-modality aspect. \n\nLooking at the four options: time-series deals with sequential data over time, which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, which doesn't fit. KG (Knowledge Graphs) involve structured data representations, which also don't seem relevant. \n\nMultimodal is about combining different data modalities, which aligns with \"Cross-Modality\". The paper is about adapting a model across different modalities (like from RGB to LiDAR) for 3D segmentation. So the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32941@AAAI"},
{"title": "TextRefiner: Internal Visual Feature as Efficient Refiner for Vision-Language Models Prompt Tuning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TextRefiner: Internal Visual Feature as Efficient Refiner for Vision-Language Models Prompt Tuning.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Vision-Language Models\" immediately makes me think of multimodal because those models combine visual (images) and language (text) data. So multimodal is a strong candidate. \n\nThe term \"Prompt Tuning\" might relate to methods like RAG (Retrieval-Augmented Generation), but RAG typically involves retrieving documents to enhance generation. However, the paper here is about refining prompts using internal visual features. The key part is \"Internal Visual Feature as Efficient Refiner.\" Since it's using visual features within the model to refine the prompt for vision-language tasks, that's more about integrating different modalities (vision and language) rather than retrieval. \n\nTime-series is about data over time, which doesn't seem relevant here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. So the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32942@AAAI"},
{"title": "Robust Tracking via Mamba-based Context-aware Token Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Robust Tracking via Mamba-based Context-aware Token Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Robust Tracking\" suggests it's about tracking something over time, maybe in a video or a sequence. \"Mamba-based\" refers to the Mamba model, which I think is a type of model for processing sequences, similar to transformers but maybe more efficient. \"Context-aware Token Learning\" implies that the model is learning tokens (like in vision transformers) that are aware of their context. \n\nNow, the possible topics. Time-series analysis deals with data over time, which tracking could be part of. Multimodal would involve combining different data types like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models. KG (Knowledge Graphs) involve structured data and relationships.\n\nThe paper is about tracking, which is typically a time-series problem because it involves sequences of data points over time. The Mamba model is known for handling sequential data efficiently, which aligns with time-series. The context-aware aspect might relate to understanding the temporal context in the sequence. There's no mention of combining different modalities, so multimodal is probably not it. RAG and KG don't seem relevant here either. So the most likely topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32943@AAAI"},
{"title": "Discrete Prior-Based Temporal-Coherent Content Prediction for Blind Face Video Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Discrete Prior-Based Temporal-Coherent Content Prediction for Blind Face Video Restoration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal-Coherent\" suggests something related to time, so maybe time-series. Time-series analysis deals with data over time, so that's a possibility. The term \"Temporal\" is a big hint here. \n\nNext, \"Blind Face Video Restoration\" – video is inherently a time-series data because it's a sequence of frames over time. So restoring a video would involve handling temporal aspects. The \"Discrete Prior-Based\" part might refer to using some prior knowledge or model that's discrete, but I'm not sure how that connects to the other topics. \n\nMultimodal usually involves combining different types of data, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation tasks, often in NLP. The title doesn't mention retrieval or generation, so RAG seems unlikely. \n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either. \n\nPutting it all together, the key terms are \"Temporal-Coherent\" and \"Video Restoration,\" which point towards time-series analysis. The paper is likely dealing with predicting content over time in a video, which fits under time-series. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32944@AAAI"},
{"title": "Expand VSR Benchmark for VLLM to Expertize in Spatial Rules", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Expand VSR Benchmark for VLLM to Expertize in Spatial Rules.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. VSR probably stands for something related to vision or spatial reasoning. VLLM might be Vision-Language Models. The benchmark is being expanded to focus on spatial rules. So the main idea is improving a benchmark for models that handle spatial reasoning tasks, possibly in vision or multimodal contexts.\n\nTime-series usually involves data over time, like stock prices or weather. This title doesn't mention time, so probably not time-series. Multimodal involves combining different data types, like text and images. Since VLLM is Vision-Language, that's multimodal. But the title is about expanding a benchmark for spatial rules. RAG is Retrieval-Augmented Generation, which is about using external data for generation. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention retrieval or knowledge graphs. The focus is on spatial reasoning, which could be part of multimodal tasks, especially if it's about vision and language. So maybe multimodal? But the key here is whether the expansion of the benchmark is specifically about multimodal aspects. Since VLLM is a multimodal model (vision and language), and the benchmark is for spatial rules, which are part of the tasks these models handle, the topic would be multimodal. The other options don't fit. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32945@AAAI"},
{"title": "PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based Talking Head Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PointTalk: Audio-Driven Dynamic Lip Point Cloud for 3D Gaussian-based Talking Head Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Audio-Driven\" suggests that audio is involved, which is a modality. \"Dynamic Lip Point Cloud\" implies some kind of visual or 3D data. So combining audio and visual data for generating a talking head. That sounds like multimodal because it's using multiple data types (audio and visual). \n\nTime-series usually involves data over time, like stock prices or sensor data. While the talking head does involve a sequence over time (since it's dynamic), the main focus here seems to be on combining different modalities (audio and visual) rather than just analyzing a time series. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation, often in NLP. The title doesn't mention anything about retrieval or generation in that context. \n\nKG (Knowledge Graph) involves structured data and relationships. The paper doesn't mention anything about knowledge graphs or structured data. \n\nSo the key elements are audio and 3D point cloud data being used together. That's multimodal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32946@AAAI"},
{"title": "HieraFashDiff: Hierarchical Fashion Design with Multi-stage Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HieraFashDiff: Hierarchical Fashion Design with Multi-stage Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Hierarchical Fashion Design\" suggests they're creating a structured approach to designing fashion. \"Multi-stage Diffusion Models\" probably refers to using diffusion models in stages, which are a type of generative model. Diffusion models are often used in image generation, so maybe this is about generating fashion images.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on generating fashion designs using a hierarchical, multi-stage approach. There's no mention of time-based data, so time-series is out. It's about generating images (fashion designs), which could be multimodal if combining different data types, but the title doesn't specify that. RAG and KG are more about using external knowledge or information retrieval. The title doesn't mention retrieval or knowledge graphs. So it's probably not any of the four. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32947@AAAI"},
{"title": "Exploring Temporal Event Cues for Dense Video Captioning in Cyclic Co-Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring Temporal Event Cues for Dense Video Captioning in Cyclic Co-Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Event Cues\" suggests something related to time, maybe time-series data. \"Dense Video Captioning\" involves generating captions for videos, which is a task in computer vision and natural language processing. Video data is inherently multimodal because it combines visual and auditory elements. However, the mention of \"cyclic co-learning\" might refer to a method where different models or modalities learn from each other in a cycle. \n\nNow, the options. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is a method that uses retrieval to enhance generation models. KG (Knowledge Graph) involves structured data representations. \n\nThe paper's focus on temporal aspects and video captioning might lean towards time-series, but video captioning is more about understanding sequences of frames, which is a multimodal task. The \"cyclic co-learning\" part could imply using multiple modalities (like video and text) in a loop, which is typical in multimodal research. So, even though there's a temporal element, the primary topic here is likely multimodal because it's about integrating different data types (video and text) for captioning. Time-series might be a component, but the main research area is multimodal learning.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32948@AAAI"},
{"title": "Few-Shot Incremental Learning via Foreground Aggregation and Knowledge Transfer for Audio-Visual Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Few-Shot Incremental Learning via Foreground Aggregation and Knowledge Transfer for Audio-Visual Semantic Segmentation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Few-Shot Incremental Learning\" suggests it's about machine learning techniques where the model learns incrementally with few examples. Then \"Foreground Aggregation and Knowledge Transfer\" might refer to methods used in the learning process. The application is \"Audio-Visual Semantic Segmentation,\" which combines audio and visual data for segmentation tasks.\n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal refers to using multiple data modalities, such as combining text, images, audio, etc. RAG is Retrieval-Augmented Generation, which is about using retrieval systems to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe key part here is \"Audio-Visual,\" which clearly indicates that two modalities (audio and visual) are being used. So this is a multimodal task. The paper is about semantic segmentation using both audio and visual inputs, which fits under multimodal learning. The other parts of the title don't mention anything about time-series data, knowledge graphs, or retrieval-augmented generation. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32950@AAAI"},
{"title": "DiffScene: Diffusion-Based Safety-Critical Scenario Generation for Autonomous Vehicles", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffScene: Diffusion-Based Safety-Critical Scenario Generation for Autonomous Vehicles.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Diffusion-Based\" probably refers to using diffusion models, which are a type of generative model. \"Safety-Critical Scenario Generation\" suggests creating scenarios that are important for safety, especially for autonomous vehicles. So the main idea is generating scenarios using diffusion models to test or improve the safety of autonomous vehicles.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or sensor data over time. Multimodal would involve combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on generating scenarios using diffusion models. Diffusion models are a type of generative model, but the question is whether this falls under any of the listed topics. The key here is that the scenario generation might involve generating sequences (time-series) if the scenarios are time-dependent. However, the title doesn't explicitly mention time-series data. It's more about generating scenarios, which could be spatial or involve sequences, but without more context, it's hard to say. \n\nMultimodal would require combining different data types, but the title doesn't mention that. RAG and KG are about retrieval and knowledge graphs, which don't seem related here. The main technique is diffusion-based generation, which isn't one of the listed topics. So the answer might be \"none\" because none of the four topics directly match the paper's focus. However, if the scenarios involve time-series data (like sequences of events over time), then maybe time-series. But the title doesn't specify that. So I think the correct answer is \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32951@AAAI"}
{"title": "DiffScene: Diffusion-Based Safety-Critical Scenario Generation for Autonomous Vehicles", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffScene: Diffusion-Based Safety-Critical Scenario Generation for Autonomous Vehicles.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Diffusion-Based\" probably refers to using diffusion models, which are a type of generative model. \"Safety-Critical Scenario Generation\" suggests creating scenarios that are important for safety, especially for autonomous vehicles. So the main idea is generating scenarios using diffusion models to test or improve the safety of autonomous vehicles.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or sensor data over time. Multimodal would involve combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on generating scenarios using diffusion models. Diffusion models are a type of generative model, but the question is whether this falls under any of the listed topics. The key here is that the scenario generation might involve generating sequences (time-series) if the scenarios are time-dependent. However, the title doesn't explicitly mention time-series data. It's more about generating scenarios, which could be spatial or involve sequences, but without more context, it's hard to say. \n\nMultimodal would require combining different data types, but the title doesn't mention that. RAG and KG are about retrieval and knowledge graphs, which don't seem related here. The main technique is diffusion-based generation, which isn't one of the listed topics. So the answer might be \"none\" because none of the four topics directly match the paper's focus. However, if the scenarios involve time-series data (like sequences of events over time), then maybe time-series. But the title doesn't specify that. So I think the correct answer is \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/32951@AAAI"},
{"title": "Details Enhancement in Unsigned Distance Field Learning for High-fidelity 3D Surface Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Details Enhancement in Unsigned Distance Field Learning for High-fidelity 3D Surface Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on 3D surface reconstruction using unsigned distance fields. The key terms here are \"unsigned distance field learning\" and \"high-fidelity 3D surface reconstruction.\" \n\nTime-series usually involves data points indexed in time order, like stock prices over time. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention multiple modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on 3D reconstruction, not on building or using knowledge graphs. \n\nSo, none of the four topics seem to fit. The paper is about improving 3D surface reconstruction using distance fields, which is more related to computer vision or machine learning in general, but not specifically any of the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32952@AAAI"},
{"title": "FR²Seg: Continual Segmentation Across Multiple Sites via Fourier Style Replay and Adaptive Consistency Regularization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FR²Seg: Continual Segmentation Across Multiple Sites via Fourier Style Replay and Adaptive Consistency Regularization.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Continual Segmentation\" suggests that the model is learning continuously, maybe adapting over time. \"Across Multiple Sites\" could imply that data comes from different sources or domains. The methods mentioned are \"Fourier Style Replay\" and \"Adaptive Consistency Regularization.\" \n\nFourier Style Replay might relate to using frequency domain techniques for replaying data, which is a common technique in continual learning to prevent forgetting. Adaptive Consistency Regularization sounds like a method to maintain consistency in predictions, possibly across different domains or time steps. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like sequences. The paper's focus on continual learning might involve time, but the title doesn't explicitly mention time-series data. Multimodal would involve combining different data types (e.g., text and images), but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which doesn't seem to fit here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem relevant. \n\nThe key terms here are continual learning and segmentation across multiple sites. Continual learning is about learning sequentially without forgetting, which is different from time-series analysis. The methods used (Fourier replay, consistency regularization) are techniques in machine learning, particularly in domains like computer vision or NLP, but not specifically tied to the four listed topics. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32953@AAAI"},
{"title": "Less Is More: Token Context-Aware Learning for Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Less Is More: Token Context-Aware Learning for Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Token Context-Aware Learning\" suggests that the method uses tokens, which are often used in machine learning, especially in vision and NLP. \"Object Tracking\" is the application area here. So the paper is about improving object tracking using a token-based approach that's context-aware.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on object tracking, which is a computer vision task. The method mentioned uses token context-aware learning. Tokens here might be similar to how Vision Transformers use patches as tokens. The key term is \"context-aware,\" which might relate to understanding the surrounding information of the object in the video frames. However, none of the four topics directly relate to object tracking or token-based learning in this context. Time-series could be a stretch if the tracking involves sequential data over time, but the primary focus here is on the learning method rather than the temporal aspect. Since the paper isn't about combining multiple modalities, RAG, or knowledge graphs, it doesn't fit into any of the given categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32954@AAAI"},
{"title": "3DHumanEdit: Multi-modal Body Part-aware Conditioning Information Integration for 3D Human Manipulation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"3DHumanEdit: Multi-modal Body Part-aware Conditioning Information Integration for 3D Human Manipulation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the title. That's one of the options. The paper talks about integrating information from different modalities, which is a key aspect of multimodal research. The other parts mention body part-aware conditioning and 3D human manipulation, which might relate to computer vision or graphics, but the key term here is \"multi-modal.\" \n\nTime-series usually involves data over time, like sequences. RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about time, retrieval, or knowledge graphs. So the most fitting category here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32955@AAAI"},
{"title": "A Unified Loss for Handling Inter-Class and Intra-Class Imbalance in Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Unified Loss for Handling Inter-Class and Intra-Class Imbalance in Medical Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions medical image segmentation, which is more about images, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining images and text. The title doesn't mention anything about combining different data types, just a loss function for image segmentation. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information and then generate responses. This paper is about a loss function for segmentation, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on handling class imbalance in medical images through a loss function, not on building or using a knowledge graph. \n\nSo none of the four topics seem to fit. The paper is about a specific loss function for image segmentation, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32956@AAAI"},
{"title": "Attention-Driven GUI Grounding: Leveraging Pretrained Multimodal Large Language Models Without Fine-Tuning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Attention-Driven GUI Grounding: Leveraging Pretrained Multimodal Large Language Models Without Fine-Tuning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Attention-Driven GUI Grounding\" – GUI is Graphical User Interface, so this is about grounding in GUIs, probably using attention mechanisms. Then \"Leveraging Pretrained Multimodal Large Language Models Without Fine-Tuning.\" The key term here is \"Multimodal,\" which refers to models that handle multiple types of data, like text and images. The mention of \"Large Language Models\" suggests it's using something like a multimodal LLM, which is definitely in the multimodal category. The fact that they're using pretrained models without fine-tuning might relate to RAG (Retrieval-Augmented Generation), but RAG typically involves retrieving information from a database and generating answers, which isn't explicitly mentioned here. The paper is more about using existing multimodal models for GUI tasks, so the main focus is on the multimodal aspect. Time-series is about data over time, which doesn't fit. KG (Knowledge Graphs) involve structured data, which isn't mentioned. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32957@AAAI"},
{"title": "Exploiting Continuous Motion Clues for Vision-Based Occupancy Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploiting Continuous Motion Clues for Vision-Based Occupancy Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Vision-Based\" suggests that the research uses visual data, like images or videos. \"Occupancy Prediction\" probably refers to predicting where objects or people are in a space over time. \"Continuous Motion Clues\" implies that the study is looking at motion over time, which might involve sequences of data points.\n\nTime-series analysis deals with data points indexed in time order. Since the paper is about motion over time and predicting occupancy, which likely involves sequences of frames or time steps, this could be a time-series topic. \n\nMultimodal would involve combining different types of data, like text and images. The title mentions vision-based, but doesn't specify combining with other modalities, so maybe not multimodal. \n\nRAG (Retrieval-Augmented Generation) is a method that combines retrieval of information with generation, often used in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention knowledge graphs or structured data, so that's unlikely. \n\nSo the most likely topic here is time-series. The focus on continuous motion and prediction over time fits well with time-series analysis.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32958@AAAI"},
{"title": "DanceFix: An Exploration in Group Dance Neatness Assessment Through Fixing Abnormal Challenges of Human Pose", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DanceFix: An Exploration in Group Dance Neatness Assessment Through Fixing Abnormal Challenges of Human Pose.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The paper here is about group dance neatness, which might involve analyzing sequences of movements over time. Human pose estimation could involve time-series data if they're tracking poses frame by frame in a video. So maybe time-series is a possibility.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The title mentions human pose, which is visual data, but does it combine with other modalities? The title doesn't specify other data types, so maybe not multimodal unless they use both video and audio or something else. But the title doesn't mention that, so maybe not.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. This paper seems focused on assessing dance neatness, which is more about analysis and correction rather than generating text based on retrieved data. So probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on human pose and group dance assessment. Unless they're building a knowledge graph of dance moves or something, which isn't indicated in the title, it's unlikely to be KG.\n\nSo the main possibilities are time-series. If the method involves analyzing sequences of poses over time to assess neatness, then time-series makes sense. The \"fixing abnormal challenges\" might involve correcting errors in the time-series data of poses. Therefore, the topic is likely time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32959@AAAI"},
{"title": "OmniSR: Shadow Removal Under Direct and Indirect Lighting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OmniSR: Shadow Removal Under Direct and Indirect Lighting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's collected over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about shadow removal in images, but the title doesn't specify using multiple modalities. It's focused on a specific image processing task, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This paper is about image processing, not text generation or retrieval, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using a knowledge graph. It's about removing shadows in images under different lighting conditions. \n\nSo none of the four topics seem to fit. The paper is about computer vision, specifically image processing for shadow removal. The given options don't cover this area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32961@AAAI"}
{"title": "OmniSR: Shadow Removal Under Direct and Indirect Lighting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OmniSR: Shadow Removal Under Direct and Indirect Lighting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's collected over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper is about shadow removal in images, but the title doesn't specify using multiple modalities. It's focused on a specific image processing task, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This paper is about image processing, not text generation or retrieval, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using a knowledge graph. It's about removing shadows in images under different lighting conditions. \n\nSo none of the four topics seem to fit. The paper is about computer vision, specifically image processing for shadow removal. The given options don't cover this area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32961@AAAI"},
{"title": "CLIP-driven View-aware Prompt Learning for Unsupervised Vehicle Re-identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CLIP-driven View-aware Prompt Learning for Unsupervised Vehicle Re-identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. CLIP is a model that's known for multimodal learning, combining text and images. So \"CLIP-driven\" suggests that the method uses CLIP, which is multimodal. Then \"View-aware Prompt Learning\" might involve using prompts that are aware of different viewpoints, which could be part of the multimodal approach. The application is \"Unsupervised Vehicle Re-identification,\" which is about identifying vehicles without labeled data. \n\nTime-series would involve data over time, like sequences. RAG is Retrieval-Augmented Generation, which uses external knowledge for generation tasks. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about time sequences, retrieval, or knowledge graphs. The key here is CLIP, which is multimodal. So the topic is likely multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32962@AAAI"},
{"title": "Physical-aware Neural Radiance Fields for Efficient Exposure Correction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Physical-aware Neural Radiance Fields for Efficient Exposure Correction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Neural Radiance Fields\" (NeRF) are typically used in 3D scene reconstruction and rendering, right? They take 2D images and create a 3D model. The term \"physical-aware\" suggests that the model incorporates some physical principles, maybe related to light or camera exposure. \"Efficient Exposure Correction\" implies that the method is addressing issues in image exposure, which is a common problem in photography where parts of the image might be too dark or too bright.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of information, often used for semantic relationships.\n\nThe paper's focus seems to be on improving exposure correction in images using a neural network that's aware of physical aspects. This doesn't seem to involve time-series data, as there's no mention of temporal sequences. It's not combining multiple modalities (like text and images), so probably not multimodal. RAG and KG are more about data retrieval and knowledge representation, which don't directly relate to exposure correction in images. \n\nTherefore, the paper doesn't fit into any of the four categories. The main topics here are computer vision and image processing, which aren't listed among the options. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32963@AAAI"},
{"title": "DASK: Distribution Rehearsing via Adaptive Style Kernel Learning for Exemplar-Free Lifelong Person Re-Identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DASK: Distribution Rehearsing via Adaptive Style Kernel Learning for Exemplar-Free Lifelong Person Re-Identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Exemplar-Free Lifelong Person Re-Identification\" suggests that the paper is about continuously identifying people over time without relying on specific examples. That might relate to lifelong learning or continual learning. The method mentioned is \"Distribution Rehearsing via Adaptive Style Kernel Learning.\" \n\nNow, the options. Time-series usually involves data over time, like sequences. Multimodal would involve multiple data types, like combining images and text. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on a method for person re-identification, which is typically a computer vision task. The terms \"Adaptive Style Kernel Learning\" might relate to learning features or representations. \"Distribution Rehearsing\" could be about maintaining knowledge over time, which is part of continual learning. But none of the four topics directly match. The paper doesn't mention time-series data, multimodal inputs, RAG, or knowledge graphs. So maybe it doesn't fit any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32964@AAAI"},
{"title": "Multiple Feature Refining Network for Visual Emotion Distribution Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multiple Feature Refining Network for Visual Emotion Distribution Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Visual Emotion Distribution Learning\" suggests that the research is about understanding emotions from visual data, like images or videos. \"Multiple Feature Refining Network\" implies that they're using a neural network to refine multiple features. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time, so maybe not time-series. \n\nMultimodal refers to combining different types of data, like text and images. The title mentions \"visual,\" which is one modality, but does it combine with others? The title doesn't specify other modalities, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge structures. \n\nSo, the paper is about refining features for visual emotion learning. Since it's focused on visual data and doesn't combine with other modalities, it's not multimodal. The other topics don't fit either. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32965@AAAI"},
{"title": "SCKD: Semi-Supervised Cross-Modality Knowledge Distillation for 4D Radar Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SCKD: Semi-Supervised Cross-Modality Knowledge Distillation for 4D Radar Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Modality\" immediately makes me think of multimodal, since that refers to using multiple types of data or modalities. But let me check the other parts. The method is called \"Knowledge Distillation,\" which is a technique where a smaller model is trained using a larger, more accurate model. But the question is about the research topic, not the specific method. \n\nThe key part here is \"Cross-Modality,\" which typically relates to multimodal learning, where the model uses data from different modalities (like combining images and text, or in this case, radar data with another modality). The 4D radar object detection suggests they're working with radar data, which is a type of sensor data. If they're using cross-modality, they might be integrating radar with another modality like LiDAR or camera data. \n\nTime-series would involve data over time, like stock prices or sensor data over time. But the title doesn't mention time-series explicitly. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem relevant. \n\nSo the main clue is \"Cross-Modality,\" which points to multimodal. Even though the paper is about knowledge distillation, the cross-modality aspect is the key here. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32966@AAAI"},
{"title": "Motion-adaptive Transformer for Event-based Image Deblurring", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Motion-adaptive Transformer for Event-based Image Deblurring.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Event-based Image Deblurring\" suggests that the input is event-based data, which I know is related to neuromorphic sensors, like those in dynamic vision sensors (DVS). These sensors capture changes in brightness over time, so the data is temporal. The term \"Motion-adaptive\" implies that the model adjusts based on motion, which is a temporal aspect. The Transformer here is likely processing sequences, which are time-series data.\n\nNow, looking at the options. Time-series deals with data over time, which fits because event-based data is a sequence of events over time. Multimodal would involve combining different data types, like text and images, but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit.\n\nSo, the paper is about processing event-based data (time-series) using a Transformer model. Therefore, the correct topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32967@AAAI"},
{"title": "LiON: Learning Point-Wise Abstaining Penalty for LiDAR Outlier DetectioN Using Diverse Synthetic Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LiON: Learning Point-Wise Abstaining Penalty for LiDAR Outlier DetectioN Using Diverse Synthetic Data.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data points indexed in time order. The title mentions LiDAR, which is a sensor that collects data over time, but the main focus here is outlier detection. The method uses synthetic data, but I don't see a clear emphasis on time-series analysis techniques like forecasting or temporal patterns.\n\nMultimodal refers to combining multiple data types, like text and images. The paper uses LiDAR data, which is a type of sensor data, but there's no mention of integrating different modalities (e.g., combining LiDAR with camera data). So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about outlier detection in LiDAR data using a penalty method with synthetic data. There's no indication of building or using a knowledge graph here.\n\nSo the paper seems to focus on a machine learning method for outlier detection in LiDAR data. The key terms are \"Learning Point-Wise Abstaining Penalty\" and \"Diverse Synthetic Data.\" Since none of the four topics (time-series, multimodal, RAG, KG) are clearly addressed, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32968@AAAI"},
{"title": "TB-HSU: Hierarchical 3D Scene Understanding with Contextual Affordances", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TB-HSU: Hierarchical 3D Scene Understanding with Contextual Affordances.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Hierarchical 3D Scene Understanding\" suggests that the paper is about understanding 3D scenes in a hierarchical manner. \"Contextual Affordances\" might refer to understanding the possible interactions or functions within the scene based on context. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like sequences or temporal data. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal research deals with combining multiple data types, like text and images. The title mentions 3D scenes, which could involve different modalities (e.g., visual, spatial), but the term \"multimodal\" isn't in the title. However, 3D scene understanding might involve integrating different data sources, so it's a possibility. But I'm not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper is about building or using a knowledge graph for scene understanding, that could fit. However, the title doesn't explicitly mention knowledge graphs. \"Contextual Affordances\" might relate to structured knowledge, but it's not clear.\n\nSo, the options are between multimodal and KG. The paper is about 3D scene understanding, which often involves combining different data types (like RGB-D data, spatial information, etc.), which is multimodal. However, the term \"contextual affordances\" might imply integrating different modalities to understand the scene's context. Alternatively, if the hierarchical structure is part of a knowledge graph, but again, the title doesn't specify that. \n\nGiven that the paper is about 3D scene understanding, which typically involves multiple modalities (e.g., visual, spatial, maybe even textual), I think it's more likely to be multimodal. The mention of \"hierarchical\" might refer to the structure of the model rather than a knowledge graph. So the answer is probably multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32969@AAAI"},
{"title": "PDDM: Pseudo Depth Diffusion Model for RGB-PD Semantic Segmentation Based in Complex Indoor Scenes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PDDM: Pseudo Depth Diffusion Model for RGB-PD Semantic Segmentation Based in Complex Indoor Scenes.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The model is called PDDM, which stands for Pseudo Depth Diffusion Model. The application is for RGB-PD semantic segmentation in complex indoor scenes. So, RGB-PD probably refers to combining RGB (color) images with pseudo depth data. \n\nSemantic segmentation is a computer vision task where each pixel is classified into a category. The use of both RGB and pseudo depth data suggests that the model is using multiple types of data—visual (RGB) and depth information. That makes me think of multimodal learning, where different modalities (like images and depth) are combined. \n\nTime-series would involve data over time, like sequences or videos. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is unlikely. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper seems focused on image segmentation, not on building or using knowledge graphs. \n\nSo, the key here is the combination of RGB and pseudo depth data. That's multimodal because it's using different data types (modalities) to improve the segmentation. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32970@AAAI"}
{"title": "Zero-shot Video Moment Retrieval via Off-the-shelf Multimodal Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Zero-shot Video Moment Retrieval via Off-the-shelf Multimodal Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Zero-shot Video Moment Retrieval\" suggests they're trying to find specific moments in a video without prior training on those specific cases. Then \"via Off-the-shelf Multimodal Large Language Models\" – \"multimodal\" here is a key term. Multimodal typically refers to models that can handle multiple types of data, like text and images or video. So the use of \"multimodal\" in the title points towards the multimodal category. \n\nLooking at the options: time-series is about data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is a method for enhancing models with external information. KG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on using multimodal models for video retrieval, which involves both visual and textual data. So the key term here is \"multimodal,\" which matches one of the given topics. \n\nI don't see any mention of time-series analysis, RAG techniques, or knowledge graphs in the title. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32971@AAAI"},
{"title": "HOIMamba: Efficient Mamba-based Disentangled Progressive Learning for HOI Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HOIMamba: Efficient Mamba-based Disentangled Progressive Learning for HOI Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. HOI stands for Human-Object Interaction, which is a computer vision task. The model is called HOIMamba, based on Mamba, which I think is a type of model architecture. Disentangled Progressive Learning suggests a method for learning features step by step, separating different aspects. \n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually combines different data types, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about HOI detection, which is image or video analysis. Mamba is a model that might be used for sequences, but the key here is the application. Since HOI detection is a vision task, and the title doesn't mention combining different modalities (like text and images), it's probably not multimodal. It's not about time-series unless the model is specifically for temporal data. The title doesn't mention retrieval or knowledge graphs. So the answer might be none. Wait, but maybe Mamba is related to time-series? Mamba is a type of state-space model, which can handle sequences, so maybe time-series? But HOI detection is more about spatial interactions in images or videos. Hmm. If the model uses Mamba for processing sequences in the video, then it could be time-series. But the title doesn't specify that. The main focus is on disentangled learning for HOI, which is a vision task. So maybe none of the four topics. I think the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32972@AAAI"},
{"title": "OOTDiffusion: Outfitting Fusion Based Latent Diffusion for Controllable Virtual Try-On", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OOTDiffusion: Outfitting Fusion Based Latent Diffusion for Controllable Virtual Try-On\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"OOTDiffusion\" probably refers to a method or model. \"Outfitting Fusion Based Latent Diffusion\" suggests that they're using some kind of fusion technique in a latent diffusion model. \"Controllable Virtual Try-On\" implies that the application is about trying on clothes virtually, which is a common task in computer vision and fashion tech.\n\nNow, the four topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieval to enhance generative models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on virtual try-on, which typically involves image generation and might use multimodal data (e.g., text descriptions and images). The term \"fusion based\" might indicate combining different modalities, like images and textual attributes. So, multimodal could be a fit here. \n\nBut wait, the method is based on latent diffusion. Diffusion models are a type of generative model, often used in image generation. If they're fusing different modalities (like images and text) in the latent space, that would be multimodal. RAG is more about using retrieved information to augment generation, which doesn't seem to be the case here. KGs are about structured knowledge, which isn't mentioned. Time-series is unrelated. So the most likely topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32973@AAAI"},
{"title": "FLAME: Learning to Navigate with Multimodal LLM in Urban Environments", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FLAME: Learning to Navigate with Multimodal LLM in Urban Environments.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal LLM\" stands out. Multimodal usually refers to using multiple types of data, like combining text, images, audio, etc. So if the paper is about using a large language model (LLM) that processes multiple modalities, that would fall under the multimodal category. \n\nThe other parts of the title mention navigation in urban environments. That's the application area, but the key term here is \"multimodal.\" The other options are time-series (which deals with sequential data over time), RAG (Retrieval-Augmented Generation, which is about enhancing models with external information retrieval), and KG (Knowledge Graphs, which are structured representations of knowledge). \n\nSince the title explicitly mentions \"Multimodal,\" and the other terms don't seem to align with the other options, the correct topic should be multimodal. There's no indication of time-series data, RAG techniques, or knowledge graphs in the title. So the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32974@AAAI"},
{"title": "FATE: Feature-Adapted Parameter Tuning for Vision-Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FATE: Feature-Adapted Parameter Tuning for Vision-Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Vision-Language Models\" immediately makes me think of multimodal because vision and language are two different modalities. So that's a hint towards the multimodal category. The term \"Feature-Adapted Parameter Tuning\" sounds like it's about adjusting parameters based on features, which could be a method in training these models. \n\nNow, checking the options. Time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is a specific technique in NLP where the model retrieves information from a database to generate answers. KG (Knowledge Graph) involves structured data and relationships. The paper's focus is on tuning parameters for vision and language models, which are multimodal. So the answer should be multimodal. I don't see any mention of time-series data, RAG, or knowledge graphs in the title. Therefore, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32975@AAAI"},
{"title": "Toward Modality Gap: Vision Prototype Learning for Weakly-supervised Semantic Segmentation with CLIP", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Toward Modality Gap: Vision Prototype Learning for Weakly-supervised Semantic Segmentation with CLIP\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Modality Gap\" suggests something related to different data modalities, like combining different types of data such as images and text. \"Vision Prototype Learning\" might be about learning visual features. \"Weakly-supervised Semantic Segmentation\" refers to a type of machine learning where the model is trained with less labeled data. \"CLIP\" is a model that connects images and text, so it's multimodal by nature.\n\nMultimodal research typically involves integrating multiple data types, like combining visual and textual information. CLIP is a well-known multimodal model that uses both images and text. The mention of \"modality gap\" implies addressing the differences between different modalities, which is a key issue in multimodal learning. The paper's focus on vision (images) and using CLIP, which is multimodal, points towards multimodal research. \n\nTime-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, often in NLP. KG (Knowledge Graphs) involves structured data representations. None of these seem to fit the title as well as multimodal does. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32976@AAAI"},
{"title": "FreeCap: Hybrid Calibration-Free Motion Capture in Open Environments", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FreeCap: Hybrid Calibration-Free Motion Capture in Open Environments.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Motion capture\" usually involves tracking movement over time, which might relate to time-series data. But the term \"hybrid\" and \"calibration-free\" could imply using multiple data sources or methods. \"Open environments\" might suggest real-world settings where multiple sensors or modalities are used.\n\nTime-series analysis deals with data points indexed in time order. Motion capture does involve time-series data because it tracks movement over time. However, the question is whether the paper's main focus is on time-series analysis techniques. The title mentions \"hybrid calibration-free,\" which might refer to combining different methods or sensors without needing prior calibration. That sounds like multimodal, which involves integrating data from multiple sources or modalities (like video, audio, sensors). \n\nRAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, which doesn't seem related here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo, the key terms are \"hybrid\" and \"calibration-free.\" Hybrid could mean combining different modalities, like using both visual and inertial sensors. Calibration-free might mean not relying on pre-set calibrations, which could involve integrating multiple data streams. Therefore, this seems like a multimodal approach. Time-series is a component, but the main topic here is the integration of different modalities without calibration. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32977@AAAI"},
{"title": "Towards Adversarially Robust Dataset Distillation by Curvature Regularization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Adversarially Robust Dataset Distillation by Curvature Regularization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Adversarially Robust\" suggests that the research is about making models resistant to adversarial attacks. \"Dataset Distillation\" refers to the process of creating a smaller, more efficient dataset that still maintains the model's performance. \"Curvature Regularization\" is a technique that might involve using the curvature of the loss function to regularize the model, preventing overfitting or improving robustness.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention different data modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation models, often used in NLP. The title doesn't mention retrieval or generation, so RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data, so that's unlikely.\n\nSo, the paper is about dataset distillation with curvature regularization for adversarial robustness. None of the four topics (time-series, multimodal, RAG, KG) seem to directly relate to this. The focus is on model robustness and dataset compression, which doesn't fall under the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32978@AAAI"},
{"title": "ShotVL: Human-Centric Highlight Frame Retrieval via Language Queries", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ShotVL: Human-Centric Highlight Frame Retrieval via Language Queries.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"ShotVL\" probably refers to a model or method. \"Human-Centric Highlight Frame Retrieval\" suggests they're retrieving specific frames (like in videos) that are highlights, focusing on humans. \"Via Language Queries\" means they're using text or language to query these frames. \n\nSo, the key elements here are using language to retrieve video frames. That sounds like a task that involves both text (language) and video (which is a form of visual data). Multimodal research deals with combining different types of data, like text and images or video. So if the paper is about using language to retrieve visual frames, that's a classic multimodal problem. \n\nTime-series usually involves data over time, like stock prices or sensor data. While video is a time-series of frames, the main focus here seems to be on the combination of language and visual data rather than the temporal aspect. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, but the title doesn't mention generation. KG (Knowledge Graphs) involve structured data and relationships, which doesn't seem to fit here. \n\nTherefore, the most likely topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32979@AAAI"},
{"title": "RetouchGPT: LLM-based Interactive High-Fidelity Face Retouching via Imperfection Prompting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RetouchGPT: LLM-based Interactive High-Fidelity Face Retouching via Imperfection Prompting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"LLM-based\" refers to a Large Language Model. The task is face retouching, which is an image processing task. The method uses \"Imperfection Prompting,\" which sounds like using prompts to guide the model. The term \"Interactive\" suggests user interaction, but that's not one of the options.\n\nNow, the four options: time-series deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper uses an LLM for face retouching. Face retouching is an image task, but the model is based on an LLM. However, LLMs are typically for text, so maybe it's multimodal if it combines text and images. The prompt is about imperfections, which might be text-based instructions. If the model takes both text prompts and images, then it's multimodal. But if it's just using the LLM to generate retouching instructions based on text prompts without integrating other modalities, maybe not. However, the term \"High-Fidelity Face Retouching\" suggests image output, so combining text (prompts) and images would make it multimodal. \n\nRAG involves retrieving information to help generate responses. The paper doesn't mention retrieving data, so probably not RAG. KG is about structured knowledge, which doesn't seem relevant here. Time-series is unrelated. So the most likely is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32980@AAAI"}
{"title": "Physical Marker: Revealing Invisible Hyperlinks Hidden in Printed Trademarks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Physical Marker: Revealing Invisible Hyperlinks Hidden in Printed Trademarks.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper talks about printed trademarks, which are visual, but the title doesn't mention combining different data types. Maybe there's a method involving images and text, but I'm not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't mention anything about retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's focus seems to be on hidden hyperlinks in trademarks. Hyperlinks could relate to connections between data points, but the term \"knowledge graph\" isn't mentioned. It might be about creating a graph structure, but the title is more about revealing hidden links rather than building a knowledge graph.\n\nThe term \"Physical Marker\" suggests something tangible, maybe a visual or physical indicator. \"Invisible Hyperlinks\" implies some kind of hidden connection or data embedded in the trademarks. This could be a method to encode information in physical objects, perhaps using images or markers that can be scanned. If it's about combining different modalities (like visual and digital), maybe multimodal. But the key here is whether it's using multiple data types. If the method involves both visual markers and some digital data, then multimodal. However, if it's just about encoding hyperlinks in physical markers without combining different data types, it might not be multimodal. \n\nAlternatively, if the hyperlinks are part of a knowledge graph structure, but the title doesn't specify that. The main idea seems to be about revealing hidden links in printed trademarks, which could be a security or data embedding technique. Since none of the four topics directly relate to data embedding, security, or physical markers, maybe the answer is \"none.\" But I need to check again. \n\nWait, multimodal could be if they use both image data (the trademark) and some other data type (like text or digital links). If the method involves processing the image to extract the hyperlink, which is a different modality, then it's multimodal. But the title doesn't explicitly state that. The term \"hyperlinks\" is digital, but the marker is physical. So maybe it's about encoding digital info into physical objects, which could be a form of multimodal interaction. However, without more context, it's hard to be certain. But given the options, the closest might be multimodal. Alternatively, if it's about knowledge graphs, but the title doesn't mention that. \n\nHmm. I'm leaning towards \"none\" because the topics listed don't seem to fit. The paper is about a physical marker revealing hyperlinks, which is more about data embedding or security, not time-series, multimodal, RAG, or KG. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32981@AAAI"},
{"title": "TG-LLaVA: Text Guided LLaVA via Learnable Latent Embeddings", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TG-LLaVA: Text Guided LLaVA via Learnable Latent Embeddings.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. \"Text Guided\" suggests that text is being used to guide something. \"LLaVA\" is likely a model name, maybe a variant of LLaVA, which I recall is a multimodal model that combines vision and language. The phrase \"via Learnable Latent Embeddings\" implies that they're using some kind of embeddings that are learned during training. \n\nMultimodal models typically handle multiple data types, like text and images. Since LLaVA is known for that, this might be a multimodal model. The \"Text Guided\" part could mean that the model uses text to influence or guide the processing of another modality, like images. That fits with multimodal research where different modalities interact.\n\nTime-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about sequences over time, so probably not that. RAG (Retrieval-Augmented Generation) involves using retrieval systems to augment model outputs, often in text generation. The title doesn't mention retrieval or augmentation, so maybe not RAG. KG (Knowledge Graphs) involve structured data and relationships between entities. Again, the title doesn't mention graphs or structured knowledge, so probably not KG.\n\nPutting it all together, the use of \"Text Guided\" with a model like LLaVA, which is multimodal, suggests that this paper is about combining text and another modality (likely vision) using learnable embeddings. So the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32982@AAAI"},
{"title": "EvSTVSR: Event Guided Space-Time Video Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EvSTVSR: Event Guided Space-Time Video Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Event Guided\" suggests that events are part of the input or guidance. \"Space-Time Video Super-Resolution\" implies that the video is being processed in both spatial and temporal dimensions. Super-resolution usually refers to enhancing the resolution, so this is about improving video quality, considering both space (frames) and time (sequence of frames).\n\nTime-series analysis deals with data points indexed in time order. Since video is a sequence of frames over time, that's definitely a time component. But the title also mentions \"Space-Time,\" which combines spatial (each frame's pixels) and temporal (sequence of frames) aspects. So time-series might be a candidate here.\n\nMultimodal refers to using multiple types of data, like combining text, images, audio, etc. The title doesn't mention different modalities, just video, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't indicate any use of knowledge graphs, so that's out.\n\nSo the main contenders are time-series and multimodal. Since the paper is about video super-resolution with space-time aspects, and video is inherently a time-series of images, I think time-series is the right category here. The \"Event Guided\" part might refer to using event data (like from event cameras) to guide the super-resolution process, which still fits under time-series processing for video.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32983@AAAI"},
{"title": "SymmCompletion: High-Fidelity and High-Consistency Point Cloud Completion with Symmetry Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SymmCompletion: High-Fidelity and High-Consistency Point Cloud Completion with Symmetry Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Point cloud completion is about generating or completing 3D point cloud data, which is a type of geometric data. The key terms here are \"symmetry guidance,\" \"high-fidelity,\" and \"high-consistency.\" \n\nTime-series usually involves data over time, like stock prices or sensor data over time. This doesn't seem to fit because the title is about 3D point clouds, not temporal data.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation in that context, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on point cloud completion using symmetry, which is more about geometric data processing rather than knowledge representation. \n\nSo, the paper is about completing point clouds using symmetry, which is a specific technique in 3D data processing. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32984@AAAI"},
{"title": "Towards Universal Rainy Image Restoration: Benchmark and Baseline", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Universal Rainy Image Restoration: Benchmark and Baseline.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Rainy Image Restoration\" sounds like an image processing task. The goal is probably to remove rain from images, making them clearer. The mention of \"Benchmark and Baseline\" suggests they're creating a standard dataset or evaluation method for this task.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This doesn't seem related to time-based data. Multimodal refers to using multiple types of data, like combining text and images. The paper is about image restoration, which is a single modality (images), so maybe not multimodal. RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generative models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper is focused on image restoration, which is a computer vision task. None of the listed topics (time-series, multimodal, RAG, KG) directly relate to image restoration. The closest might be multimodal if they were combining different data types, but the title doesn't indicate that. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32985@AAAI"},
{"title": "SGTC: Semantic-Guided Triplet Co-training for Sparsely Annotated Semi-Supervised Medical Image Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SGTC: Semantic-Guided Triplet Co-training for Sparsely Annotated Semi-Supervised Medical Image Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on medical image segmentation. The method is called Semantic-Guided Triplet Co-training. The key terms here are \"semi-supervised,\" \"sparsely annotated,\" and \"medical image segmentation.\" \n\nTime-series usually involves data over time, like stock prices or sensor data over time. This title doesn't mention anything about time, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title is about image segmentation, but there's no mention of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge bases, so that's probably not it either.\n\nThe paper is about a semi-supervised method for image segmentation with sparse annotations. The techniques mentioned (triplet co-training, semantic guidance) are specific to improving model training with limited labeled data. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32986@AAAI"},
{"title": "OLiDM: Object-aware LiDAR Diffusion Models for Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OLiDM: Object-aware LiDAR Diffusion Models for Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"LiDAR\" refers to Light Detection and Ranging, which is a remote sensing method used in autonomous vehicles to create 3D maps of the environment. \"Diffusion Models\" are a type of generative model, often used in machine learning for tasks like image generation. The term \"Object-aware\" suggests that the model is designed to recognize or be aware of objects in the LiDAR data. \n\nNow, looking at the possible topics. Time-series would involve data that is sequential over time, like stock prices or sensor data over time. Multimodal refers to models that use multiple types of data, such as combining text, images, and audio. RAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in question-answering systems. KG is Knowledge Graph, which involves structured data representing entities and their relationships.\n\nThe paper's focus is on LiDAR data and diffusion models for autonomous driving. LiDAR data is typically spatial data, but in autonomous driving, it's often processed over time as the vehicle moves, so there might be a time-series component. However, the main innovation here seems to be the object-aware aspect of the diffusion model. Diffusion models themselves are a type of generative model, but the question is whether this falls under any of the specified topics.\n\nTime-series could be a possibility if the model processes LiDAR data over time. However, the title doesn't explicitly mention time-series processing. The term \"diffusion models\" is more about the type of model rather than the data type. Multimodal would require combining different data modalities, like LiDAR with camera or radar data. The title only mentions LiDAR, so maybe not multimodal. RAG and KG don't seem relevant here. The paper is about a specific model for LiDAR data in autonomous driving, which might involve time-series aspects, but the title doesn't clearly indicate that. Since the options are time-series, multimodal, RAG, or KG, and the title doesn't mention any of these, the answer might be \"none.\" But wait, maybe the LiDAR data is sequential, so time-series? But the model is a diffusion model, which is a generative model. The key here is whether the research topic is one of the four. Since the paper is about a diffusion model for LiDAR in autonomous driving, and none of the four topics (time-series, multimodal, RAG, KG) are explicitly mentioned or implied in the title, the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32987@AAAI"},
{"title": "Data-Free Universal Attack by Exploiting the Intrinsic Vulnerability of Deep Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Data-Free Universal Attack by Exploiting the Intrinsic Vulnerability of Deep Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title is about an attack on deep models, but there's no indication of using multiple data modalities here. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP. The paper's title is about an attack, not about retrieval or generation. So RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nThe paper is about a data-free universal attack, which sounds like an adversarial attack method. Adversarial attacks are a topic in machine learning security, but none of the given options (time-series, multimodal, RAG, KG) directly relate to adversarial attacks. The options provided don't cover security or attack methods. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32988@AAAI"},
{"title": "PBECount: Prompt-Before-Extract Paradigm for Class-Agnostic Counting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PBECount: Prompt-Before-Extract Paradigm for Class-Agnostic Counting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Prompt-Before-Extract\" sounds like a method where you use a prompt before extracting something. \"Class-Agnostic Counting\" probably means it can count objects without needing to know their specific classes beforehand. So, maybe it's related to image or video analysis where you count objects regardless of their type.\n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper's focus on counting without class-specific information might be in computer vision, perhaps using prompts to guide the model. The \"Prompt-Before-Extract\" part makes me think of prompting techniques, which are common in multimodal models that handle both text and images. For example, using a text prompt to guide an image analysis model. Since class-agnostic counting could involve using textual prompts to generalize across different object classes, this might fall under multimodal research, combining text (prompts) and visual data (images for counting). \n\nRAG is more about using retrieved documents to generate answers, which doesn't seem to fit here. KGs are about structured knowledge, which also doesn't align. Time-series is unrelated to object counting. So the most likely topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32989@AAAI"},
{"title": "Multi-Teacher Knowledge Distillation with Reinforcement Learning for Visual Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Teacher Knowledge Distillation with Reinforcement Learning for Visual Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Teacher Knowledge Distillation\" – knowledge distillation is a method where a smaller model (student) learns from a larger model (teacher). So multiple teachers here. Then \"with Reinforcement Learning\" – that's a type of machine learning where an agent learns by taking actions to maximize some reward. The application is \"for Visual Recognition,\" which is about image or video processing.\n\nNow, the four options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to generate answers. KG is Knowledge Graph, which structures information in a graph format.\n\nThe paper uses reinforcement learning in knowledge distillation for visual recognition. Visual recognition is typically a computer vision task, which is unimodal (just images). There's no mention of combining different modalities like text and images, so maybe not multimodal. RAG and KG are more about information retrieval and structured knowledge, which don't seem to fit here. The main focus is on knowledge distillation and reinforcement learning in a visual context. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to knowledge distillation or reinforcement learning in this context, the answer might be \"none.\" But wait, maybe multimodal? Wait, visual recognition is a single modality. Unless the knowledge distillation involves multiple modalities, but the title doesn't specify that. The \"multi-teacher\" part refers to multiple models, not data modalities. So probably not multimodal. So the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/32990@AAAI"}
{"title": "Robust Image Hashing Based on Contrastive Masked Autoencoder with Weak-Strong Augmentation Alignment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Robust Image Hashing Based on Contrastive Masked Autoencoder with Weak-Strong Augmentation Alignment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on image hashing. Image hashing is a technique used to generate compact representations (hashes) of images for tasks like retrieval or similarity checks. The method mentioned is a Contrastive Masked Autoencoder with Weak-Strong Augmentation Alignment. \n\nContrastive learning is a common approach in self-supervised learning where the model learns to distinguish between similar and dissimilar data points. Masked Autoencoders (MAE) are a type of model that reconstructs masked parts of the input, often used in vision tasks. The Weak-Strong Augmentation part refers to using different levels of data augmentation to create pairs for contrastive learning. \n\nNow, looking at the four topics. Time-series would involve data over time, like stock prices or sensor data. The paper is about images, so probably not time-series. Multimodal research deals with combining different data types, like text and images. The title only mentions image hashing, so maybe not multimodal. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in language models. The paper's focus is on hashing for robustness, not retrieval-augmented generation. KG is Knowledge Graphs, which involve structured data and relationships. The paper doesn't mention anything about knowledge graphs.\n\nSo, the paper is about image hashing using a specific neural network architecture. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The closest might be multimodal if there were multiple data types, but since it's only images, it's not. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32991@AAAI"},
{"title": "PlanLLM: Video Procedure Planning with Refinable Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PlanLLM: Video Procedure Planning with Refinable Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video Procedure Planning\" suggests that the paper is about planning procedures using video. Since video involves both visual and temporal data, maybe it's related to multimodal because it combines different data types like video (visual) and possibly text or other modalities. But wait, the main focus here is on using a large language model (LLM) for planning. The term \"Refinable Large Language Models\" might indicate that the model is being adapted or refined for this specific task. \n\nNow, considering the options. Time-series usually deals with data over time, like stock prices or sensor data. While video does have a time component, the key here is the combination of video (a visual modality) with language models, which are text-based. So multimodal could be a fit because it's using multiple modalities (video and text). \n\nRAG (Retrieval-Augmented Generation) involves using retrieval systems to augment the generation process of a model. The title doesn't mention retrieval, so maybe not RAG. KG (Knowledge Graphs) involve structured data and relationships, which isn't directly mentioned here. \n\nSo the most likely is multimodal. The paper is using video (visual) and language models (text) together, which are different modalities. The planning aspect might involve processing the video input and generating procedural steps, which would require integrating different data types. Therefore, the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/32992@AAAI"},
{"title": "3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The dataset is called 3CAD, which probably stands for 3C Anomaly Detection. 3C products usually refer to computers, communications, and consumer electronics. The dataset is for unsupervised anomaly detection. \n\nNow, the question is about the research topic. Time-series would involve data points indexed in time order, like stock prices over time. Multimodal would involve multiple types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about combining retrieval with generative models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about a dataset for anomaly detection. The key here is what kind of data the dataset contains. The title mentions \"3C product dataset,\" but doesn't specify if it's time-series data, multimodal, etc. However, the term \"unsupervised anomaly detection\" is a method, not the data type. \n\nSince the dataset is for 3C products, which are physical products, maybe it's sensor data or something else. But without more info, I have to go by the title. The title doesn't mention time-series aspects, multiple modalities, RAG, or knowledge graphs. So it might not fit any of the four categories. \n\nTherefore, the answer is \"none\" because the title doesn't clearly indicate any of the specified topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/32993@AAAI"},
{"title": "CLIP-MSM: A Multi-Semantic Mapping Brain Representation for Human High-Level Visual Cortex", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CLIP-MSM: A Multi-Semantic Mapping Brain Representation for Human High-Level Visual Cortex.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. CLIP-MSM probably refers to a model or method. \"Multi-Semantic Mapping\" suggests that it's dealing with multiple semantic aspects. \"Brain Representation\" implies it's related to how the brain processes information. \"Human High-Level Visual Cortex\" points to neuroscience, specifically the visual processing areas of the brain.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to combining different types of data, like text and images. The term \"Multi-Semantic\" might hint at multiple modalities, but the title specifically mentions the brain's visual cortex. However, \"Multi-Semantic Mapping\" could imply integrating different semantic layers or modalities. But I'm not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representations. The title doesn't mention graphs or structured knowledge, so likely not KG.\n\nSo, the options are between multimodal and none. The term \"Multi-Semantic\" might relate to multimodal if it's combining different types of semantic information. However, the focus here is on brain representations and the visual cortex. If the model is integrating different semantic aspects (like combining visual and textual semantics), that could be multimodal. But if it's just about mapping different semantic layers within the same modality (e.g., visual), then it's not multimodal. \n\nThe title says \"Multi-Semantic Mapping Brain Representation,\" which might mean it's mapping multiple semantic features or layers within the brain's visual processing. Since it's about the brain's high-level visual cortex, it's more about neuroscience and how the brain represents information, not necessarily combining different data modalities. Therefore, it might not fit into the multimodal category either. \n\nSo, if none of the four topics (time-series, multimodal, RAG, KG) are clearly indicated, the answer would be \"none.\" But I need to be careful. The term \"Multi-Semantic\" could be a red herring. If the model uses multiple modalities (like combining fMRI data with text or images), then it's multimodal. But the title doesn't specify that. It just mentions the brain's visual cortex. So without more context, it's safer to say it doesn't fit into any of the given topics. Therefore, the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32994@AAAI"},
{"title": "PointDGMamba: Domain Generalization of Point Cloud Classification via Generalized State Space Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PointDGMamba: Domain Generalization of Point Cloud Classification via Generalized State Space Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on domain generalization for point cloud classification using a Generalized State Space Model. The term \"PointDGMamba\" probably refers to the model or method they're proposing. \n\nDomain generalization is about making models perform well on unseen domains, which is a common challenge in machine learning. Point cloud classification relates to 3D data processing, like LiDAR data. The Generalized State Space Model (GSSM) is a type of model used for sequential data, which might be related to time-series. But wait, time-series typically involves data over time, like stock prices or sensor data over time. However, point clouds are spatial data, not necessarily temporal. So maybe the GSSM here is being adapted for spatial data, but the core model might still be a state space model, which is often used in time-series analysis.\n\nLooking at the four options: time-series, multimodal, RAG, KG. \n\n- Time-series: If the model uses a state space model, which is common in time-series, but the application here is point clouds. However, the GSSM might be a variant that's not strictly for time-series. But the question is whether the research topic is about time-series. Since the problem is domain generalization for point clouds, maybe the time-series aspect isn't the main focus. Unless the GSSM is being used in a way that inherently deals with temporal aspects, but the title doesn't mention time. \n\n- Multimodal: This would involve combining different data types, like text and images. The title doesn't mention multiple modalities, so probably not this one.\n\n- RAG (Retrieval-Augmented Generation): That's more about using retrieval mechanisms to enhance generation, like in language models. Doesn't seem related here.\n\n- KG (Knowledge Graph): Involves structured data and relationships. The title doesn't mention knowledge graphs.\n\nSo the only possible fit is time-series. But wait, the GSSM is a type of model that's used in time-series, but the application here is to point clouds. However, the research topic might still be considered under time-series if the model is a time-series model. Alternatively, maybe the problem isn't time-series. The key is whether the research topic is about time-series. Since the model is a Generalized State Space Model, which is a time-series model, even if applied to non-temporal data, the research could be categorized under time-series. But I'm a bit confused here. Maybe the GSSM is being used for spatial data, but the model itself is a time-series model. So the research topic would be time-series. Alternatively, if the application is not time-series, maybe it's none. But the options are to pick one of the four. \n\nAlternatively, maybe the paper is about domain generalization, which is a broader topic, but the question is about the specific research topics listed. Since the model uses a state space model, which is a time-series method, perhaps the answer is time-series. I think that's the best fit here.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32995@AAAI"},
{"title": "Pinwheel-shaped Convolution and Scale-based Dynamic Loss for Infrared Small Target Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Pinwheel-shaped Convolution and Scale-based Dynamic Loss for Infrared Small Target Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data over time. The title mentions infrared small target detection, which sounds like image processing, maybe computer vision. So maybe not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The title doesn't mention combining different data types, just a specific convolution method and loss function for infrared detection. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on convolution and loss functions for a specific detection task, not on building or using knowledge graphs. So KG is probably not it either.\n\nSo the answer should be \"none\" because the paper's topic is about computer vision techniques for infrared target detection, which doesn't fit any of the given categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/32996@AAAI"},
{"title": "Diffusion Prior Interpolation for Flexibility Real-World Face Super-Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Diffusion Prior Interpolation for Flexibility Real-World Face Super-Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Diffusion Prior Interpolation\" sounds like a method involving diffusion models, which are often used in generative models for images. \"Flexibility Real-World Face Super-Resolution\" refers to enhancing the resolution of real-world face images, making them clearer. Super-resolution is a common task in image processing.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. This paper is about images, so probably not time-series. Multimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities, just face images. RAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. KG is Knowledge Graphs, which are structured data representations. \n\nThe paper seems focused on image super-resolution using a diffusion model. None of the four topics (time-series, multimodal, RAG, KG) directly relate to image super-resolution or diffusion models. The methods mentioned don't align with any of these categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/32997@AAAI"},
{"title": "Semi-Supervised Clustering Framework for Fine-grained Scene Graph Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Semi-Supervised Clustering Framework for Fine-grained Scene Graph Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Semi-Supervised Clustering Framework\" suggests a machine learning approach that uses both labeled and unlabeled data. Then \"Fine-grained Scene Graph Generation\" – scene graphs are typically used in computer vision to represent objects and their relationships in an image. So generating a scene graph would involve identifying objects and their interactions, which is a structured representation.\n\nNow, looking at the options. Time-series deals with data over time, like stock prices or sensor data. This title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The paper is about scene graphs, which might involve images and maybe text, but the title doesn't explicitly mention multiple modalities. It's possible, but not certain.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention retrieval or generation in that context, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of entities and their relationships. Scene graphs are similar in that they represent objects (entities) and their relationships. So generating a scene graph could be related to knowledge graphs. However, scene graphs are more specific to images, whereas knowledge graphs are broader and can be constructed from various sources. But the term \"scene graph\" is often associated with computer vision tasks, so maybe it's not exactly a knowledge graph. \n\nWait, the problem is to choose between the four given topics. The paper's focus is on generating scene graphs, which are structured data representing objects and relations. Knowledge Graphs (KG) are also structured data with entities and relations. So maybe this is related to KG. However, scene graphs are typically part of computer vision, while KGs are more about semantic relationships in data. But the question is whether the paper's topic aligns with one of these four. \n\nAlternatively, multimodal could be a fit if the scene graph generation involves combining different data types. For example, if the framework uses both images and text to generate the scene graph, that would be multimodal. But the title doesn't specify that. It just mentions a clustering framework for scene graph generation. \n\nRAG is about retrieval and generation, which doesn't seem to fit here. Time-series is out. \n\nSo between multimodal and KG. The key is whether scene graph generation is considered part of knowledge graphs. Since scene graphs are a type of structured representation, maybe the answer is KG. But I'm not entirely sure. Alternatively, if the paper is about clustering for scene graphs, maybe it's not directly any of the four. But the options are time-series, multimodal, RAG, KG. \n\nHmm. The title doesn't mention any of the four topics explicitly. The closest might be KG because scene graphs are structured, but I'm not certain. Alternatively, if the framework uses multiple data modalities (like images and text), it could be multimodal. But the title doesn't specify that. \n\nWait, the problem says if it doesn't belong to any of these, respond with \"none\". So if the paper is about scene graph generation, which is a computer vision task, and none of the four topics (time-series, multimodal, RAG, KG) directly apply, then the answer would be \"none\". But maybe scene graphs are considered part of knowledge graphs? \n\nI think the answer here is \"KG\" because scene graphs are a form of structured knowledge representation, similar to knowledge graphs. So the correct topic would be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/32998@AAAI"},
{"title": "SMamba: Sparse Mamba for Event-based Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SMamba: Sparse Mamba for Event-based Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Event-based\" suggests that the data is based on events, which are typically time-stamped occurrences. Event-based sensors, like neuromorphic cameras, capture changes in light intensity over time, producing a stream of events. So, this might relate to time-series data because events are sequential and time-dependent.\n\nNext, \"Object Detection\" is a computer vision task. But the paper is using an event-based approach, which is different from traditional frame-based images. Event data is a type of temporal data, so time-series could be a fit here. \n\nNow, checking the other options. Multimodal usually refers to combining different types of data (like text and images). The title doesn't mention combining different modalities, so probably not multimodal. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generative models, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is unlikely. \n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't indicate the use of knowledge graphs either. \n\nSo, the most likely topic here is time-series, as event-based data is inherently temporal and sequential. The \"Sparse Mamba\" part might refer to a model architecture optimized for sparse, time-series data. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/32999@AAAI"},
{"title": "LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. LiDAR refers to Light Detection and Ranging, which is a remote sensing method used to create 3D maps. LLM stands for Large Language Model. The paper is about using LLMs for understanding 3D LiDAR data. \n\nNow, the topics given are time-series, multimodal, RAG, and KG. Time-series usually involves data points indexed in time order, like stock prices over time. Multimodal refers to combining multiple types of data, such as text and images. RAG is Retrieval-Augmented Generation, which is a method where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which is a structured representation of knowledge.\n\nThe paper is about using LLMs for LiDAR data. LiDAR data is 3D spatial data, which is a type of modality. Since the paper is combining a language model (text) with LiDAR data (3D spatial), this seems like a multimodal approach. The LLM is being used to process a different type of data (LiDAR) than text, so integrating different modalities would be the key here. \n\nTime-series doesn't fit because LiDAR data here is 3D and not necessarily time-dependent. RAG and KG are more about information retrieval and structured knowledge, which doesn't seem to be the focus here. The main idea is combining different data types (LiDAR and language models), so multimodal is the right choice.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33001@AAAI"}
{"title": "LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LiDAR-LLM: Exploring the Potential of Large Language Models for 3D LiDAR Understanding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. LiDAR refers to Light Detection and Ranging, which is a remote sensing method used to create 3D maps. LLM stands for Large Language Model. The paper is about using LLMs for understanding 3D LiDAR data. \n\nNow, the topics given are time-series, multimodal, RAG, and KG. Time-series usually involves data points indexed in time order, like stock prices over time. Multimodal refers to combining multiple types of data, such as text and images. RAG is Retrieval-Augmented Generation, which is a method where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which is a structured representation of knowledge.\n\nThe paper is about using LLMs for LiDAR data. LiDAR data is 3D spatial data, which is a type of modality. Since the paper is combining a language model (text) with LiDAR data (3D spatial), this seems like a multimodal approach. The LLM is being used to process a different type of data (LiDAR) than text, so integrating different modalities would be the key here. \n\nTime-series doesn't fit because LiDAR data here is 3D and not necessarily time-dependent. RAG and KG are more about information retrieval and structured knowledge, which doesn't seem to be the focus here. The main idea is combining different data types (LiDAR and language models), so multimodal is the right choice.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33001@AAAI"},
{"title": "MegActor-Sigma: Unlocking Flexible Mixed-Modal Control in Portrait Animation with Diffusion Transformer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MegActor-Sigma: Unlocking Flexible Mixed-Modal Control in Portrait Animation with Diffusion Transformer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Mixed-Modal Control\" stands out. The term \"modal\" here probably refers to different modes of data, like text, images, audio, etc. So \"mixed-modal\" suggests combining multiple data types. That makes me think of multimodal, which is one of the options. \n\nThen there's \"Portrait Animation,\" which might involve generating or manipulating images or videos over time. But the key part here is the \"Mixed-Modal Control.\" The paper is about controlling animations using different modalities, maybe using inputs like text and images together. \n\nThe other parts of the title mention \"Diffusion Transformer,\" which is a model type, but that's more about the method rather than the topic. The main focus seems to be on integrating different modalities for control in animation. \n\nLooking at the options: time-series deals with sequential data over time, which might be relevant if the animation is a sequence, but the title emphasizes mixed-modal control more. RAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to fit here. The paper isn't about retrieving information to augment generation or using structured knowledge graphs. \n\nSo the most likely topic is multimodal. The use of \"mixed-modal\" in the title directly points to combining multiple data modalities, which is the essence of multimodal research.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33002@AAAI"},
{"title": "Asymmetric Hierarchical Difference-aware Interaction Network for Event-guided Motion Deblurring", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Asymmetric Hierarchical Difference-aware Interaction Network for Event-guided Motion Deblurring.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on motion deblurring, which is an image processing task. The term \"event-guided\" might refer to using event data, which could be from event cameras that capture changes in brightness over time. Event data is a type of time-series data because it's a sequence of events over time. So maybe time-series is a possibility here.\n\nThe \"asymmetric hierarchical difference-aware interaction network\" part sounds like a neural network architecture. But does that relate to any of the topics? RAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem relevant. Multimodal would involve combining different types of data, like text and images. The paper mentions \"event-guided,\" which could be combining event data (a type of time-series) with images for deblurring. So maybe multimodal? But the primary data type here is event data and images, which are different modalities. However, the main focus might be on the time-series aspect of the event data. Alternatively, if the model is using both event data and images together, that would be multimodal. But the title doesn't explicitly mention multiple modalities beyond the event data. The term \"event-guided\" suggests that the event data is guiding the deblurring process, which is a time-series of events. So perhaps the primary topic is time-series. But I'm a bit confused. Let me think again. If the model is using event data (time-series) to guide the deblurring of images, then it's combining two modalities: event data (time-series) and images. So that would be multimodal. However, if the focus is on processing the event data as a time-series to achieve deblurring, then it's time-series. The title doesn't mention knowledge graphs or RAG. So between time-series and multimodal. The key is whether the model is integrating multiple data types (multimodal) or just processing a time-series. The term \"event-guided\" implies that the event data is being used as input, which is a time-series, to guide the deblurring. So maybe it's a time-series application. But if the model is combining event data (time-series) with image data, then it's multimodal. The title doesn't explicitly state that it's combining multiple modalities, just that it's using event data. So perhaps the primary topic is time-series. Alternatively, maybe the model is using both event data and images, making it multimodal. The answer might depend on the paper's content, but based on the title alone, \"event-guided\" suggests using event data (time-series) to guide the process. So I think the topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33003@AAAI"},
{"title": "Dual Information Purification for Lightweight SAR Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dual Information Purification for Lightweight SAR Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Dual Information Purification\" suggests that there are two types of information being processed and refined. \"Lightweight SAR Object Detection\" refers to Synthetic Aperture Radar (SAR) object detection, which is a type of remote sensing technology. The term \"lightweight\" might imply that the model is optimized for efficiency, maybe in terms of computational resources.\n\nNow, looking at the possible topics. Time-series analysis involves data points indexed in time order, often used in forecasting or anomaly detection. Multimodal refers to the use of multiple data modalities, like combining text, images, audio, etc. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves relevant information from a database to enhance its responses. KG is Knowledge Graph, which structures information into entities and relationships.\n\nThe paper's focus is on SAR object detection. SAR is a radar technique used to create images, so it's image data. The \"dual information purification\" part might involve processing different data sources or features. However, the title doesn't mention anything about time-series data, multiple modalities, retrieval-augmented generation, or knowledge graphs. It seems to be about improving object detection in SAR images through some purification method. Since none of the four topics are explicitly mentioned or implied by the title, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33004@AAAI"},
{"title": "DriveGazen: Event-Based Driving Status Recognition Using Conventional Camera", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DriveGazen: Event-Based Driving Status Recognition Using Conventional Camera.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Event-Based Driving Status Recognition\" suggests that the research is about recognizing driving status based on events. The method uses a \"Conventional Camera,\" so maybe they're using visual data. Now, the term \"event-based\" might refer to event cameras, which are different from traditional frame-based cameras. Event cameras capture changes in brightness asynchronously, which is more like a time-series of events rather than frames. So, if they're using event-based data, that's inherently time-series data because each event is a timestamped change. \n\nTime-series analysis involves data points indexed in time order. Since event cameras produce a stream of events over time, processing that would likely involve time-series methods. The other options: multimodal would involve combining different data types (like camera and LiDAR), but the title mentions only a conventional camera. RAG (Retrieval-Augmented Generation) is more about using retrieved information to augment model outputs, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data representations, which also doesn't fit. \n\nSo, the key here is the \"event-based\" aspect, which is a type of time-series data. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33005@AAAI"},
{"title": "Semantic Segmentation on Raindrop Degraded Images Using Two-Stage Dual Teacher-Student Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Semantic Segmentation on Raindrop Degraded Images Using Two-Stage Dual Teacher-Student Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, semantic segmentation is a computer vision task, usually dealing with images. The problem here is about raindrop degraded images, so it's image processing. The method mentioned is two-stage dual teacher-student learning. Teacher-student learning is a type of training approach where a model (teacher) guides another model (student), often used in knowledge distillation. But how does that relate to the given topics?\n\nTime-series would involve data over time, like stock prices or sensor data. This doesn't seem to fit because the focus is on images, not sequences over time.\n\nMultimodal typically refers to combining different data types, like text and images. The paper is about images degraded by raindrops, but there's no mention of combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image segmentation and a specific learning method, not on building or using knowledge graphs. So KG is out.\n\nNone of the topics seem to fit. The paper is about a specific deep learning approach for image segmentation, using a teacher-student framework. The topics provided don't include computer vision, image processing, or specific learning methods like teacher-student. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33006@AAAI"},
{"title": "ERF: A Benchmark Dataset for Robust Semantic Segmentation Under Extreme Rainfall Conditions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ERF: A Benchmark Dataset for Robust Semantic Segmentation Under Extreme Rainfall Conditions.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The dataset is called ERF, and it's for robust semantic segmentation under extreme rainfall. Semantic segmentation is a computer vision task where each pixel in an image is classified into a category. So the focus here is on image data, specifically in challenging weather conditions like heavy rain.\n\nNow, the possible topics are time-series, multimodal, RAG, or KG. Time-series usually involves data points indexed in time order, like stock prices over time or sensor data over time. This dataset is about images under extreme rainfall, which might involve sequences of images over time, but the main focus seems to be on the images themselves rather than temporal analysis. However, I'm not sure if that's the case here. The title doesn't mention time-series explicitly, so maybe it's not the right fit.\n\nMultimodal refers to data that combines multiple modalities, like text and images, or audio and video. The ERF dataset is for semantic segmentation, which is typically a single modality (images). Unless the dataset includes other modalities like LiDAR or radar data along with images, but the title doesn't mention that. So maybe multimodal isn't the right choice here.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model retrieves relevant information from a database to enhance its responses. This seems unrelated to semantic segmentation, which is a computer vision task. So RAG probably isn't the topic here.\n\nKG stands for Knowledge Graph, which is a structured representation of knowledge, often used to model relationships between entities. The ERF dataset is a benchmark for a specific computer vision task, not about building or using a knowledge graph. So KG doesn't fit either.\n\nPutting it all together, the dataset is focused on improving semantic segmentation in extreme weather conditions. The key aspects are robustness in computer vision, specifically under rainfall. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The dataset is about a specific application in computer vision, not about combining modalities, time-series data, retrieval-augmented generation, or knowledge graphs. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33007@AAAI"},
{"title": "FreqTS: Frequency-Aware Token Selection for Accelerating Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FreqTS: Frequency-Aware Token Selection for Accelerating Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"FreqTS\" probably stands for Frequency-Aware Token Selection. The main goal here is to accelerate diffusion models. Diffusion models are a type of generative model, often used in image or audio generation. They work by gradually denoising data over time steps. \n\nNow, the key part is \"Frequency-Aware Token Selection.\" Token selection might relate to how the model processes data in steps. In diffusion models, each step involves generating or refining tokens (like pixels or audio samples). If they're selecting tokens based on frequency, maybe they're optimizing which parts of the data to process first or more thoroughly. \n\nLooking at the topics: time-series involves data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data retrieval during generation. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on accelerating diffusion models through token selection based on frequency. Diffusion models are typically used in image or audio generation, which are not time-series data. There's no mention of combining different modalities, so it's not multimodal. RAG and KG are about retrieval and knowledge graphs, which don't seem related here. \n\nSo, the paper is about improving the efficiency of diffusion models by selecting tokens based on their frequency. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33008@AAAI"},
{"title": "Topo2Seq: Enhanced Topology Reasoning via Topology Sequence Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Topo2Seq: Enhanced Topo Reasoning via Topo Sequence Learning.\" Hmm, the key terms here are \"topology reasoning\" and \"topology sequence learning.\" The user wants to know if this paper fits into one of the four categories: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order. The title mentions \"sequence learning,\" which might relate to time-series, but the focus here is on topology. Topology sequences could be about the structure or relationships between elements, not necessarily over time. So maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. The title doesn't mention retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus on topology reasoning might relate to knowledge graphs if they're modeling relationships as a graph. However, the term \"topology sequence learning\" suggests a different approach. Knowledge graphs typically involve entities and relations, while topology here might refer to network structures or spatial relationships. Without more context, it's a bit tricky. But since the title doesn't explicitly mention knowledge graphs or their components, maybe it's not KG either.\n\nSo, the options are time-series, multimodal, RAG, or KG. The paper's title is about topology reasoning through sequence learning. If \"topology sequence\" is a sequence of topological structures, maybe it's a type of time-series if the sequences are over time. But if it's about the structure itself, not time, then maybe not. Since the user's options don't include a category for topology or graph structures directly, and none of the four fit perfectly, the answer might be \"none.\" But wait, maybe I'm missing something. Let me check again. The four options are time-series, multimodal, RAG, KG. The paper is about topology reasoning using sequence learning. If the sequences are topological, perhaps it's a novel approach not covered by the four. So the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33009@AAAI"},
{"title": "Driving in the Occupancy World: Vision-Centric 4D Occupancy Forecasting and Planning via World Models for Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Driving in the Occupancy World: Vision-Centric 4D Occupancy Forecasting and Planning via World Models for Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"4D Occupancy Forecasting\" suggests that they're predicting the state of the environment over time, which might involve time-series data. The \"4D\" probably refers to three spatial dimensions plus time. So forecasting over time could be a time-series aspect. But I'm not sure if that's the main focus here.\n\n\"Vision-Centric\" implies that they're using visual data, maybe from cameras. If they're combining different types of data (like visual with other sensors), that would be multimodal. But the title doesn't explicitly mention multiple modalities, just vision. So maybe not multimodal.\n\n\"World Models\" – I'm not exactly sure what that refers to here. World models in AI often involve simulating the environment, which might use knowledge graphs (KG) to represent the world's structure. But I'm not certain. Alternatively, world models could be part of a planning system that uses time-series data for predictions.\n\nRAG (Retrieval-Augmented Generation) is about using retrieved information to enhance model outputs. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graphs) involve structured data and relationships. If the paper is building a model of the world using structured knowledge, maybe that's it. But the term \"world models\" could be more about simulation or prediction rather than a knowledge graph.\n\nPutting it together: The key terms are 4D occupancy forecasting, which is about predicting how the environment (occupancy) changes over time. That sounds like time-series analysis. The planning part also suggests using temporal data for future predictions. So the topic might be time-series. But I need to check if \"world models\" here is a red herring. If the main contribution is the forecasting over time, then time-series is the right choice. If it's about integrating different data sources (vision with others), it would be multimodal. But the title says \"vision-centric,\" so maybe they're using only vision, making it not multimodal. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33010@AAAI"}
{"title": "UAWTrack: Universal 3D Single Object Tracking in Adverse Weather", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UAWTrack: Universal 3D Single Object Tracking in Adverse Weather.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"3D Single Object Tracking\" suggests that the research is about tracking objects in three dimensions, probably using some kind of sensor data like LiDAR or cameras. \"Adverse Weather\" implies that the tracking has to work in challenging conditions like rain, snow, or fog. The term \"Universal\" might mean it's designed to handle various types of adverse weather or different environments.\n\nNow, looking at the possible topics. Time-series usually involves data collected over time, which is common in tracking, but the question is whether the paper specifically focuses on time-series analysis. However, tracking itself often uses time-series data, but the topic here might be more about the application rather than the time-series methodology.\n\nMultimodal refers to using multiple types of data or sensors, like combining visual and textual information. If the tracking system uses data from different modalities (e.g., LiDAR and cameras), then it would be multimodal. The title doesn't explicitly mention multiple modalities, but \"3D\" might imply using depth data, which could be a single modality. However, without more info, it's hard to say.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves relevant information from a database to enhance its responses. This doesn't seem related to object tracking.\n\nKG is Knowledge Graph, which involves structured data representation. If the paper uses or builds a knowledge graph for tracking, it would fit here. But the title doesn't mention anything about knowledge graphs.\n\nSo, the options are time-series, multimodal, RAG, or KG. The paper is about 3D object tracking in adverse weather. If it uses multiple sensors (like LiDAR and cameras), it's multimodal. If it's just using one type of data over time, maybe time-series. But the key here is that the title doesn't specify using multiple modalities. However, 3D tracking often involves combining different data sources. For example, using both visual and depth data. But without explicit mention, it's a bit ambiguous. However, given the options, the most likely is multimodal if they are combining different sensor data. Alternatively, if it's just a time-based tracking system, maybe time-series. But I think multimodal is more likely here because 3D tracking in adverse weather might require fusing different modalities to handle the challenges. So the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33011@AAAI"},
{"title": "RealPortrait: Realistic Portrait Animation with Diffusion Transformers", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RealPortrait: Realistic Portrait Animation with Diffusion Transformers.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or weather data. The paper is about portrait animation, which might involve sequences of images or frames over time. But the key term here is \"Diffusion Transformers.\" Diffusion models are a type of generative model, often used in image generation. Transformers are neural networks that handle sequential data, but in this case, it's for generating images. So maybe it's not time-series, unless the animation aspect implies a sequence over time. But I'm not sure yet.\n\nMultimodal refers to combining multiple types of data, like text and images. The title mentions portrait animation, which could involve images and maybe some other modalities, but the title doesn't explicitly state that. The focus seems to be on generating realistic portraits, which is more about image generation than combining different data types.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information and then generates a response. The title doesn't mention anything about retrieval or using external data sources, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper doesn't mention anything about graphs or structured data, so that's probably not it either.\n\nSo, the main components here are diffusion models and transformers for portrait animation. Diffusion models are used in generative tasks, and transformers can handle sequences. However, the primary application here is image generation, not time-series data. The animation part might involve sequences of images, but the core technique is diffusion with transformers. Since the options are time-series, multimodal, RAG, or KG, and none of those seem to fit perfectly, maybe the answer is none. But wait, maybe the animation aspect is time-series? If the model is generating a sequence of images over time, then it could be considered time-series. But I'm not certain. The term \"portrait animation\" suggests creating a sequence of images to form an animation, which is a time-dependent process. However, the primary focus might be on the generation method (diffusion transformers) rather than the time-series aspect. The other options don't fit, so perhaps it's time-series. Alternatively, if the model isn't explicitly dealing with time-series data, maybe it's none. Hmm. I'm a bit torn here. Let me think again. Time-series analysis typically involves statistical methods for temporal data. If the paper is about generating animated portraits, which are sequences of images, then it's a time-dependent process. But the main contribution is the use of diffusion transformers for realistic generation. The topic might not be time-series unless the paper specifically addresses time-series modeling. Since the title doesn't mention time-series, maybe it's none. But I'm not 100% sure. Alternatively, maybe multimodal if it combines different data types, but again, the title doesn't indicate that. So, I think the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33012@AAAI"},
{"title": "UniDemoiré: Towards Universal Image Demoiréing with Data Generation and Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UniDemoiré: Towards Universal Image Demoiréing with Data Generation and Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Image Demoiréing\" refers to removing moiré patterns from images. Moiré patterns are those wavy, interference patterns that can appear in images, especially when photographing screens or fabrics. So the paper is about improving image processing techniques for that specific problem.\n\nThe term \"Universal\" suggests they're aiming for a method that works across different scenarios or types of images. \"Data Generation and Synthesis\" implies they're creating synthetic data to train their model. That part is interesting because generating synthetic data is a common approach in machine learning to augment datasets, especially when real data is scarce or hard to collect.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order, like stock prices over time or sensor data. This paper is about images, so time-series doesn't seem relevant here.\n\nMultimodal research involves combining multiple types of data, like text and images, or audio and video. The paper is focused on image processing, but the title doesn't mention combining different modalities. It's about a single modality (images) and a specific task (demoiréing), so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a technique in natural language processing where a model retrieves relevant information from a database and uses it to generate responses. This is more about text generation with external knowledge. The paper here is about image processing, not text generation, so RAG doesn't fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge, often used for semantic web applications or to enhance machine learning models with relational data. The paper doesn't mention anything about knowledge graphs or structured data representation. It's about generating synthetic data for image processing, which is more related to data augmentation or generative models.\n\nSo none of the four topics—time-series, multimodal, RAG, or KG—seem to directly apply here. The paper is about image demoiréing using data generation and synthesis, which might fall under computer vision or generative models, but those aren't listed in the options. Therefore, the correct answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33013@AAAI"},
{"title": "GURecon: Learning Detailed 3D Geometric Uncertainties for Neural Surface Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GURecon: Learning Detailed 3D Geometric Uncertainties for Neural Surface Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title is about 3D geometric uncertainties and surface reconstruction. It doesn't mention multiple modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. The title doesn't seem related to retrieval or generation processes, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on 3D reconstruction and uncertainties, which doesn't directly relate to knowledge graphs.\n\nSo none of the four topics seem to fit. The paper is about neural surface reconstruction with geometric uncertainties, which is more related to computer vision or 3D modeling, not the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33014@AAAI"},
{"title": "Single Image Rolling Shutter Removal with Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Single Image Rolling Shutter Removal with Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data collected over time, like stock prices or sensor data. The paper is about removing rolling shutter effects from a single image. Rolling shutter is a distortion in images caused by the way some cameras capture images line by line over time. So, maybe there's a time component here. But the problem is about correcting a single image, not analyzing a sequence of data points over time. Hmm, not sure if it's time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions a single image, so unless they're using other modalities in the process, it might not be multimodal. The focus seems to be on image processing using diffusion models, which are a type of generative model. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information and then generates a response. The title doesn't mention anything about retrieval or combining it with generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't indicate any use of knowledge graphs or structured data. It's about image processing with diffusion models.\n\nSo, the main components here are image processing and diffusion models. The rolling shutter effect is related to how images are captured over time, but the task is to remove that effect from a single image. Diffusion models are used for generating images, so maybe they're applying a diffusion model to correct the image. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The problem is about image restoration using a specific model, which doesn't align with the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33015@AAAI"},
{"title": "Predicting the Original Appearance of Damaged Historical Documents", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Predicting the Original Appearance of Damaged Historical Documents.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in chronological order, like stock prices over time or weather data. This title is about historical documents, which are static, not a sequence over time. So probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The task here is about predicting the original appearance, which might involve image restoration. If they're using different data types (e.g., text and images), it could be multimodal. But the title doesn't explicitly mention multiple modalities. Hmm.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information before generating a response. This seems more about generating text based on retrieved documents. The task here is about image restoration, not generating text based on retrieved data. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses a knowledge graph to infer missing parts of documents, that could fit. But the title doesn't mention anything about structured knowledge or graphs. It's more about predicting the original appearance, which sounds like an image restoration or inpainting task. \n\nSo, the main question is whether this is multimodal. If the approach uses multiple data types (like text and images) to predict the original document, then it's multimodal. But if it's just image processing without combining different modalities, then it's none. The title doesn't specify, but the task of restoring damaged documents might involve using text (from the document) and images (the document's physical state). However, without explicit mention, it's a bit ambiguous. Since the options are limited, and the other three don't fit, maybe it's none. But I'm not entirely sure. Wait, maybe multimodal is possible if they use both text and image data. Let me think again. The problem is about the document's appearance, which is visual, but if they're using textual content as part of the prediction, then it's multimodal. If they're only using the image, then it's not. Since the title doesn't specify, but the task could involve both, maybe multimodal is the answer. Alternatively, if it's purely image-based, then none. But given the options, I'll go with none because the title doesn't clearly indicate multimodal data usage. The other options are definitely not applicable. So the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33016@AAAI"},
{"title": "MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MMGDreamer: Mixed-Modality Graph for Geometry-Controllable 3D Indoor Scene Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Mixed-Modality Graph\" suggests that the research involves combining different modalities, like text, images, audio, etc. That points towards \"multimodal\" because multimodal systems handle multiple types of data. The term \"Graph\" might relate to Knowledge Graphs (KG), but I need to check if that's the case here. \n\nThe rest of the title talks about generating 3D indoor scenes with geometry control. So the main focus is on generating scenes using mixed modalities. The key term here is \"Mixed-Modality,\" which directly relates to multimodal research. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation, but the title doesn't mention anything about retrieval. KG (Knowledge Graph) involves structured data and relationships, but the graph here is part of the model's architecture for handling different modalities, not necessarily a knowledge graph. Time-series is about sequential data over time, which isn't mentioned here. \n\nSo the most fitting topic is \"multimodal.\"\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33017@AAAI"},
{"title": "MoRe: Class Patch Attention Needs Regularization for Weakly Supervised Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MoRe: Class Patch Attention Needs Regularization for Weakly Supervised Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Weakly Supervised Semantic Segmentation\" suggests that the paper is about image segmentation with limited supervision. That's a computer vision task. Now, the key terms here are \"Class Patch Attention\" and \"Regularization.\" \n\n\"Class Patch Attention\" might refer to an attention mechanism that focuses on specific patches of an image related to certain classes. Attention mechanisms are common in deep learning, especially in vision and NLP. Regularization is a technique used to prevent overfitting, so the paper is probably proposing a regularization method for this attention mechanism.\n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem relevant here. Multimodal would involve combining different data types like text and images. RAG stands for Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks, typically in NLP. KG is Knowledge Graphs, which are structured representations of knowledge, often used in semantic web or information retrieval.\n\nThe paper's focus is on semantic segmentation, which is a computer vision task. The mention of attention mechanisms and regularization doesn't directly tie it to any of the four topics listed. The paper isn't about combining multiple modalities (so not multimodal), nor is it about retrieval-augmented generation or knowledge graphs. Time-series is unrelated. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33018@AAAI"},
{"title": "As Pseudo-Label Free as Possible: Leveraging Adaptive Feature Generation for Sparsely Annotated Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"As Pseudo-Label Free as Possible: Leveraging Adaptive Feature Generation for Sparsely Annotated Object Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Pseudo-Label Free\" suggests they're avoiding using pseudo-labels, which are often used in semi-supervised learning. \"Adaptive Feature Generation\" might refer to creating features dynamically. \"Sparsely Annotated Object Detection\" means they're working with object detection where there aren't many labeled examples.\n\nNow, the four options. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on object detection with sparse annotations. The methods mentioned don't seem to relate to time-series data. There's no mention of combining different modalities, so probably not multimodal. RAG is about retrieval and generation, which doesn't fit here. Knowledge Graphs are about structured data, which also doesn't seem relevant. The paper is about improving object detection with limited labels, which is more about model training techniques rather than the four topics listed. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33020@AAAI"},
{"title": "Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nNext, multimodal. That's when the research involves multiple types of data, like text and images. The title mentions text-to-image synthesis, which is definitely combining text (input) and images (output). So that's a strong candidate for multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically when a model uses a retrieval system to pull information and then generates text. The title doesn't mention anything about retrieval or augmenting generation with external data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title talks about orchestrating concepts, but there's no mention of structured data or graphs. So probably not KG.\n\nSo the most likely answer is multimodal because it's about generating images from text, combining two modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33021@AAAI"}
{"title": "Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nNext, multimodal. That's when the research involves multiple types of data, like text and images. The title mentions text-to-image synthesis, which is definitely combining text (input) and images (output). So that's a strong candidate for multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically when a model uses a retrieval system to pull information and then generates text. The title doesn't mention anything about retrieval or augmenting generation with external data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title talks about orchestrating concepts, but there's no mention of structured data or graphs. So probably not KG.\n\nSo the most likely answer is multimodal because it's about generating images from text, combining two modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33021@AAAI"},
{"title": "Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Remote Sensing Image\" suggests that the data comes from satellite or aerial imagery. \"Semantic Segmentation\" is a computer vision task where each pixel is classified into a category. \"Open-Vocabulary\" might imply that the model can recognize categories beyond the ones it was trained on, maybe using some kind of knowledge base or external information.\n\nNow, looking at the options. Time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images. The title only mentions images, so maybe not multimodal unless there's an implicit use of other data types, but the title doesn't specify that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graph, which is a structured representation of knowledge. If the paper uses a knowledge graph to enhance the segmentation, maybe. But the title doesn't explicitly mention a knowledge graph. However, \"open-vocabulary\" could hint at using external knowledge, which might be structured as a KG. But I'm not sure. Alternatively, open-vocabulary could relate to using pre-trained models with a large vocabulary, like in vision-language models. \n\nWait, another angle: semantic segmentation in remote sensing often deals with classifying land cover types. If the model is open-vocabulary, it might be using a knowledge base (KG) to map new classes. But the title doesn't mention a knowledge graph. Alternatively, maybe it's using multimodal data, like combining images with text descriptions. But again, the title doesn't specify. \n\nHmm. The options are time-series, multimodal, RAG, KG. The title is about image segmentation, which is a computer vision task. Open-vocabulary might relate to using a knowledge graph to handle new classes. But without explicit mention, it's tricky. Alternatively, maybe it's none of these. But the user wants me to pick one if it fits. \n\nWait, RAG is for retrieval-augmented generation, which is more about text generation with retrieval. The paper is about image segmentation, so RAG seems unlikely. Multimodal would require combining different modalities. The title doesn't mention that. Time-series is out. KG is possible if they use a knowledge graph for the open-vocabulary aspect. But the title doesn't say that. \n\nAlternatively, maybe it's none. But the user might expect me to pick one. Let me think again. Open-vocabulary in segmentation could involve using a knowledge graph to link image classes to a broader set of terms. So maybe KG. But I'm not certain. The title doesn't explicitly state it. However, among the options, KG might be the closest. Alternatively, maybe it's none. \n\nWait, the user says if it doesn't belong to any, respond with none. So if I can't confidently assign it to one of the four, then it's none. But maybe I'm overcomplicating. The title is about semantic segmentation in remote sensing images with open-vocabulary. None of the four topics (time-series, multimodal, RAG, KG) are directly mentioned. So the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33022@AAAI"},
{"title": "VersaFusion: A Versatile Diffusion-Based Framework for Fine-Grained Image Editing and Enhancement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VersaFusion: A Versatile Diffusion-Based Framework for Fine-Grained Image Editing and Enhancement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image editing and enhancement, which is more about images, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image editing using a diffusion-based framework. If it's using multiple modalities, like text and images together, then it would be multimodal. But the title doesn't mention combining different data types, just image editing. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically used in NLP where a model retrieves information from a database to generate responses. The title doesn't mention anything about retrieval or generation in that context, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, the paper is about a diffusion-based framework for image editing. Diffusion models are a type of generative model, but the four categories given don't include generative models directly. The options are time-series, multimodal, RAG, or KG. Since none of these seem to fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33023@AAAI"},
{"title": "PromptHaze: Prompting Real-world Dehazing via Depth Anything Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PromptHaze: Prompting Real-world Dehazing via Depth Anything Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper uses a depth model for dehazing, which might involve images and depth data. So maybe multimodal? But I'm not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title mentions \"Prompting,\" which could relate to prompts in RAG, but the main focus here seems to be dehazing using a depth model. Not sure if it's RAG.\n\nKG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about graphs or knowledge, so probably not KG.\n\nSo, the key parts are \"Prompting Real-world Dehazing via Depth Anything Model.\" Dehazing is an image processing task. Using a depth model suggests combining depth information (which is a type of data) with the image data. That sounds like multimodal because it's using different modalities (images and depth). So the answer might be multimodal. But I should double-check. If the depth model is just part of the method and not combining different data types, maybe not. But \"Depth Anything Model\" likely provides depth data, which is another modality. So I think it's multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33024@AAAI"},
{"title": "Optimized Gradient Clipping for Noisy Label Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Optimized Gradient Clipping for Noisy Label Learning\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics entails. \n\nTime-series research typically deals with data points indexed in time order, like stock prices over time or weather data. The methods here often involve models that capture temporal dependencies, such as RNNs, LSTMs, or ARIMA.\n\nMultimodal research involves combining multiple types of data, like text and images, or audio and video. It's about integrating different modalities to improve model performance or understanding.\n\nRAG stands for Retrieval-Augmented Generation. This is a method where a model uses a retrieval component to fetch relevant information from a large database and then generates a response based on that retrieved information. It's commonly used in question-answering systems.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge, often in the form of triples (subject, predicate, object). Research in this area might involve constructing, querying, or reasoning over knowledge graphs.\n\nNow, looking at the title: \"Optimized Gradient Clipping for Noisy Label Learning\". Gradient clipping is a technique used in training neural networks to prevent exploding gradients, which can happen when the gradients are too large. Noisy label learning refers to scenarios where the training data has incorrect labels, and the research is about making models robust to such noise.\n\nThe key terms here are \"gradient clipping\" and \"noisy label learning\". Gradient clipping is a training technique, and noisy label learning is about handling label noise in datasets. Neither of these directly relates to time-series data, multimodal data integration, retrieval-augmented generation, or knowledge graphs. \n\nThe paper is likely discussing a method to improve the training process (via gradient clipping) when dealing with noisy labels. This seems more related to optimization techniques in machine learning rather than the specific topics listed. Since none of the four topics (time-series, multimodal, RAG, KG) are directly addressed by the title, the correct answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33025@AAAI"},
{"title": "Personalized Lip Reading: Adapting to Your Unique Lip Movements with Vision and Language", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Personalized Lip Reading: Adapting to Your Unique Lip Movements with Vision and Language.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Personalized Lip Reading\" suggests that the research is about reading lips, but tailored to an individual. \"Adapting to Your Unique Lip Movements\" implies that the system is adjusting to each person's specific way of moving their lips. Then \"with Vision and Language\" – vision would be the visual data from the lips, and language probably refers to the textual or linguistic data. \n\nSo combining vision (visual data) and language (textual or linguistic data) sounds like multimodal because it's using multiple modalities. Multimodal typically refers to integrating different types of data like text, images, audio, etc. Here, vision (images or video of lips) and language (text) are two different modalities. \n\nTime-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title doesn't mention anything about time-based data, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves relevant information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely. \n\nKG is Knowledge Graph, which is a structured representation of knowledge. The title doesn't indicate the use of a knowledge graph, so that's probably not it either. \n\nTherefore, the most fitting topic here is multimodal because it combines vision and language data.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33026@AAAI"},
{"title": "FlexDataset: Crafting Annotated Dataset Generation for Diverse Applications", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"FlexDataset: Crafting Annotated Dataset Generation for Diverse Applications\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics entails. \n\nTime-series research typically involves data points indexed in chronological order, like stock prices over time or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, such as text, images, audio, etc. The title talks about dataset generation but doesn't specify multiple modalities. Unless \"diverse applications\" implies different data types, but that's a stretch. Not sure yet.\n\nRAG stands for Retrieval-Augmented Generation. That's a method where a model uses a retrieval system to pull relevant information and then generates a response. The title mentions dataset generation, but RAG is more about combining retrieval and generation in models, not necessarily about creating datasets. So probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge, often using graphs to show relationships between entities. The title doesn't mention anything about graphs or structured knowledge, so maybe not KG.\n\nThe title is about creating annotated datasets for various applications. Annotated datasets are used in machine learning for training models. The key here is that the paper is about generating datasets, not about the models or methods that use them. The four topics listed (time-series, multimodal, RAG, KG) are all specific areas of research. If the paper is about dataset creation in general, it might not fall under any of these specific categories. Unless \"diverse applications\" implies multimodal data, but that's not certain. Since the title doesn't specify any of the four topics, the answer is likely \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33027@AAAI"},
{"title": "Exploring Salient Object Detection with Adder Neural Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring Salient Object Detection with Adder Neural Networks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. Salient object detection is about identifying the most visually prominent objects in an image. Adder Neural Networks (AdderNets) are a type of neural network that uses addition instead of multiplication for feature extraction, which can be more efficient. \n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or sensor data. Multimodal refers to combining multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on using AdderNets for salient object detection, which is a computer vision task. None of the four topics directly relate to computer vision or neural network architectures for image processing. Time-series is about temporal data, which isn't the case here. Multimodal would involve combining different data modalities, but the paper is about a specific network for a single modality (images). RAG and KG are unrelated to the content described. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33028@AAAI"},
{"title": "Sequential Joint Dependency Aware Human Pose Estimation with State Space Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sequential Joint Dependency Aware Human Pose Estimation with State Space Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Sequential\" suggests something related to sequences, which often relates to time-series data. \"Joint Dependency\" might refer to dependencies between different parts, like in a model where elements are connected. \"Human Pose Estimation\" is the task, which is typically a computer vision problem. \"State Space Model\" is a method used for modeling systems that evolve over time, which is common in time-series analysis.\n\nTime-series usually involves data points indexed in time order. Since the model is using a state space approach and the problem is sequential (like estimating pose over time), this seems like a time-series application. \n\nMultimodal would involve combining different types of data (like text and images), but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo the most likely topic here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33029@AAAI"},
{"title": "Adversarial-Inspired Backdoor Defense via Bridging Backdoor and Adversarial Attacks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adversarial-Inspired Backdoor Defense via Bridging Backdoor and Adversarial Attacks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. The key terms here are \"adversarial,\" \"backdoor defense,\" and \"bridging backdoor and adversarial attacks.\" Adversarial attacks are a concept in machine learning where inputs are perturbed to deceive models. Backdoor attacks are a type of adversarial attack where a model is trained to behave normally but has a hidden trigger that causes it to misbehave. The paper is about defending against backdoors using insights from adversarial attacks.\n\nNow, looking at the four options. Time-series refers to data over time, like stock prices or weather. The title doesn't mention anything about time or sequential data, so probably not time-series. Multimodal involves combining different data types, like text and images. The title doesn't talk about multiple modalities either. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model uses a retrieval system to get information before generating a response. The title doesn't mention anything about retrieval or generation, so RAG is unlikely. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on backdoor defense and adversarial attacks, which are more about security and robustness in machine learning models rather than knowledge representation. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) are directly related to adversarial or backdoor attacks, the answer should be \"none.\" The paper is about machine learning security, which isn't one of the listed topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/33030@AAAI"}
{"title": "Unified Coding for Both Human Perception and Generalized Machine Analytics with CLIP Supervision", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unified Coding for Both Human Perception and Generalized Machine Analytics with CLIP Supervision.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Unified Coding\" suggests combining different types of data or models. \"Human Perception\" and \"Generalized Machine Analytics\" imply that the work might be about integrating human-like understanding with machine analysis. The mention of \"CLIP Supervision\" is key here. CLIP is a multimodal model developed by OpenAI that's trained on image-text pairs. So using CLIP supervision likely means the research uses CLIP's capabilities to bridge different modalities, like images and text.\n\nMultimodal research typically involves combining multiple data types, such as text, images, audio, etc. Since CLIP is a multimodal model, and the title talks about unified coding for both human and machine analytics, this seems to align with multimodal. The other options: time-series is about data over time, RAG is Retrieval-Augmented Generation, and KG is Knowledge Graphs. None of those seem to fit here. The paper isn't about time-based data, it's not about enhancing generation with retrieval, nor is it about structured knowledge graphs. So the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33031@AAAI"},
{"title": "GRPose: Learning Graph Relations for Human Image Generation with Pose Priors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GRPose: Learning Graph Relations for Human Image Generation with Pose Priors.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Learning Graph Relations\" makes me think of graph structures. Graphs are often associated with Knowledge Graphs (KG), which are structured representations of information. Then there's \"Human Image Generation,\" which is about generating images, so that's a computer vision task. The \"Pose Priors\" part suggests that the model uses prior knowledge about human poses, which could be structured data.\n\nNow, the options. Time-series deals with data over time, like stock prices or sensor data. This title doesn't mention anything about sequences over time, so probably not time-series. Multimodal usually involves combining different types of data, like text and images. The paper is about generating images using pose information, which is a form of structured data, but I'm not sure if that's multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval systems to augment generation, like in text generation where you retrieve documents. The title doesn't mention retrieval, so maybe not RAG. KG (Knowledge Graph) is about using graph structures to represent knowledge. The \"Graph Relations\" part seems to align with KG. The model is learning relations in a graph, which is a key aspect of knowledge graphs. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33032@AAAI"},
{"title": "RoDA: Robust Domain Alignment for Cross-Domain Retrieval Against Label Noise", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RoDA: Robust Domain Alignment for Cross-Domain Retrieval Against Label Noise.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Robust Domain Alignment\" suggests that the paper is dealing with aligning different domains, which is common in transfer learning or domain adaptation. \"Cross-Domain Retrieval\" implies that the retrieval task involves different domains, so the model is supposed to work across different data domains. \"Against Label Noise\" means the method is designed to handle noisy labels, which is a common problem in machine learning.\n\nNow, looking at the four options. Time-series would involve data that's sequential over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention different modalities, just domains. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that uses retrieval to enhance generation tasks, like in language models. The title mentions \"retrieval,\" but the context here is cross-domain retrieval, not necessarily augmentation for generation. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge bases, so probably not KG.\n\nSo the remaining options are none or maybe one of the four. Since the main focus is on domain alignment for cross-domain retrieval, which is a domain adaptation problem. But none of the four topics directly cover domain adaptation. The closest might be RAG if the retrieval is part of a generation process, but the title doesn't mention generation. So the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33033@AAAI"},
{"title": "ImagePiece: Content-aware Re-tokenization for Efficient Image Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ImagePiece: Content-aware Re-tokenization for Efficient Image Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data over time, like stock prices or weather data. The title mentions image recognition, so maybe not time-series. \n\nMultimodal involves combining different data types, like text and images. The paper is about image recognition, but does it combine with other modalities? The title doesn't mention text or audio, just image processing. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about image recognition and re-tokenization, which seems more like a computer vision technique. Unless the re-tokenization is using a knowledge graph, but the title doesn't indicate that.\n\nSo the paper is about improving image recognition through content-aware re-tokenization. That sounds like a method in computer vision, maybe related to how images are processed or tokenized. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33034@AAAI"},
{"title": "Equirectangular Point Reconstruction for Domain Adaptive Multimodal 3D Object Detection in Adverse Weather Conditions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Equirectangular Point Reconstruction for Domain Adaptive Multimodal 3D Object Detection in Adverse Weather Conditions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Multimodal 3D Object Detection.\" The word \"multimodal\" is right there. That makes me think it's related to the multimodal topic. But let me check the other parts to be sure.\n\nThe paper is about 3D object detection, which is a computer vision task. The mention of \"domain adaptive\" suggests that they're dealing with adapting models from one domain to another, maybe like different weather conditions. But the main thing here is \"multimodal,\" which typically refers to using multiple types of data, like combining images with LiDAR or radar. So if the detection is using multiple modalities (e.g., camera and LiDAR), then it's definitely multimodal.\n\nThe other options: time-series would involve data over time, like sequences. RAG is Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge. None of those seem to fit here. The title doesn't mention anything about time sequences, retrieval, or knowledge graphs. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33035@AAAI"},
{"title": "RA-SGG: Retrieval-Augmented Scene Graph Generation Framework via Multi-Prototype Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RA-SGG: Retrieval-Augmented Scene Graph Generation Framework via Multi-Prototype Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Retrieval-Augmented\" makes me think of RAG, which stands for Retrieval-Augmented Generation. That's a technique where a model uses retrieved information to enhance its outputs. So RAG is one of the options here. \n\nThen, \"Scene Graph Generation\" (SGG) is about creating structured representations of scenes, often used in computer vision tasks. Scene graphs typically involve entities and their relationships, which might relate to knowledge graphs (KG), but I need to be careful here. Knowledge graphs are more about structured data and relationships between entities in a broader sense, not necessarily scene-specific. \n\nThe framework uses \"Multi-Prototype Learning,\" which might be a method to handle different prototypes or examples for generating the scene graphs. But the key part here is \"Retrieval-Augmented,\" which directly points to RAG. \n\nMultimodal usually involves combining different types of data, like text and images. While scene graph generation can be multimodal (using both images and text), the title doesn't explicitly mention multiple modalities. The focus here is on retrieval augmentation, which is a specific technique under RAG. \n\nTime-series is about data over time, which doesn't seem relevant here. The paper is about generating scene graphs, which are more about spatial relationships than temporal data. \n\nSo putting it all together, the main topic here is RAG because the title explicitly mentions \"Retrieval-Augmented.\" Even though scene graphs can relate to knowledge graphs, the specific mention of retrieval augmentation aligns more with RAG. The other terms like multimodal or KG aren't the primary focus here. Therefore, the answer should be RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33036@AAAI"},
{"title": "Action-Agnostic Point-Level Supervision for Temporal Action Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Action-Agnostic Point-Level Supervision for Temporal Action Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Action Detection\" suggests something related to time, since \"temporal\" refers to time. So maybe time-series? Time-series analysis often deals with data points indexed in time order. But what about the other parts? \"Action-Agnostic Point-Level Supervision\" – \"action-agnostic\" might mean it's not specific to any particular action, and \"point-level\" could refer to specific points in time. \n\nTemporal action detection is a task in video analysis where you detect actions over time. So this is about sequences of data over time, which aligns with time-series. But wait, time-series is a broad term. However, the other options are more specific. Let's check the other topics. \n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval systems to augment generative models, which doesn't seem related here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo the key part here is \"Temporal Action Detection,\" which is about detecting actions over time, which is a time-series problem. The paper is likely dealing with time-series data analysis for action detection. Therefore, the correct topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33037@AAAI"},
{"title": "FOCUS: Towards Universal Foreground Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FOCUS: Towards Universal Foreground Segmentation.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. \"Foreground Segmentation\" sounds like a computer vision task, where you separate the main subject (foreground) from the background in an image or video. The term \"Universal\" might imply it's a general approach applicable to various scenarios. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. That doesn't seem related to image segmentation. Multimodal refers to using multiple data types, like combining text and images. The title doesn't mention anything about combining different modalities. RAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper's focus is on foreground segmentation, which is a specific computer vision problem. None of the listed topics (time-series, multimodal, RAG, KG) directly relate to image segmentation. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33038@AAAI"},
{"title": "CLIMB-ReID: A Hybrid CLIP-Mamba Framework for Person Re-Identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CLIMB-ReID: A Hybrid CLIP-Mamba Framework for Person Re-Identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. CLIMB-ReID probably stands for something, but the key parts here are CLIP and Mamba. CLIP is a model that's known for multimodal tasks, right? It's used for connecting text and images, so that's multimodal. Mamba is a type of model that's good for handling sequences, maybe similar to transformers but optimized for certain tasks. \n\nPerson Re-Identification (ReID) is about identifying the same person across different camera views. This usually involves image data. Now, the framework is a hybrid of CLIP and Mamba. Since CLIP is multimodal, combining it with another model might enhance the multimodal aspects. But does the paper focus on multimodal data? The title doesn't mention text or other modalities besides images, but CLIP's use suggests that maybe they're incorporating some text-based features. However, ReID typically uses images, so maybe the multimodal aspect is in how they combine different features or models. \n\nRAG (Retrieval-Augmented Generation) is more about using external knowledge during generation, which doesn't seem to fit here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem relevant. Time-series would involve data over time, but ReID is more about spatial data from images. \n\nSo the most likely topic here is multimodal because of the use of CLIP, which is inherently multimodal. Even if the primary data is images, the framework's hybrid approach might integrate different modalities. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33039@AAAI"},
{"title": "SGFormer: Semantic-Geometry Fusion Transformer for Multi-modal 3D Panoptic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SGFormer: Semantic-Geometry Fusion Transformer for Multi-modal 3D Panoptic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the title. That immediately makes me think the topic is multimodal. But let me check the other parts to be sure. The paper is about 3D panoptic segmentation, which involves combining different data types, like semantic and geometric information. The term \"fusion\" suggests integrating multiple modalities, which aligns with multimodal research. \n\nNow, the other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks. KG is Knowledge Graphs, which are structured representations of information. None of these seem to fit the title. The focus here is on combining different data modalities (semantic and geometric) for a 3D segmentation task. So the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33042@AAAI"}
{"title": "FreeNet: Liberating Depth-Wise Separable Operations for Building Faster Mobile Vision Architectures", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FreeNet: Liberating Depth-Wise Separable Operations for Building Faster Mobile Vision Architectures.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"FreeNet\" is the model name. \"Depth-Wise Separable Operations\" sounds like a type of neural network architecture, maybe related to convolutional layers. \"Building Faster Mobile Vision Architectures\" suggests it's about making models efficient for mobile devices, which is common in computer vision.\n\nNow, the topics given are time-series, multimodal, RAG, and KG. Time-series would involve data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on improving mobile vision architectures using depth-wise separable operations. Vision here refers to image or video processing, which is a modality. However, multimodal typically involves more than one modality. Since the title doesn't mention combining different data types, it's probably not multimodal. Time-series isn't relevant here. RAG and KG are about different aspects (retrieval and knowledge graphs) which don't seem related to the architecture of a vision model. So the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33041@AAAI"},
{"title": "SGFormer: Semantic-Geometry Fusion Transformer for Multi-modal 3D Panoptic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SGFormer: Semantic-Geometry Fusion Transformer for Multi-modal 3D Panoptic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the title. That immediately makes me think the topic is multimodal. But let me check the other parts to be sure. The paper is about 3D panoptic segmentation, which involves combining different data types, like semantic and geometric information. The term \"fusion\" suggests integrating multiple modalities, which aligns with multimodal research. \n\nNow, the other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks. KG is Knowledge Graphs, which are structured representations of information. None of these seem to fit the title. The focus here is on combining different data modalities (semantic and geometric) for a 3D segmentation task. So the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33042@AAAI"},
{"title": "Separating the Wheat from the Chaff: Spatio-Temporal Transformer with View-interweaved Attention for Photon-Efficient Depth Sensing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Separating the Wheat from the Chaff: Spatio-Temporal Transformer with View-interweaved Attention for Photon-Efficient Depth Sensing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Spatio-Temporal Transformer\" suggests that the model deals with both spatial and temporal data. Transformers are often used in time-series analysis because they can handle sequences, but here it's spatio-temporal, so maybe it's about data that has both spatial (like images) and temporal (time-based) components. \n\n\"View-interweaved Attention\" might refer to combining different views or modalities, but I'm not sure. The application is \"Photon-Efficient Depth Sensing,\" which sounds like it's related to depth sensing using light (photons), possibly in 3D imaging or something like LiDAR. \n\nNow, looking at the topics. Time-series would involve data over time, which the spatio-temporal part does. But multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information in generation tasks. KG is Knowledge Graphs, which are structured data representations. \n\nThe paper seems to focus on a transformer model for depth sensing, which is a type of sensor data. The spatio-temporal aspect suggests handling data that changes over time and space, which is common in time-series analysis. However, depth sensing could involve multiple modalities (like RGB and depth), but the title doesn't explicitly mention combining different modalities. The main focus seems to be on the temporal and spatial aspects of the data. So maybe it's time-series. But wait, time-series is usually just temporal, but spatio-temporal is a combination. However, the options given are time-series, multimodal, RAG, or KG. Since spatio-temporal is a type of time-series with spatial data, maybe it's still considered under time-series. Alternatively, if multimodal is about combining different data types, but the title doesn't mention that. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33043@AAAI"},
{"title": "ReMoGPT: Part-Level Retrieval-Augmented Motion-Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ReMoGPT: Part-Level Retrieval-Augmented Motion-Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Retrieval-Augmented\" makes me think of RAG, which stands for Retrieval-Augmented Generation. That's a technique where a model uses external information retrieved from a database to enhance its responses. So if the paper mentions retrieval-augmented, that's a strong hint towards RAG.\n\nThen there's \"Motion-Language Models.\" Motion could relate to time-series data, like sequences over time, but the term \"Motion-Language\" might imply combining different modalities—like visual motion data with language. That could be multimodal. But the key part here is \"Retrieval-Augmented,\" which directly points to RAG. \n\nThe other options: time-series usually involves data points indexed in time order, like stock prices or sensor data. Multimodal refers to models that handle multiple types of data (text, images, audio). KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so probably not KG. \n\nSince the title explicitly uses \"Retrieval-Augmented,\" which is RAG, and the rest of the title doesn't contradict that, the answer should be RAG. Even though there's a mention of motion and language, which could be multimodal, the retrieval-augmented part is more specific here. So the primary topic is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33044@AAAI"},
{"title": "STGC-NeRF: Spatial-Temporal Geometric Consistency for LiDAR Neural Radiance Fields in Dynamic Scenes", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"STGC-NeRF: Spatial-Temporal Geometric Consistency for LiDAR Neural Radiance Fields in Dynamic Scenes.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"STGC-NeRF\" probably stands for Spatial-Temporal Geometric Consistency Neural Radiance Fields. The key parts here are \"Spatial-Temporal,\" which suggests both space and time, so maybe time-series? But time-series usually refers to data collected over time, like stock prices or weather data. However, the mention of \"LiDAR Neural Radiance Fields\" makes me think of 3D scene reconstruction or something related to computer vision. \n\nLiDAR is a remote sensing technology that uses light to measure distances, often used in autonomous vehicles or robotics. Neural Radiance Fields (NeRF) are a method for representing 3D scenes from 2D images. The term \"Dynamic Scenes\" implies that the scenes are changing over time, which might involve temporal data. So, the paper is probably dealing with modeling dynamic 3D scenes using LiDAR data with a focus on spatial and temporal consistency.\n\nNow, looking at the options. Time-series analysis deals with sequences of data over time. But this seems more about 3D spatial data over time, which could be a form of time-series but in a spatial context. However, the other options: multimodal refers to combining different data types (like text and images), RAG is Retrieval-Augmented Generation, and KG is Knowledge Graphs. None of those seem to fit here. The paper is about a specific method (STGC-NeRF) for handling LiDAR data in dynamic scenes, focusing on spatial-temporal consistency. \n\nWait, but time-series is a broad category. If the research involves analyzing data points indexed in time order, even if it's 3D data, it could still be considered time-series. However, in machine learning contexts, time-series often refers to one-dimensional time data. The term \"spatial-temporal\" here might be more about spatiotemporal data, which is a combination of spatial and temporal data. Spatiotemporal analysis is a subset of time-series but in a multidimensional space. However, the given options don't have a spatiotemporal category. The closest is time-series. But I'm not sure if the paper's focus is on time-series analysis or something else. \n\nAlternatively, maybe it's multimodal if it's combining different modalities like LiDAR and other data. But the title only mentions LiDAR. RAG and KG are unrelated here. So, the most plausible answer is time-series, but I'm a bit uncertain because the paper is about 3D scene reconstruction with dynamic elements. However, given the options, time-series might be the best fit here.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33045@AAAI"},
{"title": "KeyPose: Category-Level 6D Object Pose Estimation with Self-Adaptive Keypoints", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"KeyPose: Category-Level 6D Object Pose Estimation with Self-Adaptive Keypoints.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Category-Level 6D Object Pose Estimation\" suggests it's about estimating the position and orientation (6D) of objects in a category, not just individual instances. The method uses \"Self-Adaptive Keypoints,\" which probably refers to adjusting key points automatically for better estimation.\n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal would involve combining different data types, like text and images. The title mentions object pose estimation, which is typically a computer vision task. If they used multiple modalities (e.g., RGB and depth), it might be multimodal. But the title doesn't specify using multiple data types, just keypoints. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents. This paper is about pose estimation, which is a different domain. So RAG is probably not relevant here.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's focus is on pose estimation using keypoints, not on building or using knowledge graphs. So KG doesn't seem to fit either.\n\nSo the paper is about object pose estimation using adaptive keypoints. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The closest might be multimodal if they used multiple data types, but the title doesn't indicate that. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33046@AAAI"},
{"title": "Fine-grained Adaptive Visual Prompt for Generative Medical Visual Question Answering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Fine-grained Adaptive Visual Prompt for Generative Medical Visual Question Answering.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Generative Medical Visual Question Answering\" suggests that it's about answering questions using both visual (image) and textual data, especially in a medical context. So, that's a hint towards multimodal because it's combining different data types like images and text. \n\n\"Fine-grained Adaptive Visual Prompt\" might refer to using specific visual cues or prompts that are adjusted (adaptive) for better performance. The term \"visual prompt\" could be part of a model that processes images and text together, which again points to multimodal approaches. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not that. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation, often in text-based models. The title doesn't mention retrieval or combining retrieved information with generation, so maybe not RAG. \n\nKG (Knowledge Graphs) involve structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so that's probably out. \n\nPutting it all together, the paper is about combining visual and textual data (images and questions) for medical QA, which is a classic multimodal task. The use of visual prompts and adaptive methods might be specific techniques within the multimodal framework. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33047@AAAI"},
{"title": "OTPNet: ODE-inspired Tuning-free Proximal Network for Remote Sensing Image Fusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OTPNet: ODE-inspired Tuning-free Proximal Network for Remote Sensing Image Fusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. OTPNet is the model name. ODE-inspired suggests it's using ordinary differential equations as inspiration. Tuning-free might mean it doesn't require hyperparameter tuning. Proximal network could relate to optimization methods. The application is remote sensing image fusion.\n\nRemote sensing image fusion typically involves combining images from different sources or sensors. So, if it's combining different types of data (like optical and SAR images), that might be multimodal. Multimodal usually refers to integrating data from multiple modalities. But the title doesn't explicitly mention multiple modalities. It just says \"image fusion,\" which could be from different sensors, which would be multimodal. However, sometimes image fusion can be within the same modality but different resolutions or times. \n\nTime-series would involve data over time, like sequential data. The title doesn't mention time or sequences, so probably not time-series. RAG (Retrieval-Augmented Generation) is about using retrieval to augment generation models, which is more in NLP. KG (Knowledge Graph) involves structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval. \n\nSo the main possibilities are multimodal or none. Since the task is image fusion in remote sensing, which often involves combining different data types (multimodal), but the title doesn't explicitly state that. However, \"image fusion\" in remote sensing is commonly multimodal. For example, fusing optical and radar images. So maybe it's multimodal. But the model itself (OTPNet) is a proximal network inspired by ODEs. The key here is whether the research topic is about the fusion method (multimodal) or something else. Since the problem is image fusion, which is a multimodal task, the paper likely belongs to the multimodal category. \n\nAlternatively, if the fusion is within the same modality, it's not multimodal. But in remote sensing, image fusion is typically multimodal. So I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33048@AAAI"},
{"title": "Cross-Lingual Text-Rich Visual Comprehension: An Information Theory Perspective", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cross-Lingual Text-Rich Visual Comprehension: An Information Theory Perspective.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Lingual\" suggests dealing with multiple languages. \"Text-Rich Visual Comprehension\" implies combining text and visual elements, so that's probably multimodal since it's using both text and images. The \"Information Theory Perspective\" part might relate to how information is processed or measured, but that's more about the methodology rather than the topic itself.\n\nLooking at the options: time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which isn't mentioned. KG (Knowledge Graphs) involves structured data and relationships, which also isn't directly referenced. Multimodal, on the other hand, deals with integrating different data types like text and images, which matches the \"Text-Rich Visual\" part. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33049@AAAI"},
{"title": "Building a Multi-modal Spatiotemporal Expert for Zero-shot Action Recognition with CLIP", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Building a Multi-modal Spatiotemporal Expert for Zero-shot Action Recognition with CLIP\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the title. That suggests it's about combining different types of data, like text and images or video. Then \"Spatiotemporal\" refers to both space and time, which might relate to time-series data, but the main term here is \"multi-modal\". \n\nZero-shot action recognition usually involves using pre-trained models to recognize actions they weren't specifically trained on. CLIP is a model that's multimodal, combining text and images. So using CLIP here would support the multimodal aspect. \n\nTime-series would involve data over time, like stock prices or sensor data. While spatiotemporal does involve time, the key term here is \"multi-modal\". RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, which doesn't seem to be mentioned here. KG (Knowledge Graph) involves structured data and relationships, which isn't indicated in the title. \n\nSo the main topic here is multimodal because the title explicitly mentions \"Multi-modal\" and uses CLIP, which is a multimodal model. The other terms like spatiotemporal might relate to time-series, but the primary focus is on combining different modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33050@AAAI"}
{"title": "Backdoor Attacks Against No-Reference Image Quality Assessment Models via a Scalable Trigger", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Backdoor Attacks Against No-Reference Image Quality Assessment Models via a Scalable Trigger.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about image quality assessment, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image quality models, but the title doesn't mention combining different modalities. It's focused on a specific type of attack, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on backdoor attacks in image models, which doesn't seem related to knowledge graphs.\n\nSo, the paper is about a backdoor attack method using a scalable trigger in image quality assessment models. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The attack is a security issue in machine learning models, but the provided options don't cover security or adversarial attacks. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33051@AAAI"},
{"title": "OLMD: Orientation-aware Long-term Motion Decoupling for Continuous Sign Language Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OLMD: Orientation-aware Long-term Motion Decoupling for Continuous Sign Language Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Orientation-aware\" suggests that the model takes into account the orientation of movements, which might be relevant in motion data. \"Long-term Motion Decoupling\" implies handling sequences of motions over time, which could relate to time-series analysis. \"Continuous Sign Language Recognition\" is about recognizing sign language in a continuous stream, which often involves temporal data.\n\nTime-series analysis deals with data points indexed in time order. Since sign language recognition involves sequences of movements over time, this could be a time-series problem. The mention of \"long-term\" might indicate that the model is capturing temporal dependencies, which is a key aspect of time-series.\n\nMultimodal would involve combining different types of data, like text and images or audio and video. The title doesn't mention combining different modalities, so maybe not multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, typically in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't suggest building or using a knowledge graph, so that's unlikely.\n\nSo, the most likely topic here is time-series. The focus on motion over time and decoupling long-term dependencies points to time-series analysis in the context of sign language recognition.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33052@AAAI"},
{"title": "Yuan: Yielding Unblemished Aesthetics Through a Unified Network for Visual Imperfections Removal in Generated Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Yuan: Yielding Unblemished Aesthetics Through a Unified Network for Visual Imperfections Removal in Generated Images.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title here is about generated images and removing visual imperfections, so time-series doesn't seem relevant.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image processing, but the title doesn't mention combining different modalities. It's focused on improving the aesthetics of generated images, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP. The paper's focus is on image imperfections, so RAG doesn't seem to fit here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nThe paper is about a unified network for removing visual imperfections in images. It's an image processing or computer vision task. Since none of the given topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33053@AAAI"},
{"title": "Instruction-guided Multi-Granularity Segmentation and Captioning with Large Multimodal Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Instruction-guided Multi-Granularity Segmentation and Captioning with Large Multimodal Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Instruction-guided\" suggests that the model uses some form of instructions, maybe like following user prompts. \"Multi-Granularity Segmentation and Captioning\" refers to segmenting data into different levels of detail and generating captions. The key part here is \"Large Multimodal Model.\" The term \"multimodal\" directly points to the use of multiple data types, like combining text and images. So that's a strong indicator for the multimodal category.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences over time, so probably not that. RAG (Retrieval-Augmented Generation) involves using retrieval systems to augment the generation process, often in question-answering. The title doesn't mention retrieval or augmentation, so RAG is unlikely. KG (Knowledge Graph) involves structured data and relationships between entities. Again, the title doesn't mention knowledge graphs or structured data. \n\nSo the main keyword here is \"Multimodal,\" which is one of the options. The paper is about using a large model that handles multiple modalities, like images and text, for segmentation and captioning. Therefore, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33054@AAAI"},
{"title": "Where Precision Meets Efficiency: Transformation Diffusion Model for Point Cloud Registration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Where Precision Meets Efficiency: Transformation Diffusion Model for Point Cloud Registration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Point Cloud Registration\" refers to aligning different sets of 3D points, which is common in computer vision or robotics. The method mentioned is a \"Transformation Diffusion Model.\" Diffusion models are a type of generative model, but here they're applied to transformations for registration. \n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on a specific model for point cloud registration using diffusion. None of the four topics directly relate to point cloud processing or diffusion models in this context. Time-series isn't relevant here. Multimodal might be if they combined different data types, but the title doesn't mention that. RAG and KG are about information retrieval and structured knowledge, which don't seem to apply. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33055@AAAI"},
{"title": "DVP-MVS: Synergize Depth-Edge and Visibility Prior for Multi-View Stereo", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DVP-MVS: Synergize Depth-Edge and Visibility Prior for Multi-View Stereo.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Multi-View Stereo\" (MVS) is a term I've heard in computer vision, related to reconstructing 3D models from multiple 2D images. The method here is called DVP-MVS, which combines depth-edge and visibility priors. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images. The paper here is about combining depth-edge and visibility priors, which are both related to visual data (depth and visibility are aspects of 3D reconstruction). But are they different modalities? Depth could be considered a different modality from RGB images, but in MVS, it's more about using multiple views (images) to infer depth. So maybe not multimodal in the traditional sense of combining different data types like text and image.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to aid in generating responses. This paper is about 3D reconstruction, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, the paper is about improving multi-view stereo by integrating depth-edge and visibility priors. Since MVS is a computer vision task, and the options given don't include computer vision, the answer might be none. But wait, the options are time-series, multimodal, RAG, KG. None of these directly relate to computer vision or 3D reconstruction. The closest might be multimodal if depth-edge and visibility are considered different modalities, but I'm not sure. However, in the context of the given options, the answer is likely \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33056@AAAI"},
{"title": "MSP-MVS: Multi-Granularity Segmentation Prior Guided Multi-View Stereo", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MSP-MVS: Multi-Granularity Segmentation Prior Guided Multi-View Stereo.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View Stereo\" (MVS) is a term I've heard in computer vision, related to reconstructing 3D models from multiple 2D images. The \"Multi-Granularity Segmentation Prior\" part suggests that the method uses segmentation at different levels of detail to guide the stereo reconstruction. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to combining different types of data, like text and images. The paper here is about using segmentation (which is image data) in MVS, but it's not combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models like those that retrieve information from a database to enhance generation tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on 3D reconstruction using segmentation, which doesn't seem related to knowledge graphs.\n\nSo, none of the four topics seem to fit. The paper is about computer vision techniques for 3D reconstruction, specifically using segmentation priors. Since the options given don't include computer vision or 3D reconstruction, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33057@AAAI"},
{"title": "ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ChangeDiff: A Multi-Temporal Change Detection Data Generator with Flexible Text Prompts via Diffusion Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, \"Multi-Temporal\" probably refers to multiple time points, which makes me think of time-series data. Time-series analysis deals with data points indexed in time order. Change detection in this context would involve identifying differences over time. So that's a strong hint towards time-series.\n\nNext, the mention of \"Flexible Text Prompts\" might suggest that the model uses text inputs, which could be part of a multimodal approach. Multimodal typically involves combining different types of data, like text and images. However, the main focus here seems to be on generating data for change detection using diffusion models. The text prompts are a feature but not necessarily the core topic.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, like in question-answering systems. The title doesn't mention anything about retrieval or augmenting generation with retrieved information, so probably not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships between entities. There's no mention of knowledge graphs or structured data in the title, so that's out.\n\nPutting it all together, the key terms are \"Multi-Temporal\" and \"Change Detection,\" which are central to time-series analysis. The use of diffusion models might be the method, but the topic is about the temporal aspect. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33058@AAAI"},
{"title": "Efficient Neural Network Encoding for 3D Color Lookup Tables", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Efficient Neural Network Encoding for 3D Color Lookup Tables.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title is about 3D color lookup tables, which might relate to image processing, but there's no indication of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title is about neural networks and encoding for color tables, which doesn't seem related to knowledge graphs.\n\nSo none of the four topics seem to fit. The paper is about optimizing neural networks for 3D color lookups, which is more related to computer graphics or machine learning models for image processing. Since it doesn't align with any of the specified topics, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33059@AAAI"},
{"title": "Gaze Label Alignment: Alleviating Domain Shift for Gaze Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Gaze Label Alignment: Alleviating Domain Shift for Gaze Estimation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data that's sequential over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. Gaze estimation could involve both visual data (images) and maybe other modalities, but the title specifically talks about \"gaze label alignment\" and \"domain shift.\" Domain shift is about adapting models from one domain to another, which is more about transfer learning or domain adaptation. Not sure if that's multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to generate answers. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on gaze estimation and domain shift, which doesn't seem related to building or using knowledge graphs.\n\nSo, none of the four topics seem to fit. The paper is about domain adaptation in gaze estimation, which is a computer vision problem. Since the options given don't include computer vision or domain adaptation, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33060@AAAI"}
{"title": "Everywhere Attack: Attacking Locally and Globally to Boost Targeted Transferability", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Everywhere Attack: Attacking Locally and Globally to Boost Targeted Transferability.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The key terms here are \"attack,\" \"locally and globally,\" and \"targeted transferability.\" Transferability in machine learning usually refers to how well a model trained on one task can perform on another. Targeted transferability might mean making the model's predictions transferable to a specific target. \n\nNow, the topics given are time-series, multimodal, RAG, and KG. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time-based data, so time-series is probably out. It's not about combining different data modalities either, so multimodal might not fit. RAG and KG are more about model architecture or knowledge representation. The term \"attack\" here is likely referring to adversarial attacks, which are a type of security threat in machine learning. Adversarial attacks can be local or global, affecting specific parts or the entire model. Transferability in this context is about how well an adversarial example can transfer from one model to another. \n\nBut none of the given topics directly relate to adversarial attacks or transferability. RAG and KG are about different aspects. So maybe the paper doesn't fit into any of the four categories. The user wants to know if it's one of those four or none. Since the attack and transferability aren't covered by the listed topics, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33061@AAAI"},
{"title": "Light-T2M: A Lightweight and Fast Model for Text-to-motion Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Light-T2M: A Lightweight and Fast Model for Text-to-motion Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Text-to-motion generation\" suggests converting text into motion data. So, the input is text, and the output is motion, which could be a sequence of movements over time. That makes me think of time-series data because motion data is typically a sequence over time. But wait, maybe it's also multimodal because it's combining text (a modality) with motion (another modality). \n\nMultimodal usually refers to models that process multiple types of data, like text and images or text and audio. In this case, text and motion. So that could be multimodal. But the main task here is generating motion from text, which is a generation task. However, the options given are time-series, multimodal, RAG, or KG. \n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database and uses it to generate responses. That doesn't seem to fit here because the paper is about generating motion from text, not retrieving information. \n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention anything about knowledge graphs, so probably not that. \n\nTime-series is about data points indexed in time order. Motion data is a time-series because it's a sequence of movements over time. So generating motion from text would involve creating a time-series output. But the model itself might be designed for time-series generation. \n\nBut the question is about the research topic the paper belongs to. The key here is whether the primary focus is on the time-series aspect, the multimodal aspect, or something else. Since the model is generating motion (a time-series) from text, it's combining two modalities (text and motion), which is multimodal. However, the task is generation, not just processing multiple modalities. \n\nWait, the options are time-series, multimodal, RAG, KG. So if the paper is about generating motion (time-series) from text, does that make it a time-series topic? Or is the fact that it's using text (a different modality) to generate motion make it multimodal? \n\nMultimodal research often involves tasks that require integrating different data types. Since the input is text and the output is motion, which are different modalities, the model is handling multimodal data. So the research topic would be multimodal. \n\nBut I'm a bit confused because time-series is also involved. However, the four options given are separate. The paper's title doesn't mention time-series explicitly, but the output is a time-series. However, the primary classification here might be based on the input and output modalities. Since it's text-to-motion, which are different modalities, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33062@AAAI"},
{"title": "D^2-DPM: Dual Denoising for Quantized Diffusion Probabilistic Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"D^2-DPM: Dual Denoising for Quantized Diffusion Probabilistic Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"D^2-DPM\" probably stands for Dual Denoising for Diffusion Probabilistic Models. The key terms here are \"diffusion probabilistic models,\" which I know are related to generative models, like those used in image generation or other data types. The \"quantized\" part might refer to quantization techniques, which are often used to reduce model size or computational requirements by using lower precision numbers.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to models that handle multiple types of data, such as text and images. RAG stands for Retrieval-Augmented Generation, which combines retrieval of information with generation, often used in question-answering systems. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus seems to be on improving diffusion models through dual denoising and quantization. Diffusion models are a type of generative model, but none of the four topics directly relate to generative models in general. Time-series could be a stretch if the model is applied to time-series data, but the title doesn't mention that. Multimodal would require handling multiple data types, which isn't indicated here. RAG and KG are about retrieval and knowledge representation, which don't seem connected to diffusion models. So, the paper doesn't fit into any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33063@AAAI"},
{"title": "GaitCycFormer: Leveraging Gait Cycles and Transformers for Gait Emotion Recognition.", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GaitCycFormer: Leveraging Gait Cycles and Transformers for Gait Emotion Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"GaitCycFormer\" probably refers to a model that uses gait cycles and transformers. Gait cycles are related to the way a person walks, which is a time-dependent process. So, gait data is likely a time-series since it's collected over time. The use of transformers suggests they're handling sequential data, which is common in time-series analysis. \n\nThe task is emotion recognition from gait, which is a specific application. Now, checking the options: time-series deals with data over time, which fits here. Multimodal would involve combining different data types like text and images, but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval systems with generative models, which doesn't seem relevant here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. \n\nSo the main focus is on time-series data from gait cycles processed with transformers. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33064@AAAI"},
{"title": "TGFormer: Transformer with Track Query Group for Multi-Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TGFormer: Transformer with Track Query Group for Multi-Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main components are \"Transformer,\" \"Track Query Group,\" and \"Multi-Object Tracking.\" Transformers are a type of neural network architecture, often used in sequence modeling. Multi-Object Tracking (MOT) is a computer vision task where the goal is to track multiple objects across video frames over time. \n\nNow, looking at the options. Time-series analysis involves data points indexed in time order, which MOT could relate to since tracking over time is involved. But is that the primary focus here? The paper's title mentions a Transformer with a specific query group for tracking, which might be more about the model architecture rather than the time aspect itself. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not that. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, typically in NLP. The title doesn't mention retrieval or generation, so that's unlikely. \n\nKG (Knowledge Graph) involves structured data representations. The paper's focus seems to be on tracking algorithms, not knowledge graphs. \n\nSo, the closest might be time-series because tracking over time is a key aspect. However, the paper is about a specific model (Transformer with Track Query Group) for MOT. While MOT does involve time-series data (tracking over time), the primary research topic here is the model architecture for tracking, which might not fit neatly into the given categories. The options are time-series, multimodal, RAG, or KG. Since the paper is about a tracking method using a Transformer, which is a model for sequence data, maybe time-series is the best fit. But I'm a bit unsure because the main contribution is the model design for tracking, not the time-series analysis itself. However, given the options, time-series might be the closest. Alternatively, if none of the options fit, the answer would be \"none.\" But I need to check if the paper's topic aligns with any of the four. Since MOT is a time-series problem (tracking over time), maybe time-series is correct. But I'm not entirely certain. Let me think again. The Transformer is a model that can handle sequences, which are time-series. The paper is applying it to tracking, which is a time-series task. So the topic would be time-series. Alternatively, if the paper is about the model itself (Transformer with Track Query Group), maybe it's not about the time-series aspect but the model. However, the given options don't include computer vision or tracking specifically. The four options are time-series, multimodal, RAG, KG. So the best fit is time-series. I'll go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33065@AAAI"},
{"title": "Frequency-Aware Density Control via Reparameterization for High-Quality Rendering of 3D Gaussian Splatting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Frequency-Aware Density Control via Reparameterization for High-Quality Rendering of 3D Gaussian Splatting.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Frequency-Aware Density Control\" suggests something related to how data is distributed in frequency space. \"Reparameterization\" might be a technique used here. The application is \"High-Quality Rendering of 3D Gaussian Splatting.\" Gaussian splatting is a method used in 3D rendering, so this is about computer graphics or visualization.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in NLP for models that retrieve information to enhance their responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on rendering techniques for 3D data using Gaussian splatting. It's about improving the quality of the rendering by controlling density in a frequency-aware manner. None of the four topics seem to directly relate to 3D rendering or computer graphics. Time-series is about temporal data, multimodal about combining data types, RAG and KG are more about information retrieval or knowledge representation. So this doesn't fit into any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33066@AAAI"},
{"title": "World Knowledge-Enhanced Reasoning Using Instruction-Guided Interactor in Autonomous Driving", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"World Knowledge-Enhanced Reasoning Using Instruction-Guided Interactor in Autonomous Driving.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"World Knowledge-Enhanced Reasoning\" suggests that the research is incorporating some form of external knowledge into the reasoning process. The term \"Knowledge\" here might hint at Knowledge Graphs (KG), which are structured representations of information. Then there's \"Instruction-Guided Interactor,\" which could be about how the system uses instructions, maybe integrating different data sources or modalities. But the key part is \"World Knowledge-Enhanced,\" which makes me think of Knowledge Graphs being used to enhance the reasoning in autonomous driving systems. \n\nTime-series usually involves data over time, like stock prices or sensor data over time. The title doesn't mention time or sequences, so probably not time-series. Multimodal would involve combining different types of data, like text and images, but the title doesn't specify multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to augment model outputs, but the title doesn't mention retrieval or generation. The focus here is on enhancing reasoning with world knowledge, which aligns more with Knowledge Graphs (KG) as a structured knowledge source. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33067@AAAI"},
{"title": "DCA: Dividing and Conquering Amnesia in Incremental Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DCA: Dividing and Conquering Amnesia in Incremental Object Detection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Incremental Object Detection\" suggests that the model is learning over time, adding new objects without forgetting old ones. The term \"amnesia\" here probably refers to catastrophic forgetting, a common issue in incremental learning where the model forgets previous tasks when learning new ones. The method \"Dividing and Conquering\" might be a strategy to handle this by splitting the problem into parts.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. KG (Knowledge Graphs) involves structured data and relationships between entities.\n\nThe paper's focus is on incremental learning in object detection, which is a computer vision task. The problem of amnesia in this context is about preventing forgetting when learning new classes incrementally. None of the four topics directly relate to incremental learning or object detection. Time-series is about temporal data, which isn't the main focus here. Multimodal would involve combining different modalities, which isn't mentioned. RAG and KG are more about retrieval and knowledge graphs, which don't seem relevant here. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33068@AAAI"},
{"title": "DetRF: Detachable Novel Views Synthesis of Dynamic Scenes Using Backdrop-Driven Neural Radiance Fields", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DetRF: Detachable Novel Views Synthesis of Dynamic Scenes Using Backdrop-Driven Neural Radiance Fields.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Detachable Novel Views Synthesis\" suggests creating new views, maybe in 3D or computer vision. \"Dynamic Scenes\" implies something changes over time, which might relate to time-series. But wait, time-series usually refers to data collected over time, like stock prices or sensor data. Here, dynamic scenes could be about video or moving objects, which is more about temporal data. But does that make it a time-series topic? Maybe, but I'm not sure yet.\n\n\"Backdrop-Driven Neural Radiance Fields\" – Neural Radiance Fields (NeRF) are used for 3D scene reconstruction from 2D images. The \"backdrop-driven\" part might mean using a background to drive the synthesis. So this seems like a computer vision or graphics technique. \n\nNow, the four options: time-series, multimodal, RAG, KG. \n\nTime-series: If the paper is about analyzing sequences of data points over time, like forecasting or anomaly detection. But here, the focus is on generating novel views of dynamic scenes, which is more about 3D reconstruction and rendering. So maybe not time-series.\n\nMultimodal: This refers to combining multiple data types, like text and images, or audio and video. The title doesn't mention multiple modalities, so probably not multimodal.\n\nRAG (Retrieval-Augmented Generation): This is about using retrieval methods to enhance generation, like in NLP models that fetch external information. The title doesn't mention retrieval or generation in that context, so probably not RAG.\n\nKG (Knowledge Graphs): These are structured representations of knowledge, often used in semantic web or information retrieval. The paper's title doesn't mention knowledge graphs or structured data, so likely not KG.\n\nSo, the answer might be none. But wait, dynamic scenes could involve time-series data. However, the primary focus here is on view synthesis using NeRF, which is a computer vision technique. The dynamic aspect might be handled through time, but the main contribution is about detachable views and backdrop-driven methods, not time-series analysis. Therefore, it doesn't fit into any of the four categories. So the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33069@AAAI"},
{"title": "TranSplat: Generalizable 3D Gaussian Splatting from Sparse Multi-View Images with Transformers", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TranSplat: Generalizable 3D Gaussian Splatting from Sparse Multi-View Images with Transformers.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"3D Gaussian Splatting\" sounds like a technique in computer vision, maybe for rendering or modeling 3D objects. \"Sparse Multi-View Images\" suggests that the input is multiple images from different angles, but not a dense set. The use of \"Transformers\" indicates that the model architecture is based on transformers, which are common in NLP but also used in vision tasks now.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The paper uses multi-view images, which are multiple images, but all from the same modality (images). Unless there's another modality involved, but the title doesn't mention it. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper seems focused on 3D modeling and image processing, not on building or using knowledge graphs. So likely not KG.\n\nSo the answer might be none. But wait, maybe I'm missing something. Let me check again. The paper uses transformers, which are a model architecture, but the topics are about research areas. The key here is whether the research topic fits into one of the four. Since the paper is about 3D Gaussian splatting from multi-view images using transformers, it's more about computer vision and 3D reconstruction. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. So the correct answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33070@AAAI"}
{"title": "Training-Free and Hardware-Friendly Acceleration for Diffusion Models via Similarity-based Token Pruning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Training-Free and Hardware-Friendly Acceleration for Diffusion Models via Similarity-based Token Pruning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on accelerating diffusion models. The methods mentioned are \"training-free\" and \"hardware-friendly,\" using \"similarity-based token pruning.\" \n\nDiffusion models are a type of generative model, often used in image or text generation. The key here is the acceleration part. The paper is about making these models run faster or more efficiently, especially on hardware. The method involves token pruning based on similarity. Token pruning usually refers to removing redundant tokens in a sequence to speed up processing, which is common in NLP tasks. \n\nNow, looking at the possible topics. Time-series analysis deals with data over time, which doesn't seem directly related here. Multimodal refers to combining different data types like text and images, but the title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) involves using retrieval mechanisms to enhance generation, which isn't mentioned here. KG (Knowledge Graphs) are structured representations of knowledge, which also don't seem relevant. \n\nThe paper is about optimizing diffusion models through token pruning, which is more about model efficiency and hardware considerations. None of the listed topics (time-series, multimodal, RAG, KG) directly relate to this. The closest might be multimodal if the diffusion model is used for multimodal tasks, but the title doesn't specify that. Since the focus is on acceleration and pruning, which are general optimization techniques, and none of the four topics fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33071@AAAI"},
{"title": "When Open-Vocabulary Visual Question Answering Meets Causal Adapter: Benchmark and Approach", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"When Open-Vocabulary Visual Question Answering Meets Causal Adapter: Benchmark and Approach\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Open-Vocabulary Visual Question Answering\" – that sounds like a task where you answer questions about images using a model that can handle a wide range of vocabulary. Visual QA is typically multimodal because it involves both images (visual) and text (questions/answers). So that part points towards multimodal.\n\nThen there's \"Causal Adapter\". Adapters are usually modules added to pre-trained models to adapt them to specific tasks. The term \"causal\" might refer to causal reasoning or causal relationships. But I'm not sure if that's directly related to any of the four topics. RAG (Retrieval-Augmented Generation) involves using retrieval to augment generation, which is more about combining retrieval with generation models. KG (Knowledge Graphs) are structured representations of knowledge. Time-series is about data over time. \n\nThe paper introduces a benchmark and approach, so it's likely proposing a new method or evaluation for the problem. Since the main components are Visual Question Answering (which is multimodal) and an adapter, I think the primary topic here is multimodal. The causal adapter might be a specific technique, but the core of the research is combining vision and language, which is multimodal. The other topics don't seem to fit here. RAG and KG are different areas, and time-series isn't mentioned. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33072@AAAI"},
{"title": "Interpretable Face Anti-Spoofing: Enhancing Generalization with Multimodal Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Interpretable Face Anti-Spoofing: Enhancing Generalization with Multimodal Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. Face anti-spoofing is about detecting fake faces, like in biometric systems. The key part here is \"Multimodal Large Language Models.\" The word \"multimodal\" suggests that the research uses multiple types of data or modalities, such as text, images, audio, etc. So if the paper is using multiple modalities, then it would fall under the multimodal category.\n\nLooking at the other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model uses a retrieval system to get information before generating a response. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe title doesn't mention anything about time-based data, so time-series is probably not it. There's no indication of using retrieval or knowledge graphs either. The mention of \"multimodal\" is explicit, so that's the most likely category. The paper is using multimodal data (like combining visual and textual data) with large language models to improve face anti-spoofing. Therefore, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33073@AAAI"},
{"title": "Hand1000: Generating Realistic Hands from Text with Only 1,000 Images", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hand1000: Generating Realistic Hands from Text with Only 1,000 Images.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or weather data. This title doesn't mention anything about time or sequences over time, so probably not time-series.\n\nNext, multimodal refers to using multiple types of data, like combining text and images. The paper is generating hands from text, which uses text as input and produces images. That sounds like a multimodal task because it's combining different modalities (text and images). So maybe multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval component to fetch relevant information and then generates a response. The title doesn't mention anything about retrieving information from a database or using retrieval, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using a knowledge graph, so that's probably not it either.\n\nSo the most likely answer is multimodal because it's using text to generate images, which are different data modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33074@AAAI"},
{"title": "AdaDiff: Adaptive Step Selection for Fast Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AdaDiff: Adaptive Step Selection for Fast Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. AdaDiff probably refers to an adaptive diffusion method. The key part here is \"Adaptive Step Selection for Fast Diffusion Models.\" Diffusion models are a type of generative model that uses a sequence of steps to generate data, often used in image generation. The adaptive step selection suggests optimizing the number of steps or the process to make it faster.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external information retrieval in generative models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on improving diffusion models by adapting the steps, which is about making the model more efficient. None of the topics directly relate to diffusion models. Time-series is about temporal data, which isn't mentioned here. Multimodal involves multiple data types, which isn't the case here. RAG and KG are about retrieval and knowledge graphs, which also don't seem related. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33075@AAAI"},
{"title": "DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Model\" is right there in the title. That's one of the options. The other parts mention \"Visual Document Understanding,\" which suggests it's dealing with both visual data (like images) and text, which are different modalities. So multimodal makes sense here. \n\nThe other options: time-series would involve data over time, like stock prices or sensor data. RAG is Retrieval-Augmented Generation, which is about combining retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about time, retrieval, or knowledge graphs. The focus is on combining different data types (visual and text) for document understanding, which aligns with multimodal. The \"Efficient Visual Slimming\" part might refer to optimizing the model's visual processing, but that's still part of the multimodal approach. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33076@AAAI"},
{"title": "RepFace: Refining Closed-Set Noise with Progressive Label Correction for Face Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RepFace: Refining Closed-Set Noise with Progressive Label Correction for Face Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The paper is about face recognition, which is image-based, but the title doesn't mention combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't seem related to retrieval or generation, so RAG is probably out.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on refining labels for face recognition, which is more about improving model training rather than building a knowledge graph. \n\nThe paper's main idea is about correcting labels in a closed-set scenario for face recognition. Closed-set noise refers to errors in the labels where the true class is among the known classes. The method involves progressive label correction, which is a technique to refine the labels during training. This seems to be about improving the model's training process, perhaps using some form of iterative refinement. However, none of the four topics (time-series, multimodal, RAG, KG) directly relate to label correction in face recognition. The paper is focused on a specific problem in computer vision (face recognition) and a method to handle noisy labels, which doesn't fall under the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33077@AAAI"},
{"title": "DSRC: Learning Density-Insensitive and Semantic-Aware Collaborative Representation Against Corruptions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DSRC: Learning Density-Insensitive and Semantic-Aware Collaborative Representation Against Corruptions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. DSRC probably stands for something, but the key parts here are \"Density-Insensitive,\" \"Semantic-Aware Collaborative Representation,\" and \"Against Corruptions.\" \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so probably not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation in models, often in NLP. The title doesn't seem to involve retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title mentions \"Collaborative Representation\" and \"Semantic-Aware,\" which might relate to knowledge graphs if they're using structured data. But the term \"Corruptions\" might refer to noisy data. However, the main focus here seems to be on learning representations that are robust against corruptions, which could be a general machine learning problem. \n\nWait, \"Collaborative Representation\" makes me think of collaborative filtering or methods used in recommendation systems, which sometimes use knowledge graphs. But the title doesn't explicitly mention knowledge graphs. The \"Semantic-Aware\" part could imply using semantic information, which might be part of a knowledge graph. However, without explicit terms like \"knowledge graph\" or \"KG\" in the title, it's a bit of a stretch. \n\nAlternatively, maybe it's about robust learning in the presence of corrupted data. But the four options given are time-series, multimodal, RAG, KG. Since none of these seem to directly relate to the title's focus on collaborative representation and corruption resistance, maybe the answer is \"none.\" \n\nBut wait, \"Collaborative Representation\" could be a method used in knowledge graphs for entity or relation representation. If the paper is about building a knowledge graph that's robust to corruptions, then it might be KG. However, the title doesn't mention knowledge graphs explicitly. The term \"Density-Insensitive\" might relate to handling data with varying densities, which could be a problem in knowledge graphs where some entities have more connections than others. \n\nHmm. I'm a bit torn here. The options are limited, and the title doesn't clearly fit into any of the four categories. The closest might be KG if it's about knowledge graph representations, but without explicit mention, it's uncertain. Alternatively, maybe it's a new approach that doesn't fit into these categories. Since the instruction says to respond with \"none\" if it doesn't belong to any, I think the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33078@AAAI"},
{"title": "StoryWeaver: A Unified World Model for Knowledge-Enhanced Story Character Customization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"StoryWeaver: A Unified World Model for Knowledge-Enhanced Story Character Customization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge-Enhanced\" suggests that some form of knowledge is being used. The term \"Knowledge Graph\" (KG) comes to mind because KGs are structured representations of knowledge. The \"Unified World Model\" might imply integrating different data sources or knowledge bases. \n\n\"Story Character Customization\" could involve generating or modifying story elements, which might use knowledge to make the characters more consistent or rich. RAG (Retrieval-Augmented Generation) is a method that combines retrieval from a knowledge base with generation, so that's possible. But the title mentions \"Knowledge-Enhanced,\" which is a bit broader. \n\nMultimodal would involve multiple data types like text, images, audio, etc. The title doesn't mention different modalities, so maybe not that. Time-series is about data over time, which doesn't seem relevant here. \n\nSo between KG and RAG. RAG is a specific technique that uses retrieval from a knowledge source to augment generation. If the paper is about using a knowledge graph to enhance the story customization, then it might be KG. But if it's about retrieving knowledge during the generation process, then RAG. The term \"Knowledge-Enhanced\" is a bit vague. However, \"Unified World Model\" might suggest a structured knowledge base, which aligns more with KG. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33079@AAAI"},
{"title": "GeoBEV: Learning Geometric BEV Representation for Multi-view 3D Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GeoBEV: Learning Geometric BEV Representation for Multi-view 3D Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-view 3D Object Detection\" suggests that the paper is dealing with detecting objects in 3D space using multiple views. That makes me think of multimodal data because different views could be different modalities, like images from different angles or sensors. But wait, multimodal usually refers to combining different types of data, like text and images. Here, it's multiple views, which might be different camera angles or something similar. So maybe it's multimodal, but I'm not sure.\n\n\"Learning Geometric BEV Representation\" – BEV stands for Bird's Eye View, which is a common concept in autonomous driving and robotics. Creating a geometric representation from multiple views could involve fusing data from different sources or perspectives. If it's using multiple views (like different camera angles) to build a 3D model, that's multimodal. But if it's just processing multiple images from the same modality (e.g., all cameras), maybe it's not multimodal. However, \"multi-view\" often implies combining different perspectives, which could be considered a form of multimodal processing.\n\nTime-series would involve data over time, like sequences. The title doesn't mention anything about time, so probably not time-series. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generation tasks, which doesn't seem related here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit.\n\nSo the most likely candidate is multimodal. The paper is about combining multiple views (different perspectives) to detect 3D objects, which is a form of multimodal data fusion. Even if all the inputs are images, the multi-view aspect implies integrating different modalities or sources of visual data. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33080@AAAI"}
{"title": "Just a Few Glances: Open-Set Visual Perception with Image Prompt Paradigm", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Just a Few Glances: Open-Set Visual Perception with Image Prompt Paradigm.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Open-Set Visual Perception\" suggests that the research is about recognizing or understanding visual data where the classes might not be fully known in advance. \"Image Prompt Paradigm\" makes me think of using images as prompts, maybe in a way similar to how text prompts are used in models like GPT. \n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or sensor data. That doesn't seem to fit here. Multimodal usually involves combining different types of data, like text and images. The paper mentions visual perception, which is image-based, but does it combine with other modalities? The title doesn't explicitly say so. \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and uses it to generate responses. The \"Image Prompt Paradigm\" might be related to using retrieved images as prompts, but I'm not sure. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data. \n\nSo, the paper is about visual perception using image prompts. If it's using images as prompts to enhance or guide the model's understanding, maybe in a retrieval context. RAG involves retrieving information to augment generation. If the image prompts are being retrieved to help generate responses or perceptions, that could be RAG. But the term \"paradigm\" might refer to a new approach rather than RAG specifically. \n\nAlternatively, multimodal could be a fit if the model is combining images with other data types. However, the title only mentions visual perception, which is image-based. Unless the image prompts are part of a multimodal setup. But without explicit mention of other modalities, it's a stretch. \n\nI'm leaning towards RAG because the image prompt paradigm might involve retrieving images to assist in the perception task, similar to how RAG retrieves text. But I'm not entirely certain. The open-set aspect might relate to handling unknown classes, which could be a challenge in RAG if the retrieved data includes new information. \n\nAlternatively, if it's about using images as prompts without retrieval, maybe it's a different approach. But given the options, RAG seems plausible. I'll go with RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33081@AAAI"},
{"title": "Textured Mesh Saliency: Bridging Geometry and Texture for Human Perception in 3D Graphics", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Textured Mesh Saliency: Bridging Geometry and Texture for Human Perception in 3D Graphics.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title mentions 3D graphics, geometry, and texture, which don't seem time-dependent. So probably not time-series.\n\nMultimodal research deals with combining different types of data, like text and images. The paper talks about bridging geometry and texture, which are two different aspects of 3D models. Geometry refers to the shape, and texture is the surface details. So combining these two modalities might make it multimodal. But wait, is geometry and texture considered different modalities? In some contexts, yes, especially in computer vision where different data types are fused. So maybe multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where models retrieve information from a database to enhance their responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper is about 3D graphics and human perception, not about structuring knowledge or relationships between entities. So likely not KG.\n\nSo the most plausible is multimodal because it's combining geometry and texture in 3D graphics for human perception. The key here is that they're integrating two different data types (geometry and texture) to achieve a common goal, which aligns with multimodal research. I think that's the answer.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33082@AAAI"},
{"title": "R^2-Art: Category-Level Articulation Pose Estimation from Single RGB Image via Cascade Render Strategy", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"R²-Art: Category-Level Articulation Pose Estimation from Single RGB Image via Cascade Render Strategy.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title mentions a single RGB image, so time-series probably isn't it. \n\nMultimodal would involve combining different data types, like text and images. The paper uses a single RGB image, so maybe not multimodal unless there's another modality involved. The title doesn't mention other data types, so maybe not.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about pose estimation, which is a computer vision task. Unless they're using a knowledge graph in their method, which the title doesn't indicate, KG might not fit.\n\nThe paper is about estimating articulation poses from a single image using a cascade render strategy. That sounds like a computer vision problem, specifically in pose estimation. The topics given don't include computer vision or pose estimation. So none of the four topics (time-series, multimodal, RAG, KG) seem to fit. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33083@AAAI"},
{"title": "Common Sense Bias Modeling for Classification Tasks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Common Sense Bias Modeling for Classification Tasks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like text and images. The title is about bias modeling in classification, but there's no mention of combining different data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation models. The title doesn't talk about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title mentions \"common sense bias,\" which might relate to incorporating common sense knowledge, possibly through a knowledge graph. But the title doesn't explicitly mention a graph structure or knowledge integration. It's possible, but not certain.\n\nAlternatively, the paper could be about modeling biases in classification tasks that stem from common sense assumptions. This might not directly fit into any of the four categories. Since none of the topics are clearly indicated, maybe the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33084@AAAI"},
{"title": "IRMamba: Pixel Difference Mamba with Layer Restoration for Infrared Small Target Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"IRMamba: Pixel Difference Mamba with Layer Restoration for Infrared Small Target Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Infrared Small Target Detection\" suggests it's about detecting small targets in infrared images. The method is called \"Pixel Difference Mamba with Layer Restoration.\" The term \"Mamba\" might refer to a type of model, maybe a neural network architecture. \n\nLooking at the options: time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is used in models that retrieve information to generate answers. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper seems focused on image processing for infrared target detection. The method uses pixel differences and layer restoration, which are image processing techniques. There's no mention of time-series data, combining multiple modalities, retrieval-augmented generation, or knowledge graphs. So it doesn't fit any of the four categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33085@AAAI"},
{"title": "Semi-supervised Infrared Small Target Detection with Thermodynamic-Inspired Uneven Perturbation and Confidence Adaptation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Semi-supervised Infrared Small Target Detection with Thermodynamic-Inspired Uneven Perturbation and Confidence Adaptation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main subject is infrared small target detection. The methods mentioned are semi-supervised learning, thermodynamic-inspired uneven perturbation, and confidence adaptation. \n\nTime-series usually involves data over time, like stock prices or sensor data over time. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The paper is about infrared detection, which is a single modality (infrared images), so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nThe paper is about a detection method using specific techniques in a semi-supervised setting. The terms used don't align with any of the four topics listed. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33086@AAAI"},
{"title": "MOCID: Motion Context and Displacement Information Learning for Moving Infrared Small Target Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MOCID: Motion Context and Displacement Information Learning for Moving Infrared Small Target Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts are \"Motion Context and Displacement Information Learning\" and \"Moving Infrared Small Target Detection.\" So, the focus is on detecting small targets in infrared images that are moving. The method involves learning motion context and displacement information.\n\nTime-series analysis usually deals with data points indexed in time order. Since the paper is about moving targets, there's a temporal aspect here. The motion context and displacement would involve tracking over time, which is a time-series element. So maybe time-series is a candidate.\n\nMultimodal refers to using multiple data modalities, like combining text and images. The title mentions infrared, which is a type of image data, but there's no indication of combining different modalities. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The paper seems focused on detection in images, not on generating text or using retrieval in that way. So RAG is unlikely.\n\nKG is Knowledge Graphs, which involve structured data and relationships. The paper doesn't mention anything about knowledge graphs or structured data representation. So KG is probably not it.\n\nPutting it all together, the main aspect here is the temporal analysis of motion in infrared images for target detection. That aligns with time-series research. Even though it's in the context of images, the motion over time is key. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33087@AAAI"},
{"title": "Decoupling Scattering: Pseudo-Label Guided NeRF for Scenes with Scattering Media", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Decoupling Scattering: Pseudo-Label Guided NeRF for Scenes with Scattering Media.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, I'll break down the title. \"NeRF\" stands for Neural Radiance Fields, which is a method used in 3D scene reconstruction and rendering. The paper is about handling scenes with scattering media, which might relate to how light interacts with materials that scatter light, like fog or glass. The term \"Pseudo-Label Guided\" suggests that they're using some form of semi-supervised learning or pseudo-labeling techniques to guide the NeRF model.\n\nNow, looking at the possible topics. Time-series would involve data over time, like sequences or temporal data. Multimodal usually refers to combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper seems focused on improving NeRF for specific scene rendering, using pseudo-labels. None of the topics directly relate to time-series data. It's not about combining multiple modalities, so multimodal might not fit. RAG and KG are more about information retrieval and knowledge representation, which don't seem to be the focus here. The core is about 3D scene rendering with a specific technique, which doesn't align with any of the four listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33088@AAAI"},
{"title": "PanoDiT: Panoramic Videos Generation with Diffusion Transformer", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PanoDiT: Panoramic Videos Generation with Diffusion Transformer.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Panoramic Videos Generation\" suggests creating videos that are panoramic in nature. \"Diffusion Transformer\" probably refers to using a diffusion model combined with a transformer architecture. \n\nTime-series usually involves data that's sequential over time, like stock prices or sensor data. While videos are inherently time-series data, the main focus here might not be on time-series analysis but rather on generating the videos themselves. \n\nMultimodal research deals with combining different types of data, like text and images. The title doesn't mention combining different modalities, just generating panoramic videos. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title doesn't mention retrieval, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't indicate anything about knowledge graphs. \n\nSo, the paper is about generating panoramic videos using a diffusion transformer. None of the listed topics (time-series, multimodal, RAG, KG) directly apply here. The main focus is on video generation, which might be a subset of computer vision or generative models, but not one of the specified topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33089@AAAI"},
{"title": "SIGraph: Saliency Image-Graph Network for Retinal Disease Classification in Fundus Image", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SIGraph: Saliency Image-Graph Network for Retinal Disease Classification in Fundus Image.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points collected over time, like stock prices or sensor data over time. This title mentions a fundus image, which is a medical image of the retina. So time-series doesn't seem right here.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title talks about an image-based network, but I don't see mention of combining different data types. It's focused on images, specifically fundus images, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The paper here is about a neural network for classification, not retrieval or generation. So probably not RAG.\n\nKG is Knowledge Graph, which involves structured data representing entities and relationships. The title mentions a \"Graph Network,\" but the context is about a saliency image-graph. The graph here might refer to a graph neural network (GNN) used to process the image data, not a knowledge graph. So maybe not KG either.\n\nWait, the term \"Graph\" in the title could be part of a Graph Neural Network (GNN), which is different from a Knowledge Graph (KG). Since the options are RAG or KG, and the paper is about a graph network for image classification, it's more likely related to GNNs, but since the given options don't include GNN, and the closest is KG, but I don't think it's that. The paper doesn't mention knowledge graphs. So maybe none of the options fit. The correct answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33090@AAAI"}
{"title": "Visual Perturbation for Text-Based Person Search", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Visual Perturbation for Text-Based Person Search.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Visual Perturbation\" suggests something related to modifying or altering visual data. \"Text-Based Person Search\" implies that the task involves searching for a person using text descriptions. So, combining these, the paper is probably about using visual data (like images) and text to find a person, maybe in a video or image database.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time, so maybe not time-series. \n\nMultimodal refers to using multiple types of data, like combining text and images. Since the paper uses both visual (images) and text-based information, this seems like a strong candidate. \n\nRAG stands for Retrieval-Augmented Generation, which is more about enhancing models with retrieval from a database. The title doesn't mention anything about retrieval or generation, so probably not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so likely not KG either.\n\nSo, the most fitting topic here is multimodal because it combines visual and textual data for a search task. The key is the combination of different modalities (text and vision) to achieve the person search. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33091@AAAI"},
{"title": "EDENet: Echo Direction Encoding Network for Place Recognition Based on Ground Penetrating Radar", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EDENet: Echo Direction Encoding Network for Place Recognition Based on Ground Penetrating Radar.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. EDENet is the name of the network. Echo Direction Encoding suggests they're encoding the direction of echoes, which might relate to how data is processed. Place Recognition is the task, so they're trying to recognize locations. Ground Penetrating Radar (GPR) is the sensor used, which sends radar pulses into the ground to detect objects or structures.\n\nNow, the four topics: time-series, multimodal, RAG, KG. \n\nTime-series usually involves data points indexed in time order. GPR data might be collected over time, but the key here is the method. If the paper is about processing sequences over time, it's time-series. But the title mentions \"Echo Direction Encoding,\" which might be more about spatial information rather than temporal.\n\nMultimodal refers to using multiple data types (like combining images and text). The paper uses GPR, which is a single modality, so maybe not multimodal unless they combine it with other sensors, but the title doesn't mention that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. This seems unrelated to GPR-based place recognition.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses or builds a knowledge graph, it would fit here. But the title doesn't mention anything about knowledge graphs.\n\nSo, the paper is about a neural network (EDENet) for place recognition using GPR data. The key here is the method. Echo Direction Encoding might involve encoding spatial features from the radar data. Since GPR data is a type of sensor data, maybe it's a time-series if the data is collected over time. However, place recognition often deals with spatial data. But the problem is whether the paper's focus is on the time-series aspect. The title doesn't explicitly mention time-series processing. The main contribution seems to be the encoding method for echo directions, which is more about spatial features. Therefore, it might not fit into any of the four categories. The answer could be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33092@AAAI"},
{"title": "View Transformation Robustness for Multi-View 3D Object Reconstruction with Reconstruction Error-Guided View Selection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"View Transformation Robustness for Multi-View 3D Object Reconstruction with Reconstruction Error-Guided View Selection.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Multi-View 3D Object Reconstruction\" suggests that the research is about reconstructing 3D objects from multiple views. The term \"multi-view\" might relate to using different perspectives or data sources. But does that make it multimodal? Multimodal usually refers to combining different types of data, like text and images. Here, it's about multiple views of the same object, which could be different images from different angles. So maybe multimodal? But I'm not sure. \n\nThen there's \"View Transformation Robustness.\" That part is about making the reconstruction robust to changes in view transformations, like rotations or translations. That seems more about the method's robustness rather than the data modality. \n\n\"Reconstruction Error-Guided View Selection\" implies that the selection of views is guided by reconstruction errors. This is about optimizing the selection process based on error metrics. \n\nLooking at the four options: time-series involves data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieved information to augment generation, which isn't mentioned. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't fit. \n\nMultimodal would be if they're combining different data types, like text and images. But in this case, it's multiple views of the same object, which are all images. So maybe not multimodal. The key term is \"multi-view,\" which is about different perspectives, not different modalities. \n\nWait, but sometimes \"multi-view\" can be considered a form of multimodal if each view is a different modality. However, in most contexts, multimodal refers to different types of data (e.g., text, image, audio), not different views of the same type. So perhaps this isn't multimodal. \n\nIf none of the four topics fit, the answer would be \"none.\" But let me check again. The paper is about 3D reconstruction from multiple views, focusing on robustness to view transformations and view selection based on error. None of the listed topics directly relate to 3D reconstruction, view transformations, or error-guided selection. Time-series is about sequences over time, RAG and KG are about retrieval and knowledge graphs. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33093@AAAI"},
{"title": "Rethinking Pseudo-Label Guided Learning for Weakly Supervised Temporal Action Localization from the Perspective of Noise Correction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Rethinking Pseudo-Label Guided Learning for Weakly Supervised Temporal Action Localization from the Perspective of Noise Correction.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Temporal Action Localization\" suggests something related to time, since \"temporal\" refers to time. That makes me think of time-series data, which is data collected over time. So maybe it's a time-series topic. \n\nThen there's \"Weakly Supervised,\" which is a type of machine learning where the training data is not fully labeled. But that's more about the learning approach rather than the data type. \n\n\"Pseudo-Label Guided Learning\" refers to using pseudo-labels, which are generated labels for unlabeled data. Again, this is a methodological aspect. \n\n\"Noise Correction\" from the perspective of that. So the paper is about correcting noise in the pseudo-labels used for weakly supervised learning in temporal action localization. \n\nNow, looking at the possible topics. Time-series deals with data over time. The task here is temporal action localization, which is about identifying actions in a video over time, so that's definitely time-series data. \n\nMultimodal would involve multiple types of data, like combining text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal. \n\nRAG (Retrieval-Augmented Generation) is a method that uses retrieval to augment generation in models, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is out. \n\nKG (Knowledge Graph) involves structured data and relationships. The title doesn't mention knowledge graphs or structured data, so that's not it either. \n\nSo the main focus here is on temporal data (time-series) for action localization, using pseudo-labels and addressing noise. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33094@AAAI"},
{"title": "Matching While Perceiving: Enhance Image Feature Matching with Applicable Semantic Amalgamation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Matching While Perceiving: Enhance Image Feature Matching with Applicable Semantic Amalgamation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Image Feature Matching\" suggests it's about images, so maybe computer vision. \"Semantic Amalgamation\" implies combining different types of information, possibly from different modalities. \"Matching While Perceiving\" might refer to integrating perception (like visual data) with some kind of matching process. \n\nMultimodal research typically involves combining data from multiple modalities, like text and images, or audio and video. If this paper is about enhancing image feature matching using semantic information, maybe from another modality (like text or other data types), that would fit under multimodal. \n\nTime-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is more about using retrieval in generative models, which isn't mentioned. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't seem to be the focus. \n\nThe key terms are \"image feature matching\" and \"semantic amalgamation.\" If they're combining image features with semantic data (like from text or other sources), that's multimodal. So the answer is probably multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33095@AAAI"},
{"title": "DiMSOD: A Diffusion-Based Framework for Multi-Modal Salient Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiMSOD: A Diffusion-Based Framework for Multi-Modal Salient Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the title. That immediately makes me think the topic is multimodal. But let me check the other parts to be sure. The framework is diffusion-based, which might relate to some techniques in machine learning, but the key part here is \"Multi-Modal Salient Object Detection.\" \n\nSalient object detection usually refers to identifying the most noticeable objects in an image or video. But since it's multi-modal, that means it's using more than one type of data input, like combining images with text or other sensor data. So the \"multi-modal\" aspect is central here. \n\nLooking at the options: time-series is about data over time, which doesn't seem to fit. RAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships. None of those seem to directly relate to the multi-modal aspect mentioned in the title. \n\nTherefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33096@AAAI"},
{"title": "Pragmatist: Multiview Conditional Diffusion Models for High-Fidelity 3D Reconstruction from Unposed Sparse Views", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Pragmatist: Multiview Conditional Diffusion Models for High-Fidelity 3D Reconstruction from Unposed Sparse Views.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multiview Conditional Diffusion Models\" suggests that the model uses multiple views. \"3D Reconstruction from Unposed Sparse Views\" means they're trying to create a 3D model from a few, maybe randomly placed images. \n\nNow, the key terms here. \"Multiview\" might relate to multimodal, since multimodal often involves combining different types of data. But wait, multimodal typically refers to using different modalities like text, image, audio together. Here, it's about multiple views of the same object, which could be images from different angles. So maybe that's more about the input being multiple images, but not necessarily different modalities. \n\nTime-series would involve data over time, like sequences. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information from a database to enhance generation. The title doesn't mention retrieval or generation in that context, so maybe not RAG. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on 3D reconstruction using diffusion models, which doesn't seem to involve building or using a knowledge graph. \n\nSo, the main term here is \"Multiview,\" which could imply multimodal if the different views are considered different modalities. However, in 3D reconstruction, multiple views are usually different perspectives of the same modality (images). So maybe the paper is using multiple input views (images) to reconstruct 3D, which is a single modality. Therefore, it might not be multimodal. \n\nBut wait, the term \"multimodal\" can sometimes be used in the context of multiple input sources. If the model is combining different types of data (like images and text), then it's multimodal. Here, it's all images from different angles, so maybe it's not multimodal. \n\nSo, none of the four topics seem to fit. The paper is about 3D reconstruction using diffusion models with multiple views, which doesn't directly relate to time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33097@AAAI"},
{"title": "Point Cloud Mamba: Point Cloud Learning via State Space Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Point Cloud Mamba: Point Cloud Learning via State Space Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Point Cloud\" refers to a set of data points in space, often used in 3D modeling or LiDAR data. \"Mamba\" might be the name of the model or method. \"State Space Model\" is a term I've heard in time-series analysis, like in Kalman filters or SSMs used for sequential data. So the key part here is \"State Space Model,\" which is typically associated with time-series data. \n\nNow, checking the options. Time-series deals with data over time, which SSMs are used for. Multimodal would involve combining different data types like text and images. RAG is Retrieval-Augmented Generation, which is more about using external knowledge in generation tasks. KG is Knowledge Graphs, which are structured representations of information. \n\nThe paper uses a State Space Model for point cloud learning. Since SSMs are a time-series method, even though point clouds are spatial, the model's core is a time-series approach. So the topic should be time-series. I don't see multimodal aspects here, and RAG or KG aren't mentioned. So the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33098@AAAI"},
{"title": "DZAD: Diffusion-based Zero-shot Anomaly Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DZAD: Diffusion-based Zero-shot Anomaly Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Diffusion-based\" probably refers to using diffusion models, which are a type of generative model. \"Zero-shot Anomaly Detection\" means detecting anomalies without prior examples of those anomalies. So the method is using diffusion to detect anomalies in a zero-shot setting.\n\nNow, the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge sources. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title doesn't mention anything about time, so time-series might not be it. There's no indication of combining multiple modalities either. RAG and KG are about knowledge retrieval or structured data, which doesn't seem to be the focus here. The paper is about anomaly detection using diffusion models, which is a machine learning technique but doesn't fit into the four categories given. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33099@AAAI"},
{"title": "Few-Shot Domain Adaptation for Learned Image Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Few-Shot Domain Adaptation for Learned Image Compression.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Few-Shot Domain Adaptation\" refers to a machine learning technique where the model adapts to a new domain with very few examples. \"Learned Image Compression\" suggests that the focus is on using machine learning models to compress images. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time, so probably not time-series. \n\nMultimodal typically involves combining different data types, like text and images. The paper here is about image compression, which is a single modality (images), so maybe not multimodal unless there's another modality involved, but the title doesn't indicate that.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge representation, so probably not KG.\n\nSo, the paper is about domain adaptation in image compression. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The main focus is on domain adaptation techniques for image compression models, which is more about machine learning methods rather than the specific topics listed. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33100@AAAI"}
{"title": "SVTformer: Spatial-View-Temporal Transformer for Multi-View 3D Human Pose Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SVTformer: Spatial-View-Temporal Transformer for Multi-View 3D Human Pose Estimation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View 3D Human Pose Estimation\" suggests that the research is about estimating human poses in 3D using multiple camera views. The method is called SVTformer, which combines Spatial-View-Temporal Transformers. \n\nLooking at the components: \"Spatial-View\" might refer to handling data from different viewpoints (like multiple cameras), which could be a form of multimodal data since it's integrating information from different sources. \"Temporal\" implies that there's a time component, so maybe time-series data is involved. However, the main focus here is on combining spatial and temporal information for pose estimation. \n\nNow, the options. Time-series usually involves data over time, like stock prices or sensor data. This paper does have a temporal aspect, but the key innovation seems to be the combination of spatial (multi-view) and temporal data. \n\nMultimodal refers to using multiple types of data (e.g., text and images). In this case, the multi-view aspect is about different camera angles, which could be considered different modalities. So maybe multimodal is a fit here. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation tasks, like in language models. This doesn't seem related. \n\nKG (Knowledge Graphs) involve structured data and relationships. The paper doesn't mention anything about knowledge graphs. \n\nSo, the main question is whether \"multi-view\" in the title points to multimodal. Since each camera view is a different modality (or perspective), integrating them would be multimodal. The temporal part is part of the method but the primary classification might be multimodal. Alternatively, if the focus is on the time aspect, it could be time-series. But given that the problem is 3D pose estimation with multiple views, the multimodal aspect is more prominent. So the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33101@AAAI"},
{"title": "Enhancing Implicit Neural Representations via Symmetric Power Transformation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Implicit Neural Representations via Symmetric Power Transformation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Implicit Neural Representations\" probably refers to using neural networks to represent data in a continuous or implicit way, maybe like neural radiance fields or something similar. The \"Symmetric Power Transformation\" part sounds like a mathematical technique applied to these representations. The goal is to enhance them, so maybe improving their accuracy or efficiency.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of information, usually involving entities and relationships.\n\nThe title doesn't mention anything about time, so time-series is probably out. There's no indication of combining multiple modalities either, so multimodal might not fit. RAG and KG are more about specific applications or structures. The paper seems focused on improving neural representations through a mathematical transformation. None of the four topics directly relate to enhancing neural representations via power transformations. So maybe it doesn't fit any of the given categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33102@AAAI"},
{"title": "Bootstraping Clustering of Gaussians for View-consistent 3D Scene Understanding", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bootstraping Clustering of Gaussians for View-consistent 3D Scene Understanding.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title talks about 3D scene understanding, which might involve different modalities, but the key part here is \"clustering of Gaussians\" and \"view-consistent.\" Not sure if it's multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus seems to be on clustering and 3D scenes, not on building or using knowledge graphs.\n\nThe main terms here are clustering, Gaussians, and 3D scene understanding. Clustering is a machine learning technique, and Gaussians might refer to Gaussian Mixture Models. View-consistent suggests that the method ensures consistency across different views of a 3D scene. This seems more related to computer vision or 3D reconstruction rather than the listed topics. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33103@AAAI"},
{"title": "MTGA: Multi-View Temporal Granularity Aligned Aggregation for Event-Based Lip-Reading", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MTGA: Multi-View Temporal Granularity Aligned Aggregation for Event-Based Lip-Reading.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-View\" might suggest using multiple perspectives or data sources, which could hint at multimodal. But I need to check the other parts. \"Temporal Granularity\" definitely relates to time, so that's a time-series aspect. \"Event-Based Lip-Reading\" is about reading lips based on events, which is a specific application. \n\nNow, the main question is whether the paper's focus is on time-series data, multimodal data, RAG (Retrieval-Augmented Generation), or Knowledge Graphs (KG). The term \"temporal\" in the title points towards time-series analysis. The \"Multi-View\" could imply using different modalities, like audio and video, but the key here is the temporal alignment and aggregation. Since the core of the method is about aligning different temporal granularities, the primary topic is likely time-series. \n\nMultimodal usually involves combining different types of data (e.g., text and images), but the title doesn't explicitly mention different modalities. RAG and KG are more about information retrieval and structured data, which don't seem relevant here. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33104@AAAI"},
{"title": "Transtreaming: Adaptive Delay-aware Transformer for Real-time Streaming Perception", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Transtreaming: Adaptive Delay-aware Transformer for Real-time Streaming Perception.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Transtreaming\" probably combines \"Transformer\" and \"streaming.\" The key parts here are \"Adaptive Delay-aware Transformer\" and \"Real-time Streaming Perception.\" \n\nReal-time streaming suggests that the data is being processed as it comes in, which is common in time-series analysis because time-series data is sequential and often processed in real-time. The mention of \"delay-aware\" implies that the model is handling the timing aspects, which is a big part of time-series processing. Transformers are typically used in sequence modeling, which is also relevant for time-series data.\n\nMultimodal would involve combining different types of data, like text and images, but the title doesn't mention anything about multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, which isn't indicated here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't seem to fit.\n\nSo, putting it all together, the focus on real-time streaming and delay-awareness points towards time-series processing. The use of a Transformer model adapted for streaming data aligns with time-series analysis techniques. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33105@AAAI"},
{"title": "Iterative Self-Training with Class-Aware Text-to-Image Synthesis for Visual Task Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Iterative Self-Training with Class-Aware Text-to-Image Synthesis for Visual Task Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Iterative Self-Training\" suggests a machine learning approach where the model trains itself iteratively. \"Class-Aware Text-to-Image Synthesis\" implies generating images from text, considering different classes. \"Visual Task Learning\" points to tasks involving images or vision.\n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The text-to-image synthesis part uses both text and images, so that's a strong indicator. The model is generating images based on text, which is a multimodal task.\n\nRAG (Retrieval-Augmented Generation) involves using retrieval to enhance generation, often in text. The title doesn't mention retrieval or augmenting with retrieved data, so maybe not RAG.\n\nKG (Knowledge Graphs) are structured data representations. The title doesn't mention knowledge graphs or structured data, so probably not KG.\n\nPutting it all together: the paper is about generating images from text, which is a multimodal task. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33106@AAAI"},
{"title": "Enhancing Multimodal Large Language Models Complex Reason via Similarity Computation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Multimodal Large Language Models Complex Reason via Similarity Computation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Multimodal Large Language Models\" and \"Similarity Computation.\" The word \"Multimodal\" is right there in the title. Multimodal refers to models that can process multiple types of data, like text, images, audio, etc. So that's a strong indicator. The other part is about enhancing complex reasoning through similarity computation. But the main topic here seems to be the multimodal aspect. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series. RAG stands for Retrieval-Augmented Generation, which involves using external information retrieval to enhance model outputs. The title doesn't mention retrieval or generation, so RAG is unlikely. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't reference knowledge graphs either. \n\nSo the only matching term is \"Multimodal\" from the title. The paper is about improving multimodal models, so the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33107@AAAI"},
{"title": "Toy-GS: Assembling Local Gaussians for Precisely Rendering Large-Scale Free Camera Trajectories", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Toy-GS: Assembling Local Gaussians for Precisely Rendering Large-Scale Free Camera Trajectories.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Toy-GS\" probably refers to a method or model. \"Assembling Local Gaussians\" suggests using Gaussian distributions, maybe in a spatial or probabilistic context. \"Precisely Rendering Large-Scale Free Camera Trajectories\" implies generating or simulating camera movements, possibly in a 3D environment. \n\nTime-series analysis deals with data points indexed in time order. This paper seems more about spatial rendering and camera paths, not time-dependent data sequences. So maybe not time-series.\n\nMultimodal research involves combining different data types, like text and images. The title doesn't mention multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. The title doesn't mention retrieval or generation in that context, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's focus on assembling Gaussians for rendering doesn't seem related to knowledge graphs.\n\nSo, none of the four topics seem to fit. The paper is about rendering camera trajectories using Gaussian methods, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33108@AAAI"},
{"title": "Beyond Spatial Domain: Cross-domain Promoted Fourier Convolution Helps Single Image Dehazing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Beyond Spatial Domain: Cross-domain Promoted Fourier Convolution Helps Single Image Dehazing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Beyond Spatial Domain\" suggests they're moving beyond just the spatial domain, maybe into frequency domain. \"Cross-domain Promoted Fourier Convolution\" – Fourier is related to frequency analysis, so they're using Fourier transforms. Convolution here is part of the method. The application is \"Single Image Dehazing,\" which is an image processing task, like removing haze from images.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper is about image dehazing using Fourier convolution. That's image processing, which is a single modality (images), so not multimodal. It's not about time-series data. RAG and KG are more about data retrieval or knowledge structures, which don't seem related here. The method uses Fourier transforms, which is a technique in signal processing, but the main topic here is image dehazing, which doesn't fit any of the four categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33109@AAAI"},
{"title": "CAMSIC: Content-aware Masked Image Modeling Transformer for Stereo Image Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CAMSIC: Content-aware Masked Image Modeling Transformer for Stereo Image Compression.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Content-aware Masked Image Modeling Transformer\" suggests it's using a transformer model for image processing. \"Stereo Image Compression\" means it's about compressing stereo images, which are pairs of images taken from slightly different viewpoints to create a 3D effect. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This doesn't seem to fit because the focus is on images, not sequences over time. \n\nMultimodal refers to combining multiple data types, like text and images. The paper is about stereo images, which are two images (left and right) but still within the same modality (images). Unless they're combining images with another modality, but the title doesn't mention that. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't indicate any use of knowledge graphs or structured data. \n\nSo, the paper is about image compression using a transformer model, specifically for stereo images. None of the given topics (time-series, multimodal, RAG, KG) directly apply here. The closest might be multimodal if stereo images are considered as two modalities, but typically stereo images are still within the same modality (visual). Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33111@AAAI"}
{"title": "CAMSIC: Content-aware Masked Image Modeling Transformer for Stereo Image Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CAMSIC: Content-aware Masked Image Modeling Transformer for Stereo Image Compression.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Content-aware Masked Image Modeling Transformer\" suggests it's using a transformer model for image processing. \"Stereo Image Compression\" means it's about compressing stereo images, which are pairs of images taken from slightly different viewpoints to create a 3D effect. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This doesn't seem to fit because the focus is on images, not sequences over time. \n\nMultimodal refers to combining multiple data types, like text and images. The paper is about stereo images, which are two images (left and right) but still within the same modality (images). Unless they're combining images with another modality, but the title doesn't mention that. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't indicate any use of knowledge graphs or structured data. \n\nSo, the paper is about image compression using a transformer model, specifically for stereo images. None of the given topics (time-series, multimodal, RAG, KG) directly apply here. The closest might be multimodal if stereo images are considered as two modalities, but typically stereo images are still within the same modality (visual). Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33111@AAAI"},
{"title": "Pose Magic: Efficient and Temporally Consistent Human Pose Estimation with a Hybrid Mamba-GCN Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Pose Magic: Efficient and Temporally Consistent Human Pose Estimation with a Hybrid Mamba-GCN Network.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus is on human pose estimation. The key terms here are \"temporally consistent\" and \"Hybrid Mamba-GCN Network.\" Temporally consistent suggests that the model maintains consistency over time, which is a common concern in time-series data. Time-series analysis deals with data points indexed in time order, so if the model is handling sequences of poses over time, that's a time-series aspect.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about combining different data types, so maybe not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem relevant here.\n\nThe hybrid network uses Mamba and GCN. Mamba is a type of model for sequence modeling, which is related to time-series. GCN (Graph Convolutional Network) is used for graph-structured data, which in this case could be the human body's joints. But the key part here is \"temporally consistent,\" which directly points to handling sequences over time. So the primary topic here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33112@AAAI"},
{"title": "SGDiff: Scene Graph Guided Diffusion Model for Image Collaborative SegCaptioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SGDiff: Scene Graph Guided Diffusion Model for Image Collaborative SegCaptioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Scene Graph Guided Diffusion Model\" – scene graphs are related to knowledge graphs (KG), right? Because scene graphs represent objects and their relationships in an image, which is a structured form of knowledge. So \"Scene Graph Guided\" suggests that the model uses a knowledge graph structure to guide the diffusion process.\n\nThen, \"Image Collaborative SegCaptioning\" – SegCaptioning probably refers to segmentation and captioning. So the model is doing both tasks together. But the key part here is the use of scene graphs. Since scene graphs are a type of knowledge graph, this would fall under the KG topic. \n\nTime-series is about data over time, which doesn't seem relevant here. Multimodal usually involves combining different data types like text and images, but the title doesn't mention multiple modalities explicitly. RAG (Retrieval-Augmented Generation) involves using retrieval to augment generation, which isn't mentioned here either. So the most fitting topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33113@AAAI"},
{"title": "VideoElevator: Elevating Video Generation Quality with Versatile Text-to-Image Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"VideoElevator: Elevating Video Generation Quality with Versatile Text-to-Image Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The paper here is about video generation, which does involve sequences over time, but the main focus seems to be on using text-to-image models. So maybe time-series is part of it, but not sure yet.\n\nMultimodal refers to combining multiple modalities, like text and images. The title mentions text-to-image, which is combining text (language) and images. So that's a strong indicator of multimodal. The model is taking text input and generating images, which are different modalities.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text. The title doesn't mention anything about retrieval or augmenting with external data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about graphs or structured data, so likely not KG.\n\nSo the main focus is on combining text and image modalities to generate videos. Even though video is a time-series of images, the key here is the multimodal aspect of text-to-image. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33114@AAAI"},
{"title": "Category Prompt Mamba Network for Nuclei Segmentation and Classification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Category Prompt Mamba Network for Nuclei Segmentation and Classification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Category Prompt Mamba Network\" sounds like a neural network model. \"Nuclei Segmentation and Classification\" refers to the task, which is in the field of image processing, probably in biomedical imaging since nuclei are part of cells.\n\nNow, the four options. Time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on segmentation and classification of nuclei in images. The model name \"Mamba\" might refer to a specific architecture. I recall that Mamba is a type of state-space model that's been used in vision tasks, but it's not directly related to time-series, multimodal, RAG, or KG. The key here is the task: image segmentation and classification. None of the four topics listed (time-series, multimodal, RAG, KG) directly relate to image processing tasks unless there's a specific mention. The model might use some components from these areas, but the primary focus is on the application in image analysis. Since the title doesn't mention combining different data types (multimodal), using retrieval (RAG), or building a knowledge graph (KG), and it's not about time-series data, the answer would be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33116@AAAI"},
{"title": "Improving Generalization of Universal Adversarial Perturbation via Dynamic Maximin Optimization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Improving Generalization of Universal Adversarial Perturbation via Dynamic Maximin Optimization.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Universal adversarial perturbation\" sounds like it's related to adversarial examples in machine learning. Those are inputs designed to fool models. \"Generalization\" here probably refers to making these perturbations work across different models or datasets. The method mentioned is \"Dynamic Maximin Optimization,\" which seems like an optimization technique.\n\nNow, the four topics: time-series deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on adversarial perturbations and optimization methods. None of the four topics directly relate to adversarial attacks or optimization techniques. Time-series is about temporal data, which isn't mentioned. Multimodal is about combining data modalities, which isn't the case here. RAG and KG are about retrieval and knowledge representation, which also don't fit. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33117@AAAI"},
{"title": "Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cross-Modal Few-Shot Learning with Second-Order Neural Ordinary Differential Equations.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Modal\" suggests that the research involves multiple modalities, like combining different types of data such as text and images. That points towards the \"multimodal\" topic. Then there's \"Few-Shot Learning,\" which is a type of machine learning where the model learns from a small number of examples. But the question is about the main topic, not the learning method. The key part here is \"Cross-Modal,\" which directly relates to multimodal processing. \n\nThe other parts of the title mention \"Second-Order Neural Ordinary Differential Equations,\" which might be the technical approach used, but the main focus for categorization is the cross-modal aspect. The other options: time-series is about data over time, RAG is Retrieval-Augmented Generation, and KG is Knowledge Graphs. None of those seem to fit here. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33118@AAAI"},
{"title": "InstantSticker: Realistic Decal Blending via Disentangled Object Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"InstantSticker: Realistic Decal Blending via Disentangled Object Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper's title talks about decal blending and object reconstruction. Decals are images, so maybe it's about image processing. But does it combine different modalities? The term \"disentangled object reconstruction\" might involve separating different aspects of an object, but I'm not sure if that's multimodal. Maybe, but not certain.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information and then generate text. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge, so likely not KG.\n\nSo, the options left are multimodal or none. The paper is about blending decals (stickers) into images in a realistic way using disentangled reconstruction. Disentangled might mean separating different components of the object, like shape and texture. This could be part of computer vision or image processing. If it's combining different aspects (like different features) of the object, maybe that's multimodal. But multimodal usually refers to different data types, not just different features within the same modality. So maybe it's not multimodal either. If none of the four topics fit, the answer would be \"none.\" But I'm not entirely sure. Let me think again. The key terms are \"decal blending\" and \"disentangled object reconstruction.\" Decal blending is about integrating an object into a scene, which is image manipulation. Disentangled reconstruction might involve separating factors like pose, lighting, etc. This could be related to generative models or image editing. Since the four options don't include image processing or computer vision, and none of the listed topics (time-series, multimodal, RAG, KG) seem to fit, the answer might be \"none.\" But wait, maybe multimodal is a stretch here. If the decal blending involves combining different modalities, like RGB and depth, but the title doesn't specify. Without more info, it's safer to say \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33119@AAAI"},
{"title": "DiffGrasp: Whole-Body Grasping Synthesis Guided by Object Motion Using a Diffusion Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DiffGrasp: Whole-Body Grasping Synthesis Guided by Object Motion Using a Diffusion Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Whole-Body Grasping Synthesis\" suggests it's about robotic grasping, using the entire body, maybe like a robot arm. \"Guided by Object Motion\" implies that the motion of the object is a factor. \"Diffusion Model\" is a type of generative model, often used in image generation or sequence modeling. \n\nNow, the possible topics. Time-series usually involves data over time, like stock prices or sensor data. Multimodal would involve combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper uses a diffusion model for grasping, which is a generative model. Diffusion models can handle sequences, but here it's about generating grasping actions. The key part is \"Guided by Object Motion.\" If the object's motion is a time-dependent aspect, maybe the model uses time-series data of the object's movement to guide the grasping. However, the main focus seems to be on the synthesis of grasping actions using a diffusion model, not necessarily analyzing time-series data. \n\nAlternatively, multimodal could be a fit if they're combining different modalities, like visual and motion data. But the title doesn't explicitly mention multiple data types. RAG and KG don't seem relevant here. The paper is about robotic grasping using a specific model, not about retrieval or knowledge graphs. \n\nSo, the closest might be time-series if the object motion is a time-dependent input. But I'm not entirely sure. The use of a diffusion model might be for generating sequences, which could relate to time-series. However, the primary application is in robotics and grasping, which might not fall under the standard time-series analysis. Since the options are limited, and the other topics don't fit, maybe it's none. Wait, but the user wants to check if it's one of the four. If the object motion is a time-series input, then maybe time-series. But the main contribution is the diffusion model for grasping, which might not be categorized under time-series. Hmm. I'm leaning towards none here because the core topics are robotics and diffusion models, which don't directly map to the four given categories. So the answer would be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33120@AAAI"},
{"title": "Partial Point Cloud Registration with Multi-view 2D Image Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Partial Point Cloud Registration with Multi-view 2D Image Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Partial Point Cloud Registration\" sounds like a 3D data processing task. Point clouds are sets of data points in space, often used in 3D modeling or robotics. Registration here probably refers to aligning different point clouds. Then \"Multi-view 2D Image Learning\" suggests using multiple 2D images from different viewpoints. So combining 2D images to help with 3D point cloud registration.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. This title doesn't mention time, so probably not time-series. Multimodal refers to using multiple types of data, like combining images and text. Here, the paper uses both 2D images and 3D point clouds, which are different modalities. So multimodal might be a fit. \n\nRAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, common in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge, so likely not KG.\n\nSo the main question is whether this is multimodal. Since the paper uses both 2D images (visual modality) and point clouds (another modality), combining them for registration, it's definitely multimodal. The key here is the combination of different data types. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33121@AAAI"}
{"title": "Partial Point Cloud Registration with Multi-view 2D Image Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Partial Point Cloud Registration with Multi-view 2D Image Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Partial Point Cloud Registration\" sounds like a 3D data processing task. Point clouds are sets of data points in space, often used in 3D modeling or robotics. Registration here probably refers to aligning different point clouds. Then \"Multi-view 2D Image Learning\" suggests using multiple 2D images from different viewpoints. So combining 2D images to help with 3D point cloud registration.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or sensor data. This title doesn't mention time, so probably not time-series. Multimodal refers to using multiple types of data, like combining images and text. Here, the paper uses both 2D images and 3D point clouds, which are different modalities. So multimodal might be a fit. \n\nRAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, common in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge, so likely not KG.\n\nSo the main question is whether this is multimodal. Since the paper uses both 2D images (visual modality) and point clouds (another modality), combining them for registration, it's definitely multimodal. The key here is the combination of different data types. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33121@AAAI"},
{"title": "RP-PGD: Boosting Segmentation Robustness with a Region-and-Prototype Based Adversarial Attack", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RP-PGD: Boosting Segmentation Robustness with a Region-and-Prototype Based Adversarial Attack.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on improving segmentation robustness using an adversarial attack method called RP-PGD. Segmentation is typically in computer vision, like image segmentation. The method mentioned is a type of adversarial attack, which is part of machine learning security. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. Multimodal usually refers to combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time-series data. It's about adversarial attacks in segmentation, which is image processing. There's no indication of combining multiple modalities (multimodal), nor does it relate to RAG or KG. The focus is on making segmentation models more robust against adversarial examples, which is a different area. So none of the listed topics fit here.\n</think>\n\nnone", "url": "https://papers.cool/venue/33122@AAAI"},
{"title": "Stable-Hair: Real-World Hair Transfer via Diffusion Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Stable-Hair: Real-World Hair Transfer via Diffusion Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather. This paper is about hair transfer, which is more about images or videos, maybe. But the title doesn't mention time, so probably not time-series.\n\nMultimodal refers to using multiple data types, like combining text and images. The paper is about transferring hair in images, maybe using different modalities? But the title doesn't specify using multiple data types, just a diffusion model. Not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is used in NLP for tasks like question answering by retrieving documents. The paper uses a diffusion model, which is a type of generative model, but RAG is more about combining retrieval with generation. Doesn't seem to fit here.\n\nKG is Knowledge Graphs, which are structured data representations. The paper doesn't mention anything about knowledge graphs or structured data. \n\nSo, the paper is about using a diffusion model for hair transfer. Diffusion models are a type of generative model used in image generation. The topics given don't include image generation or diffusion models directly. The options are time-series, multimodal, RAG, KG. None of these seem to fit. The paper might be in the field of computer vision or image processing, but since the given options don't cover that, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33123@AAAI"},
{"title": "Zero-Shot Learning in Industrial Scenarios: New Large-Scale Benchmark, Challenges and Baseline", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Zero-Shot Learning in Industrial Scenarios: New Large-Scale Benchmark, Challenges and Baseline.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, zero-shot learning is a concept where a model can recognize or predict something it hasn't seen during training. The paper is about applying this in industrial scenarios, creating a benchmark, discussing challenges, and providing a baseline. \n\nNow, looking at the options. Time-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time-based data, so probably not time-series. \n\nMultimodal refers to using multiple types of data, like text and images. The title doesn't specify combining different data modalities, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The paper's focus is on zero-shot learning, which is more about classification or prediction without prior examples, not retrieval. So RAG might not be it. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper mentions a benchmark and challenges but doesn't indicate the use of knowledge graphs. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33124@AAAI"},
{"title": "Leveraging Consistent Spatio-Temporal Correspondence for Robust Visual Odometry", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Leveraging Consistent Spatio-Temporal Correspondence for Robust Visual Odometry.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatio-Temporal\" refers to both space and time. So that's a hint. \"Correspondence\" might relate to matching features over time. \"Visual Odometry\" is about estimating position and orientation from visual data, like in robotics or autonomous vehicles. \n\nTime-series analysis deals with data points indexed in time order. Since the title mentions spatio-temporal, which involves time, maybe it's related to time-series. But I should check the other options. \n\nMultimodal usually involves combining different types of data, like text and images. The title doesn't mention multiple modalities, so probably not that. \n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. Doesn't seem relevant here. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data. \n\nSo, the key terms are spatio-temporal and time-series. Visual odometry often uses sequences of images over time to track movement, which is a time-series problem. The spatio-temporal aspect suggests analyzing data across both space and time, which is common in time-series analysis for things like motion tracking. \n\nTherefore, the paper likely belongs to the time-series topic.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33125@AAAI"},
{"title": "Training-Free Image Manipulation Localization Using Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Training-Free Image Manipulation Localization Using Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about image manipulation, so probably not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image manipulation, but the title doesn't mention combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information and then generate text. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image manipulation using diffusion models, which doesn't seem related to knowledge graphs.\n\nSo none of the four topics seem to fit. The paper is about image manipulation using diffusion models without training, which is a different area. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33126@AAAI"},
{"title": "Multi-scale Activation, Refinement, and Aggregation: Exploring Diverse Cues for Fine-Grained Bird Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-scale Activation, Refinement, and Aggregation: Exploring Diverse Cues for Fine-Grained Bird Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not that. \n\nMultimodal refers to using multiple types of data, like combining images and text. The title talks about \"diverse cues,\" which might mean different features or data types. But the main focus here is on activation, refinement, and aggregation in a model for bird recognition. It's about processing different scales of features, which is more about model architecture than combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information and then generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about graphs or knowledge structures, so that's out.\n\nSo the answer is none. The paper is about improving a model's performance in bird recognition through multi-scale processing, which doesn't fit any of the given topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/33127@AAAI"},
{"title": "Single-view Image to Novel-view Generation for Hand-Object Interactions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Single-view Image to Novel-view Generation for Hand-Object Interactions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nNext, multimodal. That's when the research uses multiple types of data, like combining images and text. The title here is about generating a novel view from a single image, but it's specifically about hand-object interactions. I'm not sure if it's using multiple modalities. Maybe the input is an image and some other data? The title says \"single-view image,\" so maybe the input is just an image, and the output is another image. So maybe not multimodal unless they're combining different data types.\n\nRAG stands for Retrieval-Augmented Generation. That's typically in NLP where a model retrieves information from a database and uses it to generate text. The title here is about image generation, not text, so RAG might not fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about building or using a knowledge graph, so probably not KG.\n\nSo the remaining options are either multimodal or none. Let me think again. The task is generating a novel view from a single image. If the model uses both visual data (image) and maybe some other modality like depth or pose information, then it could be multimodal. But the title doesn't specify. If it's just image to image, maybe it's not multimodal. However, hand-object interactions might involve understanding both the hand and the object, which could be considered different modalities. But I'm not certain. The key here is whether the research combines multiple data types. If it's only using images, then it's not multimodal. If it's using images plus another modality (like text or depth), then it is. The title doesn't mention other modalities, so maybe it's just image-based. Therefore, it might not belong to any of the four topics. But wait, the options are time-series, multimodal, RAG, KG. If it's image generation, maybe it's not any of these. So the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33128@AAAI"},
{"title": "DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"LLM-Enhanced\" suggests they're using a Large Language Model. \"World Models\" might refer to models that simulate environments, which could be related to time-series if they're modeling sequences over time. \"Driving Video Generation\" implies creating videos, which are sequences of frames, so that's a time-series aspect. But videos can also be multimodal if they combine different data types like images and text. However, the key here is the use of LLMs. \n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to enhance its responses. KG (Knowledge Graph) involves structured data representations. The title doesn't mention anything about retrieval or knowledge graphs, so probably not RAG or KG. \n\nMultimodal would involve combining different modalities like text, images, audio. The paper is about generating driving videos, which are visual, but if they're using LLMs, maybe they're integrating text with video? The title doesn't specify other modalities, though. \n\nTime-series is about data over time. Driving videos are sequences, so generating them would involve time-series modeling. The \"World Models\" part might be about simulating the environment over time, which is a time-series approach. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33130@AAAI"},
{"title": "Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Extending Mamba\" – Mamba is a model I've heard about, maybe related to time-series? Wait, Mamba is a type of model that's efficient for long sequences, right? It's used in time-series data processing. But the title says \"Multi-Modal Large Language Model.\" So they're taking Mamba and making it multi-modal. \n\nMulti-modal usually refers to combining different types of data, like text and images, or text and audio. So the key term here is \"Multi-Modal.\" The other part is \"Efficient Inference,\" which might relate to how the model processes information quickly, but that's not one of the topics listed. \n\nLooking at the options: time-series, multimodal, RAG, KG. The title clearly mentions \"Multi-Modal,\" so that's a strong indicator. RAG is Retrieval-Augmented Generation, which is about using external data during generation. KG is Knowledge Graphs, which involve structured data. The title doesn't mention anything about retrieval or knowledge graphs. Time-series is about sequential data over time, but the main focus here is on multi-modality. \n\nSo the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33131@AAAI"}
{"title": "Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Extending Mamba\" – Mamba is a model I've heard about, maybe related to time-series? Wait, Mamba is a type of model that's efficient for long sequences, right? It's used in time-series data processing. But the title says \"Multi-Modal Large Language Model.\" So they're taking Mamba and making it multi-modal. \n\nMulti-modal usually refers to combining different types of data, like text and images, or text and audio. So the key term here is \"Multi-Modal.\" The other part is \"Efficient Inference,\" which might relate to how the model processes information quickly, but that's not one of the topics listed. \n\nLooking at the options: time-series, multimodal, RAG, KG. The title clearly mentions \"Multi-Modal,\" so that's a strong indicator. RAG is Retrieval-Augmented Generation, which is about using external data during generation. KG is Knowledge Graphs, which involve structured data. The title doesn't mention anything about retrieval or knowledge graphs. Time-series is about sequential data over time, but the main focus here is on multi-modality. \n\nSo the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33131@AAAI"},
{"title": "Adaptive Wavelet-Positional Encoding for High-Frequency Information Learning in Implicit Neural Representation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adaptive Wavelet-Positional Encoding for High-Frequency Information Learning in Implicit Neural Representation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Adaptive Wavelet-Positional Encoding\" sounds like it's about encoding methods, maybe using wavelets. \"High-Frequency Information Learning\" suggests dealing with data that has high-frequency components, which could be related to time-series data since those often involve temporal frequencies. \"Implicit Neural Representation\" refers to using neural networks to represent data implicitly, like in some models where the network outputs a value based on input coordinates.\n\nTime-series analysis often involves handling data points in sequence over time, which might require capturing high-frequency patterns. Wavelet transforms are commonly used in time-series analysis for their ability to capture both time and frequency information. Positional encoding is a term I associate with models like transformers, which handle sequences, but in this case, it's combined with wavelets. So maybe this is about improving how time-series data is encoded in neural networks, especially for high-frequency parts.\n\nMultimodal would involve combining different types of data (like text and images), which doesn't seem to be the case here. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, typically in NLP. KG (Knowledge Graphs) involve structured data representations, which also doesn't fit. The paper seems focused on encoding methods for neural networks dealing with high-frequency data, which is more about time-series analysis techniques. So the answer is probably time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33132@AAAI"},
{"title": "MagicNaming: Consistent Identity Generation by Finding a “Name Space” in T2I Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MagicNaming: Consistent Identity Generation by Finding a 'Name Space' in T2I Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"T2I Diffusion Models\" probably stands for Text-to-Image diffusion models. Those are used in generating images from text descriptions. The main focus here is on generating consistent identities, specifically through a \"name space.\" The term \"MagicNaming\" suggests creating names that maintain consistency in the generated images. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather. That doesn't seem relevant here. Multimodal refers to combining multiple data types, like text and images. Since the paper is about generating images from text (T2I), that's a multimodal task. RAG (Retrieval-Augmented Generation) involves using retrieval methods to enhance generation, but the title doesn't mention retrieval. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't seem to fit. The paper is about generating consistent identities in a diffusion model, which is a multimodal application. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33133@AAAI"},
{"title": "Multimodal Class-aware Semantic Enhancement Network for Audio-Visual Video Parsing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multimodal Class-aware Semantic Enhancement Network for Audio-Visual Video Parsing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key words here are \"Multimodal,\" \"Audio-Visual,\" and \"Video Parsing.\" The term \"Multimodal\" is right there at the beginning, which immediately makes me think that this might be the answer. But I should check the other options to be sure.\n\nTime-series usually involves data that's sequential over time, like stock prices or weather data. The title mentions video, which does involve time, but the main focus here seems to be on combining different modalities (audio and visual), not just the temporal aspect.\n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval of information with generating responses, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG probably isn't it.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't reference knowledge graphs or structured data, so that's probably not the case either.\n\nSo the main term here is \"Multimodal,\" which refers to the integration of multiple data types, like audio and visual in this case. The network is designed for audio-visual video parsing, which is a multimodal task. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33134@AAAI"},
{"title": "Excluding the Impossible for Open Vocabulary Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Excluding the Impossible for Open Vocabulary Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Open Vocabulary Semantic Segmentation\" sounds like a computer vision task where the model can recognize and segment objects even if they weren't in the training data. \"Excluding the Impossible\" might refer to a method that rules out unlikely possibilities during this segmentation process.\n\nNow, looking at the options. Time-series is about data over time, like stock prices or sensor data. That doesn't seem related here. Multimodal involves combining different data types, like text and images. The title doesn't mention anything about combining modalities, so maybe not that. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. KG (Knowledge Graphs) are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or retrieval. \n\nThe paper seems focused on improving semantic segmentation with an open vocabulary approach. None of the given topics directly relate to semantic segmentation or open vocabulary tasks. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33135@AAAI"},
{"title": "KALAHash: Knowledge-Anchored Low-Resource Adaptation for Deep Hashing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"KALAHash: Knowledge-Anchored Low-Resource Adaptation for Deep Hashing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge-Anchored\" suggests that knowledge is involved. \"Low-Resource Adaptation\" might refer to adapting models with limited data. \"Deep Hashing\" is about creating hash codes for data, which is often used in retrieval tasks. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe term \"Knowledge-Anchored\" makes me think of Knowledge Graphs (KG), as they are about anchoring information in structured knowledge. The paper's focus on adaptation using knowledge might be leveraging a knowledge graph to improve hashing in low-resource scenarios. So, the topic is likely KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33136@AAAI"},
{"title": "Training-free Open-Vocabulary Semantic Segmentation via Diverse Prototype Construction and Sub-region Matching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Training-free Open-Vocabulary Semantic Segmentation via Diverse Prototype Construction and Sub-region Matching.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Training-free\" suggests that the method doesn't require training, maybe using pre-trained models or some other approach. \"Open-vocabulary semantic segmentation\" implies that the model can handle a wide range of object categories beyond the ones it was trained on. \"Diverse prototype construction\" and \"sub-region matching\" are the techniques used here.\n\nNow, the four options. Time-series usually involves data over time, like stock prices or sensor data. Multimodal refers to combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on semantic segmentation, which is an image processing task. The methods mentioned don't seem to involve time-series data. There's no mention of combining different modalities like text and images, so multimodal might not fit. RAG is about retrieval and generation, which isn't directly related here. Knowledge Graphs are about structured data, which also doesn't seem to be the case here. The paper is about improving segmentation through prototypes and sub-region matching, which are more about model architecture and techniques rather than the four listed topics. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33137@AAAI"},
{"title": "Audio-Visual Adaptive Fusion Network for Question Answering Based on Contrastive Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Audio-Visual Adaptive Fusion Network for Question Answering Based on Contrastive Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Audio-Visual\" suggests that both audio and visual data are involved. So that's combining different modalities, which makes me think of multimodal. Then \"Adaptive Fusion Network\" implies that the model is fusing these different modalities in some way. The task is \"Question Answering,\" which is a common NLP task. The method used is \"Contrastive Learning,\" which is a technique for learning representations by contrasting positive and negative examples.\n\nNow, looking at the options. Time-series would involve data that's sequential over time, like stock prices or sensor data. The title doesn't mention anything about time series, so probably not that. Multimodal is about combining multiple data types, like audio and visual here. That fits. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database and uses it to generate answers. The title doesn't mention retrieval or generation in that context. KG (Knowledge Graph) involves structured data and relationships between entities. Again, the title doesn't mention knowledge graphs.\n\nSo the key terms here are \"Audio-Visual\" which points to multimodal. The fusion of different modalities for a task like question answering. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33138@AAAI"},
{"title": "Local Conditional Controlling for Text-to-Image Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Local Conditional Controlling for Text-to-Image Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time, so probably not that.\n\nMultimodal refers to combining different types of data, like text and images. The paper is about text-to-image models, which definitely uses both text and images. So that's a possibility.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generation tasks. The title doesn't mention retrieval or augmenting with external data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem to relate to knowledge graphs either.\n\nSo the most likely answer is multimodal because it's combining text and image data in a diffusion model. The key part is \"text-to-image,\" which is a classic multimodal task.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33139@AAAI"},
{"title": "Hierarchical Cross-Modal Alignment for Open-Vocabulary 3D Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hierarchical Cross-Modal Alignment for Open-Vocabulary 3D Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Modal Alignment\" immediately makes me think of multimodal. Because cross-modal usually refers to combining different types of data, like text and images, or audio and video. So that's a hint towards multimodal. \n\nThen, \"Hierarchical\" might refer to the structure of the model or the way the alignment is done in layers. But that's more about the method rather than the topic category. \n\n\"Open-Vocabulary 3D Object Detection\" suggests that the model can detect objects in 3D space using a vocabulary that's not limited to a fixed set, which might involve combining different modalities like text descriptions with 3D data. \n\nNow, checking the options. Time-series is about data over time, which doesn't seem to fit here. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which isn't mentioned here. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't seem to be the focus. \n\nMultimodal is about integrating multiple data types, which aligns with cross-modal. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33140@AAAI"}
{"title": "ESEG: Event-Based Segmentation Boosted by Explicit Edge-Semantic Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ESEG: Event-Based Segmentation Boosted by Explicit Edge-Semantic Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Event-Based Segmentation\" suggests that the paper is about segmenting data based on events. The term \"event-based\" might relate to time-series data, which often involves sequences of events over time. But I'm not sure yet. \n\nThen there's \"Explicit Edge-Semantic Guidance.\" Edge-semantic could relate to graph structures, where edges have semantic meaning. Knowledge Graphs (KG) are all about structured data with entities and relationships (edges). So maybe this is about using edge semantics in a graph context. But the main focus here is segmentation, which is more about partitioning data. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to augment its responses. That doesn't seem to fit here. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so probably not that. \n\nTime-series is about data points indexed in time order. Event-based segmentation could be part of time-series analysis, like segmenting time-series data into events. But the mention of edge-semantic might point towards a graph structure. \n\nWait, \"edge-semantic guidance\" might imply that the segmentation is guided by semantic information from edges in a graph. So if the edges are part of a Knowledge Graph, then maybe this is a KG-related paper. But the main task is segmentation, which is more common in computer vision or time-series. \n\nAlternatively, maybe the edges here are in an image, like edges in an image for segmentation. But \"edge-semantic\" could be about the meaning of edges in a graph. Hmm. \n\nI'm a bit torn between time-series and KG. The event-based part could be time-series, but the edge-semantic might relate to a graph. However, the primary task is segmentation, which is more common in computer vision. But the options given are time-series, multimodal, RAG, KG. \n\nSince the paper is about segmentation boosted by edge semantics, and if edges are part of a graph structure, then it's Knowledge Graph (KG). But if the edges are in an image, then it's not KG. The title doesn't specify, but the term \"edge-semantic guidance\" in the context of segmentation might be using a graph's edges. \n\nAlternatively, maybe it's using edges in an image (like in image processing) for segmentation. But the term \"explicit edge-semantic\" might imply that the edges have semantic meaning, which is more aligned with KGs where edges represent relationships. \n\nSo I think the answer is KG. But I'm not 100% sure. Let me check again. The title is about event-based segmentation, which could be time-series, but the edge-semantic part points to KG. Since the options are only these four, and the edge-semantic guidance is a key part, I'll go with KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33141@AAAI"},
{"title": "NightReID: A Large-Scale Nighttime Person Re-Identification Benchmark", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"NightReID: A Large-Scale Nighttime Person Re-Identification Benchmark.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"NightReID\" probably refers to person re-identification in nighttime conditions. Person re-identification (ReID) is a computer vision task where the goal is to match images of the same person across different camera views. The \"nighttime\" part suggests that the focus is on low-light or nighttime scenarios, which might involve different challenges like reduced visibility, different lighting conditions, etc.\n\nNow, looking at the possible topics. Time-series usually involves data that is sequential over time, like stock prices or sensor data. Multimodal refers to using multiple types of data (e.g., text, images, audio) together. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used for semantic relationships between entities.\n\nThe paper's title doesn't mention anything about time-series data. It's about a benchmark for a specific computer vision task. The term \"benchmark\" here is about creating a dataset or evaluation framework for ReID in nighttime conditions. Since ReID typically involves image data, maybe multimodal if they use different modalities (like infrared and visible light images), but the title doesn't specify that. The main focus is on the nighttime aspect of the ReID task. There's no indication of RAG or KG here. So, the most likely answer is that it doesn't fit into any of the given topics. Wait, but maybe multimodal? If the benchmark includes different modalities (like thermal and RGB images), then it could be multimodal. However, the title doesn't explicitly state that. The term \"nighttime\" might imply different sensors (like IR cameras), but without explicit mention, it's safer to assume it's just a standard ReID task under specific conditions. Therefore, the answer would be \"none\" since it's about a benchmark for a specific computer vision task, not any of the listed topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/33142@AAAI"},
{"title": "HFF-Tracker: A Hierarchical Fine-grained Fusion Tracker for Referring Multi-Object Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HFF-Tracker: A Hierarchical Fine-grained Fusion Tracker for Referring Multi-Object Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Referring Multi-Object Tracking\" suggests that the paper is about tracking multiple objects, possibly in a video or a sequence of images. The \"Referring\" part might mean that it's about identifying specific objects based on some reference, like a language query. \n\nNow, the key terms here. \"Multi-Object Tracking\" is a common task in computer vision, often involving video data where objects are tracked over time. That makes me think of time-series data because tracking over time involves sequences. But wait, the question is whether the paper's main topic is one of the four listed. \n\nThe options are time-series, multimodal, RAG, or KG. Let's consider each. \n\nTime-series analysis typically involves data points indexed in time order. If the paper is about tracking objects over time, that's a time-series aspect. But the question is whether the paper's primary focus is on time-series methods. However, multi-object tracking is a specific application area. The title mentions \"Hierarchical Fine-grained Fusion Tracker,\" which might involve combining different data sources or modalities. \n\nMultimodal refers to using multiple types of data, like combining visual and textual information. If the \"Referring\" part involves using language to refer to objects, then it's multimodal (vision + language). For example, if the tracker uses both visual data and natural language references to track objects, that would be multimodal. \n\nRAG (Retrieval-Augmented Generation) is a method that combines retrieval of information with generation, often used in NLP. KG (Knowledge Graph) involves structured data representations. The title doesn't mention anything about retrieval or knowledge graphs, so those might be out. \n\nSo, the key is whether \"Referring Multi-Object Tracking\" implies multimodal. If \"referring\" here means using language to specify which objects to track, then it's combining vision (tracking) with language (referring expressions), making it multimodal. \n\nTherefore, the paper likely belongs to the multimodal topic. Time-series is a part of the application (tracking over time), but the main research focus here is on integrating different modalities (vision and language) for tracking. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33143@AAAI"},
{"title": "Heterogeneous Prompt-Guided Entity Inferring and Distilling for Scene-Text Aware Cross-Modal Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Heterogeneous Prompt-Guided Entity Inferring and Distilling for Scene-Text Aware Cross-Modal Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-Modal Retrieval\" immediately makes me think of multimodal. Because cross-modal usually refers to different types of data, like text and images, which is a key aspect of multimodal research. So that's a strong hint towards multimodal.\n\nThen there's \"Scene-Text Aware,\" which suggests that the model is dealing with text in images (scene text), which is a common task in multimodal systems where both visual and textual data are involved. \n\nThe other parts like \"Heterogeneous Prompt-Guided Entity Inferring and Distilling\" might be about using different types of prompts or methods to infer entities, but the key term here is \"cross-modal,\" which is a hallmark of multimodal research. \n\nRAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, often in a text-only context. KG (Knowledge Graphs) involve structured data and relationships, which isn't directly mentioned here. Time-series is about data over time, which doesn't seem relevant here. \n\nSo putting it all together, the paper is about cross-modal retrieval involving scene text, which fits under the multimodal category.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33144@AAAI"},
{"title": "Multi-concept Model Immunization through Differentiable Model Merging", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-concept Model Immunization through Differentiable Model Merging.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-concept\" might suggest something related to handling multiple concepts, which could be multimodal if it's about different types of data. But \"model immunization\" sounds like making a model more robust, maybe against certain issues. \"Differentiable model merging\" refers to combining models in a way that's differentiable, which is a technique in machine learning.\n\nMultimodal typically involves integrating different data types like text, images, audio. Time-series is about sequential data over time. RAG (Retrieval-Augmented Generation) combines retrieval of information with generation models. KG (Knowledge Graphs) are structured representations of knowledge.\n\nThe paper's focus seems to be on merging models, which is a technique that could be used in various contexts. But none of the four topics directly relate to model merging. Multimodal might involve combining different data types, but merging models is more about combining models themselves. RAG and KG are specific areas. Time-series is about temporal data. Since the title doesn't mention anything about time, retrieval, knowledge graphs, or multimodal data, it doesn't fit into any of the four categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33145@AAAI"},
{"title": "PHR-DIFF: Portrait Highlights Removal via Patch-aware Diffusion Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PHR-DIFF: Portrait Highlights Removal via Patch-aware Diffusion Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal would involve combining different types of data, like text and images. The paper is about removing highlights from portraits, which is image processing. But does it use multiple modalities? The title doesn't mention text or other data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically used in NLP where a model retrieves information from a database and uses it to generate responses. The paper here is about an image processing technique using a diffusion model. Doesn't seem related to retrieval or generation in that context.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data.\n\nThe paper uses a diffusion model for a specific image editing task. Diffusion models are a type of generative model, but the key here is the application. The topics given don't include image processing or generative models directly. Since none of the four topics (time-series, multimodal, RAG, KG) are directly related to the content of the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33146@AAAI"},
{"title": "Breaking Information Isolation: Accelerating MRI via Inter-sequence Mapping and Progressive Masking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Breaking Information Isolation: Accelerating MRI via Inter-sequence Mapping and Progressive Masking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main goal here is accelerating MRI. MRI is Magnetic Resonance Imaging, which is a medical imaging technique. The methods mentioned are inter-sequence mapping and progressive masking. \n\nInter-sequence mapping might refer to using different MRI sequences (like T1, T2, etc.) and mapping between them. That could involve combining data from different sequences, which might be related to multimodal since multimodal often involves integrating different types of data. But I'm not entirely sure yet.\n\nProgressive masking sounds like a technique where parts of the data are masked progressively, maybe to speed up the imaging process. That could be a method to reduce the amount of data needed, thus accelerating the MRI. \n\nNow, looking at the four options. Time-series usually involves data over time, like stock prices or sensor data over time. This paper is about MRI, which is a single image or a set of images, not necessarily over time. Unless the MRI is dynamic, but the title doesn't mention time aspects.\n\nMultimodal refers to using multiple modalities or types of data. If the paper is using different MRI sequences (which are different types of images), that could be multimodal. But I need to confirm if inter-sequence mapping is considered multimodal. Sometimes, different sequences in MRI are considered different modalities, so combining them would be multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, typically in NLP. This paper is about accelerating MRI, which is more in the domain of medical imaging, so RAG seems unrelated.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it.\n\nSo, the most likely candidate is multimodal. The paper is using inter-sequence mapping, which involves different MRI sequences (modalities) to accelerate the process. Progressive masking might be a technique to handle the data more efficiently, but the key aspect here is combining different sequences, which points to multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33147@AAAI"},
{"title": "Supportive Negatives Spectral Augmentation for Source-Free Cross-Domain Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Supportive Negatives Spectral Augmentation for Source-Free Cross-Domain Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Source-Free Cross-Domain Segmentation\" suggests it's about domain adaptation in segmentation tasks. The method mentioned is \"Supportive Negatives Spectral Augmentation.\" \n\nTime-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series.\n\nMultimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. The term \"spectral augmentation\" here might be a different kind of data augmentation, but RAG is more about retrieval and generation. Not sure yet.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge, so probably not KG.\n\nSo, the remaining options are RAG or none. Wait, the method is about spectral augmentation. Spectral could relate to frequency domains, maybe image processing. But RAG is about retrieval. The term \"supportive negatives\" might be a technique in data augmentation for training models. Since the paper is about cross-domain segmentation, which is a computer vision task, and the augmentation method is part of the approach, but none of the four topics directly relate to data augmentation techniques in domain adaptation. The four options given are time-series, multimodal, RAG, KG. None of these seem to fit. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33148@AAAI"},
{"title": "Anti-Diffusion: Preventing Abuse of Modifications of Diffusion-Based Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Anti-Diffusion: Preventing Abuse of Modifications of Diffusion-Based Models.\" Hmm. I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Diffusion-Based Models\" probably refers to machine learning models that use diffusion processes, like those used in image generation or other generative models. The paper is about preventing abuse of modifications to these models. So the main focus is on security or ethical use of diffusion models.\n\nNow, looking at the options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time, so time-series is out. It's not about combining different data modalities, so multimodal isn't it. RAG and KG are more about specific techniques or structures. The paper is about preventing abuse in diffusion models, which is a security or ethical issue. None of the four topics directly relate to security or ethical considerations in diffusion models. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33149@AAAI"},
{"title": "Seg2Box: 3D Object Detection by Point-Wise Semantics Supervision", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Seg2Box: 3D Object Detection by Point-Wise Semantics Supervision.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title mentions 3D object detection, which is more about spatial data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title doesn't mention anything about combining different data types, just 3D object detection. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like in some NLP tasks. The title doesn't seem related to retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on 3D object detection using point-wise semantics, which sounds like computer vision or robotics, not knowledge graphs.\n\nSo none of the four topics seem to fit. The paper is about 3D object detection with a specific method (Seg2Box), which is a computer vision task. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33150@AAAI"}
{"title": "When Shadow Removal Meets Intrinsic Image Decomposition: A Joint Learning Framework Using Unpaired Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"When Shadow Removal Meets Intrinsic Image Decomposition: A Joint Learning Framework Using Unpaired Data.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper is about shadow removal and intrinsic image decomposition, which are both image processing tasks. But does it combine different modalities? The title mentions a joint learning framework, but it's using unpaired data. Maybe it's combining different aspects of image data, but not different modalities like text and image. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. The paper seems to be about image processing, not text generation or retrieval, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data, so that's out.\n\nSo the answer is none. The paper is about image processing techniques, specifically shadow removal and intrinsic image decomposition, which don't fall under the given topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/33151@AAAI"},
{"title": "A New Adversarial Perspective for LiDAR-based 3D Object Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A New Adversarial Perspective for LiDAR-based 3D Object Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"LiDAR-based 3D Object Detection\" refers to using LiDAR data to detect objects in 3D space. LiDAR is a sensor that provides point cloud data, which is a type of data modality. Now, the paper is introducing an adversarial perspective. Adversarial methods in machine learning often involve generating adversarial examples to test or improve models.\n\nLooking at the possible topics: time-series deals with data over time, like sequences. Multimodal refers to using multiple data types (like combining images and text). RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about 3D object detection using LiDAR, which is a single modality (LiDAR data). The adversarial aspect here is likely about improving the model's robustness or generating adversarial examples for LiDAR data. Since it's focused on a single modality (LiDAR) and not combining multiple modalities, it's not multimodal. Time-series isn't relevant here unless the LiDAR data is sequential over time, but the title doesn't mention that. RAG and KG are unrelated to adversarial methods in object detection. So the answer should be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33152@AAAI"},
{"title": "ContextualStory: Consistent Visual Storytelling with Spatially-Enhanced and Storyline Context", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ContextualStory: Consistent Visual Storytelling with Spatially-Enhanced and Storyline Context.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual Storytelling\" suggests that there's a narrative component, possibly involving images or videos. \"Consistent\" might imply maintaining some structure or context over time. \"Spatially-Enhanced\" could mean incorporating spatial information, maybe like location or layout. \"Storyline Context\" refers to the narrative structure.\n\nLooking at the options: time-series usually deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper seems to focus on creating consistent visual stories, which might involve integrating different modalities (like text and images) to tell a story. The mention of \"spatially-enhanced\" could imply using spatial data, but that's not one of the options. Since the main elements are combining different aspects (visual and storyline), it might be multimodal. However, if the focus is on the storyline structure, maybe a knowledge graph? But KGs are more about structured data relationships. RAG is about retrieval, which doesn't seem to fit. Time-series is about temporal data, which isn't the main focus here. So the most likely is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33153@AAAI"},
{"title": "OODML: Whole Slide Image Classification Meets Online Pseudo-Supervision and Dynamic Mutual Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"OODML: Whole Slide Image Classification Meets Online Pseudo-Supervision and Dynamic Mutual Learning.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Whole Slide Image Classification\" suggests that the research is about classifying images, specifically whole slide images, which are probably large images used in medical contexts, like pathology slides. So image classification is the main task here.\n\nThen there's \"Online Pseudo-Supervision and Dynamic Mutual Learning.\" Online pseudo-supervision might refer to generating pseudo-labels during training in an online manner, which is a semi-supervised learning technique. Dynamic mutual learning could involve multiple models learning from each other, maybe in a collaborative way. These are methods to improve model training, especially when labeled data is scarce.\n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal research involves combining different data types, like text and images. The paper here is about image classification, but there's no mention of combining multiple modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image classification techniques, not on building or using knowledge graphs. So KG is probably not the right fit.\n\nSince none of the four topics (time-series, multimodal, RAG, KG) are clearly mentioned or implied in the title, the answer should be \"none.\" The paper is about image classification methods using pseudo-supervision and mutual learning, which are techniques in machine learning but don't fall under the specified categories.\n</think>\n\nnone", "url": "https://papers.cool/venue/33154@AAAI"},
{"title": "Decoupled Spatio-Temporal Consistency Learning for Self-Supervised Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Decoupled Spatio-Temporal Consistency Learning for Self-Supervised Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatio-Temporal\" refers to both space and time. That makes me think of time-series data because time-series often involves temporal aspects. But spatio-temporal could also be relevant in other contexts, like video analysis which is multimodal (combining visual and temporal data). However, the key here is \"Consistency Learning\" and \"Self-Supervised Tracking.\" \n\nSelf-supervised learning is a method where the model learns from the data without explicit labels, often using some form of pretext task. Tracking usually involves following objects over time, which is inherently temporal. So the focus here is on learning consistency across time and space for tracking, which is a time-series problem. \n\nMultimodal would involve combining different types of data (like text and images), but the title doesn't mention different modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generation tasks, which doesn't seem related here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit. \n\nSo the main elements are spatio-temporal and time-series aspects. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33155@AAAI"},
{"title": "Universal Domain Adaptive Object Detection via Dual Probabilistic Alignment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Universal Domain Adaptive Object Detection via Dual Probabilistic Alignment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Domain Adaptive Object Detection\" suggests that the paper is about making an object detection model work across different domains. Domain adaptation is a common problem in machine learning where a model trained on one domain (source) needs to perform well on another domain (target) without retraining. So, the main focus here is domain adaptation in object detection.\n\nNow, the methods mentioned are \"Dual Probabilistic Alignment.\" Probabilistic alignment might involve aligning distributions between domains using probabilistic models. But how does this relate to the given topics?\n\nLooking at the options:\n\n1. Time-series: This usually involves data points indexed in time order. The title doesn't mention anything about time or sequences, so probably not time-series.\n\n2. Multimodal: This refers to using multiple types of data (e.g., text and images). The title is about object detection, which is typically a vision task, but there's no mention of combining different modalities. So maybe not multimodal.\n\n3. RAG (Retrieval-Augmented Generation): This is a method used in NLP where a model retrieves relevant information from a database to augment its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\n4. KG (Knowledge Graph): These are structured representations of knowledge. The paper's focus is on domain adaptation through probabilistic alignment, not on building or using knowledge graphs. So KG is probably not the right fit.\n\nSince none of the four topics (time-series, multimodal, RAG, KG) directly relate to domain adaptation in object detection, the answer should be \"none.\" The paper's main contribution is about domain adaptation techniques, which isn't one of the specified topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/33156@AAAI"},
{"title": "MMPF: Multi-Modal Perception Framework for Abnormal Medical Condition Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MMPF: Multi-Modal Perception Framework for Abnormal Medical Condition Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Modal\" is right there in the name. That immediately makes me think of the \"multimodal\" topic. Multi-modal usually refers to using multiple types of data, like combining images, text, and sensor data, for example. The framework is for medical condition detection, which might involve different data sources such as patient vitals, imaging, and maybe lab results. \n\nNow, checking the other options. Time-series would involve data points indexed in time order, like stock prices over time or sensor data collected over time. The title doesn't mention time-series explicitly, so maybe not. RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval of information with generation models, often in NLP tasks. The title doesn't seem to relate to that. KG is Knowledge Graph, which involves structured data and relationships between entities. Again, the title doesn't mention anything about knowledge graphs.\n\nSo, the key term here is \"Multi-Modal,\" which directly corresponds to the multimodal research topic. The framework uses multiple modalities for detection, which fits under multimodal. The other topics don't seem to apply here. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33157@AAAI"},
{"title": "DECIDER: Difference-aware Contrastive Diffusion Model with Adversarial Perturbations for Image Change Captioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DECIDER: Difference-aware Contrastive Diffusion Model with Adversarial Perturbations for Image Change Captioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components here are \"Difference-aware Contrastive Diffusion Model\" and \"Adversarial Perturbations for Image Change Captioning.\" The task seems to be about image change captioning, which involves describing changes between images. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like sequences. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge for generation tasks. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper is about image change captioning, which involves images (visual data) and generating text (language) to describe the changes. That sounds like combining two modalities: vision and language. So, multimodal makes sense here. The other topics don't fit. Time-series isn't mentioned, RAG and KG aren't part of the title's keywords. The model uses diffusion and adversarial methods, but those are techniques, not the main research topic. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33158@AAAI"},
{"title": "IPVTON: Image-based 3D Virtual Try-on with Image Prompt Adapter", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"IPVTON: Image-based 3D Virtual Try-on with Image Prompt Adapter.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nNext, multimodal. That's when the research uses multiple types of data, like combining images and text. The title mentions \"Image-based 3D Virtual Try-on,\" which uses images, but does it combine different modalities? The \"Image Prompt Adapter\" might be part of using images as prompts, maybe in conjunction with another modality. But I'm not sure yet. Let me think more.\n\nRAG stands for Retrieval-Augmented Generation. That's typically when a model uses a retrieval system to get information and then generates a response. The title doesn't mention anything about retrieval or generation in that context, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem to relate to building or using knowledge graphs, so probably not KG.\n\nBack to multimodal. The key part here is \"Image-based 3D Virtual Try-on.\" Virtual try-on usually involves using images of a person and an item of clothing to generate a 3D model. This might involve combining different data types, like images and 3D models, or maybe images with some other form of data. The \"Image Prompt Adapter\" suggests that images are being used as prompts, which could be part of a multimodal approach where the model takes an image input and processes it alongside other data. Since it's using images for a 3D task, which might involve different modalities (like images and 3D data), this could be considered multimodal. I think the answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33159@AAAI"},
{"title": "PointCFormer: A Relation-Based Progressive Feature Extraction Network for Point Cloud Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PointCFormer: A Relation-Based Progressive Feature Extraction Network for Point Cloud Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data that's ordered in time, like stock prices or sensor data over time. The title mentions point cloud completion, which is about 3D data, so maybe not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper here is about point clouds, which are a type of 3D data, but the title doesn't mention combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on a neural network for point cloud completion, which is a computer vision or 3D processing task. There's no mention of knowledge graphs here either.\n\nSo, the paper is about a neural network architecture for point cloud completion. The topics given don't seem to fit. The key terms are \"point cloud,\" \"feature extraction,\" and \"completion,\" which are more related to computer vision or machine learning models for 3D data. Since none of the four topics (time-series, multimodal, RAG, KG) are directly related to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33161@AAAI"}
{"title": "PointCFormer: A Relation-Based Progressive Feature Extraction Network for Point Cloud Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"PointCFormer: A Relation-Based Progressive Feature Extraction Network for Point Cloud Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data that's ordered in time, like stock prices or sensor data over time. The title mentions point cloud completion, which is about 3D data, so maybe not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper here is about point clouds, which are a type of 3D data, but the title doesn't mention combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on a neural network for point cloud completion, which is a computer vision or 3D processing task. There's no mention of knowledge graphs here either.\n\nSo, the paper is about a neural network architecture for point cloud completion. The topics given don't seem to fit. The key terms are \"point cloud,\" \"feature extraction,\" and \"completion,\" which are more related to computer vision or machine learning models for 3D data. Since none of the four topics (time-series, multimodal, RAG, KG) are directly related to this, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33161@AAAI"},
{"title": "SlerpFace: Face Template Protection via Spherical Linear Interpolation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SlerpFace: Face Template Protection via Spherical Linear Interpolation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Face Template Protection\" suggests it's about securing facial data, maybe in biometrics. \"Spherical Linear Interpolation\" (SLERP) is a method used in 3D rotations and quaternions, often in computer graphics or robotics. So the paper is probably using SLERP to protect face templates, perhaps by transforming or obfuscating the data in a spherical space.\n\nNow, the possible topics. Time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where models retrieve information from a database to enhance their responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on protecting face templates using a specific mathematical technique. Face templates are typically part of biometric systems, which might involve multimodal data if they combine different biometric types (like face and fingerprint), but the title doesn't mention combining different modalities. It's specifically about protecting a single modality (face) using SLERP. Since the other topics don't seem relevant—time-series isn't mentioned, RAG and KG are unrelated to template protection—it doesn't fit into any of the four categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33162@AAAI"},
{"title": "UrBench: A Comprehensive Benchmark for Evaluating Large Multimodal Models in Multi-View Urban Scenarios", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UrBench: A Comprehensive Benchmark for Evaluating Large Multimodal Models in Multi-View Urban Scenarios.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal\" is right there in the title. The paper is about evaluating models that handle multiple modalities. The options given include multimodal as one of the topics. So that's a strong indicator. \n\nThe other parts mention \"Large Multimodal Models\" and \"Multi-View Urban Scenarios.\" The key term here is \"multimodal,\" which refers to models that process multiple types of data, like images, text, audio, etc. So the research topic here is definitely multimodal. \n\nTime-series would involve data over time, like stock prices or weather data. RAG is Retrieval-Augmented Generation, which is about combining retrieval with generation models. KG is Knowledge Graphs, which are structured representations of knowledge. None of these terms are in the title. The focus is on benchmarking multimodal models, so the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33163@AAAI"},
{"title": "Polarization Guided Mask-Free Shadow Removal", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Polarization Guided Mask-Free Shadow Removal.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title mentions \"Polarization Guided,\" which might relate to using different data modalities, but I'm not sure. Polarization could be a technique in image processing, maybe using different light polarizations to enhance images. But does that count as multimodal? Maybe, but I need to think more.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, common in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem related to building or using knowledge graphs either.\n\nSo, the main part is \"Shadow Removal.\" That's an image processing task. The method uses polarization guidance. Polarization in imaging could involve using different polarized light to separate shadows from the actual objects. Since it's about combining different data (polarized images) to solve a problem, maybe it's multimodal. But multimodal typically refers to different types of data like text and images. Here, it's the same type (images) but different polarizations. So maybe it's not exactly multimodal. Alternatively, if polarization is considered a different modality, then it could be. But I'm not certain. The term \"mask-free\" suggests it's avoiding using a mask, which is a common technique in image segmentation. \n\nGiven the options, I think the closest might be multimodal if polarization is considered a different modality. But I'm not entirely sure. Alternatively, if none of the options fit, then the answer would be \"none.\" But since the task is to choose from the four, and the others are clearly not applicable, maybe multimodal is the best fit here. However, I'm a bit uncertain because polarization might be a technique rather than a modality. Hmm. Let me check again. The four options are time-series, multimodal, RAG, KG. The paper is about shadow removal using polarization. If polarization is a modality, then multimodal. Otherwise, none. Since the user is asking to choose from these four, and the others are out, maybe it's multimodal. But I'm not 100% sure. Alternatively, maybe it's none. But I need to decide. Given that polarization could be a different data source, perhaps it's multimodal. So I'll go with multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33164@AAAI"},
{"title": "Controllable Distortion-Perception Tradeoff Through Latent Diffusion for Neural Image Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Controllable Distortion-Perception Tradeoff Through Latent Diffusion for Neural Image Compression.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title mentions image compression, which is more about images, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The paper is about image compression using latent diffusion, which might involve different modalities, but the title doesn't explicitly mention combining different data types. Maybe, but not sure.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information and then generate text. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image compression techniques, not on building or using knowledge graphs. So that's out.\n\nSo, the remaining options are multimodal or none. The paper is about neural image compression using latent diffusion. Latent diffusion models are a type of generative model, often used in image generation. The controllable tradeoff between distortion and perception might involve optimizing how the model balances quality and compression. But does this relate to multimodal? If the model uses multiple modalities (like text and images), then it would be multimodal. However, the title only mentions image compression. Unless the latent diffusion is part of a multimodal system, but the title doesn't specify that. So maybe it's not multimodal either.\n\nTherefore, the paper doesn't clearly fit into any of the four categories. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33165@AAAI"},
{"title": "Position-Aware Guided Point Cloud Completion with CLIP Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Position-Aware Guided Point Cloud Completion with CLIP Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Point Cloud Completion\" refers to generating or completing 3D point cloud data, which is a common task in computer vision. \"Position-Aware Guided\" suggests that the model takes into account the spatial positions of points. Then there's \"CLIP Model,\" which I know is a multimodal model developed by OpenAI that connects text and images. CLIP is trained on image-text pairs, so it's used for tasks that require understanding both visual and textual information.\n\nNow, looking at the topics. Time-series would involve data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation models, often in NLP. KG (Knowledge Graph) involves structured data representations, like relationships between entities.\n\nThe paper uses CLIP, which is multimodal. The task is point cloud completion, which is a 3D vision task. But the key here is the use of CLIP, which bridges text and images. So the research might be combining point cloud data (a type of 3D data) with text using CLIP. That would make it multimodal because it's integrating different modalities (text and 3D data). \n\nI don't see any mention of time-series data, so that's out. RAG and KG don't seem relevant here either. The main focus is on using a multimodal model (CLIP) for a specific task in 3D data completion. Therefore, the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33166@AAAI"},
{"title": "TrackGo: A Flexible and Efficient Method for Controllable Video Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"TrackGo: A Flexible and Efficient Method for Controllable Video Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The paper is about video generation, which does involve sequences over time, so maybe time-series? But video generation could also be considered multimodal if it combines different data types like text and video. However, the title doesn't mention combining different modalities. \n\nMultimodal typically refers to models that handle multiple types of data, like text, images, audio together. The title here is about video generation, which is a single modality (video), unless it's using other inputs. But the title doesn't specify that. \n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP. The title doesn't mention retrieval or augmentation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's unlikely.\n\nSo the main options are time-series or multimodal. Since video is a sequence of frames over time, it's a time-series data. The method is for generating controllable video, which involves generating sequences. So maybe time-series. But sometimes video generation is considered under computer vision or generative models, which might not be one of the listed topics. However, given the options, time-series is the closest fit here. The key is whether the paper's focus is on the temporal aspect. Since the title mentions \"controllable video generation,\" which is about generating sequences over time, I think time-series is the right category.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33167@AAAI"},
{"title": "Low-Light Image Enhancement via Generative Perceptual Priors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Low-Light Image Enhancement via Generative Perceptual Priors.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. This title is about image enhancement, so probably not time-series. \n\nMultimodal would involve combining different types of data, like text and images. The title mentions image enhancement but doesn't specify combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation tasks. The title doesn't mention retrieval or generation in that context. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on image enhancement using generative models, so probably not related to knowledge graphs.\n\nThe term \"Generative Perceptual Priors\" suggests using generative models, maybe like GANs or VAEs, to enhance images. Since none of the given topics directly relate to generative models in image processing, the answer might be \"none.\" But wait, RAG is about generation, but it's more about using retrieved data. The paper's method is about perceptual priors, which could be a type of prior knowledge in generative models. However, RAG is a specific technique. Since the title doesn't mention RAG or any of the other topics, the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33168@AAAI"},
{"title": "Video Anomaly Detection with Motion and Appearance Guided Patch Diffusion Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Video Anomaly Detection with Motion and Appearance Guided Patch Diffusion Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. Video is a time-series in a way because it's a sequence of frames. But the title mentions motion and appearance, which are visual elements. So maybe it's related to video processing, which could be a type of time-series, but I'm not sure if that's the primary focus here.\n\nMultimodal refers to combining multiple types of data, like text and images, or audio and video. The title mentions motion and appearance, which are two different aspects of video data. So combining motion (which could be considered a temporal aspect) and appearance (visual features) might be multimodal. But wait, in video processing, motion and appearance are often considered different modalities. So maybe this is multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval of information with generation models, often in NLP contexts. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo the options are time-series or multimodal. The paper is about video anomaly detection using both motion and appearance. Since motion and appearance are different modalities (motion could be considered a type of data modality, like optical flow, and appearance as RGB frames), combining them would be multimodal. Therefore, the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33169@AAAI"},
{"title": "Core-to-Global Reasoning for Compositional Visual Question Answering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Core-to-Global Reasoning for Compositional Visual Question Answering.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Compositional Visual Question Answering\" suggests that the paper is about answering questions based on visual data, and the questions are compositional, meaning they might involve combining different elements or reasoning steps. \n\n\"Core-to-Global Reasoning\" probably refers to a method where the model starts with a core part of the problem and then expands to a global understanding. This could involve integrating different types of information, like combining visual and textual data. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather. The title doesn't mention anything about time, so probably not that. \n\nMultimodal refers to using multiple modalities, like combining text and images. Since the paper is about visual question answering, which typically uses both images and text, this seems likely. \n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database and uses it to generate answers. The title doesn't mention retrieval or generation, so maybe not RAG. \n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so probably not that either. \n\nSo, the most fitting topic here is multimodal because it's about combining visual and textual information for question answering. The core-to-global reasoning might be a specific approach within multimodal processing. I don't see any mention of time-series, RAG, or KG in the title, so the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33170@AAAI"}
{"title": "Joint Class-level and Instance-level Relationship Modeling for Novel Class Discovery", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Joint Class-level and Instance-level Relationship Modeling for Novel Class Discovery.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Joint Class-level and Instance-level Relationship Modeling\" suggests that the paper is dealing with relationships between classes and individual instances. \"Novel Class Discovery\" implies that the research is about identifying new classes that weren't present in the training data. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generation tasks, often in NLP. The title doesn't seem to involve retrieval or generation, so RAG is probably not it. \n\nKG is Knowledge Graphs, which are structured representations of entities and their relationships. The title talks about modeling relationships between classes and instances, which sounds like building or using a knowledge graph. Novel class discovery could involve expanding a knowledge graph by finding new classes based on existing relationships. \n\nSo, the most likely topic here is KG. The other options don't fit as well. The paper is about modeling relationships for class discovery, which aligns with knowledge graphs.\n</think>\n\nKG", "url": "https://papers.cool/venue/33171@AAAI"},
{"title": "GaussianPainter: Painting Point Cloud into 3D Gaussians with Normal Guidance", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GaussianPainter: Painting Point Cloud into 3D Gaussians with Normal Guidance.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or sensor data. This title mentions point clouds and 3D Gaussians, which are more about spatial data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper here is about converting point clouds into 3D Gaussians using normal guidance. It's a single modality (3D data) transformation, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of information. The paper's focus is on 3D data processing, not on building or using knowledge graphs. So KG is probably not it either.\n\nSince none of the four topics seem to fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33172@AAAI"},
{"title": "All-in-One: Transferring Vision Foundation Models into Stereo Matching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"All-in-One: Transferring Vision Foundation Models into Stereo Matching.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Transferring Vision Foundation Models into Stereo Matching.\" Vision foundation models are typically related to computer vision tasks, like image recognition or processing. Stereo matching is a specific task in computer vision where the goal is to find corresponding points between two images taken from slightly different viewpoints, often used for depth estimation.\n\nNow, looking at the options. Time-series deals with data over time, like stock prices or sensor data. That doesn't seem relevant here. Multimodal refers to combining multiple data types, like text and images. The paper is about transferring models from one vision task to another, so maybe not multimodal. RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation in models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. \n\nThe paper is about transferring vision models to stereo matching. Since stereo matching is a vision task, and the transfer is within the same modality (vision), it's not multimodal. The other topics don't fit either. So the answer should be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33173@AAAI"},
{"title": "SceneX: Procedural Controllable Large-Scale Scene Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SceneX: Procedural Controllable Large-Scale Scene Generation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title talks about scene generation, which might involve generating visual elements, but there's no mention of combining different data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to pull information and then generates text based on that. The title doesn't mention anything about retrieval or augmenting generation with external data, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title is about generating scenes procedurally and controllably. If it's about creating scenes, maybe it's using some structured data, but the term \"procedural\" suggests it's more about algorithms or rules for generation rather than a knowledge graph. Unless the knowledge graph is part of the procedural generation, but the title doesn't specify that.\n\nSo none of the four topics seem to fit. The paper is about generating large-scale scenes in a procedural and controllable way, which sounds more like computer graphics or procedural content generation, which isn't listed in the options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33174@AAAI"},
{"title": "GLIC: General Format Learned Image Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GLIC: General Format Learned Image Compression.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"GLIC\" is probably the acronym for the method. \"General Format Learned Image Compression\" suggests it's about image compression using a learned model. Learned image compression typically refers to using machine learning, like neural networks, to compress images efficiently. \n\nNow, looking at the possible topics. Time-series is about data over time, like stock prices or sensor data. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in models that retrieve information to enhance generation tasks. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on image compression. None of the listed topics directly relate to image compression. Time-series is about sequential data, which isn't the case here. Multimodal would involve multiple data modalities, but the title only mentions image compression. RAG and KG are unrelated to compression. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33175@AAAI"},
{"title": "Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on adversarial robustness, which is about making machine learning models more resistant to adversarial attacks. The method mentioned is feature disentanglement, which is a technique used to separate different factors of variation in data. The term \"feature gap\" might refer to the difference between features that are important for the model's predictions and those that are not, or maybe between different feature representations.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention different modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nSo, the paper is about adversarial robustness through feature disentanglement. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The topics listed are more about data types or specific methods, while the paper is about improving model robustness. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33176@AAAI"},
{"title": "Spatiotemporal-Aware Neural Fields for Dynamic CT Reconstruction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spatiotemporal-Aware Neural Fields for Dynamic CT Reconstruction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatiotemporal-Aware\" suggests that the model considers both spatial and temporal aspects. So, time is a component here. \"Neural Fields\" might refer to neural networks that model continuous spaces, like in some vision tasks. \"Dynamic CT Reconstruction\" implies that the CT scans are dynamic, meaning they capture changes over time, unlike static images.\n\nNow, looking at the options. Time-series research deals with data that is sequential over time. Since the paper mentions spatiotemporal aspects, which include time, it might be related to time-series. But wait, CT reconstruction is more about image processing. However, dynamic CT would involve sequences of images over time, so time-series could be a fit here.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so probably not multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG (Knowledge Graphs) involve structured data and relationships. The paper seems focused on reconstruction techniques, not on building or using knowledge graphs. So KG is probably not it.\n\nSo, the main contenders are time-series and multimodal. Since the paper is about dynamic CT, which involves time-dependent data, and spatiotemporal modeling, I think it's time-series. Even though it's in the context of imaging, the temporal aspect is key here. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33177@AAAI"},
{"title": "Test-Time Adaptation on Noisy Data via Model-Pruning-Based Filtering and Flatness-Aware Entropy Minimization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Test-Time Adaptation on Noisy Data via Model-Pruning-Based Filtering and Flatness-Aware Entropy Minimization.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Test-Time Adaptation\" suggests that the model is adjusting during testing, which is a common concept in machine learning, especially in domains where data distribution might shift. \"Noisy Data\" implies dealing with data that has errors or irrelevant information. The methods mentioned are \"Model-Pruning-Based Filtering\" and \"Flatness-Aware Entropy Minimization.\" Model pruning is about reducing the model's complexity by removing unnecessary parts, which can help in making the model more robust. Entropy minimization is often used in semi-supervised learning to encourage the model to be confident in its predictions, which might help in noisy environments.\n\nNow, looking at the possible topics. Time-series would involve data that's sequential over time, like stock prices or weather data. The title doesn't mention anything about sequences or time, so maybe not time-series. Multimodal refers to combining different types of data, like text and images. The title doesn't mention multiple data modalities, so probably not that either. RAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models, often in NLP tasks. The title doesn't mention retrieval or generation, so RAG seems unlikely. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge structures, so that's probably not it either.\n\nSo, none of the four topics seem to fit. The paper is about improving model robustness during testing with noisy data using specific techniques, but it doesn't fall under time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33179@AAAI"},
{"title": "Dynamic Contrastive Knowledge Distillation for Efficient Image Restoration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dynamic Contrastive Knowledge Distillation for Efficient Image Restoration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dynamic Contrastive Knowledge Distillation\" sounds like a method. \"Efficient Image Restoration\" is the application area. So the main focus is on improving image restoration using this distillation technique. \n\nNow, the four options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, often in NLP. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's title doesn't mention anything about time-based data, so time-series is probably out. It's about image restoration, which is a single modality (images), so multimodal might not fit unless it's combining image with another modality. But the title doesn't specify that. Knowledge Distillation is a technique where a smaller model learns from a larger one, which is more about model compression or transfer learning. RAG and KG are different. RAG is about retrieval during generation, and KG is about structured knowledge. The term \"Knowledge Distillation\" here is about transferring knowledge from a teacher model to a student, which is a different concept from RAG or KG. So none of the four topics seem to fit. The paper is about model distillation for image restoration, which isn't directly related to time-series, multimodal, RAG, or KG. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33180@AAAI"},
{"title": "Improving Generalization of Deep Neural Networks by Optimum Shifting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Improving Generalization of Deep Neural Networks by Optimum Shifting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't talk about multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance model outputs, often in NLP. The title is about improving generalization through shifting, which doesn't sound like retrieval or generation. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data. \n\nThe paper is about improving generalization in DNNs using optimum shifting. Generalization is a broad topic in machine learning, but none of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The methods mentioned (optimum shifting) don't align with any of the specified areas. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33181@AAAI"}
{"title": "Improving Generalization of Deep Neural Networks by Optimum Shifting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Improving Generalization of Deep Neural Networks by Optimum Shifting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't talk about multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance model outputs, often in NLP. The title is about improving generalization through shifting, which doesn't sound like retrieval or generation. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data. \n\nThe paper is about improving generalization in DNNs using optimum shifting. Generalization is a broad topic in machine learning, but none of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The methods mentioned (optimum shifting) don't align with any of the specified areas. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33181@AAAI"},
{"title": "Achieving Ensemble-Like Performance in a Single Model: A Feature Diversification Framework for Image-Text Matching", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Achieving Ensemble-Like Performance in a Single Model: A Feature Diversification Framework for Image-Text Matching.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, the main focus here is on image-text matching. That immediately makes me think of multimodal because it's combining two different modalities: images and text. Multimodal research often deals with integrating data from different sources or types, like combining visual and textual information. \n\nThe paper talks about a feature diversification framework. Feature diversification might be a method to handle different types of data, which in this case are images and text. So that aligns with multimodal learning. \n\nTime-series usually involves data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, often in NLP tasks. While image-text matching could involve retrieval, the title doesn't specify using retrieval to augment a model. It's more about combining features from different modalities. \n\nKG (Knowledge Graphs) involve structured data and relationships between entities. The title doesn't mention anything about knowledge graphs or structured data, so that's probably not it either. \n\nSo the most likely answer is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33182@AAAI"},
{"title": "Expanding the Scope of Negatives: Boosting Image-Text Matching with Negatives Distribution Guided Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Expanding the Scope of Negatives: Boosting Image-Text Matching with Negatives Distribution Guided Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on image-text matching. That's when you have both images and text data, trying to find how they relate. So that immediately makes me think of multimodal learning because multimodal involves combining different types of data, like images and text. \n\nThe other parts of the title mention \"negatives distribution guided learning.\" Negatives in this context probably refer to negative samples used in training, which is common in contrastive learning where you want the model to distinguish between positive (matching) and negative (non-matching) pairs. But the key here is the combination of image and text. \n\nTime-series is about data over time, like stock prices or weather data. That doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is a method where a model uses a retrieval component to get information before generating a response. While image-text matching could be part of a RAG system, the title doesn't mention retrieval or generation. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. \n\nSo the main topic here is multimodal because it's about integrating different modalities (images and text) to improve matching. The method they're using with negatives is a technique within multimodal learning. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33183@AAAI"},
{"title": "An Exemplar-based Framework for Chinese Text Recognition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"An Exemplar-based Framework for Chinese Text Recognition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. \"Exemplar-based\" suggests that the method uses examples or instances to guide the process. \"Chinese Text Recognition\" is about recognizing text in Chinese, which is a language-specific task. So the main focus here is on text recognition, specifically for Chinese characters.\n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices over time or sensor data. This doesn't seem related to text recognition, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images or text and audio. The title mentions text recognition, but there's no indication of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information from a database with generation of text. The title doesn't mention anything about retrieval or generation, so RAG might not be the right fit here.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's title doesn't mention anything about building or using a knowledge graph, so that's probably not it either.\n\nSo, the paper is about a framework for recognizing Chinese text using an exemplar-based approach. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The closest might be multimodal if there's an aspect of combining different data types, but the title doesn't specify that. Since the options don't include text recognition or exemplar-based methods, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33184@AAAI"},
{"title": "Dense Audio-Visual Event Localization Under Cross-Modal Consistency and Multi-Temporal Granularity Collaboration", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dense Audio-Visual Event Localization Under Cross-Modal Consistency and Multi-Temporal Granularity Collaboration.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dense Audio-Visual Event Localization\" suggests that the research involves both audio and visual data, which points towards multimodal. The term \"cross-modal consistency\" definitely relates to combining different modalities (like audio and video) and ensuring they align, which is a key aspect of multimodal research. \n\nThen there's \"multi-temporal granularity collaboration.\" Temporal aspects often relate to time-series data, but here it's mentioned in the context of collaboration across different temporal granularities. However, the main focus here seems to be on integrating different modalities (audio and visual) rather than just analyzing time-series data. \n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to be directly mentioned here. The title doesn't talk about knowledge graphs or retrieval mechanisms. So RAG and KG are probably not the right choices. \n\nSo the main keywords are \"audio-visual\" and \"cross-modal,\" which are strong indicators of multimodal research. Even though there's a mention of temporal aspects, the primary focus is on combining different data modalities. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33185@AAAI"},
{"title": "GoHD: Gaze-oriented and Highly Disentangled Portrait Animation with Rhythmic Poses and Realistic Expressions", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GoHD: Gaze-oriented and Highly Disentangled Portrait Animation with Rhythmic Poses and Realistic Expressions.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Portrait Animation\" suggests creating animated portraits, probably using some kind of model. \"Gaze-oriented\" might relate to eye movement or direction, which could be part of the animation's features. \"Highly Disentangled\" usually refers to separating different factors of variation in data, which is common in generative models. \"Rhythmic Poses\" and \"Realistic Expressions\" imply that the animation needs to have dynamic, possibly time-dependent elements, like movements over time.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, which could fit if the animation involves sequences. Multimodal would involve combining different data types, like text and images, but the title doesn't mention that. RAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance generation, but again, the title doesn't mention retrieval. KG is Knowledge Graphs, which are structured data representations, which also doesn't seem relevant here.\n\nThe key terms here are \"Portrait Animation\" and \"Rhythmic Poses.\" Since animations are sequences over time, this might be a time-series problem. However, disentanglement in generative models is more about the structure of the data rather than the temporal aspect. But the mention of \"rhythmic\" and \"poses\" over time could imply temporal modeling. However, the main focus here seems to be on generating realistic and disentangled features in the animation, which might not strictly be time-series analysis. Time-series typically involves forecasting or analyzing sequential data, but here it's about generating animations with specific characteristics. So maybe it's not time-series. The other options don't fit either. So perhaps the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33186@AAAI"},
{"title": "MultiBooth: Towards Generating All Your Concepts in an Image from Text", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MultiBooth: Towards Generating All Your Concepts in an Image from Text.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences over time, so probably not time-series.\n\nNext, multimodal. That refers to models that handle multiple types of data, like text and images. The title says generating an image from text, which is combining text (modal) and image (another modality). So that sounds like multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates text. The title doesn't mention retrieval or augmenting with external data, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about graphs or structured knowledge, so probably not KG.\n\nSo the most likely answer is multimodal because it's about generating images from text, combining two modalities.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33187@AAAI"},
{"title": "Adaptive Prototype Replay for Class Incremental Semantic Segmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adaptive Prototype Replay for Class Incremental Semantic Segmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Class Incremental Semantic Segmentation\" suggests that the research is about improving a model's ability to handle new classes over time in semantic segmentation tasks. That's a common problem in machine learning where the model needs to learn new classes without forgetting old ones. \n\nNow, \"Adaptive Prototype Replay\" probably refers to a method where the model uses some form of prototype (like example data points) to replay or review past information when learning new classes. This is a technique used in continual learning to prevent catastrophic forgetting. \n\nLooking at the four options: time-series deals with data over time, like stock prices or weather. Multimodal involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of information. \n\nThe paper's focus is on semantic segmentation, which is a computer vision task. The method mentioned (prototype replay) is related to continual learning strategies but doesn't directly relate to time-series data, multimodal inputs, retrieval-augmented generation, or knowledge graphs. So none of the four topics seem to fit. The paper is about improving a model's incremental learning in a specific task, but the techniques used don't align with the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33188@AAAI"},
{"title": "Optimizing Label Assignment for Weakly Supervised Person Search", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Optimizing Label Assignment for Weakly Supervised Person Search.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Weakly supervised\" usually refers to a type of machine learning where the training data is not fully labeled. So, maybe the paper is about improving the labeling process in such scenarios. \"Person search\" likely involves identifying a specific person in images or videos, which could be part of computer vision tasks. \n\nNow, the main question is about label assignment optimization. That sounds like it's about how to assign labels more effectively when the supervision is weak. But how does this relate to the given topics?\n\nTime-series analysis deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The paper is about person search, which might involve images and maybe text (like descriptions), but the title doesn't explicitly mention multiple modalities. However, person search can be multimodal if it uses both images and textual information. But the focus here is on label assignment, not the modalities themselves.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graph, which involves structured data and relationships between entities. The paper's focus is on label assignment in a weakly supervised setting, which doesn't directly relate to building or using knowledge graphs.\n\nSo, none of the four topics seem to fit perfectly. The paper is about optimizing labels in a weakly supervised scenario for person search, which is more related to machine learning and computer vision, but not specifically time-series, multimodal (unless the multimodal aspect is implied but not stated), RAG, or KG. Since the title doesn't clearly indicate any of the four, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33189@AAAI"},
{"title": "Two-stream Beats One-stream: Asymmetric Siamese Network for Efficient Visual Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Two-stream Beats One-stream: Asymmetric Siamese Network for Efficient Visual Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Two-stream\" and \"One-stream\" probably refer to different network architectures. Siamese networks are typically used for comparing two inputs, like in tasks such as face verification or tracking. The term \"asymmetric\" suggests that the two streams might have different structures or purposes. The application here is \"visual tracking,\" which is a computer vision task where the model tracks an object across a video sequence.\n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices or sensor data. Visual tracking does involve sequences of images over time, so maybe time-series? But the main focus here is on the network architecture (Siamese) and the tracking method, not necessarily the time-series analysis itself.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything related to knowledge graphs.\n\nSo, the paper is about a Siamese network for visual tracking. Siamese networks are often used in tasks where you need to compare two inputs, which in tracking could be the target and the current frame. The \"two-stream\" approach might process different parts of the data, but it's not about time-series analysis per se. The key here is that the topic options don't include computer vision or tracking directly. The closest might be time-series because tracking involves sequences, but I'm not sure if that's the intended classification here. However, the main focus is on the network architecture for tracking, which doesn't fit into the given topics. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33191@AAAI"}
{"title": "Two-stream Beats One-stream: Asymmetric Siamese Network for Efficient Visual Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Two-stream Beats One-stream: Asymmetric Siamese Network for Efficient Visual Tracking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Two-stream\" and \"One-stream\" probably refer to different network architectures. Siamese networks are typically used for comparing two inputs, like in tasks such as face verification or tracking. The term \"asymmetric\" suggests that the two streams might have different structures or purposes. The application here is \"visual tracking,\" which is a computer vision task where the model tracks an object across a video sequence.\n\nNow, looking at the possible topics. Time-series usually involves data points indexed in time order, like stock prices or sensor data. Visual tracking does involve sequences of images over time, so maybe time-series? But the main focus here is on the network architecture (Siamese) and the tracking method, not necessarily the time-series analysis itself.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything related to knowledge graphs.\n\nSo, the paper is about a Siamese network for visual tracking. Siamese networks are often used in tasks where you need to compare two inputs, which in tracking could be the target and the current frame. The \"two-stream\" approach might process different parts of the data, but it's not about time-series analysis per se. The key here is that the topic options don't include computer vision or tracking directly. The closest might be time-series because tracking involves sequences, but I'm not sure if that's the intended classification here. However, the main focus is on the network architecture for tracking, which doesn't fit into the given topics. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33191@AAAI"},
{"title": "A Lottery Ticket Hypothesis Approach with Sparse Fine-tuning and MAE for Image Forgery Detection and Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Lottery Ticket Hypothesis Approach with Sparse Fine-tuning and MAE for Image Forgery Detection and Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. The main components here are the Lottery Ticket Hypothesis, sparse fine-tuning, MAE (which I think stands for Masked Autoencoder), and the application to image forgery detection and localization. \n\nThe Lottery Ticket Hypothesis is a concept in neural network training where a randomly initialized subnetwork can be trained in isolation to achieve good performance. Sparse fine-tuning refers to adjusting only a subset of the model's parameters during training, which is a technique to make training more efficient. MAE is a type of autoencoder used in self-supervised learning, often for image data. \n\nNow, the application here is image forgery detection and localization. That's about identifying and locating manipulated parts in images. So the focus is on image data. \n\nLooking at the four topics: time-series deals with data over time, like stock prices or sensor data. Multimodal involves combining different types of data, like text and images. RAG (Retrieval-Augmented Generation) is a method where a model retrieves information from a database to enhance its responses. KG (Knowledge Graph) involves structured data representations, often for relationships between entities.\n\nThe paper's focus is on image processing using specific training techniques (Lottery Ticket Hypothesis, sparse fine-tuning, MAE). There's no mention of time-series data, combining multiple data modalities, retrieval-augmented generation, or knowledge graphs. So it doesn't fit into any of the four categories listed. The main area here is image analysis, which isn't one of the specified topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33192@AAAI"},
{"title": "Large Images Are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Large Images Are Gaussians: High-Quality Large Image Representation with Levels of 2D Gaussian Splatting.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. The title here is about images, so maybe not time-series. \n\nMultimodal refers to combining multiple data types, like text and images. The paper is about representing images using Gaussian splatting, but there's no mention of combining different modalities. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about image representation using Gaussians, not about structured data or knowledge. So KG doesn't fit either.\n\nThe paper's focus is on representing large images using 2D Gaussian splatting. None of the given topics directly relate to image representation techniques like Gaussian splatting. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33193@AAAI"},
{"title": "A Comprehensive Overhaul of Multimodal Assistant with Small Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Comprehensive Overhaul of Multimodal Assistant with Small Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Assistant\" immediately stands out. Multimodal usually refers to systems that can process multiple types of data, like text, images, audio, etc. So that's a hint. The other part mentions \"Small Language Models,\" which might relate to the models used in the assistant. \n\nNow, looking at the options. The topic \"multimodal\" is one of the choices. The title directly uses the term \"Multimodal,\" so that's a strong indicator. The other options: time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is a technique for enhancing models with external information retrieval, but the title doesn't mention retrieval or generation in that context. KG (Knowledge Graph) involves structured data and relationships, which also isn't mentioned here. \n\nThe paper is about overhauling a multimodal assistant, so the primary focus is on multimodal systems. Even though it uses small language models, the key term here is \"multimodal.\" Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33194@AAAI"},
{"title": "Thin-Plate Spline-based Interpolation for Animation Line Inbetweening", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Thin-Plate Spline-based Interpolation for Animation Line Inbetweening.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. Thin-Plate Spline is a mathematical method used for interpolation, especially in 2D or 3D spaces. Interpolation here refers to estimating values between known data points. The application is in animation line inbetweening, which is the process of generating intermediate frames between keyframes in animation. So the paper is about using a specific interpolation technique for creating smooth transitions in animations.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order. While animation does involve sequences over time, the core of this paper seems to be about spatial interpolation rather than analyzing time-dependent data. So maybe not time-series.\n\nMultimodal refers to combining multiple data modalities, like text, images, audio. The title doesn't mention anything about combining different types of data, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This doesn't seem related to animation interpolation.\n\nKG is Knowledge Graph, which involves structured data representation and relationships. Again, the paper's focus is on interpolation techniques, not on knowledge representation.\n\nSo, none of the four topics (time-series, multimodal, RAG, KG) directly relate to the content of the paper. The paper is about a specific interpolation method in animation, which is more related to computer graphics or computational geometry rather than the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33195@AAAI"},
{"title": "Mesh Watermark Removal Attack and Mitigation: A Novel Perspective of Function Space", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Mesh Watermark Removal Attack and Mitigation: A Novel Perspective of Function Space.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title is about mesh watermarks, which might be 3D models or something visual, but there's no indication of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't talk about knowledge or graphs in that sense. The word \"mesh\" might refer to a 3D mesh, but that's different from a knowledge graph.\n\nThe paper seems to focus on watermark removal in meshes, which is more about computer graphics or security. None of the given topics fit here. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33196@AAAI"},
{"title": "DreaMark: Rooting Watermark in Score Distillation Sampling Generated Neural Radiance Fields", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DreaMark: Rooting Watermark in Score Distillation Sampling Generated Neural Radiance Fields.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"DreaMark\" sounds like a name for the method or system. \"Rooting Watermark\" suggests that the paper is about embedding a watermark. \"Score Distillation Sampling\" might refer to a specific technique used in generating the neural radiance fields. Neural Radiance Fields (NeRF) are 3D scene representations that can render novel views from 2D images. So, the paper is likely about watermarking in NeRFs generated using score distillation sampling.\n\nNow, the four topics: time-series, multimodal, RAG, KG. Time-series would involve data over time, like stock prices or sensor data. Multimodal deals with combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses external knowledge sources during generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on watermarking in neural radiance fields. Watermarking is a method to embed information into data, often for copyright or authentication. The techniques here are specific to 3D models generated via NeRFs. None of the four topics directly relate to watermarking or NeRFs. Time-series is about temporal data, which isn't the case here. Multimodal could be if combining different modalities, but the paper is about a single modality (3D fields). RAG and KG are about knowledge retrieval and structured data, which don't seem relevant here. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33197@AAAI"},
{"title": "Mesoscopic Insights: Orchestrating Multi-Scale & Hybrid Architecture for Image Manipulation Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Mesoscopic Insights: Orchestrating Multi-Scale & Hybrid Architecture for Image Manipulation Localization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Image Manipulation Localization\" suggests it's about detecting or identifying manipulated parts in images. The terms \"Multi-Scale & Hybrid Architecture\" might refer to using different scales of analysis and combining different models or methods. \n\nTime-series usually involves data over time, like stock prices or sensor data. This title doesn't mention anything about time, so probably not time-series.\n\nMultimodal typically involves combining different types of data, like text and images. The paper here is about image manipulation, but the title doesn't mention combining different modalities. Unless the hybrid architecture refers to multimodal, but I'm not sure. The main focus seems to be on image processing techniques.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation tasks, like in language models. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about knowledge graphs or structured data, so probably not KG.\n\nSo, the options left are multimodal or none. The paper is about image manipulation localization using a hybrid architecture. If the hybrid architecture combines different data types (like images and text), then it could be multimodal. But the title says \"Multi-Scale & Hybrid Architecture,\" which might refer to different scales of image analysis (like different resolutions) rather than different modalities. Since the problem is image-specific and there's no mention of combining different data types, it's more likely not multimodal either. Therefore, the answer might be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33198@AAAI"},
{"title": "Exploring Task-Level Optimal Prompts for Visual In-Context Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring Task-Level Optimal Prompts for Visual In-Context Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual In-Context Learning\" suggests that the research involves using visual data in some kind of in-context learning setup. In-context learning is a concept where models learn from examples provided in the input prompt, often seen in few-shot learning scenarios. The term \"visual\" points towards images or video, which are part of multimodal data when combined with text or other modalities.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to augment model outputs, typically in text-based tasks. KG (Knowledge Graphs) involves structured data representations, often for linking entities and relationships. \n\nMultimodal refers to the use of multiple data types, such as combining text and images. Since the title mentions \"visual,\" which is a modality, and in-context learning, which is a method, it's possible that the paper is about using visual data along with text prompts, making it multimodal. The \"task-level optimal prompts\" part might be about optimizing how these multimodal prompts are structured for specific tasks. \n\nI don't see any mention of time-series data, so that's out. RAG and KG don't seem to fit here either. The focus is on prompts and visual learning, which aligns more with multimodal approaches. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33199@AAAI"},
{"title": "ST3: Accelerating Multimodal Large Language Model by Spatial-Temporal Visual Token Trimming", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ST3: Accelerating Multimodal Large Language Model by Spatial-Temporal Visual Token Trimming.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Large Language Model\" immediately makes me think of the multimodal category. Multimodal models handle multiple types of data, like text and images. The paper is about accelerating such a model, so the core topic here is multimodal. \n\nThen there's \"Spatial-Temporal Visual Token Trimming.\" Spatial-temporal usually relates to both space and time, which might hint at time-series, but in this context, it's part of the method used to trim tokens in a visual modality. The key term here is \"Multimodal,\" which directly matches one of the options. \n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to be mentioned here. The title doesn't talk about retrieval or knowledge graphs. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33201@AAAI"}
{"title": "ST3: Accelerating Multimodal Large Language Model by Spatial-Temporal Visual Token Trimming", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ST3: Accelerating Multimodal Large Language Model by Spatial-Temporal Visual Token Trimming.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Large Language Model\" immediately makes me think of the multimodal category. Multimodal models handle multiple types of data, like text and images. The paper is about accelerating such a model, so the core topic here is multimodal. \n\nThen there's \"Spatial-Temporal Visual Token Trimming.\" Spatial-temporal usually relates to both space and time, which might hint at time-series, but in this context, it's part of the method used to trim tokens in a visual modality. The key term here is \"Multimodal,\" which directly matches one of the options. \n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to be mentioned here. The title doesn't talk about retrieval or knowledge graphs. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33201@AAAI"},
{"title": "Dynamic Entity-Masked Graph Diffusion Model for Histopathology Image Representation Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dynamic Entity-Masked Graph Diffusion Model for Histopathology Image Representation Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph Diffusion Model\" makes me think of graph structures. Graphs are often related to Knowledge Graphs (KG), which are a type of structured data representation. But wait, the term \"Graph Diffusion\" might be a specific model or method. Then there's \"Entity-Masked,\" which could imply some masking technique, maybe similar to how BERT uses masked language modeling. But RAG (Retrieval-Augmented Generation) usually involves retrieving information from a database and using it in generation. However, RAG is more about combining retrieval with generation, not necessarily graph-based models.\n\nMultimodal typically involves combining different data types like text and images. The paper mentions histopathology images, which are images, but the model is a graph-based model. So maybe it's using graph structures to represent image data. But multimodal would require more than one modality. The title doesn't mention other data types, so maybe not multimodal.\n\nTime-series is about sequential data over time. The title doesn't mention time or sequences, so probably not time-series.\n\nKnowledge Graphs (KG) are about structured data, entities, and relationships. The term \"Entity-Masked\" might relate to entities in a knowledge graph. However, the model is a graph diffusion model for image representation. It's using a graph structure to model the image data, but it's not necessarily a knowledge graph. Knowledge graphs are usually about real-world entities and their relations, whereas here it's about histopathology images, which are medical images. So maybe the graph is part of the model's architecture, not a knowledge graph. \n\nRAG is about retrieval and generation. The title doesn't mention retrieval or generation, so probably not RAG.\n\nSo the options left are KG or none. But the model is a graph-based model for image representation. Since it's using a graph structure, but not necessarily a knowledge graph, maybe it's none. Wait, but the term \"Entity-Masked\" could imply entities, which are part of knowledge graphs. However, in this context, the entities might refer to parts of the image (like cells or structures in histopathology images) rather than real-world entities. So maybe it's not a knowledge graph. Therefore, the correct answer might be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33202@AAAI"},
{"title": "CoCoCo: Improving Text-Guided Video Inpainting for Better Consistency, Controllability and Compatibility", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CoCoCo: Improving Text-Guided Video Inpainting for Better Consistency, Controllability and Compatibility.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Text-Guided Video Inpainting\" suggests that the research involves using text to guide the inpainting process in videos. Inpainting typically refers to filling in missing parts of an image or video. So, combining text (a modality) with video (another modality) would be a multimodal approach. \n\nMultimodal research deals with integrating information from multiple modalities, like text and video here. The other options: time-series is about data over time, which video is, but the key here is the combination with text. RAG (Retrieval-Augmented Generation) is more about using retrieval to enhance generation models, which doesn't seem directly related. KG (Knowledge Graphs) involves structured data and relationships, which isn't mentioned here. \n\nSo the main focus is on combining text and video, making it multimodal. The answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33203@AAAI"},
{"title": "RhythmMamba: Fast, Lightweight, and Accurate Remote Physiological Measurement", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RhythmMamba: Fast, Lightweight, and Accurate Remote Physiological Measurement.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Remote physiological measurement\" probably refers to measuring things like heart rate, respiration, maybe using sensors or cameras from a distance. The terms \"fast,\" \"lightweight,\" and \"accurate\" suggest it's about efficiency and performance in processing data.\n\nNow, the four options. Time-series would involve data collected over time, like stock prices or sensor data. Multimodal usually means combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information to generate answers. KG is Knowledge Graph, which is about structured data and relationships between entities.\n\nThe paper's focus seems to be on physiological signals, which are typically time-series data. For example, heart rate is measured over time. The name \"RhythmMamba\" might hint at a model or method for processing rhythmic data, which is common in time-series. The other terms like \"remote\" and \"measurement\" don't immediately suggest multimodal, RAG, or KG. Unless they're using multiple modalities (like combining video and audio for physiological signals), but the title doesn't mention that. RAG and KG are more about information retrieval and structured knowledge, which don't seem relevant here. So the most likely topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33204@AAAI"},
{"title": "AdaCo: Overcoming Visual Foundation Model Noise in 3D Semantic Segmentation via Adaptive Label Correction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AdaCo: Overcoming Visual Foundation Model Noise in 3D Semantic Segmentation via Adaptive Label Correction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Visual Foundation Model\" probably refers to models like CLIP or other vision models that are pre-trained on large datasets. The problem here is noise in 3D semantic segmentation. The method is called Adaptive Label Correction (AdaCo). \n\nNow, the key parts here are \"Visual Foundation Model\" and \"3D Semantic Segmentation.\" Visual models are typically related to computer vision, which is a part of multimodal learning since they deal with images or videos. But the title doesn't mention combining different modalities like text and images. It's more about improving the segmentation by correcting labels from a noisy model. \n\nTime-series would involve data over time, like stock prices or sensor data. This doesn't seem to fit. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation, often in NLP. KG (Knowledge Graphs) involve structured data and relationships. The paper here is about correcting labels in a 3D segmentation task, which is more about computer vision and model training techniques. \n\nMultimodal usually refers to combining different data types, like text and images. However, the paper is focused on a single modality (visual) and improving its segmentation. So maybe it's not multimodal. RAG and KG don't seem relevant here. Time-series is out. \n\nWait, but the problem is about noise in the model's output. The method is adaptive label correction. This might be a technique to improve model training by adjusting labels, but it's not directly related to the four topics listed. The four options are time-series, multimodal, RAG, KG. Since the paper is about a computer vision task (3D segmentation) and a method to correct labels, none of the four topics seem to fit. Unless multimodal is considered because it's using a foundation model, but foundation models can be unimodal. \n\nI think the answer is \"none\" because the paper's focus is on improving 3D segmentation through label correction, which doesn't directly align with time-series, multimodal, RAG, or KG.\n</think>\n\nnone", "url": "https://papers.cool/venue/33205@AAAI"},
{"title": "L-Man: A Large Multi-modal Model Unifying Human-centric Tasks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"L-Man: A Large Multi-modal Model Unifying Human-centric Tasks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Large Multi-modal Model\" – the word \"multi-modal\" stands out. That usually refers to models that can process multiple types of data, like text, images, audio, etc. So that's a hint towards the \"multimodal\" category. \n\nThe other parts of the title mention \"Human-centric Tasks,\" which might relate to applications in areas like NLP, computer vision, or other AI fields that deal with human-related data. But the key term here is \"multi-modal.\" The other options are time-series (which deals with sequential data over time), RAG (Retrieval-Augmented Generation, which combines retrieval and generation for tasks like question answering), and KG (Knowledge Graphs, which are structured representations of knowledge). \n\nSince the title explicitly uses \"multi-modal,\" I think the correct category here is \"multimodal.\" There's no mention of time-series data, retrieval-augmented generation, or knowledge graphs in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33206@AAAI"},
{"title": "Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should say \"none\".\n\nFirst, I need to understand what each of these topics refers to. \n\nTime-series research typically involves data that is collected over time, like stock prices or weather data. It's about analyzing sequences of data points indexed in chronological order. \n\nMultimodal research deals with combining multiple types of data or modalities, such as text, images, audio, etc. For example, a system that uses both text and images to perform a task would be multimodal.\n\nRAG stands for Retrieval-Augmented Generation. This is a method where a model uses a retrieval component to fetch relevant information from a database and then generates a response based on that retrieved information. It's commonly used in question-answering systems.\n\nKG stands for Knowledge Graph, which is a structured representation of knowledge, often in the form of a graph with nodes and edges representing entities and their relationships. Research in this area might involve building or querying knowledge graphs.\n\nNow, looking at the title \"Cirbo: A New Tool for Boolean Circuit Analysis and Synthesis\". Boolean circuits are related to digital logic and computer engineering. Analysis and synthesis of circuits would involve verifying their correctness, optimizing them, or generating circuits from specifications. \n\nThe key terms here are \"Boolean Circuit\", \"Analysis\", and \"Synthesis\". None of these terms directly relate to time-series data, multimodal data, retrieval-augmented generation, or knowledge graphs. The paper seems to be about a tool for working with Boolean circuits, which is more in the domain of computer science, specifically in areas like formal methods, hardware design, or automated reasoning. \n\nSince the four topics provided (time-series, multimodal, RAG, KG) don't seem to intersect with Boolean circuit analysis and synthesis, the correct answer would be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33207@AAAI"},
{"title": "AAAI.2025 - Constraint Satisfaction and Optimization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"AAAI.2025 - Constraint Satisfaction and Optimization\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics entails. \n\nTime-series research typically involves data points indexed in time order, often used in forecasting, anomaly detection, etc. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple data modalities, like text, images, audio. The title here is about constraint satisfaction and optimization, which sounds more like a problem-solving or algorithmic approach rather than data modality integration. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title's focus is on constraint satisfaction and optimization, which could be related to various fields like operations research, AI planning, or optimization algorithms. However, unless the paper specifically discusses building or utilizing knowledge graphs, it's not directly related to KG.\n\nThe title mentions \"Constraint Satisfaction and Optimization,\" which are general areas in computer science and AI. These topics are about solving problems with constraints and finding optimal solutions. None of the four given topics (time-series, multimodal, RAG, KG) directly align with constraint satisfaction or optimization. The paper might be about algorithms, problem-solving techniques, or optimization methods, but those aren't among the listed options. Therefore, the correct answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/AAAI.2025?group=Constraint Satisfaction and Optimization"},
{"title": "Learning Valid Dual Bounds in Constraint Programming: Boosted Lagrangian Decomposition with Self-Supervised Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Learning Valid Dual Bounds in Constraint Programming: Boosted Lagrangian Decomposition with Self-Supervised Learning.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on constraint programming and using some kind of decomposition method with self-supervised learning. The key terms here are \"dual bounds,\" \"Lagrangian decomposition,\" and \"self-supervised learning.\" \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so that's probably out.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title is about constraint programming and optimization techniques, not about building or using knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about constraint programming and optimization methods using self-supervised learning, which doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33208@AAAI"},
{"title": "Exploiting Symmetries in MUS Computation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploiting Symmetries in MUS Computation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I should break down the title. \"MUS\" probably stands for Minimal Unsatisfiable Subset. That's a term from computational logic, especially in SAT solving. The paper is about finding symmetries in the computation of these subsets. \n\nNow, the four options. Time-series deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using external data in models like LLMs. KG is Knowledge Graphs, which are structured representations of information.\n\nThe title doesn't mention anything about time, so time-series is out. There's no indication of combining multiple data modalities, so multimodal isn't it. RAG and KG are both about knowledge, but RAG is more about retrieving information to augment generation, while KGs are structured data. The paper is about computational methods in logic, which doesn't directly relate to either RAG or KG. \n\nSo, none of the four topics seem to fit. The paper is about algorithmic improvements in MUS computation using symmetries, which is more of a computational logic or SAT solving problem. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33209@AAAI"}
{"title": "Optimal Classification Trees for Continuous Feature Data Using Dynamic Programming with Branch-and-Bound", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. The title is \"Optimal Classification Trees for Continuous Feature Data Using Dynamic Programming with Branch-and-Bound.\" \n\nFirst, I need to break down the title. The main subject here is \"Optimal Classification Trees.\" Classification trees are a type of machine learning model, often used in decision trees. The mention of \"continuous feature data\" suggests that the data being classified has numerical features rather than categorical ones.\n\nNext, the methods mentioned are \"Dynamic Programming with Branch-and-Bound.\" Dynamic programming is an optimization technique, and branch-and-bound is another algorithm for solving optimization problems. These are more about the algorithmic approach rather than the data type or model structure.\n\nNow, looking at the four possible topics: time-series, multimodal, RAG, KG. \n\nTime-series research typically deals with data points indexed in time order. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to data that combines multiple modalities, like text and images. The title doesn't mention combining different data types, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in natural language processing where a model uses a retrieval system to fetch information before generating a response. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graph, which involves structured data representations, often using graphs to represent entities and their relationships. The title doesn't mention knowledge graphs or structured data in that sense.\n\nThe paper seems focused on improving classification trees using dynamic programming and branch-and-bound techniques. These are optimization methods applied to machine learning models. Since none of the four topics (time-series, multimodal, RAG, KG) directly relate to the optimization of decision trees or the specific algorithms mentioned, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33210@AAAI"},
{"title": "Massively Parallel Continuous Local Search for Hybrid SAT Solving on GPUs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Massively Parallel Continuous Local Search for Hybrid SAT Solving on GPUs.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Hybrid SAT Solving\" refers to solving the Boolean satisfiability problem using a hybrid approach. SAT solvers are algorithms that determine if there's an assignment of variables that makes a given Boolean formula true. The mention of \"GPUs\" suggests that the research is about optimizing these solvers to run on graphics processing units, which are good for parallel processing. \"Massively Parallel Continuous Local Search\" probably refers to a method that uses parallel computing to perform local search algorithms continuously.\n\nNow, looking at the four topics: time-series, multimodal, RAG, KG. \n\nTime-series analysis deals with data points indexed in time order, like stock prices over time. This paper doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data modalities, like text and images. The title doesn't mention different data types, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. This paper is about SAT solving, which is a computational problem in logic, not about generating text or retrieving information. So RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on solving SAT problems using parallel computing, not on building or querying knowledge graphs. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) are directly related to the content of the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33211@AAAI"},
{"title": "Linear Equations with Min and Max Operators: Computational Complexity", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Linear Equations with Min and Max Operators: Computational Complexity\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics refers to. \n\nTime-series research typically involves data points indexed in time order, often used in forecasting, anomaly detection, etc. The title here doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining multiple data modalities, like text, images, audio. The title is about linear equations with min and max operators, which seems more mathematical and doesn't mention different data types. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge, often used for semantic reasoning. The title is about computational complexity of a specific type of equation, which seems more like theoretical computer science or mathematics. \n\nThe title is about linear equations with min and max operators and their computational complexity. This sounds like it's related to algorithms, computational theory, maybe operations research or optimization problems. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. The paper is likely in the field of computational complexity theory, which isn't listed here. Therefore, the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33212@AAAI"},
{"title": "Quantified Linear and Polynomial Arithmetic Satisfiability via Template-based Skolemization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Quantified Linear and Polynomial Arithmetic Satisfiability via Template-based Skolemization.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main terms here are \"Quantified Linear and Polynomial Arithmetic Satisfiability\" and \"Template-based Skolemization.\" Satisfiability in arithmetic usually relates to determining if there's a solution to a set of equations or inequalities. Skolemization is a technique in logic to eliminate existential quantifiers by introducing functions, which is part of automated theorem proving or formal methods.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using external knowledge in generating responses. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's title doesn't mention anything about time, different data modalities, retrieval, or knowledge graphs. It's focused on logical satisfiability and a specific method (Skolemization) in arithmetic. So none of the four topics seem to fit. The core of the research is in formal methods or automated reasoning, which isn't covered by the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33213@AAAI"},
{"title": "GPU-Accelerated Parallel Bilevel Optimization for Roubst 6G ISAC", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GPU-Accelerated Parallel Bilevel Optimization for Robust 6G ISAC\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"GPU-Accelerated\" refers to using graphics processing units for faster computation. \"Parallel Bilevel Optimization\" sounds like an optimization technique, maybe involving two levels of optimization problems. \"Robust 6G ISAC\" – ISAC is Integrated Sensing and Communication, which is a concept in 5G/6G networks where sensing and communication are combined. So the paper is about optimizing something related to 6G ISAC using GPU acceleration.\n\nNow, the four topics. Time-series would involve data over time, like stock prices or weather data. Multimodal refers to combining multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on optimization algorithms for 6G ISAC, using parallel processing on GPUs. None of the topics here directly relate to time-series data, multimodal data, RAG, or knowledge graphs. The optimization techniques and GPU acceleration are more about computational methods and system design for 6G, which doesn't fit into any of the listed categories. So the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33214@AAAI"},
{"title": "Proof Simulation via Round-based Strategy Extraction for QBF", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Proof Simulation via Round-based Strategy Extraction for QBF.\" Hmm, I need to figure out which of the given topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. \"Proof Simulation\" sounds like it's related to formal methods or logic, maybe in computer science. \"Round-based Strategy Extraction\" might refer to a method involving steps or rounds in a process. QBF stands for Quantified Boolean Formulas, which is a topic in computational logic and complexity theory. \n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to combining multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time, data over time, or sequences, so probably not time-series. It's about QBF and proof strategies, which is more theoretical computer science. Multimodal doesn't fit here either since there's no mention of combining different data modalities. RAG and KG are both related to knowledge and information retrieval, but the title is about proof simulation and strategy extraction in QBF. That seems unrelated to knowledge graphs or retrieval-augmented generation. \n\nSo, none of the listed topics (time-series, multimodal, RAG, KG) seem to fit. The paper is about computational logic and proof methods, which isn't covered by any of the given options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33215@AAAI"},
{"title": "Diffusion-based Synthetic Data Generation for Visible-Infrared Person Re-Identification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Diffusion-based Synthetic Data Generation for Visible-Infrared Person Re-Identification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Diffusion-based\" refers to using diffusion models, which are a type of generative model. \"Synthetic Data Generation\" means creating artificial data, probably to augment datasets. The application here is \"Visible-Infrared Person Re-Identification,\" which involves matching people across different modalities—visible (like regular images) and infrared (thermal images). \n\nSo, person re-identification typically uses data from different sensors or modalities. Visible and infrared are two different types of data, so combining them would be multimodal. The paper is about generating synthetic data for this task. The key here is whether the focus is on the multimodal aspect or another topic. \n\nLooking at the options: time-series is about data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, but the title doesn't mention retrieval. KG (Knowledge Graphs) involves structured data, which isn't indicated here. The main thing is that the data comes from two different modalities (visible and infrared), so multimodal makes sense. The synthetic data generation is the method, but the application area is multimodal. So the topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33216@AAAI"},
{"title": "Complete Symmetry Breaking for Finite Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Complete Symmetry Breaking for Finite Models\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should say \"none\".\n\nFirst, I need to understand what each of these topics entails. \n\nTime-series research typically deals with data points indexed in time order, often used in forecasting, anomaly detection, etc. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to combining multiple data modalities like text, images, audio. The title doesn't mention different data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't seem related to retrieval or generation processes.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title mentions \"symmetry breaking\" and \"finite models,\" which might relate to model structure or optimization, but not directly to knowledge graphs.\n\n\"Complete Symmetry Breaking\" sounds like it's about breaking symmetries in models, which could be a concept in machine learning or optimization. However, none of the four topics listed (time-series, multimodal, RAG, KG) directly relate to symmetry breaking in models. The term \"finite models\" might refer to models with a finite number of parameters or states, but again, not directly tied to the given topics.\n\nSince the title doesn't clearly align with any of the four specified research areas, the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33217@AAAI"},
{"title": "Decentralized Projected Riemannian Stochastic Recursive Momentum Method for Nonconvex Optimization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Decentralized Projected Riemannian Stochastic Recursive Momentum Method for Nonconvex Optimization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Decentralized\" might refer to a distributed system or network. \"Projected Riemannian\" suggests some mathematical or geometric approach, maybe in optimization. \"Stochastic Recursive Momentum Method\" sounds like an optimization algorithm, possibly related to gradient descent or similar methods. \"Nonconvex Optimization\" is a general area in optimization problems where the objective function isn't convex.\n\nNow, looking at the four options. Time-series usually involves data over time, like forecasting or analysis of temporal data. Multimodal refers to combining multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title doesn't mention anything about time, data modalities, retrieval, or knowledge graphs. It's focused on an optimization method, specifically a decentralized approach using Riemannian geometry. None of the four topics listed directly relate to optimization algorithms or Riemannian methods. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33218@AAAI"},
{"title": "SORREL: Suboptimal-Demonstration-Guided Reinforcement Learning for Learning to Branch", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SORREL: Suboptimal-Demonstration-Guided Reinforcement Learning for Learning to Branch.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Reinforcement Learning\" is a key term here. RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. Multimodal refers to using multiple types of data like text, images, audio together. Time-series is about data over time, like stock prices or sensor data.\n\nThe paper's title mentions \"Suboptimal-Demonstration-Guided Reinforcement Learning.\" So it's about using demonstrations (which could be like examples or data) to guide the reinforcement learning process. Reinforcement learning itself is a machine learning method where an agent learns by interacting with an environment. The term \"demonstration-guided\" might relate to imitation learning or using expert demonstrations, but here it's suboptimal, meaning the demonstrations aren't perfect. \n\nNow, does this fit into any of the four categories? RAG is about retrieval and generation, which doesn't seem directly related. KG is about knowledge graphs, which are more about structured data and relationships. Multimodal would require the use of multiple data modalities. Time-series would involve sequential data over time. The title doesn't mention any of these. The core focus here is on reinforcement learning with suboptimal demonstrations, which is a specific area within RL but doesn't fall under the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33219@AAAI"}
{"title": "Langevin Multiplicative Weights Update with Applications in Polynomial Portfolio Management", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Langevin Multiplicative Weights Update with Applications in Polynomial Portfolio Management.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Langevin Multiplicative Weights Update\" sounds like an algorithm or method. The Langevin part might relate to stochastic processes, maybe something with differential equations or optimization. The \"Multiplicative Weights Update\" is a known algorithm in machine learning, often used in online learning and optimization. The application mentioned is \"Polynomial Portfolio Management,\" which is about managing financial portfolios, probably involving time-based data since portfolio management often deals with time series data like stock prices over time.\n\nNow, the possible topics. Time-series analysis involves data points indexed in time order. Portfolio management definitely uses time-series data because stock prices, returns, etc., are time-dependent. So maybe this paper is about applying some algorithm (Langevin MWU) to time-series problems in finance.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to augment its responses. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about building or using knowledge graphs, so that's probably not it either.\n\nSo the most likely topic here is time-series. The application in portfolio management uses time-based financial data, and the method (Langevin MWU) could be a new approach for optimizing portfolios over time, which is a time-series problem. The other topics don't fit based on the title's content.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33220@AAAI"},
{"title": "Parameterized Complexity of Caching in Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Parameterized Complexity of Caching in Networks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. \"Parameterized Complexity\" refers to computational complexity theory, where problems are analyzed based on parameters. \"Caching in Networks\" probably relates to how data is stored and retrieved in network systems. So the paper is likely about the computational complexity of caching strategies in networks, considering different parameters.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or weather data. Multimodal refers to combining multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time-based data, so time-series is probably not it. It's not about combining different data modalities, so multimodal is out. RAG and KG are both related to information retrieval and knowledge representation, but the title is about the complexity of caching algorithms in networks. Caching in networks could involve data retrieval, but the focus here is on computational complexity parameters, not specifically on retrieval methods or knowledge graphs. \n\nSo none of the four topics seem to fit. The paper is about computational complexity in caching, which is more of an algorithms or computer networks topic, not directly related to time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33221@AAAI"},
{"title": "FFCG: Effective and Fast Family Column Generation for Solving Large-Scale Linear Program", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FFCG: Effective and Fast Family Column Generation for Solving Large-Scale Linear Program.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Column Generation\" is a method used in optimization, particularly in linear programming. It's a technique for solving large-scale problems by iteratively generating columns (variables) that improve the solution. The paper is about improving this method, making it faster and more effective for large-scale problems.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like forecasting or trend analysis. Multimodal refers to combining different types of data (e.g., text, images, audio). RAG stands for Retrieval-Augmented Generation, which is used in AI for enhancing model outputs with retrieved information. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on an optimization algorithm (column generation) for linear programming. None of the four topics directly relate to optimization methods. Time-series is about temporal data, multimodal about multiple data types, RAG and KG are in AI and knowledge representation. Since the paper is about an algorithm for solving linear programs, it doesn't fit into any of the listed topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33222@AAAI"},
{"title": "Breaking Symmetries in Quantified Graph Search: A Comparative Study", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Breaking Symmetries in Quantified Graph Search: A Comparative Study.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Quantified Graph Search\" makes me think of graphs, which are related to knowledge graphs (KG). But wait, \"breaking symmetries\" might refer to some algorithmic approach in graph theory. The term \"symmetries\" in graphs could be about automorphisms or redundant paths, which are common in graph algorithms. \n\nNow, the options are time-series, multimodal, RAG, or KG. Time-series is about data over time, which doesn't seem to fit here. Multimodal usually involves combining different data types like text and images. RAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external data retrieval. KG is Knowledge Graphs, which are structured representations of knowledge using graphs.\n\nThe title mentions \"Quantified Graph Search,\" which sounds like it's dealing with searching within a graph structure, possibly optimizing or analyzing the search process. Breaking symmetries might be a technique to improve search efficiency in such graphs. Since knowledge graphs are a type of graph used for structured data, this could be related to KG. However, the term \"Quantified Graph\" isn't standard, but maybe it's a specific method or framework. \n\nAlternatively, if it's about graph algorithms in general, maybe it's not specifically about knowledge graphs. But the options given are only these four. Since the other three (time-series, multimodal, RAG) don't fit, the closest would be KG. Unless \"Quantified Graph\" refers to something else. Wait, \"Quantified\" might relate to quantifiers in logic, like in quantified Boolean formulas. But even then, if it's about graph search with quantifiers, maybe it's part of knowledge graph reasoning. \n\nI think the best fit here is KG. The other options don't align with the title's focus on graph search and symmetries. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33223@AAAI"},
{"title": "A Complete Algorithm for Optimization Modulo Nonlinear Real Arithmetic", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Complete Algorithm for Optimization Modulo Nonlinear Real Arithmetic.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. \"Optimization\" suggests it's about finding the best solution under certain constraints. \"Modulo Nonlinear Real Arithmetic\" probably refers to mathematical operations involving real numbers and nonlinear equations. The term \"modulo\" here might mean that the algorithm works under the constraints of nonlinear real arithmetic. \n\nNow, the four options. Time-series analysis deals with data points indexed in time order, like stock prices over time. Multimodal refers to combining multiple data types or modalities, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in AI where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used in semantic web and information retrieval.\n\nThe paper's title doesn't mention anything about time, data modalities, retrieval, or knowledge graphs. It's focused on an algorithm for optimization within a specific mathematical framework. Since none of the four topics directly relate to optimization algorithms in nonlinear real arithmetic, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33224@AAAI"},
{"title": "DCC: Differentiable Cardinality Constraints for Partial Index Tracking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DCC: Differentiable Cardinality Constraints for Partial Index Tracking.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Differentiable Cardinality Constraints\" sounds like it's about optimization with constraints that can be differentiated, maybe in machine learning. \"Partial Index Tracking\" might relate to tracking a subset of an index, perhaps in finance or data analysis. \n\nTime-series usually involves data over time, like stock prices or weather data. Multimodal refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on optimization techniques with cardinality constraints, which is more about mathematical modeling or machine learning algorithms. It doesn't mention anything about time-based data, multiple data modalities, retrieval, or knowledge graphs. So it probably doesn't fit into any of the four categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33225@AAAI"},
{"title": "Improving the Lower Bound in Branch-and-Bound Algorithms for MaxSAT", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Improving the Lower Bound in Branch-and-Bound Algorithms for MaxSAT\" and determine which of the given topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics refers to. \n\nTime-series research typically involves data points indexed in time order, often used in forecasting, anomaly detection, etc. The title here is about MaxSAT algorithms, which is a problem in computer science related to Boolean satisfiability. Doesn't seem related to time-series data.\n\nMultimodal refers to combining multiple data modalities, like text, images, audio. The paper title doesn't mention anything about combining different data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model uses a retrieval system to fetch relevant information before generating a response. The title is about improving lower bounds in algorithms for MaxSAT, which is an optimization problem. Doesn't seem to involve retrieval or generation.\n\nKG is Knowledge Graph, which involves structured data representation, linking entities, etc. The paper's focus is on algorithmic improvements for MaxSAT, which is a computational problem. No mention of knowledge graphs here.\n\nSo, the paper is about enhancing the lower bound in branch-and-bound algorithms for MaxSAT. Branch-and-bound is a method used in optimization problems to find the optimal solution by systematically exploring the solution space. MaxSAT is the Maximum Satisfiability problem, which is a classic NP-hard problem in computer science. The research here is focused on algorithmic improvements, specifically in the lower bound calculation within the branch-and-bound framework. None of the provided topics (time-series, multimodal, RAG, KG) are directly related to this area. Therefore, the correct response should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33226@AAAI"},
{"title": "Online Prompt Selection for Program Synthesis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Online Prompt Selection for Program Synthesis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title is about program synthesis, which is about generating code, but there's no mention of multiple data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get relevant information before generating a response. The title mentions \"Prompt Selection,\" which sounds like selecting the best prompts (maybe from a database) to help in generating code. That could be related to RAG because it's about retrieving and using prompts effectively.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or structured data, so probably not KG.\n\nSo the most likely answer is RAG. The paper is about selecting prompts online (in real-time) for program synthesis, which aligns with retrieval-augmented generation techniques where the model retrieves relevant information (prompts) to aid in generation.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33227@AAAI"},
{"title": "DiverSAT: A Novel and Effective Local Search Algorithm for Diverse SAT Problem", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"DiverSAT: A Novel and Effective Local Search Algorithm for Diverse SAT Problem\" and determine which of the topics it belongs to: time-series, multimodal, RAG, or KG. If none, respond with \"none\".\n\nFirst, I need to understand what each of these topics refers to. Time-series typically involves data points indexed in time order, like stock prices over time. Multimodal refers to combining multiple data modalities, such as text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used for semantic relationships between entities.\n\nNow, looking at the title: DiverSAT is a local search algorithm for the Diverse SAT problem. SAT stands for Satisfiability, which is a classic problem in computer science and logic, where the goal is to determine if there's an assignment of variables that makes a given Boolean formula true. The term \"Diverse SAT\" might refer to variations or extensions of the SAT problem, perhaps looking for diverse solutions. \n\nThe key here is the algorithm type. Local search algorithms are common in optimization problems, including SAT solving. The topics provided don't include anything about algorithms for SAT problems. Time-series is unrelated. Multimodal would involve multiple data types, which isn't mentioned. RAG and KG are more about information retrieval and knowledge representation, not algorithm design for SAT. \n\nTherefore, the paper is about a new algorithm for a specific SAT problem, which doesn't fall under any of the listed topics. So the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33228@AAAI"},
{"title": "Towards Real-Time Approximate Counting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Real-Time Approximate Counting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title mentions \"Real-Time,\" which could relate to time-series since real-time data processing is common there. But \"approximate counting\" might be a method for handling data streams, which is a time-series context. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't seem to involve retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge representation, so likely not KG.\n\nSo, the most plausible is time-series. The real-time aspect and approximate counting could be part of time-series data processing, especially in streaming scenarios where exact counting is impractical, and approximations are used for efficiency. I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33231@AAAI"}
{"title": "Certifying Bounds Propagation for Integer Multiplication Constraints", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Certifying Bounds Propagation for Integer Multiplication Constraints.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal research deals with combining different types of data, like text and images. The title is about integer multiplication constraints and bounds propagation. Doesn't seem to involve multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model uses external information retrieved from a database. The title is about certifying bounds in integer multiplication, which sounds more like a mathematical or computational problem, not related to retrieval or generation. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title doesn't mention anything about graphs, knowledge, or relationships between entities. So probably not KG either.\n\nSo none of the four topics seem to fit. The paper is about certifying bounds in integer multiplication constraints, which sounds like it's in the area of formal verification, computational mathematics, or constraint solving. Since none of the given options match, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33230@AAAI"},
{"title": "Towards Real-Time Approximate Counting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Real-Time Approximate Counting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time or sensor data. The title mentions \"Real-Time,\" which could relate to time-series since real-time data processing is common there. But \"approximate counting\" might be a method for handling data streams, which is a time-series context. \n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about combining different modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't seem to involve retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about graphs or knowledge representation, so likely not KG.\n\nSo, the most plausible is time-series. The real-time aspect and approximate counting could be part of time-series data processing, especially in streaming scenarios where exact counting is impractical, and approximations are used for efficiency. I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33231@AAAI"},
{"title": "The Impact of Literal Sorting on Cardinality Constraint Encodings", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"The Impact of Literal Sorting on Cardinality Constraint Encodings.\" Hmm. I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Literal Sorting\" probably refers to the order in which literals (which are variables or their negations in logic) are arranged. \"Cardinality Constraint Encodings\" sounds like it's about encoding constraints that involve the number of variables that can be true, like in SAT problems. So the paper is likely discussing how sorting literals affects the way cardinality constraints are encoded, maybe in the context of SAT solving or logic programming.\n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem related. Multimodal involves combining different data types like text and images, which also doesn't fit. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which isn't mentioned here. KG (Knowledge Graphs) deals with structured data and relationships, but the title doesn't mention anything about knowledge graphs or structured data representation.\n\nThe paper seems to be in the area of logic and constraint satisfaction, specifically dealing with encoding techniques for cardinality constraints. None of the given topics (time-series, multimodal, RAG, KG) directly relate to this. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33232@AAAI"},
{"title": "Computationally Hard Problems Are Hard for QBF Proof Systems Too", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Computationally Hard Problems Are Hard for QBF Proof Systems Too\" and determine which of the topics it belongs to: time-series, multimodal, RAG, or KG. If none of these fit, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics refers to. \n\nTime-series analysis typically involves data points indexed in time order, often used in forecasting or analyzing trends over time. Examples include stock market data or weather patterns.\n\nMultimodal refers to systems or models that process multiple types of data, like combining text, images, and audio. For example, a model that uses both text and images to answer questions.\n\nRAG stands for Retrieval-Augmented Generation. This is a method where a model retrieves relevant information from a database or knowledge source and then uses that to generate responses. It's commonly used in question-answering systems to enhance the model's knowledge beyond its training data.\n\nKG stands for Knowledge Graph, which is a structured representation of knowledge, often in the form of a graph with nodes and edges representing entities and their relationships. Knowledge graphs are used for organizing and querying complex data.\n\nNow, looking at the paper title: \"Computationally Hard Problems Are Hard for QBF Proof Systems Too\". QBF stands for Quantified Boolean Formula, which is a concept in computational complexity theory. The title suggests that the paper is discussing the difficulty of certain computational problems within the context of QBF proof systems. \n\nQBF is related to logic and computational complexity, specifically dealing with problems that involve quantifiers in Boolean formulas. The paper seems to be theoretical, focusing on the hardness of problems in proof systems, which is a topic in computational complexity and theoretical computer science.\n\nComparing this to the given topics: time-series, multimodal, RAG, and KG. None of these topics are directly related to computational complexity, proof systems, or QBF. Time-series is about temporal data, multimodal about multiple data types, RAG about retrieval and generation, and KG about structured knowledge representation. The paper's focus is on theoretical aspects of computational problems and proof systems, which doesn't align with any of the listed topics. \n\nTherefore, the correct response should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33233@AAAI"},
{"title": "Decomposed Quadratization: Efficient QUBO Formulation for Learning Bayesian Network", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Decomposed Quadratization: Efficient QUBO Formulation for Learning Bayesian Network.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"QUBO\" stands for Quadratic Unconstrained Binary Optimization, which is a type of optimization problem. \"Learning Bayesian Network\" refers to constructing a Bayesian network, which is a probabilistic graphical model. So the paper is about formulating a QUBO problem efficiently for learning Bayesian networks.\n\nNow, the four options. Time-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to combining multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which is used in models that combine retrieval with generation, like some LLMs. KG is Knowledge Graph, which is a structured representation of knowledge, often using graphs.\n\nThe paper is about Bayesian networks, which are a type of probabilistic graphical model. Knowledge Graphs (KG) are also graph-based structures that represent entities and their relationships. However, Bayesian networks are more about probabilistic dependencies between variables, while KGs are about factual knowledge. The paper's focus is on formulating QUBO for learning Bayesian networks, which is an optimization problem in probabilistic modeling. \n\nSince the options are time-series, multimodal, RAG, or KG, and the paper is about Bayesian networks, which are related to probabilistic models but not directly a Knowledge Graph. Knowledge Graphs are more about structured data and relationships, whereas Bayesian networks are about probabilistic inference. So the paper doesn't fit into KG. It's also not about time-series, multimodal data, or RAG. Therefore, the answer should be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33234@AAAI"},
{"title": "Scalable Quantum-Inspired Optimization Through Dynamic Qubit Compression", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Scalable Quantum-Inspired Optimization Through Dynamic Qubit Compression.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Quantum-Inspired Optimization\" suggests it's about optimization techniques inspired by quantum computing. \"Dynamic Qubit Compression\" probably refers to methods for managing qubits efficiently, which are the basic units of quantum information. The key here is that the paper is about optimization algorithms that are inspired by quantum mechanics but might not be actual quantum computing. \n\nNow, looking at the four options. Time-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to combining multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graphs, which are structured representations of information, often used for semantic relationships.\n\nThe paper's title doesn't mention anything about time-based data, so time-series is out. It's not about combining different data modalities, so multimodal isn't it. RAG and KG are both related to information retrieval and knowledge representation, but the title is about optimization techniques inspired by quantum computing. None of the four topics directly relate to quantum-inspired optimization or qubit management. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33235@AAAI"},
{"title": "Generalizing Constraint Models in Constraint Acquisition", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Generalizing Constraint Models in Constraint Acquisition.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let me break down the title. \"Constraint Models\" and \"Constraint Acquisition\" are the key parts. Constraint acquisition usually refers to the process of learning or extracting constraints from data or user input. Generalizing these models would mean making them applicable to a broader range of scenarios or data.\n\nNow, looking at the options. Time-series is about data over time, like stock prices or weather. Multimodal involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which is a structured representation of knowledge, often used for linking entities and their relationships.\n\nThe title doesn't mention anything about time or sequential data, so time-series is probably out. There's no indication of combining multiple data modalities, so multimodal isn't it. RAG and KG are both related to knowledge representation and retrieval. Constraint acquisition might involve building or refining knowledge structures, but the term \"constraint models\" here is more about logical constraints rather than knowledge graphs. RAG is more about augmenting generation with retrieval, which doesn't seem directly related. \n\nSince none of the four topics (time-series, multimodal, RAG, KG) are clearly addressed in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33236@AAAI"},
{"title": "Solving Higher-Order Quantified Boolean Satisfiability via Higher-Order Model Checking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Solving Higher-Order Quantified Boolean Satisfiability via Higher-Order Model Checking.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. Quantified Boolean Satisfiability (QBF) is a problem in computer science, specifically in logic and computational complexity. Higher-order here probably refers to the level of quantifiers in the Boolean formulas. Model checking is a method used in formal verification to check if a system model meets a specification. So the paper is about solving QBF using model checking techniques.\n\nNow, the four options: time-series deals with data over time, like stock prices or weather. Multimodal involves combining multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is used in AI for enhancing models with external information. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's topic is about formal methods in logic and computational problems. None of the four topics listed seem directly related. Time-series is about temporal data, which isn't mentioned here. Multimodal is about combining different data modalities, which also doesn't fit. RAG and KG are related to AI and knowledge representation, but the paper is about solving a specific computational problem using model checking. So it doesn't fit any of the given categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33237@AAAI"},
{"title": "On the Modelling of Constraints with Tractable Logical Operators", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"On the Modelling of Constraints with Tractable Logical Operators.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title is about constraints and logical operators, which doesn't seem related to multiple data modalities.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title talks about modeling constraints with logical operators. Logical operators are used in knowledge representation and reasoning, which is a part of knowledge graphs. Tractable logical operators might relate to making the reasoning process efficient, which is important in KGs. So this could be related to KG.\n\nAlternatively, maybe it's about logical constraints in general, but since the options are limited to the four given, and the closest fit is KG, I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33238@AAAI"},
{"title": "Prediction-Based Adaptive Variable Ordering Heuristics for Constraint Satisfaction Problems", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Prediction-Based Adaptive Variable Ordering Heuristics for Constraint Satisfaction Problems.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. \"Constraint Satisfaction Problems\" (CSPs) are a type of problem in computer science and AI where you have variables with domains and constraints that need to be satisfied. The paper is about variable ordering heuristics, which are strategies to decide the order in which variables are considered during problem solving. The \"prediction-based adaptive\" part suggests that the heuristics use some kind of prediction model that adapts over time.\n\nNow, looking at the possible topics. Time-series usually involves data over time, like forecasting or analyzing sequences. Multimodal refers to combining multiple data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generative models, often in NLP. KG (Knowledge Graph) involves structured data representations, like ontologies or semantic networks.\n\nThe paper's focus is on heuristics for CSPs, which is more about algorithms and problem-solving strategies. None of the four topics directly relate to CSPs or variable ordering heuristics. Time-series is about temporal data, which isn't mentioned here. Multimodal deals with multiple data modalities, which isn't the case here. RAG and KG are more about knowledge representation and retrieval, which also don't seem to connect. The paper is about improving the efficiency of solving CSPs through adaptive heuristics, which is a different area. So, it doesn't fit any of the given topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/33239@AAAI"}
{"title": "Towards Projected and Incremental Pseudo-Boolean Model Counting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Projected and Incremental Pseudo-Boolean Model Counting.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Projected and Incremental\" might refer to methods or approaches. \"Pseudo-Boolean Model Counting\" sounds like a computational problem, maybe in logic or optimization. Pseudo-Boolean functions are Boolean functions that take integer values, often used in optimization problems. Model counting is about counting the number of solutions to a logical formula. So this paper is probably about algorithms or techniques for efficiently counting models in pseudo-Boolean contexts, with some projection and incremental aspects.\n\nNow, the four options. Time-series analysis deals with data over time, like forecasting or pattern recognition in sequences. Multimodal refers to combining multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where models use external information during generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe title doesn't mention anything about time, sequences, or temporal data, so time-series is out. There's no indication of combining different data modalities, so multimodal isn't it. RAG is about using retrieval in generation, which doesn't seem related to model counting. Knowledge Graphs involve structured data and relationships, but the title is about model counting in pseudo-Boolean functions, which is more of a computational logic or optimization problem. None of the four topics directly relate to this. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33240@AAAI"},
{"title": "Motif-aware Graph Neural Networks for Networked Time Series Imputation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Motif-aware Graph Neural Networks for Networked Time Series Imputation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Networked Time Series\" suggests that the data is time series data that's connected in a network structure. So time-series is definitely part of it. Then \"Graph Neural Networks\" points to using graph structures, which relates to knowledge graphs (KG) since KGs are a type of graph. But the term here is \"Graph Neural Networks,\" which is more about the model using graph structures, not necessarily a knowledge graph. Wait, but the options are RAG, KG, multimodal, or time-series. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, like in NLP. That doesn't seem to fit here. Multimodal would involve multiple data types, like text and images, but the title doesn't mention that. The focus is on time series with a network (graph) structure. So the main components are time series and graph neural networks. \n\nThe problem is imputation, which is filling in missing data points in time series. The model is motif-aware, which refers to specific patterns in the graph. So the key elements are time series and graph structures. The options are time-series, multimodal, RAG, KG. Since the paper is about time series imputation using graph neural networks, the primary topic here is time-series. The graph aspect might relate to KG, but the title doesn't explicitly mention knowledge graphs. The main focus is on the time series aspect with a network structure. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33241@AAAI"},
{"title": "AAAI.2025 - Data Mining and Knowledge Management", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"AAAI.2025 - Data Mining and Knowledge Management\" and determine which of the given topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to break down the title. The conference is AAAI 2025, which is the Association for the Advancement of Artificial Intelligence. The topic mentioned is \"Data Mining and Knowledge Management\". \n\nNow, looking at the possible categories. Time-series usually involves data points indexed in time order, like stock prices or weather data. Multimodal refers to combining multiple data types, such as text, images, and audio. RAG stands for Retrieval-Augmented Generation, which is a method in NLP that uses retrieval to enhance generation models. KG is Knowledge Graph, which structures information as entities and relationships.\n\nThe title here is about Data Mining and Knowledge Management. Data Mining is a broad field that includes techniques for discovering patterns in large datasets. Knowledge Management involves organizing and managing knowledge within an organization. Neither of these directly points to time-series analysis. They also don't specifically mention multimodal data. RAG is a specific technique in NLP, and while knowledge management might relate to knowledge graphs (KG), the title doesn't explicitly mention graphs or structured data. \n\nHowever, \"Knowledge Management\" could be related to Knowledge Graphs (KG) since KGs are used to represent and manage knowledge. But the title is more general. The main focus here is on data mining and knowledge management, which are broader topics. Since none of the options (time-series, multimodal, RAG, KG) are explicitly mentioned or clearly implied by the title, the correct answer would be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/AAAI.2025?group=Data Mining and Knowledge Management"},
{"title": "Revisiting Multimodal Emotion Recognition in Conversation from the Perspective of Graph Spectrum", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Revisiting Multimodal Emotion Recognition in Conversation from the Perspective of Graph Spectrum\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. The key terms here are \"Multimodal Emotion Recognition\" and \"Graph Spectrum.\" The word \"Multimodal\" is right there in the title, which immediately makes me think that the topic might be \"multimodal.\" But I need to check the other parts to be sure.\n\nMultimodal research typically involves combining multiple types of data, like text, audio, and video. Emotion recognition in conversation would likely use data from different modalities, such as speech, facial expressions, and maybe text. So that's a strong indicator for the multimodal category.\n\nNow, the other part of the title mentions \"Graph Spectrum.\" Graph Spectrum might relate to graph theory or graph-based methods. But the options given are RAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs). RAG is more about combining retrieval with generative models, often in NLP tasks. KGs are structured representations of knowledge, usually in the form of triples. The term \"Graph Spectrum\" here doesn't directly point to RAG or KG. It might be referring to spectral graph theory, which is a mathematical approach to analyzing graphs. However, since the user's options are RAG, KG, time-series, or multimodal, and the title explicitly mentions \"Multimodal,\" I should prioritize that.\n\nTime-series would involve data points indexed in time order, like stock prices over time. The title doesn't mention anything about time-series data, so that's probably not it. RAG and KG are less likely here. The main focus seems to be on multimodal data for emotion recognition, using graph-based methods. So the correct category is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33242@AAAI"},
{"title": "GeoPro-Net: Learning Interpretable Spatiotemporal Prediction Models Through Statistically-Guided Geo-Prototyping", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GeoPro-Net: Learning Interpretable Spatiotemporal Prediction Models Through Statistically-Guided Geo-Prototyping.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatiotemporal\" refers to both space and time, so that's a hint. Spatiotemporal models usually deal with data that varies over both space and time, which is common in time-series analysis, especially when dealing with geospatial data. The mention of \"prediction models\" suggests forecasting, which is a key part of time-series analysis. \n\nThe term \"Geo-Prototyping\" might relate to geographic or spatial aspects. But the main focus here seems to be on creating interpretable models for spatiotemporal data. The \"statistically-guided\" part might indicate that they're using statistical methods to guide the model, but that's more about methodology than the topic itself.\n\nLooking at the options: time-series is about data over time, which fits spatiotemporal. Multimodal would involve multiple data types (like text and images), which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which doesn't seem relevant. KG (Knowledge Graphs) involves structured data and relationships, which also isn't directly mentioned.\n\nSo, the key terms are spatiotemporal and prediction, which align with time-series analysis. Even though it's spatial, the time component is there, making it a time-series topic. The answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33243@AAAI"},
{"title": "Alleviating Performance Disparity in Adversarial Spatiotemporal Graph Learning Under Zero-Inflated Distribution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Alleviating Performance Disparity in Adversarial Spatiotemporal Graph Learning Under Zero-Inflated Distribution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatiotemporal\" suggests both spatial and temporal aspects, so that's time-series related? Because time-series often involves data over time, but spatiotemporal is more about data that has both spatial (like locations) and temporal (time) components. So maybe time-series is part of it, but not sure yet.\n\n\"Graph Learning\" – that makes me think of Knowledge Graphs (KG), since graphs are a key part of KGs. But wait, adversarial spatiotemporal graph learning... Adversarial could refer to adversarial attacks or training methods, but the main focus here is the graph structure. However, the problem is about performance disparity under zero-inflated distribution. Zero-inflated might refer to data with many zeros, which could be a data distribution issue.\n\nNow, the options are time-series, multimodal, RAG, or KG. Let's consider each:\n\n- Time-series: The spatiotemporal aspect does involve time, so maybe. But the main focus here is on graph learning with adversarial aspects and zero-inflated data. Time-series typically deals with sequences over time, but spatiotemporal graphs are more complex, combining both space and time in a graph structure. However, the core topic might still be time-series if the temporal aspect is dominant.\n\n- Multimodal: This usually refers to combining different types of data (e.g., text, images, audio). The title doesn't mention multiple modalities, so probably not this one.\n\n- RAG (Retrieval-Augmented Generation): That's about using retrieval methods to augment generation in models, like in NLP. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\n- KG (Knowledge Graph): This involves structured data in the form of graphs, often for knowledge representation. The paper mentions \"graph learning,\" which could be related to KGs. However, adversarial spatiotemporal graph learning might be more about graph neural networks in a spatiotemporal context rather than knowledge graphs specifically. Knowledge graphs are more about semantic relationships and structured knowledge, whereas spatiotemporal graphs might model physical or spatial-temporal data (like traffic, weather, etc.).\n\nSo, the key terms are \"spatiotemporal\" and \"graph learning.\" Spatiotemporal data is a type of time-series data that includes spatial information. So maybe the primary topic here is time-series. However, the graph aspect complicates it. But the options given are time-series, multimodal, RAG, or KG. Since the paper is about graph learning in a spatiotemporal context, and the main challenge is performance disparity under zero-inflated distribution, the core topic might still be time-series because of the temporal component. Alternatively, if the graph is central, maybe it's KG. But I think in academic contexts, spatiotemporal graph learning is often categorized under time-series analysis, especially when dealing with temporal aspects. So I'm leaning towards time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33244@AAAI"},
{"title": "CUGF: A Reliable and Fair Recommendation Framework", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CUGF: A Reliable and Fair Recommendation Framework.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like text and images. The title doesn't specify different data modalities, so maybe not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval and generation for tasks like question answering. The title is about a recommendation framework, which might use retrieval, but the key terms here are \"reliable\" and \"fair,\" which are more about the framework's properties rather than RAG specifically.\n\nKG is Knowledge Graph, which involves structured data and relationships. If the framework uses a knowledge graph for recommendations, that would fit. However, the title doesn't mention knowledge graphs or structured data explicitly.\n\nThe title focuses on reliability and fairness in recommendations. These are more about the ethical or algorithmic aspects of the recommendation system rather than the specific technical areas listed. Since none of the four topics (time-series, multimodal, RAG, KG) are directly indicated in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33245@AAAI"},
{"title": "Cross-modal Multi-task Learning for Multimedia Event Extraction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Cross-modal Multi-task Learning for Multimedia Event Extraction.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Cross-modal\" suggests that the research involves multiple modalities, like combining different types of data such as text, images, audio, etc. \"Multi-task Learning\" means the model is trained to perform multiple tasks simultaneously. \"Multimedia Event Extraction\" implies that the tasks are related to extracting events from multimedia content, which typically involves more than one data type.\n\nLooking at the options: multimodal is about combining different data modalities, which aligns with \"cross-modal.\" Time-series would involve data over time, like stock prices or sensor data. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation tasks, often in NLP. KG (Knowledge Graph) involves structured data representations. \n\nThe paper's focus on cross-modal learning for multimedia events fits best under multimodal. There's no mention of time-series data, RAG techniques, or knowledge graphs in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33246@AAAI"},
{"title": "Spatiotemporal-aware Trend-Seasonality Decomposition Network for Traffic Flow Forecasting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spatiotemporal-aware Trend-Seasonality Decomposition Network for Traffic Flow Forecasting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatiotemporal-aware\" suggests that the model considers both spatial and temporal aspects. \"Trend-Seasonality Decomposition\" is a term I often associate with time-series analysis, where you separate the data into trend and seasonal components. The application here is \"Traffic Flow Forecasting,\" which is a classic time-series problem because you're predicting future traffic based on past data over time.\n\nNow, checking the options. Time-series is definitely a candidate. Multimodal usually refers to combining different types of data, like text and images, which doesn't seem to be the case here. RAG (Retrieval-Augmented Generation) is more about using retrieved information to enhance model outputs, typically in NLP tasks. KG (Knowledge Graph) involves structured data representations, which isn't mentioned here. The paper's focus is on decomposing time-series data into trend and seasonality, which is a core aspect of time-series analysis. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33247@AAAI"},
{"title": "Enhancing Long-and Short-Term Representations for Next POI Recommendations via Frequency and Hierarchical Contrastive Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Long-and Short-Term Representations for Next POI Recommendations via Frequency and Hierarchical Contrastive Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on next POI (Point of Interest) recommendations. That's about predicting where someone might go next, like in location-based services. The key parts here are \"Long-and Short-Term Representations,\" which makes me think of time-series data because they're considering both long-term and short-term patterns over time. Time-series analysis often deals with sequences of data points over time, which fits here since user check-ins or movements are sequential.\n\nThen there's \"Frequency and Hierarchical Contrastive Learning.\" Frequency might relate to how often certain POIs are visited, which could be part of time-series analysis. Hierarchical contrastive learning sounds like a method to learn representations at different levels, maybe temporal hierarchies. \n\nNow, checking the options. Time-series is a strong candidate here. Multimodal would involve combining different data types (like text and images), which isn't mentioned. RAG (Retrieval-Augmented Generation) is about using retrieval in generative models, which doesn't seem relevant. KG (Knowledge Graph) involves structured data and relationships, which also isn't directly mentioned. The paper is about sequential data and temporal representations, so time-series makes sense. I don't see any mention of knowledge graphs or retrieval-augmented generation. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33248@AAAI"}
{"title": "LLM-DR: A Novel LLM-Aided Diffusion Model for Rule Generation on Temporal Knowledge Graphs", "topic": "none", "raw_response": "<think>\nOkay, let's break down the title: \"LLM-DR: A Novel LLM-Aided Diffusion Model for Rule Generation on Temporal Knowledge Graphs.\" \n\nFirst, the key terms here are LLM (Large Language Model), Diffusion Model, Rule Generation, and Temporal Knowledge Graphs. The main focus seems to be on generating rules using a diffusion model that's aided by an LLM, specifically applied to temporal knowledge graphs.\n\nNow, looking at the possible topics: time-series, multimodal, RAG, KG. \n\nTime-series usually involves data over time, like stock prices or weather data. The title mentions \"Temporal Knowledge Graphs,\" which do involve time, but the primary focus here isn't on analyzing time-series data per se. It's more about the structure of the knowledge graph that changes over time.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so probably not this one.\n\nRAG (Retrieval-Augmented Generation) involves using retrieval mechanisms to enhance generation tasks. The paper uses an LLM, but the title doesn't specify retrieval, so maybe not RAG.\n\nKG stands for Knowledge Graphs. The title explicitly mentions \"Temporal Knowledge Graphs,\" which are a type of knowledge graph that includes time as a dimension. The research is about generating rules on these graphs, so this seems to fit under the KG topic. \n\nEven though there's a mention of time (temporal), the primary research area here is the application to knowledge graphs, making KG the correct category.\n</think>\n\nKG", "url": "https://papers.cool/venue/33249@AAAI"},
{"title": "DHMoE: Diffusion Generated Hierarchical Multi-Granular Expertise for Stock Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DHMoE: Diffusion Generated Hierarchical Multi-Granular Expertise for Stock Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the main focus here is stock prediction. Stock data is typically time-series data because it's collected over time with regular intervals. So maybe time-series? But let's check the other parts of the title. \n\nThe term \"Hierarchical Multi-Granular Expertise\" suggests that the model might be using different levels of granularity, which could relate to different time scales (like daily, weekly, monthly data). That still fits with time-series analysis. \n\nThe \"Diffusion Generated\" part might refer to a method of generating data, but I'm not sure if that's related to RAG (Retrieval-Augmented Generation) or something else. RAG usually involves retrieving information from a database and using it to augment the model's responses. Since the title doesn't mention retrieval or knowledge bases, maybe RAG isn't the right fit here.\n\nMultimodal usually involves combining different types of data, like text and images. The title doesn't mention different data modalities, so probably not multimodal. \n\nKG stands for Knowledge Graph, which is a structured representation of knowledge. The title doesn't mention anything about graphs or structured knowledge, so that's probably not it either.\n\nPutting it all together, the paper is about predicting stock prices using a hierarchical, multi-granular approach. Since stock data is time-series and the methods mentioned are about handling different time granularities, the topic is likely time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33250@AAAI"},
{"title": "Designing Specialized Two-Dimensional Graph Spectral Filters for Spatial-Temporal Graph Modeling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Designing Specialized Two-Dimensional Graph Spectral Filters for Spatial-Temporal Graph Modeling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatial-Temporal Graph Modeling\" suggests that the research involves both spatial and temporal aspects. So, time-series might be a possibility because of the temporal part. But time-series typically deals with data points indexed in time order, often without the spatial component. However, spatial-temporal data combines both, like traffic flow over time and across locations.\n\nNext, \"Graph Spectral Filters\" points to graph-based methods. Graphs are structures with nodes and edges, so this might relate to Knowledge Graphs (KG), which are a type of graph used to represent entities and their relationships. But the term \"KG\" usually refers to structured knowledge bases, while here it's about modeling spatial-temporal data using graphs. Maybe it's more about graph neural networks or graph signal processing rather than a knowledge graph specifically.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so probably not that. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generation models, which also doesn't seem relevant here.\n\nSo, the key terms are spatial-temporal and graph. The paper is about modeling data that has both spatial and temporal dimensions using graph structures. Time-series is a subset, but since it's specifically about spatial-temporal graphs, maybe it's more aligned with time-series if the focus is on the temporal aspect. However, the presence of \"graph\" might lean towards Knowledge Graphs (KG). But KGs are more about structured knowledge, not necessarily spatial-temporal modeling. \n\nWait, maybe the paper is using graph structures to model spatial-temporal data, which is a different approach. In that case, it's not exactly a Knowledge Graph. So perhaps the closest is time-series because of the temporal component, but the spatial aspect complicates it. However, the primary focus is on the graph modeling technique. Since none of the options perfectly fit, but the closest might be time-series if the temporal aspect is dominant. Alternatively, if the graph part is more about Knowledge Graphs, but I think KG is a stretch here. The answer might be none, but the options given are time-series, multimodal, RAG, KG. Since spatial-temporal graph modeling is a specific area, maybe it's not covered by any of these. But the user wants to choose from the four. Let me check again. The paper is about designing filters for spatial-temporal graphs. Time-series is about sequences over time. The paper's focus is on graph-based methods for spatial-temporal data. Since the options don't include graph neural networks or spatial-temporal specifically, maybe the answer is none. But the user might consider time-series if the temporal aspect is emphasized. However, the title mentions both spatial and temporal. Hmm. Maybe the answer is none because it's a specialized graph method not covered by the four topics. Alternatively, if the user thinks that spatial-temporal data is a type of time-series, then time-series. But I'm not sure. The safest answer might be none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33251@AAAI"},
{"title": "POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, POI stands for Points of Interest. The paper is about enhancing the representation learning of POIs using an LLM-based framework. The key terms here are \"semantic enhancement\" and \"representation learning.\" \n\nTime-series usually involves data over time, like stock prices or weather data. This title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so maybe not multimodal.\n\nRAG is Retrieval-Augmented Generation, which involves using retrieved information to enhance model outputs. The title mentions an LLM-based framework but doesn't specify retrieval or generation, so maybe not RAG.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge. The paper talks about semantic enhancement for POI representation. If they're integrating knowledge graphs to enhance the semantic information, that could fit. However, the title doesn't explicitly mention a knowledge graph. It just says \"semantic enhancement,\" which could be achieved through various methods, including LLMs without a KG. \n\nWait, the framework is called POI-Enhancer, which uses an LLM. If they're using a knowledge graph to provide additional semantic information to the POI representations, then it would be KG. But the title doesn't mention a knowledge graph. It's possible that the enhancement is done purely through the LLM's existing knowledge, which might not involve a KG. \n\nAlternatively, maybe the framework is building a knowledge graph for POIs. But again, the title doesn't specify that. The term \"semantic enhancement\" could be part of any method. Since the options are limited to the four given, and none of the other three seem to fit, maybe it's none. But wait, the user said if it doesn't belong to any, respond with \"none.\" \n\nBut let me double-check. The LLM-based approach could be part of RAG if they're retrieving information. However, RAG typically involves a retrieval step followed by generation. The title doesn't mention retrieval, so maybe not RAG. \n\nAlternatively, if the LLM is being used to generate enhanced representations by incorporating external knowledge, that might be RAG. But again, the title doesn't specify retrieval. \n\nSince the title doesn't mention time-series, multimodal, RAG, or KG explicitly, and the focus is on semantic enhancement via LLM for POI representation, it might not fit any of the four categories. So the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33252@AAAI"},
{"title": "Descriptive and Discriminative Document Identifiers for Generative Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Descriptive and Discriminative Document Identifiers for Generative Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Generative Retrieval\" makes me think of RAG, which stands for Retrieval-Augmented Generation. RAG is a method where a model retrieves relevant documents and then uses them to generate a response. So if the paper is about improving document retrieval for generative models, that's RAG. \n\nThe terms \"Descriptive and Discriminative Document Identifiers\" suggest they're working on how documents are identified or selected. In RAG, the retrieval part is crucial, so enhancing how documents are identified (maybe through better embeddings or identifiers) would be part of RAG research. \n\nMultimodal would involve multiple data types like text and images, but the title doesn't mention that. Time-series is about data over time, which isn't indicated here. KG is Knowledge Graphs, which structure data in graphs, but the title doesn't reference that either. \n\nSo the most likely topic here is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33253@AAAI"},
{"title": "In-context Prompt-augmented Micro-video Popularity Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"In-context Prompt-augmented Micro-video Popularity Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"In-context Prompt-augmented\" suggests that they're using some kind of prompting technique, maybe similar to how large language models use prompts. \"Micro-video\" refers to short videos, like TikTok or Instagram Reels. \"Popularity Prediction\" is about forecasting how popular these videos will be.\n\nNow, the possible topics. Time-series would involve data over time, like stock prices or weather. Multimodal usually means combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and then generates a response. KG is Knowledge Graph, which is a structured representation of information.\n\nThe paper's title mentions \"Prompt-augmented,\" which makes me think of RAG because RAG involves augmenting the model's input with retrieved information. However, \"In-context\" might refer to using in-context learning, which is a technique in prompting where the model uses examples within the input. But RAG specifically involves retrieval from a database. \n\nAlternatively, if they're combining different modalities (like video and text) for prediction, it could be multimodal. But the title doesn't explicitly mention multiple data types. The focus is on micro-video popularity, which could involve time-series data if they're analyzing trends over time. However, popularity prediction might not necessarily be time-series unless they're using historical data points over time. \n\nSince the title includes \"Prompt-augmented,\" which is a term often associated with RAG, especially in the context of using prompts to enhance model performance. So I'm leaning towards RAG. But I need to be careful. If the paper is about using prompts in a way that's part of RAG's methodology, then RAG would be the right choice. If it's just using prompts without retrieval, maybe it's not RAG. But given the options, RAG seems the closest fit here.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33254@AAAI"},
{"title": "No More Tuning: Prioritized Multi-Task Learning with Lagrangian Differential Multiplier Methods", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"No More Tuning: Prioritized Multi-Task Learning with Lagrangian Differential Multiplier Methods.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Prioritized Multi-Task Learning\" suggests that the paper is about handling multiple tasks simultaneously, with some prioritization. That part might relate to multimodal if the tasks involve different data types, but I'm not sure yet. The method mentioned is \"Lagrangian Differential Multiplier Methods,\" which sounds like an optimization technique. \n\nNow, looking at the four options. Time-series typically involves data over time, like stock prices or weather. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal usually refers to combining different types of data, like text and images. The paper's focus is on multi-task learning, which is about multiple tasks, not necessarily different modalities. So maybe not multimodal either. \n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. The title doesn't mention retrieval or generation, so probably not RAG. \n\nKG (Knowledge Graphs) involve structured data and relationships between entities. The title doesn't mention knowledge graphs or structured data, so that's out. \n\nSo the paper is about multi-task learning with a specific optimization method. None of the four topics directly match. The closest might be multimodal if multi-task implies different modalities, but the title doesn't specify that. Since the options are time-series, multimodal, RAG, or KG, and none fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33255@AAAI"},
{"title": "ALTBI: Constructing Improved Outlier Detection Models via Optimization of Inlier-Memorization Effect", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ALTBI: Constructing Improved Outlier Detection Models via Optimization of Inlier-Memorization Effect.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on outlier detection models. The method mentioned is optimizing the inlier-memorization effect. Outlier detection is a common problem in data analysis, but the question is about the specific research area this falls into.\n\nTime-series analysis deals with data points indexed in time order. If the paper was about detecting outliers in time-series data, it would fit under time-series. But the title doesn't mention time or sequences, so maybe not.\n\nMultimodal refers to combining multiple data modalities, like text and images. The title doesn't mention different data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generation, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper was about using or constructing knowledge graphs, it would fit here. But again, the title doesn't mention knowledge graphs or structured data.\n\nThe paper is about improving outlier detection by optimizing inlier memorization. This seems more like a general machine learning or data mining technique rather than one of the specified topics. Since none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33256@AAAI"},
{"title": "Unsupervised Anomaly Detection for Tabular Data Using Deep Noise Evaluation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unsupervised Anomaly Detection for Tabular Data Using Deep Noise Evaluation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on unsupervised anomaly detection for tabular data. The method mentioned is \"Deep Noise Evaluation.\" Now, the four options are time-series, multimodal, RAG (Retrieval-Augmented Generation), and KG (Knowledge Graphs).\n\nTime-series data involves data points indexed in time order. The title mentions tabular data, which is more general. Unless the tabular data is specifically time-series, like with timestamps, it might not fit here. The title doesn't mention time, so maybe not time-series.\n\nMultimodal refers to data that combines multiple modalities, like text and images. The title is about tabular data, which is a single modality. So probably not multimodal.\n\nRAG is a technique in NLP where a model retrieves information from a database to augment its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG, or Knowledge Graphs, are structured representations of knowledge. The paper's title doesn't mention anything about building or using a knowledge graph. The method is about deep noise evaluation, which sounds like a neural network approach for anomaly detection.\n\nSo, the paper is about anomaly detection in tabular data using a deep learning method. None of the four topics (time-series, multimodal, RAG, KG) seem to fit. The closest might be time-series if the data were time-based, but the title specifies tabular data without time context. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33257@AAAI"},
{"title": "GeoAggregator: An Efficient Transformer Model for Geo-Spatial Tabular Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GeoAggregator: An Efficient Transformer Model for Geo-Spatial Tabular Data.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in chronological order. The title mentions \"Geo-Spatial,\" which is about geographical data, but there's no mention of time here. So maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title talks about a transformer model for tabular data, but it's specifically geo-spatial. I don't see any indication of combining different data modalities here.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about a transformer model for geo-spatial data, which is tabular. There's no mention of building or using a knowledge graph here.\n\nSo none of the four topics seem to fit. The paper is about a transformer model for a specific type of data (geo-spatial tabular), but it doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33259@AAAI"}
{"title": "GeoAggregator: An Efficient Transformer Model for Geo-Spatial Tabular Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GeoAggregator: An Efficient Transformer Model for Geo-Spatial Tabular Data.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in chronological order. The title mentions \"Geo-Spatial,\" which is about geographical data, but there's no mention of time here. So maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title talks about a transformer model for tabular data, but it's specifically geo-spatial. I don't see any indication of combining different data modalities here.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper is about a transformer model for geo-spatial data, which is tabular. There's no mention of building or using a knowledge graph here.\n\nSo none of the four topics seem to fit. The paper is about a transformer model for a specific type of data (geo-spatial tabular), but it doesn't align with time-series, multimodal, RAG, or KG. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33259@AAAI"},
{"title": "Towards Global-Topology Relation Graph for Inductive Knowledge Graph Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Global-Topology Relation Graph for Inductive Knowledge Graph Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge Graph Completion\" immediately makes me think of Knowledge Graphs (KG). The term \"Inductive\" here might refer to inductive learning, which is common in machine learning tasks where the model generalizes from training data to unseen data. The \"Global-Topology Relation Graph\" part sounds like they're working on the structure or topology of the graph, which is a key aspect of knowledge graphs. \n\nTime-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time, so probably not that. Multimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data modalities. RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval from a database with generation models, often in NLP tasks. The title doesn't mention retrieval or generation, so RAG is out. \n\nSo the focus here is on completing a knowledge graph, which is about filling in missing links or relations in the graph. That's a classic problem in knowledge graph research. The mention of \"Global-Topology\" suggests they're looking at the overall structure of the graph, which is part of KG methods. Inductive completion would mean the model can handle new entities not seen during training, which is an important aspect in KG tasks. \n\nTherefore, the paper is about Knowledge Graph (KG) completion. The other options don't fit. The answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33260@AAAI"},
{"title": "On Finding Hubs in High Dimensions with Sampling", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"On Finding Hubs in High Dimensions with Sampling.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data points indexed in time order, like stock prices over time. The title doesn't mention anything about time or sequences, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title is about finding hubs in high-dimensional data using sampling. No mention of multiple modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The title doesn't seem related to retrieval or generation, so RAG is probably out.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's title is about finding hubs in high-dimensional data. Hubs might refer to central nodes in a network, but the term \"high dimensions\" makes me think of data in a high-dimensional space, maybe in machine learning or data analysis. If it's about hubs in a graph structure, maybe it's related to knowledge graphs. But the title doesn't explicitly mention graphs or knowledge. It just says \"hubs in high dimensions,\" which could be a different context, like in a dataset's feature space. \n\nAlternatively, \"hubs\" in a network context could relate to nodes with many connections, which is common in graph theory. If the paper is about identifying such hubs in high-dimensional data, maybe it's related to knowledge graphs. But without more context, it's a bit unclear. However, since the other options (time-series, multimodal, RAG) don't fit, and the title mentions hubs which could be nodes in a graph, maybe it's related to KG. But I'm not entirely sure. The term \"high dimensions\" might refer to the data's feature space rather than a graph structure. So perhaps it's none of the listed topics. Wait, the options are time-series, multimodal, RAG, KG. If the paper is about finding hubs in high-dimensional data using sampling, and none of the four topics directly relate to that, then the answer would be \"none.\" But maybe \"KG\" is a stretch. Let me think again. Knowledge Graphs are structured as graphs, so if the paper is about finding hubs (central nodes) in such a graph, then it would be KG. However, the title says \"high dimensions,\" which is more about the data's dimensionality rather than the graph's structure. So maybe it's not KG. Therefore, the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33261@AAAI"},
{"title": "Neural Reasoning for Sure Through Constructing Explainable Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Neural Reasoning for Sure Through Constructing Explainable Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Neural Reasoning\" suggests using neural networks for reasoning tasks. \"Explainable Models\" implies that the focus is on making the models' decisions understandable. Now, the options are time-series (which deals with sequential data over time), multimodal (combining multiple data types like text and images), RAG (Retrieval-Augmented Generation, which uses retrieval to enhance generation models), and KG (Knowledge Graphs, which are structured representations of knowledge).\n\nThe title doesn't mention anything about time or sequential data, so time-series is probably out. Multimodal would involve combining different modalities, but the title doesn't specify that. RAG is about using retrieval to augment generation, which isn't directly mentioned here. Knowledge Graphs (KG) are about structured knowledge, and if the paper is about constructing explainable models through reasoning, maybe they're using a knowledge graph to structure the reasoning process. However, the title doesn't explicitly mention KG. Alternatively, RAG could be a possibility if they're retrieving information to aid in reasoning, but again, the title doesn't specify retrieval. The key part is \"Constructing Explainable Models,\" which might relate to making the reasoning process transparent, which could be part of RAG or KG. But without more specific terms like \"retrieval\" or \"knowledge graph,\" it's hard to say. Since none of the terms in the title directly align with the four options, maybe the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33262@AAAI"},
{"title": "Active Large Language Model-Based Knowledge Distillation for Session-Based Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Active Large Language Model-Based Knowledge Distillation for Session-Based Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Active Large Language Model-Based Knowledge Distillation\" – knowledge distillation is a technique where a smaller model is trained to mimic a larger, more complex model. The mention of a large language model suggests it's using something like a transformer-based model. \"Session-Based Recommendation\" refers to recommending items based on a user's current session, which is a type of recommendation system that often deals with sequential data, like what a user is clicking on in real-time.\n\nNow, looking at the possible topics. Time-series would involve data that's ordered in time, which session-based recommendations might use since they track user interactions over a session. But the key here is whether the paper is specifically about time-series analysis. Multimodal would involve combining different types of data (like text and images), but the title doesn't mention multiple modalities. RAG stands for Retrieval-Augmented Generation, which combines retrieval of information with generation models. KG is Knowledge Graph, which involves structured data representations. \n\nThe paper uses knowledge distillation, which is a model compression technique, but the main focus here is on applying a large language model to session-based recommendations. Session-based recommendations often use sequential data, which is time-dependent, so time-series might be a fit. However, the term \"knowledge distillation\" doesn't directly relate to time-series. The paper isn't about retrieving information (RAG) or building a knowledge graph (KG). So the closest might be time-series if the session data is treated as a time series. But I'm not entirely sure. Wait, session-based recommendations can be modeled as sequences, which are time-ordered, so maybe time-series. But sometimes they use other methods like recurrent networks or transformers without explicitly being labeled as time-series research. Alternatively, if the paper is about using a language model (which is good at sequences) for session data, maybe it's more about the model application rather than the data type. Hmm. The options are time-series, multimodal, RAG, KG. Since the paper is about knowledge distillation in a recommendation system using a large language model, none of the four topics seem to directly fit. The main components here are knowledge distillation and session-based recommendations. The four options don't include recommendation systems or knowledge distillation. So maybe the answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33263@AAAI"},
{"title": "Global Attribute-Association Pattern Aggregation for Graph Fraud Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Global Attribute-Association Pattern Aggregation for Graph Fraud Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"Graph Fraud Detection.\" Graphs are often related to knowledge graphs (KG), which are structured representations of information. The other parts mention \"Attribute-Association Pattern Aggregation,\" which sounds like analyzing relationships between attributes in a graph structure. \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time, so probably not time-series. \n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generative models, often in NLP tasks. The title doesn't seem to involve retrieval or generation, so RAG is unlikely. \n\nKG (Knowledge Graph) is about structured data and relationships. Since the paper is about graph fraud detection and attribute associations, it's likely related to knowledge graphs. The term \"Graph\" in the title is a strong indicator here. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33264@AAAI"},
{"title": "Representation Space Augmentation for Effective Self-Supervised Learning on Tabular Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Representation Space Augmentation for Effective Self-Supervised Learning on Tabular Data.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"Representation Space Augmentation,\" \"Self-Supervised Learning,\" and \"Tabular Data.\" \n\nSelf-supervised learning is a type of machine learning where the model learns from the data itself without explicit labels. It's commonly used in areas like NLP and computer vision, but here it's applied to tabular data. Tabular data refers to structured data in rows and columns, like spreadsheets or databases. \n\nNow, looking at the four options. Time-series data involves data points indexed in time order, like stock prices over time. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal refers to data that combines multiple modalities, such as text and images. The title is about tabular data, which is a single modality, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generation, often used in NLP tasks. The title talks about augmentation in the representation space, but not specifically retrieval or generation. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on self-supervised learning and augmentation for tabular data, not on building or using knowledge graphs. \n\nSo, the paper is about enhancing self-supervised learning through representation space augmentation for tabular data. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The paper doesn't focus on time-series data, multimodal inputs, retrieval-augmented generation, or knowledge graphs. Therefore, the correct answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33265@AAAI"},
{"title": "BeFA: A General Behavior-driven Feature Adapter for Multimedia Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"BeFA: A General Behavior-driven Feature Adapter for Multimedia Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimedia Recommendation\" suggests that the system is dealing with multiple types of media, like text, images, videos, etc. That makes me think of multimodal, since multimodal systems handle different data types. The term \"Feature Adapter\" might be about combining features from different modalities. \n\nThen there's \"Behavior-driven,\" which could relate to user behavior data, maybe time-series data if it's tracking user actions over time. But the main focus here seems to be on adapting features for multimedia, which is more about combining different data types rather than temporal analysis. \n\nRAG (Retrieval-Augmented Generation) is typically about using retrieval to enhance generation models, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't directly relate to the title. \n\nSo, the key terms are \"Multimedia\" and \"Feature Adapter.\" Multimedia implies multiple modalities, so the topic is likely multimodal. The answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33266@AAAI"},
{"title": "Amplifier: Bringing Attention to Neglected Low-Energy Components in Time Series Forecasting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Amplifier: Bringing Attention to Neglected Low-Energy Components in Time Series Forecasting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Time Series Forecasting\" right there. That's a big hint. Time series forecasting is a subfield of time-series analysis, so that's a strong indicator. The other parts of the title talk about \"low-energy components\" and using attention mechanisms, which are common in deep learning models for time series. The word \"Amplifier\" in the title might refer to a model or method that enhances certain aspects of the time series data.\n\nNow, checking the other options. Multimodal usually involves combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge. None of these seem to fit the title's focus on time series forecasting. The paper is clearly about improving time series models by addressing neglected components, so the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33267@AAAI"},
{"title": "Entire-Space Variational Information Exploitation for Post-Click Conversion Rate Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Entire-Space Variational Information Exploitation for Post-Click Conversion Rate Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Post-click conversion rate prediction\" sounds like it's about predicting whether a user will convert after clicking on something, like an ad. That's a common problem in online advertising. Now, the method mentioned is \"Entire-Space Variational Information Exploitation.\" Variational methods are often used in probabilistic models, maybe for optimization or inference. \n\nLooking at the possible topics: time-series would involve data over time, like stock prices or sensor data. Multimodal would involve combining different types of data, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generative models, often in NLP. KG (Knowledge Graph) involves structured data and relationships between entities.\n\nThe title doesn't mention anything about time or temporal data, so probably not time-series. There's no indication of combining multiple modalities like text and images, so not multimodal. RAG and KG are more about knowledge and retrieval. The term \"variational\" might hint at a probabilistic approach, but the key part here is \"post-click conversion rate prediction.\" That's typically a problem in recommendation systems or online advertising, where they might use user behavior data. However, the specific methods mentioned don't align with RAG or KG. The paper seems focused on a variational method for exploiting information in the entire space, which might be a novel approach to the prediction problem. Since none of the four topics (time-series, multimodal, RAG, KG) are clearly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33268@AAAI"}
{"title": "Modeling Latent Non-Linear Dynamical System over Time Series", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Modeling Latent Non-Linear Dynamical System over Time Series.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Time Series\" is right there in the title. The main focus seems to be on modeling something over time series data. The other parts mention latent non-linear dynamical systems. That sounds like it's about understanding the underlying processes that generate the time series data. \n\nNow, looking at the options. Time-series is one of the options, so that's a strong candidate. The other options are multimodal (which involves combining different types of data like text and images), RAG (Retrieval-Augmented Generation, which is about using retrieval to enhance generation in models), and KG (Knowledge Graphs, which are structured representations of knowledge). \n\nThe paper's title doesn't mention anything about combining different data modalities, so multimodal is probably not it. RAG and KG are more about specific techniques or structures, and the title doesn't reference retrieval, generation, or knowledge graphs. The key term here is \"time series,\" so the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33269@AAAI"},
{"title": "Both Supply and Precision: Sample Debias and Ranking Consistency Joint Learning for Large Scale Pre-Ranking System", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Both Supply and Precision: Sample Debias and Ranking Consistency Joint Learning for Large Scale Pre-Ranking System.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main focus seems to be on a pre-ranking system, which is probably related to information retrieval or recommendation systems. The terms \"Sample Debias\" and \"Ranking Consistency\" suggest they're working on improving the ranking process by addressing biases in the samples and ensuring consistent rankings. \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or temporal data, so probably not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention different modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval and generation models, often used in NLP tasks. The paper here is about a pre-ranking system, which might be part of a retrieval process, but the title doesn't mention generation or augmentation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus on ranking and debiasing doesn't directly relate to knowledge graphs unless they're using a graph structure, but the title doesn't indicate that.\n\nSo, none of the four topics seem to fit. The paper is about improving ranking systems through debiasing and consistency, which is more related to machine learning or information retrieval, but not the specific topics listed. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33270@AAAI"},
{"title": "Spatial-Temporal Heterogenous Graph Contrastive Learning for Microservice Workload Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Spatial-Temporal Heterogenous Graph Contrastive Learning for Microservice Workload Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatial-Temporal\" suggests both spatial and temporal aspects, so time-series might be involved because of the temporal part. But the main focus here seems to be on a graph structure. \"Heterogenous Graph\" points to a Knowledge Graph (KG), since KGs often deal with heterogeneous data and complex relationships. The term \"Contrastive Learning\" is a method used in machine learning, but the key part here is the graph structure. \n\nMicroservice workload prediction involves forecasting workloads, which could be time-series data, but the approach here uses a graph-based model. So while there's a temporal element (spatial-temporal), the core technique is leveraging a graph, which aligns more with Knowledge Graphs. \n\nMultimodal would involve multiple data types like text, images, etc., which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which doesn't fit. Time-series is part of the problem (workload prediction over time), but the method is graph-based. So the primary topic here is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33271@AAAI"},
{"title": "Responsive Dynamic Graph Disentanglement for Metro Flow Forecasting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Responsive Dynamic Graph Disentanglement for Metro Flow Forecasting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Metro Flow Forecasting\" sounds like a time-series problem because forecasting usually involves predicting future values based on past data. But the key part here is \"Dynamic Graph Disentanglement.\" \n\nGraphs are related to Knowledge Graphs (KG), which are structured representations of information. The term \"Dynamic Graph\" might imply that the graph structure changes over time, which could be part of a time-series approach. However, the mention of \"Disentanglement\" suggests that the research is about separating different factors or components in the graph. \n\nRAG (Retrieval-Augmented Generation) is more about combining retrieval of information with generation models, which doesn't seem to fit here. Multimodal would involve combining different types of data (like text, images, etc.), but the title doesn't mention multiple modalities. \n\nSo, the focus on graphs and their dynamic nature points towards Knowledge Graphs (KG). Even though there's a time element in forecasting, the core method seems to be about graph disentanglement, which is a KG-related technique. Time-series is a possible aspect, but the primary topic here is the graph structure. Therefore, the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33272@AAAI"},
{"title": "Mixed-Curvature Multi-Modal Knowledge Graph Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Mixed-Curvature Multi-Modal Knowledge Graph Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge Graph Completion\" immediately makes me think of Knowledge Graphs (KG), which is one of the options. But there's also \"Multi-Modal\" mentioned. So, does that mean it's multimodal? But the main focus here is on completing a knowledge graph, which is a structured representation of entities and their relationships. The \"Multi-Modal\" part might refer to incorporating different types of data (like text, images, etc.) into the knowledge graph. However, the primary research area here is still knowledge graph completion. \n\nRAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, which doesn't seem to fit here. Time-series is about data over time, which isn't mentioned. So the key terms are \"Knowledge Graph\" and \"Completion,\" which points to KG as the main topic. Even though \"Multi-Modal\" is part of the title, the primary classification would still be under Knowledge Graphs. The mixed-curvature part might relate to the geometric approach used in the model, but that's a methodological detail. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33273@AAAI"},
{"title": "Behavior Importance-Aware Graph Neural Architecture Search for Cross-Domain Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Behavior Importance-Aware Graph Neural Architecture Search for Cross-Domain Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph Neural Architecture Search\" suggests that graph structures are involved. \"Cross-Domain Recommendation\" implies that it's about recommendation systems that work across different domains. The \"Behavior Importance-Aware\" part might refer to how user behaviors are weighted in the model.\n\nNow, looking at the options. Time-series would involve data over time, like sequences. Multimodal deals with multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which combines retrieval and generation models. KG stands for Knowledge Graph, which is a structured representation of knowledge using graphs.\n\nThe paper mentions \"Graph Neural Architecture,\" which points to using graph structures. Since KG is about knowledge graphs, which are a type of graph, this might be a fit. However, the term \"Graph Neural Architecture Search\" could also relate to using graph neural networks (GNNs) in neural architecture search. But the key here is whether it's specifically about knowledge graphs. The cross-domain aspect might involve transferring knowledge between domains, which could be modeled with a knowledge graph. The \"Behavior Importance-Aware\" part might be about how user interactions (like clicks, purchases) are represented in the graph. \n\nAlternatively, if the graph is used to model relationships between entities (like users, items, domains), that's a knowledge graph. So the paper is likely in the KG category. The other options don't fit: it's not time-series, not multimodal (unless combining different data types, but the title doesn't mention that), and not RAG. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33274@AAAI"},
{"title": "Multiple Purchase Chains with Negative Transfer Elimination for Multi-Behavior Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multiple Purchase Chains with Negative Transfer Elimination for Multi-Behavior Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multiple Purchase Chains\" suggests that there are sequences of purchases, which might relate to time-series data since purchases over time could form a sequence. But \"Multi-Behavior Recommendation\" makes me think about different user behaviors, like clicks, views, purchases, etc. That could be multimodal if they're combining different types of data. \n\nNegative Transfer Elimination is a term I've heard in transfer learning, where combining different tasks can sometimes hurt performance. So maybe they're dealing with multiple behaviors (tasks) and trying to prevent negative transfer. But how does that fit into the given topics? \n\nTime-series would involve data over time, which purchase chains might be. But the main focus here seems to be on handling multiple behaviors (like different types of user interactions) in a recommendation system. That sounds like multimodal because it's combining different data modalities (behaviors). \n\nRAG (Retrieval-Augmented Generation) is more about using retrieval to augment generation models, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't directly relate to purchase chains or multi-behavior. \n\nSo, the key terms are \"Multi-Behavior\" and \"Recommendation.\" Multi-behavior implies handling different types of user interactions, which are different data modalities. Therefore, the topic is likely multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33275@AAAI"},
{"title": "Identifying Predictions That Influence the Future: Detecting Performative Concept Drift in Data Streams", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Identifying Predictions That Influence the Future: Detecting Performative Concept Drift in Data Streams.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Data Streams\" makes me think of time-series data because data streams are often sequential and time-dependent. Then there's \"Performative Concept Drift,\" which sounds like changes in the data distribution over time that affect predictions. Concept drift is a common issue in time-series analysis where the underlying patterns change, so detecting that would be relevant here.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about multiple data types, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, often in NLP. The title doesn't seem to involve retrieval or generation. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't fit here.\n\nSo the main clues are \"data streams\" and \"concept drift,\" which are both related to time-series analysis. The paper is about detecting changes in data over time, which is a key aspect of time-series research. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33276@AAAI"},
{"title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on detecting semantic anomalies in business processes using large language models (LLMs). The key terms here are \"semantic anomalies,\" \"business processes,\" and \"large language models.\" \n\nTime-series analysis usually involves data points indexed in time order, like stock prices over time. The title doesn't mention anything about time or sequential data, so maybe not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The paper here is about using LLMs for business processes, but there's no indication of multiple data modalities being used. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and then generates a response. The title doesn't mention retrieval or generation, so RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper were about building or using a knowledge graph for anomaly detection, that would be relevant. However, the title mentions using LLMs, not knowledge graphs. \n\nThe paper is using LLMs to detect anomalies in business processes. Since none of the four topics (time-series, multimodal, RAG, KG) are explicitly mentioned or implied in the title, the answer might be \"none.\" But wait, maybe I'm missing something. Let me check again. The use of LLMs could be part of RAG if they're retrieving information, but the title doesn't specify that. It's more about detection using LLMs, which is a general application. Since none of the four topics are directly addressed, the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33277@AAAI"},
{"title": "K-ON: Stacking Knowledge on the Head Layer of Large Language Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"K-ON: Stacking Knowledge on the Head Layer of Large Language Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"K-ON\" probably stands for something related to knowledge. \"Stacking Knowledge\" suggests that they're adding or integrating knowledge into the model. The \"Head Layer of Large Language Model\" part is interesting. The head layer in a transformer model is usually the final part that produces the output, like the attention heads. So, modifying or stacking knowledge there might be about enhancing the model's knowledge base.\n\nNow, looking at the options. Time-series is about data over time, which doesn't seem related here. Multimodal involves combining different data types like text and images, but the title doesn't mention that. RAG is Retrieval-Augmented Generation, which uses external knowledge during generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's title mentions \"Stacking Knowledge,\" which could be related to integrating a knowledge graph into the model. If they're adding a knowledge graph structure to the head layer, that would be KG. Alternatively, if they're using retrieval methods to augment the model's knowledge, it might be RAG. But the term \"Stacking\" might imply a more structural integration rather than retrieval. Also, the mention of the \"Head Layer\" suggests modifying the model's architecture to incorporate knowledge, which aligns more with Knowledge Graphs (KG) as a structural component. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33278@AAAI"}
{"title": "GraphMoRE: Mitigating Topological Heterogeneity via Mixture of Riemannian Experts", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GraphMoRE: Mitigating Topological Heterogeneity via Mixture of Riemannian Experts.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"GraphMoRE\" probably stands for something related to graphs. \"Mitigating Topological Heterogeneity\" suggests dealing with differences in the structure of graphs, maybe in how nodes are connected. \"Mixture of Riemannian Experts\" – Riemannian geometry is a branch of mathematics dealing with curved spaces, which is often used in machine learning for handling data on manifolds. The term \"experts\" might refer to a model that combines multiple specialized models, like an ensemble method.\n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem to fit here. Multimodal usually refers to combining different types of data (like text and images), but the title doesn't mention different modalities. RAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, typically in NLP. KG is Knowledge Graphs, which are structured representations of knowledge, often using graph structures.\n\nThe paper's focus is on graphs and their topological properties. The mention of Riemannian geometry might relate to how the graph's structure is modeled in a geometric space. Since the title is about graphs and their topology, it seems related to Knowledge Graphs (KG), which are a type of graph used to represent entities and their relationships. However, the term \"Riemannian Experts\" might be a specific technique, but the main topic here is the graph structure. So, the most fitting category would be KG. I don't think it's RAG because that's more about retrieval and generation. Multimodal and time-series don't fit either. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33279@AAAI"},
{"title": "Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Traffic State\" and \"Trajectory\" are mentioned. Traffic state could involve data over time, like how traffic conditions change, which might be time-series. Trajectory data is also sequential, so that's another hint towards time-series. The dynamic road network suggests that the data is changing over time, which again points to time-series analysis. Representation learning here is about creating models that can capture the temporal dynamics of traffic and trajectories.\n\nMultimodal would involve combining different types of data, like text and images, but the title doesn't mention different modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which doesn't seem relevant here. KG (Knowledge Graphs) involve structured data and relationships, which also isn't mentioned. \n\nSo the key elements are traffic state (time-dependent data) and trajectory (sequential movement over time). The dynamic aspect reinforces the time-series nature. Therefore, the paper likely belongs to the time-series topic.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33280@AAAI"},
{"title": "Decomposed Spatio-Temporal Mamba for Long-Term Traffic Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Decomposed Spatio-Temporal Mamba for Long-Term Traffic Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatio-Temporal\" suggests that the model deals with both spatial and temporal data. That's a common term in time-series analysis, especially when dealing with data that has both location and time components, like traffic. \"Long-Term Traffic Prediction\" definitely sounds like a time-series problem because it's about forecasting future traffic conditions based on past data. \n\nNow, checking the other options. Multimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about multiple data types, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, often in NLP tasks. The title doesn't mention retrieval or generation, so RAG is out. KG (Knowledge Graph) involves structured data and relationships between entities. Again, the title doesn't hint at knowledge graphs. \n\nSo, the key terms here are \"Spatio-Temporal\" and \"Long-Term Prediction,\" which are classic in time-series analysis, especially in domains like traffic, weather, or any sequential data over time. The model might be using a specific architecture (Mamba) for handling these spatio-temporal patterns, but the core topic is time-series. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33281@AAAI"},
{"title": "MSR: A Multifaceted Self-Retrieval Framework for Microscopic Cascade Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MSR: A Multifaceted Self-Retrieval Framework for Microscopic Cascade Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multifaceted Self-Retrieval Framework\" – the term \"self-retrieval\" makes me think of RAG (Retrieval-Augmented Generation), which uses retrieval to augment model outputs. But RAG typically involves retrieving external documents or data. Here, \"self-retrieval\" might mean the model retrieves from its own previous outputs or internal data. \n\nThen, \"Microscopic Cascade Prediction.\" Cascade prediction could relate to time-series, as cascades often involve sequences of events over time. But the term \"microscopic\" might imply looking at detailed, possibly multi-dimensional data. However, the key part here is the \"self-retrieval\" framework. \n\nMultimodal usually involves combining different data types like text, images, audio. The title doesn't mention different modalities, so probably not that. KG (Knowledge Graph) involves structured data and relationships, which isn't directly indicated here. \n\nSo, the main focus seems to be on the retrieval aspect of the framework. Since RAG is about using retrieval to enhance generation, and the paper's title mentions a self-retrieval framework, it's likely related to RAG. Even though the application is cascade prediction, the core method is the retrieval part. Therefore, the answer should be RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33282@AAAI"},
{"title": "Modality-Independent Graph Neural Networks with Global Transformers for Multimodal Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Modality-Independent Graph Neural Networks with Global Transformers for Multimodal Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Recommendation\" immediately stands out. Multimodal usually refers to using multiple types of data or modalities, like text, images, audio, etc. So that's a hint towards the \"multimodal\" topic. \n\nThen there's \"Graph Neural Networks\" which makes me think of Knowledge Graphs (KG), since GNNs are often used in KGs for tasks like node classification or link prediction. But the title also mentions \"Global Transformers,\" which are a type of model architecture, maybe related to attention mechanisms. However, the key part here is \"Multimodal Recommendation,\" which is a strong indicator. \n\nRAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, typically in NLP tasks. The title doesn't mention anything about retrieval or generation, so probably not RAG. Time-series is about sequential data over time, which isn't mentioned here either. \n\nSo putting it all together, the main focus is on multimodal data for recommendation systems. Even though there's a mention of graph neural networks, the primary classification here would be multimodal because of the explicit mention in the title. The graph part might be a method used within the multimodal approach. Therefore, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33283@AAAI"},
{"title": "Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations with Large Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on knowledge-aware recommendations. The user-side knowledge gap probably refers to the lack of user knowledge that affects recommendations. They're using large language models to bridge this gap. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. The title doesn't mention anything about time, so probably not that. \n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data types, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate a response. The paper here is about recommendations using knowledge, but the title doesn't explicitly mention retrieval or generation. It's more about using knowledge to improve recommendations.\n\nKG is Knowledge Graph. Knowledge-aware recommendations often use knowledge graphs to incorporate structured knowledge. The title mentions \"knowledge-aware,\" which aligns with using a knowledge graph. The user-side knowledge gap might be addressed by integrating a knowledge graph to enhance the recommendation system's understanding of user preferences and item relationships.\n\nSo, the most likely topic here is KG (Knowledge Graph). The paper is about improving recommendations by addressing knowledge gaps using knowledge-aware methods, which typically involve knowledge graphs.\n</think>\n\nKG", "url": "https://papers.cool/venue/33284@AAAI"},
{"title": "Beyond Graph Convolution: Multimodal Recommendation with Topology-aware MLPs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Beyond Graph Convolution: Multimodal Recommendation with Topology-aware MLPs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Recommendation\" immediately makes me think of the \"multimodal\" topic. That's one of the options. But I should check the rest to be sure. \n\nThe part \"Beyond Graph Convolution\" suggests that the paper is moving past traditional graph convolution methods. Graph Convolution is often associated with Graph Neural Networks (GNNs), which are used in Knowledge Graphs (KG) tasks. So maybe it's related to KG? But the title mentions \"Topology-aware MLPs\" instead of GNNs. MLPs are Multi-Layer Perceptrons, which are standard neural networks. So they're using MLPs that are aware of the graph topology, which is a different approach from GNNs. \n\nBut the main focus here is on multimodal recommendation. The paper is combining multiple modalities (like text, images, etc.) for recommendations. That's a classic multimodal problem. The mention of topology-aware might relate to how the model handles the structure of the data (like a graph structure), but the key term here is \"multimodal.\" \n\nRAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to augment model outputs, which doesn't seem to be the case here. Time-series is about sequential data over time, which isn't mentioned. KG (Knowledge Graph) is about structured data and relationships, but the paper is about recommendation systems using multimodal data with a specific architecture. \n\nSo the primary topic here is multimodal. The paper is about multimodal recommendation systems, using a topology-aware MLP approach instead of graph convolutions. Therefore, the correct answer should be \"multimodal.\"\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33285@AAAI"},
{"title": "Future Sight and Tough Fights: Revolutionizing Sequential Recommendation with FENRec", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Future Sight and Tough Fights: Revolutionizing Sequential Recommendation with FENRec\". I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Sequential Recommendation\" is a key part here. Sequential recommendation systems are typically used in scenarios where the order of user interactions matters, like recommending the next item based on previous ones. That's a common problem in time-series data because the data is ordered over time. So maybe it's related to time-series.\n\nThen there's \"FENRec\". I'm not sure what that stands for, but the name might be an acronym. Maybe it's a new model or framework. The term \"sequential\" definitely points towards time-series analysis since time-series data is inherently sequential.\n\nMultimodal usually involves combining different types of data, like text and images. The title doesn't mention anything about multiple data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval and generation in models, often used in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper was about integrating knowledge graphs into recommendations, that would be a clue. But the title doesn't mention knowledge graphs either.\n\nSo putting it all together, the focus on sequential recommendation suggests that the research is about handling sequences of user interactions over time, which aligns with time-series analysis. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33287@AAAI"},
{"title": "Multiplex Graph Representation Learning with Homophily and Consistency", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multiplex Graph Representation Learning with Homophily and Consistency.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multiplex Graph\" suggests that the paper is dealing with graphs that have multiple layers or types of relationships. Graphs are often related to Knowledge Graphs (KG), which are structured representations of information. So maybe KG is a possibility here.\n\nThen \"Representation Learning\" is a common term in machine learning, especially in areas like graph neural networks. Homophily refers to the tendency of nodes to connect to similar nodes, which is a concept in graph theory. Consistency might relate to how the model maintains consistency across different layers or aspects of the graph.\n\nLooking at the options: Time-series deals with data over time, which doesn't seem to be the case here. Multimodal involves combining different data types like text and images, which isn't mentioned. RAG (Retrieval-Augmented Generation) is about using retrieval in generative models, which also doesn't fit. KG (Knowledge Graphs) is about structured data and graph representations, which aligns with the title's mention of multiplex graphs and representation learning. So the answer is likely KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33288@AAAI"},
{"title": "Event2Tracking: Reconstructing Multi-Agent Soccer Trajectories Using Long-Term Multimodal Context", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Event2Tracking: Reconstructing Multi-Agent Soccer Trajectories Using Long-Term Multimodal Context.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main task seems to be reconstructing trajectories in a soccer context, involving multiple agents (players). The key part here is \"Long-Term Multimodal Context.\" The word \"multimodal\" stands out. Multimodal usually refers to using multiple types of data, like combining visual, audio, or other sensor data. So if the paper is using different data modalities to track the agents, that would fall under multimodal.\n\nTime-series could be a possibility because tracking trajectories over time involves time-series data. But the question is whether the paper's main focus is on time-series analysis. The title mentions \"Long-Term,\" which might imply time, but the key term here is \"Multimodal Context.\" So maybe the primary contribution is integrating multiple data types rather than just analyzing time-series data.\n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to be directly mentioned. The title doesn't reference retrieval, generation, or knowledge graphs. So those can probably be ruled out.\n\nSo the most likely answer is multimodal. The paper uses multiple modalities (like video, audio, or other sensor data) to reconstruct trajectories, which aligns with the multimodal research topic.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33289@AAAI"}
{"title": "Event2Tracking: Reconstructing Multi-Agent Soccer Trajectories Using Long-Term Multimodal Context", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Event2Tracking: Reconstructing Multi-Agent Soccer Trajectories Using Long-Term Multimodal Context.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main task seems to be reconstructing trajectories in a soccer context, involving multiple agents (players). The key part here is \"Long-Term Multimodal Context.\" The word \"multimodal\" stands out. Multimodal usually refers to using multiple types of data, like combining visual, audio, or other sensor data. So if the paper is using different data modalities to track the agents, that would fall under multimodal.\n\nTime-series could be a possibility because tracking trajectories over time involves time-series data. But the question is whether the paper's main focus is on time-series analysis. The title mentions \"Long-Term,\" which might imply time, but the key term here is \"Multimodal Context.\" So maybe the primary contribution is integrating multiple data types rather than just analyzing time-series data.\n\nRAG (Retrieval-Augmented Generation) and KG (Knowledge Graphs) don't seem to be directly mentioned. The title doesn't reference retrieval, generation, or knowledge graphs. So those can probably be ruled out.\n\nSo the most likely answer is multimodal. The paper uses multiple modalities (like video, audio, or other sensor data) to reconstruct trajectories, which aligns with the multimodal research topic.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33289@AAAI"},
{"title": "Unaligned Message-Passing and Contextualized-Pretraining for Robust Geo-Entity Resolution", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unaligned Message-Passing and Contextualized-Pretraining for Robust Geo-Entity Resolution.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Geo-Entity Resolution\" probably refers to identifying geographical entities in text, like resolving mentions of places to specific locations. That might relate to knowledge graphs (KG) because KGs often store structured information about entities, including geographical ones. \n\n\"Unaligned Message-Passing\" sounds like a technique used in graph-based models, maybe in a knowledge graph setting where nodes (entities) pass messages to update their representations. Message passing is common in graph neural networks, which are used in KG tasks. \n\n\"Contextualized-Pretraining\" suggests using pre-trained models that consider context, like BERT or similar transformers. This is often used in NLP tasks, but how does it tie into the other parts? If they're pretraining for geo-entity resolution, maybe integrating contextual information into a knowledge graph structure.\n\nTime-series would involve data over time, which doesn't seem to be the case here. Multimodal would involve multiple data types like text and images, but the title doesn't mention that. RAG (Retrieval-Augmented Generation) combines retrieval from a corpus with generation, but the title doesn't mention retrieval or generation specifically. \n\nPutting it all together, the focus on message passing and geo-entity resolution points towards Knowledge Graphs (KG). The techniques mentioned are likely applied to enhance entity resolution within a KG framework. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33290@AAAI"},
{"title": "LEARN: Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LEARN: Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key terms here are \"Knowledge Adaptation,\" \"Large Language Model,\" \"Recommendation,\" and \"Industrial Application.\" The main idea seems to be about adapting knowledge from a large language model into a recommendation system. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. Multimodal usually refers to combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method that uses retrieval to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on transferring knowledge from a large language model to a recommendation system. That sounds like it's about using the knowledge from the LLM to improve recommendations. RAG involves using retrieval to augment generation, but here it's more about adapting knowledge for a specific application. Knowledge Graphs (KG) are about structured data, but the title doesn't mention graphs. The term \"Knowledge Adaptation\" might relate to transferring knowledge, which could be part of RAG if they're using retrieval. However, RAG specifically is about combining retrieval with generation. Alternatively, if they're building a knowledge graph from the LLM's knowledge, it might be KG. But the title doesn't mention graphs. The term \"Knowledge Adaptation\" could be a process that's part of RAG, where the model retrieves knowledge from the LLM. But I'm not entirely sure. Maybe it's more about using the LLM's knowledge in the recommendation system, which could be a form of RAG if they're retrieving information from the LLM. Alternatively, if they're creating a knowledge graph from the LLM's data, it would be KG. But the title doesn't specify a graph structure. Hmm. The key here is that the paper is about adapting knowledge from an LLM to a recommendation system. RAG is a method where you retrieve information from a knowledge base to augment the model's responses. If the paper is using the LLM as a source of knowledge for the recommendation system, that might align with RAG. But I'm not 100% certain. Alternatively, if they're creating a knowledge graph from the LLM's outputs, it would be KG. But the title doesn't mention a graph. The term \"Knowledge Adaptation\" is a bit vague. Maybe it's none of these? Wait, the options are time-series, multimodal, RAG, KG. The paper is about knowledge adaptation from LLM to recommendation. That seems more like RAG because RAG involves using external knowledge sources (like a retrieval system) to enhance the model's output. If they're adapting the LLM's knowledge into the recommendation system, that could be a form of RAG. Alternatively, if they're using the LLM's knowledge to build a knowledge graph for recommendations, it would be KG. But the title doesn't mention a graph. The key is the process of adapting knowledge from the LLM. RAG is about retrieval and generation, so maybe that's the fit here. I think the answer is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33291@AAAI"},
{"title": "Time Series Supplier Allocation via Deep Black-Litterman Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Time Series Supplier Allocation via Deep Black-Litterman Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Time Series\" right there. That's a strong indicator. The main focus seems to be on time series data since it's in the title. The method used is the Deep Black-Litterman Model, which I think is related to financial modeling or portfolio optimization. But the key part here is \"Time Series Supplier Allocation.\" So they're using time series data to allocate suppliers, probably over time. \n\nNow, checking the other options. Multimodal would involve multiple types of data, like combining text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about combining different data types, retrieval, or knowledge graphs. \n\nSo the most fitting category here is definitely time-series. The other options don't apply. The answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33292@AAAI"},
{"title": "Auto Encoding Neural Process for Multi-interest Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Auto Encoding Neural Process for Multi-interest Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Auto Encoding Neural Process\" sounds like it's using some kind of autoencoder, which is a type of neural network used for unsupervised learning. Then \"Multi-interest Recommendation\" suggests that the model is handling multiple user interests in a recommendation system.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather. The title doesn't mention anything about time, so maybe not. Multimodal usually refers to combining different data types, like text and images. The title doesn't mention different modalities, so that's probably not it either.\n\nRAG stands for Retrieval-Augmented Generation, which is used in models that combine retrieval of information with generating responses. That's more about combining retrieval with generation, which isn't directly mentioned here. KG is Knowledge Graph, which involves structured data and relationships between entities. The title doesn't mention knowledge graphs either.\n\nThe key part here is \"Multi-interest Recommendation.\" Recommendation systems often deal with user preferences, which can be modeled in various ways. The use of an autoencoder might be for learning user embeddings or latent representations. But none of the given topics directly relate to recommendation systems unless it's multimodal, but that's not the case here. Since the options are time-series, multimodal, RAG, or KG, and the paper is about a recommendation system using an autoencoder, it doesn't fit into any of these categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33293@AAAI"},
{"title": "HLMEA: Unsupervised Entity Alignment Based on Hybrid Language Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HLMEA: Unsupervised Entity Alignment Based on Hybrid Language Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Entity Alignment\" usually refers to matching entities across different knowledge bases or datasets. That makes me think of Knowledge Graphs (KG), because entity alignment is a common task in aligning entities between different KGs. \n\nThe term \"Hybrid Language Models\" might be a mix of different models or approaches. But the key here is \"Unsupervised Entity Alignment.\" Unsupervised methods don't require labeled data, which is common in KG tasks where you might not have explicit labels for entity pairs. \n\nNow, checking the options. Time-series deals with data over time, which doesn't seem relevant here. Multimodal involves multiple data types like text and images, but the title doesn't mention that. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which isn't directly mentioned either. \n\nKG (Knowledge Graphs) is about structured data and relationships between entities. Since entity alignment is a core problem in KGs, especially when integrating different knowledge bases, this seems like the best fit. The paper's focus on unsupervised methods for aligning entities using hybrid language models aligns with challenges in the KG domain. \n\nI don't see any mention of time-series data, multimodal inputs, or RAG techniques here. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33294@AAAI"},
{"title": "Bites of Tomorrow: Personalized Recommendations for a Healthier and Greener Plate", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Bites of Tomorrow: Personalized Recommendations for a Healthier and Greener Plate.\" I need to figure out which research topic this belongs to among time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time-based data, so maybe not that. \n\nMultimodal would involve combining different types of data, like text and images. The title talks about personalized recommendations, but there's no indication of using multiple data modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and then generates a response. If the paper is about generating personalized recommendations by retrieving relevant data, maybe RAG could be a fit. \n\nKG is Knowledge Graph, which involves structured data and relationships. If the recommendations are based on a knowledge graph of food items, nutrients, or environmental impact, that could be it. \n\nThe title mentions \"personalized recommendations\" for health and sustainability. Personalized recommendations often use user data, maybe combining different sources. If they're using a knowledge graph to structure the information about food and its impacts, that would make sense. Alternatively, if they're retrieving information from a database to generate recommendations, RAG might be involved. \n\nBut the key here is the specific terms. The paper's title doesn't explicitly mention time-series data, multimodal inputs, or RAG. The term \"personalized recommendations\" could be linked to a knowledge graph where entities like food items, dietary needs, environmental factors are connected. So I think KG is the most likely answer here. The other options don't fit as well. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33295@AAAI"},
{"title": "CasFT: Future Trend Modeling for Information Popularity Prediction with Dynamic Cues-Driven Diffusion Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CasFT: Future Trend Modeling for Information Popularity Prediction with Dynamic Cues-Driven Diffusion Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Future Trend Modeling\" suggests predicting how something will change over time. \"Information Popularity Prediction\" is about forecasting how popular information will be, which likely involves time-based data. \"Dynamic Cues-Driven Diffusion Models\" – diffusion models are often used in time-series for generating sequences or predicting future states. \n\nTime-series analysis deals with data points indexed in time order. Since the paper is about predicting future trends, that's a strong indicator of time-series. The other options: multimodal would involve multiple data types (like text and images), RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models, and KG is Knowledge Graphs, which structure information in graphs. The title doesn't mention anything about multiple modalities, retrieval, or knowledge graphs. So the most fitting topic here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33296@AAAI"},
{"title": "HePa: Heterogeneous Graph Prompting for All-Level Classification Tasks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HePa: Heterogeneous Graph Prompting for All-Level Classification Tasks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Heterogeneous Graph Prompting\" – the term \"graph\" makes me think of Knowledge Graphs (KG), which are a type of structured data representation. Heterogeneous graphs specifically refer to graphs with multiple types of nodes and edges, which is a concept often discussed in KG research. \n\nThe other parts of the title mention \"All-Level Classification Tasks,\" which is about applying the method to classification problems at different levels. But the key term here is \"graph,\" which points towards Knowledge Graphs. \n\nNow, checking the other options. Time-series deals with data over time, which isn't mentioned here. Multimodal involves combining different data types like text and images, which also doesn't fit. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, typically in NLP, which isn't the focus here. \n\nSo, the most likely topic is KG. The paper is about using a heterogeneous graph (KG) for prompting in classification tasks. Therefore, the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33297@AAAI"},
{"title": "Distribution-Driven Dense Retrieval: Modeling Many-to-One Query-Document Relationship", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Distribution-Driven Dense Retrieval: Modeling Many-to-One Query-Document Relationship.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Dense retrieval\" makes me think of information retrieval methods that use dense vector representations, like those in neural networks. \"Many-to-one query-document relationship\" suggests that a single query might relate to multiple documents, but the model is handling that mapping. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time, so probably not that. Multimodal usually refers to combining different types of data, like text and images. The title is about query and document relationships, which are both text, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation. That's a method where a model retrieves relevant documents and then uses them to generate a response. The title mentions \"dense retrieval,\" which is part of RAG systems. So this could be RAG. \n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention graphs or structured data, so probably not KG. \n\nSo the most likely answer is RAG. The paper is about improving retrieval methods, which is a key component of RAG models. The \"many-to-one\" part might refer to how queries can map to multiple documents, which RAG systems handle by retrieving the most relevant ones. Yeah, I think RAG is the right choice here.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33299@AAAI"}
{"title": "Distribution-Driven Dense Retrieval: Modeling Many-to-One Query-Document Relationship", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Distribution-Driven Dense Retrieval: Modeling Many-to-One Query-Document Relationship.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Dense retrieval\" makes me think of information retrieval methods that use dense vector representations, like those in neural networks. \"Many-to-one query-document relationship\" suggests that a single query might relate to multiple documents, but the model is handling that mapping. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time, so probably not that. Multimodal usually refers to combining different types of data, like text and images. The title is about query and document relationships, which are both text, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation. That's a method where a model retrieves relevant documents and then uses them to generate a response. The title mentions \"dense retrieval,\" which is part of RAG systems. So this could be RAG. \n\nKG is Knowledge Graphs, which are structured representations of information. The title doesn't mention graphs or structured data, so probably not KG. \n\nSo the most likely answer is RAG. The paper is about improving retrieval methods, which is a key component of RAG models. The \"many-to-one\" part might refer to how queries can map to multiple documents, which RAG systems handle by retrieving the most relevant ones. Yeah, I think RAG is the right choice here.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33299@AAAI"},
{"title": "ESPRESSO: An Effective Approach to Passage Retrieval for High-Quality Conversational Recommender Systems", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ESPRRESSO: An Effective Approach to Passage Retrieval for High-Quality Conversational Recommender Systems.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Passage Retrieval\" and \"Conversational Recommender Systems.\" Passage retrieval usually refers to fetching relevant passages from a document or database, which is a common task in information retrieval. Conversational recommender systems are systems that engage in dialogue to recommend items, like chatbots that suggest products based on user interactions.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather data. That doesn't seem relevant here. Multimodal typically involves combining different data types, like text and images. The title doesn't mention anything about multiple modalities, so maybe not that. \n\nRAG stands for Retrieval-Augmented Generation. That's a method where a model retrieves relevant documents and then uses them to generate a response. Since the paper is about passage retrieval for a recommender system, which is part of the retrieval process in RAG, this could be a fit. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper were using a graph structure or integrating knowledge bases, it might be KG. But the title doesn't mention graphs or structured data, just passage retrieval. \n\nSo, the main focus is on retrieving passages to enhance the conversational recommender system. That aligns with RAG, where retrieval is a key component. Therefore, the topic should be RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33300@AAAI"},
{"title": "HI-DR: Exploiting Health Status-Aware Attention and an EHR Graph+ for Effective Medication Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"HI-DR: Exploiting Health Status-Aware Attention and an EHR Graph+ for Effective Medication Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Health Status-Aware Attention\" might relate to how the model processes health data over time, maybe using attention mechanisms. But the key part here is \"EHR Graph+\". EHR stands for Electronic Health Records. The term \"Graph+\" suggests some kind of graph structure. So, they're using a graph-based approach for medication recommendation.\n\nNow, looking at the options. Time-series would involve data points indexed in time order, like patient data over time. Multimodal would involve combining different types of data (text, images, etc.). RAG is Retrieval-Augmented Generation, which is a method combining retrieval and generation models. KG is Knowledge Graph, which is a structured representation of information, often in graph form.\n\nThe paper mentions an \"EHR Graph+\", which sounds like a knowledge graph tailored for electronic health records. Knowledge Graphs (KG) are used to represent entities and their relationships, which fits here. The EHR data is structured into a graph, so the research is likely focused on leveraging that graph structure for medication recommendations. Therefore, the topic should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33301@AAAI"},
{"title": "Reverse Distribution Based Video Moment Retrieval for Effective Bias Elimination", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Reverse Distribution Based Video Moment Retrieval for Effective Bias Elimination.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Video Moment Retrieval\" suggests that the paper is about finding specific moments in a video. That could involve processing video data, which is a type of multimedia. So maybe multimodal? Because video is a combination of visual and audio data, which are different modalities. But I need to check if the paper's focus is on combining multiple modalities.\n\nThe term \"Reverse Distribution Based\" might refer to a method or technique used in the retrieval process. \"Bias Elimination\" is the goal here, so they're trying to reduce bias in the retrieval. But how does that tie into the four topics?\n\nTime-series usually deals with data points indexed in time order, like stock prices over time. Video is a time-series in a way, but the main focus here isn't just on temporal data analysis. The key part is the retrieval of moments, which might involve more than just time-series analysis.\n\nMultimodal would involve integrating different types of data, like text, images, and audio. If the video moment retrieval uses both visual and audio features, that's multimodal. But the title doesn't explicitly mention combining different modalities. It's possible, but not certain.\n\nRAG (Retrieval-Augmented Generation) is a method where a model retrieves relevant information from a database and uses it to generate responses. The title mentions \"retrieval,\" but the context here is about video moments, not generating text based on retrieved data. So maybe not RAG.\n\nKG (Knowledge Graph) involves structured data and relationships between entities. The title doesn't mention anything about knowledge graphs or structured data, so probably not KG.\n\nSo, the most likely candidate is multimodal if the video processing involves combining different modalities. However, the title doesn't explicitly state that. But video is inherently multimodal (video + audio), so maybe the research is about handling those modalities to retrieve moments effectively. The \"bias elimination\" part might relate to ensuring that the retrieval isn't biased towards certain modalities or features. \n\nAlternatively, if the paper is focused on the temporal aspect of video (since video is a time-series of frames), but the main topic here is retrieval, not just time-series analysis. The key term is \"video moment retrieval,\" which is more about information retrieval in a multimodal context. \n\nTherefore, I think the topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33302@AAAI"},
{"title": "Unlocking the Power of LSTM for Long Term Time Series Forecasting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Unlocking the Power of LSTM for Long Term Time Series Forecasting\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I need to break down the title. The key terms here are \"LSTM\" and \"Long Term Time Series Forecasting.\" LSTM stands for Long Short-Term Memory, which is a type of recurrent neural network (RNN) commonly used in time series analysis because it can capture long-term dependencies. The phrase \"Long Term Time Series Forecasting\" directly mentions time series, which is one of the options provided. \n\nNow, checking the other topics. Multimodal refers to combining multiple data types, like text and images, which isn't mentioned here. RAG is Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval, typically in NLP tasks. KG stands for Knowledge Graphs, which involve structured data representations, again not related to time series forecasting. \n\nThe title is clearly focused on using LSTM for forecasting in time series data. There's no indication of multimodal data, RAG, or knowledge graphs involved. So the correct topic here should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33303@AAAI"},
{"title": "Statistical Model-driven Similarity Hashing: Bridging Modalities for Efficient Unsupervised Retrieval", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Statistical Model-driven Similarity Hashing: Bridging Modalities for Efficient Unsupervised Retrieval.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Statistical Model-driven Similarity Hashing\" suggests they're using some statistical models to create similarity hashes. Then \"Bridging Modalities\" – the word \"modalities\" here is key. Modalities usually refer to different types of data, like text, images, audio, etc. So bridging them implies combining different data types, which points towards multimodal research. \n\nThe purpose is \"Efficient Unsupervised Retrieval.\" Unsupervised retrieval might mean they're not using labeled data, but the main focus here seems to be on handling multiple modalities. \n\nLooking at the options: time-series is about data over time, which doesn't seem to fit. RAG (Retrieval-Augmented Generation) is more about using retrieval to enhance generation models, like in NLP. KG (Knowledge Graphs) involves structured data and relationships. None of these seem to directly relate to bridging different data modalities. \n\nMultimodal is all about integrating multiple data types, so \"Bridging Modalities\" definitely aligns with that. The paper is likely about combining different modalities for retrieval, using hashing techniques. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33304@AAAI"},
{"title": "From Your Block to Our Block: How to Find Shared Structure Between Stochastic Block Models over Multiple Graphs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"From Your Block to Our Block: How to Find Shared Structure Between Stochastic Block Models over Multiple Graphs.\" Hmm. The key terms here are Stochastic Block Models and multiple graphs. \n\nStochastic Block Models (SBMs) are used in network analysis to detect communities or clusters within graphs. The paper is talking about finding shared structures between SBMs across multiple graphs. So, the focus is on comparing or aligning different graph structures using SBMs.\n\nNow, the possible topics are time-series, multimodal, RAG, or KG. Let's break them down. Time-series deals with data over time, which doesn't seem to fit here. Multimodal usually refers to combining different types of data (like text and images), but the title is about multiple graphs, not different data modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval, typically in NLP. That doesn't seem related to graph models. KG is Knowledge Graphs, which are structured representations of information, often using graphs. However, the paper is about stochastic block models and shared structures between multiple graphs, which is more about community detection and graph comparison rather than building or using knowledge graphs.\n\nSo, none of the listed topics (time-series, multimodal, RAG, KG) directly fit. The paper is about graph analysis and stochastic block models, which isn't one of the provided options. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33305@AAAI"},
{"title": "RouterRetriever: Routing over a Mixture of Expert Embedding Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RouterRetriever: Routing over a Mixture of Expert Embedding Models.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"RouterRetriever\" suggests some kind of routing mechanism in a retrieval system. \"Mixture of Expert Embedding Models\" implies that there are multiple expert models, each possibly handling different aspects or types of data. The routing part would decide which expert to use for a given query.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. Multimodal deals with multiple data types, like text and images. RAG stands for Retrieval-Augmented Generation, which combines retrieval from a database with generation models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus is on routing between different embedding models. Embedding models are used in various contexts, but the key here is the mixture of experts. RAG involves using retrieval to augment generation, but this seems more about selecting between different retrieval models. However, the term \"RouterRetriever\" might be part of a RAG system where different retrieval methods are used. Alternatively, if it's about combining different experts, maybe it's multimodal if the experts handle different modalities. But the title doesn't mention different data types like text, image, etc. It just says \"expert embedding models,\" which could be different models for the same modality. \n\nWait, RAG typically uses a retriever to get information from a corpus, and then a generator. If the RouterRetriever is part of the retrieval step, maybe it's part of RAG. But the mixture of experts could be a different approach. Alternatively, if the experts are different models for different tasks, maybe it's multimodal. But without more context, it's hard to say. However, the key term here is \"embedding models,\" which are common in RAG systems. The routing mechanism might be part of a RAG setup where different retrieval strategies are used. So I think the answer is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33306@AAAI"},
{"title": "Exploiting Fine-Grained Skip Behaviors for Micro-Video Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploiting Fine-Grained Skip Behaviors for Micro-Video Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on micro-video recommendations. The key part here is \"Fine-Grained Skip Behaviors.\" Skip behaviors might refer to how users skip through videos, maybe the timing or patterns of when they skip. That could relate to time-series data because it's about sequences of actions over time. \n\nBut wait, micro-video recommendations could also involve multiple modalities, like combining video content with user behavior data. However, the title specifically mentions \"skip behaviors,\" which are user interactions over time. Time-series analysis often deals with sequential data, so if the paper is analyzing how users skip through videos in a sequence, that's time-series. \n\nRAG (Retrieval-Augmented Generation) is more about combining retrieval with generation models, which doesn't seem to fit here. KG (Knowledge Graphs) involve structured data and relationships, which also doesn't directly relate to user behavior patterns in videos. \n\nMultimodal would involve combining different types of data, like text, images, and audio. The title doesn't mention different modalities, just user behavior. So the most likely topic here is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33307@AAAI"},
{"title": "Feature-Structure Adaptive Completion Graph Neural Network for Cold-start Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Feature-Structure Adaptive Completion Graph Neural Network for Cold-start Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph Neural Network\" immediately makes me think of Graphs, which is related to Knowledge Graphs (KG). But wait, the other options are RAG (Retrieval-Augmented Generation) and multimodal. Let me check each part.\n\n\"Cold-start Recommendation\" is a common problem in recommendation systems where new users or items have little data. GNNs are often used in recommendation systems, especially when dealing with user-item interactions, which can be modeled as graphs. So maybe KG here refers to Knowledge Graphs, which are structured representations of entities and relationships. But the title mentions \"Feature-Structure Adaptive Completion,\" which might be about adapting the graph structure based on features. \n\nRAG is more about combining retrieval and generation, typically in NLP tasks like question answering. Multimodal would involve combining different data types like text, images, audio. Time-series is about sequential data over time. \n\nThe paper's focus seems to be on using a graph neural network for recommendation, which is a type of structured data. So the most likely topic here is KG (Knowledge Graphs). Even though the title doesn't explicitly mention \"knowledge,\" the use of GNNs in recommendation systems often involves knowledge graphs. The other options don't fit as well. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33309@AAAI"}
{"title": "Feature-Structure Adaptive Completion Graph Neural Network for Cold-start Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Feature-Structure Adaptive Completion Graph Neural Network for Cold-start Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph Neural Network\" immediately makes me think of Graphs, which is related to Knowledge Graphs (KG). But wait, the other options are RAG (Retrieval-Augmented Generation) and multimodal. Let me check each part.\n\n\"Cold-start Recommendation\" is a common problem in recommendation systems where new users or items have little data. GNNs are often used in recommendation systems, especially when dealing with user-item interactions, which can be modeled as graphs. So maybe KG here refers to Knowledge Graphs, which are structured representations of entities and relationships. But the title mentions \"Feature-Structure Adaptive Completion,\" which might be about adapting the graph structure based on features. \n\nRAG is more about combining retrieval and generation, typically in NLP tasks like question answering. Multimodal would involve combining different data types like text, images, audio. Time-series is about sequential data over time. \n\nThe paper's focus seems to be on using a graph neural network for recommendation, which is a type of structured data. So the most likely topic here is KG (Knowledge Graphs). Even though the title doesn't explicitly mention \"knowledge,\" the use of GNNs in recommendation systems often involves knowledge graphs. The other options don't fit as well. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33309@AAAI"},
{"title": "ST-FiT: Inductive Spatial-Temporal Forecasting with Limited Training Data", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ST-FiT: Inductive Spatial-Temporal Forecasting with Limited Training Data.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatial-Temporal Forecasting\" suggests that the research involves both spatial (like location-based) and temporal (time-based) data. Forecasting usually refers to predicting future values based on past data, which is a common task in time-series analysis. So time-series seems like a strong candidate here.\n\nThe term \"inductive\" might refer to the model's ability to generalize to new, unseen data, which is important in time-series when dealing with limited training data. The mention of \"limited training data\" could imply that the method is designed to work efficiently with small datasets, which is a challenge in many machine learning areas, but particularly relevant in time-series where data might be scarce or expensive to collect.\n\nNow, checking the other options. Multimodal typically involves combining different types of data (like text, images, audio). The title doesn't mention anything about multiple data types, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms to enhance generation tasks, often in NLP. The title doesn't mention anything about retrieval or generation, so RAG is unlikely. KG (Knowledge Graphs) involve structured data representations, which again isn't indicated here.\n\nSo the most fitting topic is time-series. The paper is about forecasting in a spatial-temporal context, which is a subset of time-series analysis. The other topics don't align with the keywords in the title.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33310@AAAI"},
{"title": "Semantic Convergence: Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Semantic Convergence: Harmonizing Recommender Systems via Two-Stage Alignment and Behavioral Semantic Tokenization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus seems to be on recommender systems. The terms \"Semantic Convergence\" and \"Behavioral Semantic Tokenization\" suggest that they're dealing with semantics, maybe combining different data sources or modalities. The \"Two-Stage Alignment\" part might involve aligning different types of data or representations.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal refers to combining multiple types of data, like text and images. The paper talks about \"semantic tokenization\" and \"alignment,\" which could be about integrating different modalities. For example, aligning user behavior data (maybe text or actions) with semantic information. That sounds like multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG (Knowledge Graphs) involve structured data and relationships. If the paper was about building or using a knowledge graph for recommendations, that would fit. But the title mentions \"alignment\" and \"tokenization,\" which might be more about integrating different data sources rather than structured knowledge graphs.\n\nSo, the most likely is multimodal. The paper is probably combining different data types (like user behavior and semantic features) in a recommender system, which aligns with multimodal approaches.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33311@AAAI"},
{"title": "DisCo: Graph-Based Disentangled Contrastive Learning for Cold-Start Cross-Domain Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DisCo: Graph-Based Disentangled Contrastive Learning for Cold-Start Cross-Domain Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph-Based\" makes me think of Knowledge Graphs (KG), since graphs are often used in KGs. But wait, there's also \"Contrastive Learning,\" which is a machine learning technique. The term \"Disentangled\" might relate to separating different factors in the data. \"Cold-Start Cross-Domain Recommendation\" refers to recommendation systems where there's a lack of user or item data (cold-start) and the system needs to work across different domains.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. The title doesn't mention time, so probably not that. Multimodal usually involves combining different data types, like text and images. The title doesn't mention multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, often in NLP. The title doesn't mention retrieval or generation. \n\nKG (Knowledge Graph) is about structured data in graph form. The paper uses a graph-based approach, which aligns with KG. However, the main focus here is on contrastive learning for recommendations. But the graph-based part might be using a knowledge graph structure. Alternatively, maybe it's using a graph neural network, which is different from a knowledge graph. Wait, the problem is cross-domain recommendation, which often uses knowledge graphs to link different domains. So maybe the graph here is part of a knowledge graph. \n\nAlternatively, the graph could be a user-item interaction graph. But the term \"graph-based\" in the context of cross-domain recommendation might be using a knowledge graph to transfer knowledge between domains. So the key here is whether the graph is part of a knowledge graph. If the paper is using a knowledge graph to model the cross-domain relationships, then it's KG. If it's just using a graph structure for the model, maybe not. But the title doesn't specify. However, given the options, the most likely is KG. The other options don't fit. So the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33312@AAAI"},
{"title": "Contrastive Representation for Interactive Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Contrastive Representation for Interactive Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Contrastive Representation\" refers to a method where models learn by contrasting positive and negative examples. This is common in self-supervised learning. \"Interactive Recommendation\" suggests that the system is making recommendations based on user interactions, like clicks or purchases, which are sequential in nature.\n\nNow, looking at the options. Time-series deals with data over time, which could fit if the interactions are sequential. But the key here is the contrastive learning part. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which doesn't seem directly related. KG (Knowledge Graph) involves structured data and relationships, which also doesn't fit. Multimodal is about combining different data types like text and images, which isn't mentioned here.\n\nWait, but interactive recommendation might involve user-item interactions over time, which could be time-series. However, the main focus here is on the contrastive representation method. But the question is about the research topic the paper belongs to. If the paper is about using contrastive learning for recommendations, does that fall under time-series? Or is it a different area altogether?\n\nAlternatively, maybe it's not any of the four. The four options are time-series, multimodal, RAG, KG. The paper's focus is on contrastive learning in the context of interactive recommendations. Since none of the four topics directly relate to contrastive learning or interactive recommendations, maybe the answer is \"none.\" But wait, interactive recommendations often use sequential data, which is time-series. However, the primary method here is contrastive representation, which isn't one of the listed topics. So the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33313@AAAI"},
{"title": "Disentangled Contrastive Bundle Recommendation with Conditional Diffusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Disentangled Contrastive Bundle Recommendation with Conditional Diffusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Bundle Recommendation\" makes me think of recommendation systems. But the options given don't include recommendation systems directly. The four topics are time-series, multimodal, RAG, and KG. \n\n\"Disentangled Contrastive\" might refer to methods in machine learning where they separate different factors of variation. \"Conditional Diffusion\" could be a type of generative model, maybe using diffusion processes. But how does this relate to the given topics?\n\nTime-series is about data over time, like stock prices or weather. The title doesn't mention time or sequences, so probably not time-series.\n\nMultimodal usually involves combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval to enhance generative models. The title doesn't mention retrieval or generation, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. If the paper uses a knowledge graph for recommendations, maybe. But the title doesn't explicitly mention a knowledge graph. \"Bundle Recommendation\" could use a KG if it's leveraging structured data, but the title's focus seems more on the contrastive learning and diffusion aspects.\n\nAlternatively, maybe it's none of these. The paper might be about recommendation systems using contrastive learning and diffusion models, which are separate from the four topics listed. Since the options are time-series, multimodal, RAG, KG, and the title doesn't clearly fit any of those, the answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33314@AAAI"},
{"title": "Public Opinion Field Effect and Hawkes Process Join Hands for Information Popularity Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Public Opinion Field Effect and Hawkes Process Join Hands for Information Popularity Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, I'll break down the title. \"Public Opinion Field Effect\" sounds like it's about how public opinion spreads or influences things. Then \"Hawkes Process\" is a term I remember from time-series analysis. Hawkes processes are used to model events that trigger other events over time, like how one news story might lead to more related stories or social media posts. So that part is definitely related to time-series modeling because it's about temporal patterns and dependencies.\n\nThe phrase \"Join Hands for Information Popularity Prediction\" suggests combining these two concepts to predict how popular information becomes. The main focus here seems to be on modeling the spread and popularity over time, which is a temporal aspect. \n\nNow, looking at the options: time-series is about data over time, which fits the Hawkes process part. Multimodal would involve multiple types of data (like text and images), but the title doesn't mention different data types. RAG (Retrieval-Augmented Generation) is about using retrieval methods in generative models, which isn't mentioned here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem to be the case here. \n\nSo the key element here is the Hawkes process, which is a time-series model. Therefore, the paper likely falls under the time-series topic.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33315@AAAI"},
{"title": "Self-Explainable Graph Transformer for Link Sign Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Self-Explainable Graph Transformer for Link Sign Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph Transformer\" suggests that the model is working with graph-structured data. Transformers are a type of neural network architecture, so combining that with graphs might relate to knowledge graphs (KG) since they often represent information as graphs with nodes and edges. \n\nThen, \"Link Sign Prediction\" is a task where the model predicts the sign (positive or negative) of a link between two nodes in a graph. This is a common problem in signed network analysis, which is often studied in the context of knowledge graphs. For example, in social networks, predicting whether a relationship is positive or negative.\n\nThe term \"Self-Explainable\" might indicate that the model provides explanations for its predictions, which is a feature in some KG-related models to enhance transparency. \n\nLooking at the options: time-series deals with sequential data over time, which doesn't seem to fit here. Multimodal involves combining different data types like text and images, which isn't mentioned. RAG (Retrieval-Augmented Generation) is about using retrieval systems to augment model outputs, typically in NLP tasks. KG (Knowledge Graphs) involves structured data representation and reasoning, which aligns with graph-based models and link prediction tasks.\n\nSo, the paper is about a graph-based model for link sign prediction, which is a task in knowledge graphs. Therefore, the correct topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33316@AAAI"},
{"title": "Adaptive Dataset Quantization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title \"Adaptive Dataset Quantization\" and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. If it doesn't fit any, I should respond with \"none\".\n\nFirst, I need to understand what each of these topics entails. \n\nTime-series research typically deals with data points indexed in chronological order. Examples include stock prices over time or weather data. The key here is the temporal aspect.\n\nMultimodal refers to the integration of multiple data types, like combining text, images, and audio. Research in this area might focus on how to effectively process and combine different modalities for tasks like video analysis or cross-modal retrieval.\n\nRAG stands for Retrieval-Augmented Generation. This is a method where a model uses a retrieval component to fetch relevant information from a database and then generates a response based on that. It's commonly used in question-answering systems to enhance the model's knowledge with up-to-date or specific data.\n\nKG stands for Knowledge Graphs, which are structured representations of knowledge, often in the form of triples (subject-predicate-object). Research here might involve constructing, querying, or utilizing knowledge graphs for various applications like recommendation systems or semantic search.\n\nNow, looking at the title \"Adaptive Dataset Quantization\". Quantization usually refers to the process of reducing the precision of data, often to compress models or datasets. Adaptive quantization would mean adjusting the quantization parameters dynamically based on certain criteria. \n\nThe term \"dataset\" suggests that the focus is on the data itself rather than a model or a specific application. Quantization in this context might be about optimizing storage, reducing data size, or improving efficiency in data processing. \n\nDoes this relate to time-series? If the dataset is time-series data, maybe. But the title doesn't specify the data type, so it's too vague. \n\nMultimodal? If the dataset combines different modalities, but again, the title doesn't mention that. \n\nRAG? Quantization of a dataset might be part of optimizing the retrieval component, but RAG is more about combining retrieval and generation. Unless the quantization is specifically for the retrieval part, but the title doesn't indicate that.\n\nKG? If the dataset is a knowledge graph, then quantizing it could be relevant. But again, the title doesn't specify that the dataset is a knowledge graph. \n\nSince the title is very general and doesn't mention any of the specific aspects of time-series, multimodal, RAG, or KG, it's likely that the paper is about data compression or optimization techniques for datasets in general. Therefore, it doesn't fit into any of the four specified topics. The answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33317@AAAI"},
{"title": "Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge Graph Completion\" immediately makes me think of Knowledge Graphs (KG), since that's a common term in that area. The paper is about completing a knowledge graph, which involves predicting missing links or entities. Then there's \"inductive,\" which in machine learning terms usually refers to models that can generalize to unseen data, as opposed to transductive models. \n\n\"Context-aware\" suggests that the model takes into account the surrounding context when making predictions. \"Latent Type Constraints\" might refer to using hidden or inferred types of entities or relations to impose constraints during the completion process. \"Subgraph Reasoning\" implies that the model uses reasoning over subgraphs, which are parts of the knowledge graph, to make inferences.\n\nLooking at the options: time-series deals with data over time, which doesn't seem relevant here. Multimodal involves combining different data types like text and images, which isn't mentioned. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which also doesn't fit. The key term here is \"Knowledge Graph,\" so the topic should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33318@AAAI"}
{"title": "Context-aware Graph Neural Network for Graph-based Fraud Detection with Extremely Limited Labels", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Context-aware Graph Neural Network for Graph-based Fraud Detection with Extremely Limited Labels.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The main components are \"Graph Neural Network\" and \"Graph-based Fraud Detection.\" The term \"Graph\" here is key. Graph Neural Networks (GNNs) are a type of neural network designed to work with graph-structured data. So, the paper is using GNNs for fraud detection, which is a common application in graph-based machine learning.\n\nNow, looking at the options. The four topics are time-series, multimodal, RAG, and KG. Let's consider each:\n\n- Time-series: This involves data points indexed in time order. The title doesn't mention anything about time or sequences, so probably not this one.\n- Multimodal: This refers to combining multiple types of data (like text, images, audio). The title doesn't mention multiple data sources, so maybe not.\n- RAG (Retrieval-Augmented Generation): This is a method that combines retrieval of information with generation, often used in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n- KG (Knowledge Graph): Knowledge Graphs are structured representations of knowledge, often using graphs. The paper uses a graph neural network, which is related to graph structures. However, the term \"Knowledge Graph\" is more specific. The paper is about fraud detection using graphs, which could be a general graph structure rather than a knowledge graph. But the mention of \"Graph Neural Network\" might still align with KG if the graph is a knowledge graph. However, the title doesn't explicitly mention knowledge graphs. The term \"graph-based\" is more general. So maybe it's not KG either.\n\nWait, but the options are time-series, multimodal, RAG, or KG. The paper is about a graph neural network applied to fraud detection. The key here is whether \"KG\" refers to Knowledge Graphs. If the graph in the paper is a Knowledge Graph, then it would be under KG. But the title doesn't specify that. It just says \"graph-based,\" which could be any graph structure, not necessarily a knowledge graph. So maybe it's not KG. Then, none of the four topics fit? But the options are to choose between those four or none. The paper is about graph neural networks, which is a type of model, but the topics given are research areas. The four topics are time-series, multimodal, RAG, KG. Since the paper is about graph-based methods, but the options don't include a general graph topic, unless KG is considered. But without explicit mention of knowledge graphs, maybe it's none. Wait, but the user might consider \"KG\" as any graph-related work. However, typically, KG refers specifically to knowledge graphs. So if the paper is using a general graph structure (like a transaction graph for fraud detection), it's not a knowledge graph. Therefore, the answer would be none. But wait, the user's options include KG. Let me check again. The title says \"Graph Neural Network for Graph-based Fraud Detection.\" So the model is a GNN, applied to a graph structure. The research topic here is graph-based methods, but the given options are time-series, multimodal, RAG, KG. Since KG is Knowledge Graphs, and the paper isn't about knowledge graphs specifically, the answer would be none. But maybe I'm missing something. Alternatively, maybe the user considers any graph-related work under KG. But that's not standard. So the correct answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33319@AAAI"},
{"title": "Structure Balance and Gradient Matching-Based Signed Graph Condensation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Structure Balance and Gradient Matching-Based Signed Graph Condensation.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Signed Graph Condensation\" makes me think of graph structures, maybe something related to knowledge graphs (KG) since they often use graphs. But wait, \"Structure Balance\" and \"Gradient Matching\" might be techniques used in the process. \n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, usually in NLP. That doesn't seem to fit here. \n\nMultimodal research involves combining different data types like text, images, audio. The title doesn't mention anything about multiple modalities, so probably not that. \n\nTime-series is about data over time, sequences. The title doesn't mention time or sequences, so probably not that either. \n\nSo, the remaining options are KG or maybe RAG. But RAG is more about retrieval and generation. The term \"Signed Graph\" makes me think of signed networks, which are a type of graph where edges have positive or negative signs. This is often studied in social network analysis, and knowledge graphs can have such structures. So, this might be related to Knowledge Graphs (KG). \n\nBut wait, the paper is about condensing a signed graph. Condensation here might refer to summarizing or compressing the graph structure. Techniques like structure balance and gradient matching could be methods to achieve this condensation. Since knowledge graphs often deal with structured data and relationships, this seems plausible. \n\nI don't see any direct mention of RAG components like retrieval or generation. So, the most likely topic here is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33320@AAAI"},
{"title": "SSL-STMFormer Self-Supervised Learning Spatio-Temporal Entanglement Transformer for Traffic Flow Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SSL-STMFormer Self-Supervised Learning Spatio-Temporal Entanglement Transformer for Traffic Flow Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Self-Supervised Learning\" (SSL) is a method, so that's part of the approach. Then \"Spatio-Temporal Entanglement Transformer\" suggests that the model deals with both spatial and temporal data. Traffic flow prediction is the application here. \n\nTime-series analysis involves data points indexed in time order. Since traffic flow is inherently time-dependent, this seems like a time-series problem. The mention of \"Spatio-Temporal\" adds that it's considering both spatial (like different locations on a road network) and temporal (time-based) aspects. So, even though it's spatio-temporal, the core of the problem is still time-series prediction. \n\nMultimodal would involve combining different types of data (like text, images, audio), but the title doesn't mention different data types. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in models, which isn't indicated here. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem relevant. \n\nTherefore, the paper is focused on time-series analysis for traffic flow prediction using a spatio-temporal model. So the correct topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33321@AAAI"},
{"title": "Enhancing Healthcare Recommendations: A Privacy-Protective and Interpretable Cross-Domain Framework", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Healthcare Recommendations: A Privacy-Protective and Interpretable Cross-Domain Framework.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time-based data, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like text and images. The title talks about healthcare recommendations, but there's no indication of combining different data modalities. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when you use a retrieval system to get information and then generate a response, often in NLP tasks. The title mentions a framework for recommendations, but I don't see any mention of retrieval or generation processes. So maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of information. If the paper uses a knowledge graph to enhance recommendations, that would fit. The term \"cross-domain\" might imply using a structured knowledge base to transfer knowledge between domains. Also, \"interpretable\" could be a feature of a knowledge graph, as they can provide explainable paths. So maybe KG?\n\nBut wait, the title doesn't explicitly mention knowledge graphs. It's about a cross-domain framework with privacy and interpretability. Could it be using a knowledge graph without stating it? Or maybe it's a different approach. Since the options are limited to the four, and none of the others seem to fit, I'll go with KG. Alternatively, if it's none, but I think KG is the closest possible fit here.\n</think>\n\nKG", "url": "https://papers.cool/venue/33322@AAAI"},
{"title": "Iterative Sparse Attention for Long-sequence Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Iterative Sparse Attention for Long-sequence Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Long-sequence Recommendation\" suggests that the paper is about recommendation systems that handle long sequences. Recommendation systems often deal with user interactions over time, like what a user has clicked on or purchased in the past. So that might relate to time-series data, which involves sequences of data points over time.\n\nThen there's \"Iterative Sparse Attention.\" Attention mechanisms are common in models that process sequences, like in transformers. Sparse attention might refer to a method where the model focuses on only a subset of the sequence elements, which is useful for long sequences to reduce computational load. The iterative part could mean that the attention is applied in multiple steps or layers.\n\nNow, looking at the possible topics. Time-series is about data over time, which fits if the sequences are temporal. Multimodal would involve combining different data types, like text and images, which doesn't seem to be the case here. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation models, which is more about combining retrieval with generation, not directly related to sequences in recommendations. KG (Knowledge Graph) involves structured data and relationships, which also doesn't seem to fit unless the paper is using a knowledge graph for recommendations, but the title doesn't mention that.\n\nSo, the key elements are long sequences and attention mechanisms in a recommendation system. Since recommendation systems often model user behavior over time (like click history, purchase history), the sequences here are likely time-series data. Therefore, the topic would be time-series. The other topics don't align as closely with the title's components.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33323@AAAI"},
{"title": "Exploring the Relationship Between Samples and Masks for Robust Defect Localization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Exploring the Relationship Between Samples and Masks for Robust Defect Localization.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like combining text and images. The title talks about samples and masks. Masks could be related to image processing, maybe in computer vision, but there's no mention of combining different modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is about using retrieval systems to enhance generative models. The title doesn't mention anything about retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't seem to involve knowledge graphs either.\n\nThe paper is about defect localization, which is often in computer vision, like finding defects in images. The relationship between samples and masks might involve segmentation masks or something similar. But none of the given topics directly relate to computer vision or defect detection. The options are time-series, multimodal, RAG, KG. Since none of these fit, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33324@AAAI"},
{"title": "Unified Graph Neural Networks Pre-training for Multi-domain Graphs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unified Graph Neural Networks Pre-training for Multi-domain Graphs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph Neural Networks\" immediately makes me think of graph structures. GNNs are used for data that can be represented as graphs, like social networks, molecular structures, etc. The term \"pre-training\" suggests that it's about training models in a general way before applying them to specific tasks, which is common in transfer learning.\n\nNow, the options are time-series, multimodal, RAG, or KG. Let's go through each. Time-series deals with data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series.\n\nMultimodal refers to combining multiple types of data, like text and images. The title mentions \"multi-domain,\" which could be similar, but \"domain\" here might refer to different types of graphs rather than different data modalities. Not sure yet.\n\nRAG stands for Retrieval-Augmented Generation, which is a method combining retrieval from a database with generation models, often used in NLP. The title doesn't mention retrieval or generation, so probably not RAG.\n\nKG is Knowledge Graphs. Knowledge Graphs are structured representations of knowledge, often in graph form. The paper is about pre-training GNNs for multi-domain graphs. Since knowledge graphs are a type of graph structure, and the paper is about training GNNs which are used in KGs, this seems like a fit. The term \"multi-domain\" might imply that the model can handle various types of knowledge graphs from different domains.\n\nSo, putting it all together: the paper is about pre-training GNNs for graphs in different domains, which aligns with Knowledge Graphs (KG) as a research topic. The other options don't fit as well. The answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33325@AAAI"},
{"title": "Distribution-Consistency-Guided Multi-modal Hashing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Distribution-Consistency-Guided Multi-modal Hashing.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-modal\" is right there in the title. That immediately makes me think the topic is multimodal. But let me check the other parts to be sure. The term \"hashing\" suggests it's about creating hash codes, which is a method used in information retrieval and data compression. The \"Distribution-Consistency-Guided\" part probably refers to ensuring that the distribution of the data is consistent across different modalities when hashing. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time, so probably not that. RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generative models, often in NLP. The title doesn't mention generation or retrieval in that context. KG is Knowledge Graphs, which are structured representations of knowledge. Again, the title doesn't mention anything about knowledge graphs. \n\nSo the key term here is \"Multi-modal,\" which directly matches one of the options. Even though the rest of the title talks about hashing and distribution consistency, the presence of \"multi-modal\" makes it clear. The paper is about handling multiple data modalities (like text, images, audio) together, which is the definition of multimodal research. Therefore, the correct topic is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33326@AAAI"},
{"title": "LLMEmb: Large Language Model Can Be a Good Embedding Generator for Sequential Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LLMEmb: Large Language Model Can Be a Good Embedding Generator for Sequential Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. It mentions a Large Language Model (LLM) being used as an embedding generator for sequential recommendation. Sequential recommendation usually involves predicting the next item in a sequence based on previous interactions, which is a common task in recommendation systems. That part makes me think of time-series data because the sequence of user interactions over time is a key aspect here. Time-series analysis deals with data points indexed in time order, so sequential recommendations fit into that category.\n\nNow, checking the other options. Multimodal refers to combining multiple types of data (like text, images, audio), but the title doesn't mention anything about different data modalities. RAG (Retrieval-Augmented Generation) is a method that combines retrieval of documents with generation, often used in question-answering systems. The title doesn't mention retrieval or generation in that context. KG (Knowledge Graph) involves structured data representations, which also isn't mentioned here.\n\nThe key part here is \"sequential recommendation,\" which is a time-dependent process. The use of embeddings generated by an LLM for this purpose still falls under the broader umbrella of time-series analysis because the sequence's temporal aspect is crucial. So the correct topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33327@AAAI"},
{"title": "Personalized Federated Learning for Spatio-Temporal Forecasting: A Dual Semantic Alignment-Based Contrastive Approach", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Personalized Federated Learning for Spatio-Temporal Forecasting: A Dual Semantic Alignment-Based Contrastive Approach.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. \"Spatio-Temporal Forecasting\" immediately makes me think of time-series data because forecasting over time is a key aspect. Spatio-temporal implies both spatial and temporal dimensions, so time-series is definitely part of it. But the question is whether the paper's main topic is time-series. The other parts mention federated learning and a contrastive approach with dual semantic alignment. \n\nFederated learning is a machine learning technique where models are trained across decentralized data sources, but that's more about the learning framework rather than the data type. The \"dual semantic alignment\" part might relate to aligning different data sources or modalities, but the main focus here is on forecasting, which is a time-series task. \n\nMultimodal would involve combining different types of data (like text, images, audio), but the title doesn't mention different modalities. RAG (Retrieval-Augmented Generation) is about using retrieval mechanisms in generation tasks, which isn't mentioned here. KG (Knowledge Graphs) involve structured data representations, which also don't seem to be the focus. \n\nSo, the core of the paper is spatio-temporal forecasting, which is a subset of time-series analysis. Even though there's federated learning and alignment techniques, the primary research topic here is time-series. The other elements are methods or approaches applied to the time-series problem. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33328@AAAI"}
{"title": "Coherency Improved Explainable Recommendation via Large Language Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Coherency Improved Explainable Recommendation via Large Language Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to using multiple types of data, like text and images. The title talks about recommendations and using a large language model, but there's no mention of combining different data modalities. So maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The title mentions a large language model, which could be part of RAG, but the key part here is \"explainable recommendation.\" RAG is more about enhancing generation with retrieved data. Not sure yet.\n\nKG is Knowledge Graph. If the paper uses a structured knowledge base to improve recommendations, that would fit. But the title doesn't mention knowledge graphs explicitly. It says \"coherency improved\" and \"explainable,\" which might relate to making the recommendations more logical and understandable, possibly using some form of reasoning. However, without explicit mention of a knowledge graph or structured data, it's a stretch.\n\nThe main focus here is on making recommendations more explainable using a large language model. RAG could be involved if they're retrieving information to generate explanations. But the term \"RAG\" isn't in the title. Alternatively, maybe it's about improving the coherency of explanations, which might not directly map to any of the four categories. Since the options are time-series, multimodal, RAG, or KG, and none of these seem to fit perfectly, the answer might be \"none.\" But wait, maybe RAG is a possibility. If the model is using retrieval to generate explanations, that's RAG. However, the title doesn't specify retrieval. It just says \"via large language model.\" So maybe it's not RAG. Therefore, the correct answer is \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33329@AAAI"},
{"title": "Effective and Efficient Representation Learning for Flight Trajectories", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Effective and Efficient Representation Learning for Flight Trajectories.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Representation Learning\" suggests they're trying to create models that can represent data in a useful way. \"Flight Trajectories\" refers to the paths that aircraft take over time. So, the data here is probably sequences of positions, altitudes, speeds, etc., over time. That makes me think of time-series data because each trajectory is a sequence of data points over time. Time-series analysis often deals with sequential data where the order and timing matter, which fits flight paths.\n\nNow, checking the other options. Multimodal would involve combining different types of data, like text and images, but the title doesn't mention multiple data types. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem relevant here. KG (Knowledge Graph) involves structured data and relationships between entities, which also doesn't directly relate to flight trajectories. \n\nSo, the most likely topic here is time-series. The focus is on learning representations from sequential data (flight trajectories), which is a classic time-series problem. The efficiency and effectiveness part might relate to how well the model handles the temporal aspects and processes the data efficiently, which are common concerns in time-series research.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33330@AAAI"},
{"title": "THGNets: Constrained Temporal Hypergraphs and Graph Neural Networks in Hyperbolic Space for Information Diffusion Prediction", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"THGNets: Constrained Temporal Hypergraphs and Graph Neural Networks in Hyperbolic Space for Information Diffusion Prediction.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Constrained Temporal Hypergraphs\" – temporal suggests time-related, so maybe time-series? But hypergraphs are a type of graph structure where edges can connect more than two nodes. Then \"Graph Neural Networks\" – that's a common term in knowledge graphs (KG) and maybe RAG (Retrieval-Augmented Generation), but RAG is more about combining retrieval with generation models. \n\nThe hyperbolic space part is interesting. Hyperbolic geometry is often used in embedding hierarchical data, which is common in knowledge graphs. But the main focus here seems to be on modeling information diffusion, which is about how information spreads over time. So maybe time-series? But time-series typically deals with sequences of data points over time, like stock prices or weather. \n\nWait, the paper uses temporal hypergraphs and GNNs in hyperbolic space. Hypergraphs can model complex relationships, and temporal aspects imply time. But the key here is the application to information diffusion prediction. Information diffusion is about how information spreads through a network over time, which is a dynamic process. So maybe time-series? But time-series analysis usually doesn't involve graph structures. Alternatively, knowledge graphs (KG) often model entities and their relationships, which can be static or dynamic. If the paper is using hypergraphs (a type of graph structure) in hyperbolic space for this purpose, it might be related to knowledge graphs, especially if they're modeling entities and their evolving relationships over time. \n\nRAG is about using retrieval systems to augment generation models, which doesn't seem to fit here. Multimodal would involve combining different data types like text, images, etc., which isn't mentioned. So between time-series and KG. The temporal aspect is there, but the use of hypergraphs and GNNs in hyperbolic space leans more towards knowledge graphs, especially since hyperbolic embeddings are used in KGs for hierarchical data. However, the problem is information diffusion prediction, which is a dynamic process. Maybe the temporal hypergraphs are used to model the time-evolving structure of the network, which is part of the knowledge graph's dynamic aspect. \n\nAlternatively, time-series could be a fit if the focus is on predicting future states based on past data. But the mention of hypergraphs and hyperbolic space suggests a more structured approach, which is common in KGs. So I'm leaning towards KG here. But I'm not entirely sure. Let me check again. The paper's title includes \"Graph Neural Networks\" and \"Hyperbolic Space,\" which are techniques used in knowledge graph embeddings and modeling. So the topic is likely KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33331@AAAI"},
{"title": "Attack-in-the-Chain: Bootstrapping Large Language Models for Attacks Against Black-Box Neural Ranking Models", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Attack-in-the-Chain: Bootstrapping Large Language Models for Attacks Against Black-Box Neural Ranking Models.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on using large language models (LLMs) to perform attacks on black-box neural ranking models. The term \"bootstrapping\" here probably refers to using the LLMs to generate data or examples that can be used to attack the target models. \n\nNow, looking at the four options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time-based data, so probably not that. \n\nMultimodal usually refers to combining different types of data, like text and images. The paper's title doesn't mention different data modalities, so maybe not multimodal either.\n\nRAG stands for Retrieval-Augmented Generation. That's when a model uses a retrieval system to get information and then generates a response. The paper here is about attacking models, not about enhancing generation with retrieval. So RAG might not be the right fit.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about building or using knowledge graphs, so that's probably not it either.\n\nThe paper is about adversarial attacks using LLMs. None of the four topics directly relate to adversarial attacks or security in this context. The options given are time-series, multimodal, RAG, or KG. Since the paper's focus is on attacks against models, which isn't covered by any of these four categories, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33332@AAAI"},
{"title": "Direct Routing Gradient (DRGrad): A Personalized Information Surgery for Multi-Task Learning (MTL) Recommendations", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Direct Routing Gradient (DRGrad): A Personalized Information Surgery for Multi-Task Learning (MTL) Recommendations.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. The main focus seems to be on Multi-Task Learning (MTL) in the context of recommendations. The method proposed is called DRGrad, which is a personalized information surgery approach. \n\nTime-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time or sequential data, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The title doesn't mention different data modalities, so maybe not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of information with generation, often used in NLP. The title doesn't mention retrieval or generation, so RAG might not fit here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs or structured data, so that's probably not it either.\n\nThe paper is about Multi-Task Learning in recommendations, focusing on personalized information routing. Since none of the four topics (time-series, multimodal, RAG, KG) are directly mentioned or implied in the title, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33333@AAAI"},
{"title": "CoRA: Collaborative Information Perception by Large Language Model’s Weights for Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CoRA: Collaborative Information Perception by Large Language Model’s Weights for Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Collaborative Information Perception\" sounds like it's about combining information, maybe from different sources. \"Large Language Model’s Weights\" suggests they're using a pre-trained language model and maybe adjusting its weights. \"For Recommendation\" indicates the application is in recommendation systems.\n\nNow, the options. Time-series would involve data over time, like stock prices or weather. Multimodal usually refers to combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieval to enhance model outputs. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper uses a large language model's weights for collaborative filtering in recommendations. That doesn't seem to involve time-series data. It's not about combining different modalities like text and images, so probably not multimodal. RAG involves retrieval, but the title doesn't mention retrieval. It's about using the model's weights for collaborative perception, which might be more about how the model processes information for recommendations. Knowledge Graphs are structured data, but the title doesn't mention graphs. So maybe none of these topics fit. Wait, but maybe RAG? If they're using retrieval, but the title says \"weights,\" which might be more about model parameters. Hmm. I think it's none of the listed topics. The main focus is on recommendation systems using collaborative information and LLM weights, which doesn't align with the four options given.\n</think>\n\nnone", "url": "https://papers.cool/venue/33334@AAAI"},
{"title": "RDPI: A Refine Diffusion Probability Generation Method for Spatiotemporal Data Imputation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"RDPI: A Refine Diffusion Probability Generation Method for Spatiotemporal Data Imputation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatiotemporal Data Imputation\" refers to filling in missing data that has both spatial and temporal components. So, that's data that varies over space and time. Time-series data is a subset of spatiotemporal, but spatiotemporal includes both spatial and temporal aspects. The method mentioned is a diffusion probability generation method, which sounds like a technique for generating data, maybe using diffusion models. \n\nNow, looking at the options. Time-series is about data over time. Multimodal involves multiple types of data (like text and images). RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on imputing missing data in spatiotemporal datasets. The method uses diffusion probability, which is a type of generative model. Since the data is spatiotemporal, it's definitely involving time, so time-series might be a candidate. However, spatiotemporal is broader than just time-series. But the question is whether it fits into one of the four given topics. The other options don't seem to fit. It's not multimodal (no mention of combining different data types), not RAG (no retrieval involved), and not KG (no knowledge graph structure). So the closest would be time-series, even though spatiotemporal is more than just time. The key here is that the data has a temporal component, so time-series is the best fit among the options provided.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33335@AAAI"},
{"title": "SIGMA: Selective Gated Mamba for Sequential Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"SIGMA: Selective Gated Mamba for Sequential Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Sequential Recommendation\" immediately makes me think of time-series data because recommendations often involve sequences of user interactions over time. Like, what a user has clicked on before to predict what they might like next. So that's a time-series aspect.\n\nThen there's \"Selective Gated Mamba.\" Mamba is a type of model architecture, right? I remember that Mamba is a state-space model designed for handling sequential data efficiently. It's used in time-series tasks because it can process sequences with long-range dependencies more effectively than traditional RNNs or Transformers. The \"gated\" part might refer to mechanisms that control the flow of information, which is common in models like LSTMs or GRUs, but here it's part of the Mamba architecture.\n\nThe term \"Selective\" could imply that the model is choosing which parts of the sequence to focus on, which is a common technique in time-series analysis to improve efficiency or accuracy. \n\nNow, checking the other options. Multimodal would involve combining different types of data, like text and images, but the title doesn't mention anything about multiple modalities. RAG (Retrieval-Augmented Generation) is about using retrieval systems to augment generative models, which isn't indicated here. KG (Knowledge Graph) involves structured data and relationships between entities, which also doesn't seem to be the case here.\n\nSo putting it all together, the paper is about a model (SIGMA) for sequential recommendation using a Mamba-based architecture with gating mechanisms. Since sequential recommendation is a time-series problem and Mamba is a time-series model, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33336@AAAI"},
{"title": "Revisiting Multimodal Fusion for 3D Anomaly Detection from an Architectural Perspective", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. The title is \"Revisiting Multimodal Fusion for 3D Anomaly Detection from an Architectural Perspective.\" \n\nFirst, I need to break down the title. The key terms here are \"Multimodal Fusion\" and \"3D Anomaly Detection.\" The word \"Multimodal\" immediately stands out. Multimodal typically refers to the integration of multiple data modalities, like combining text, images, audio, etc. So if the paper is about multimodal fusion, that would directly point to the \"multimodal\" topic.\n\nNext, the other parts of the title: \"3D Anomaly Detection\" and \"Architectural Perspective.\" The 3D aspect might relate to spatial data, but the main focus here is on how different modalities are fused. The architectural perspective suggests they're looking at the structure or design of the model, but that doesn't necessarily change the primary topic. \n\nLooking at the other options: time-series would involve data over time, like sequences or temporal data. The title doesn't mention anything about time, so probably not that. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which isn't mentioned here. KG (Knowledge Graphs) involves structured data and relationships, which also doesn't seem relevant. \n\nSo the most fitting category here is \"multimodal\" because the title explicitly mentions multimodal fusion. The other parts of the title don't conflict with that. Therefore, the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33337@AAAI"},
{"title": "EPERM: An Evidence Path Enhanced Reasoning Model for Knowledge Graph Question and Answering", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EPERM: An Evidence Path Enhanced Reasoning Model for Knowledge Graph Question and Answering.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key parts here are \"Knowledge Graph\" and \"Question and Answering.\" The model is called EPERM, which stands for Evidence Path Enhanced Reasoning Model. The mention of \"Knowledge Graph\" immediately makes me think of the KG topic. Knowledge Graphs are structured representations of information, often used in tasks like question answering where relationships between entities are important.\n\nNow, checking the other options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences over time, so probably not that. Multimodal usually refers to combining different types of data, like text and images. The title doesn't mention multiple data modalities. RAG stands for Retrieval-Augmented Generation, which is a method that combines retrieval of documents with generation of answers. While the paper is about question answering, the title specifically mentions \"Knowledge Graph,\" which is more aligned with KG than RAG. RAG typically uses a corpus of documents rather than a structured knowledge graph. \n\nSo, the main focus here is on enhancing reasoning using evidence paths within a knowledge graph for QA. Therefore, the correct topic should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33338@AAAI"}
{"title": "Densest k-Subgraph Mining via a Provably Tight Relaxation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Densest k-Subgraph Mining via a Provably Tight Relaxation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Densest k-Subgraph Mining\" sounds like a graph theory problem. The densest subgraph is a concept in graph algorithms where you look for a subset of nodes with the highest density of edges. The \"k\" here probably refers to the size of the subgraph, so it's about finding the densest subgraph with exactly k nodes. \n\nThe method mentioned is \"Provably Tight Relaxation,\" which suggests they're using some mathematical relaxation technique to solve the problem. Now, the four options are time-series, multimodal, RAG, and KG. \n\nTime-series analysis deals with data over time, like stock prices or weather data. Multimodal refers to combining different types of data, like text and images. RAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. KG is Knowledge Graph, which is a structured representation of information, often using graphs to represent entities and their relationships.\n\nThe paper's title is about finding a dense subgraph, which is a graph problem. Knowledge Graphs (KG) are a type of graph structure, so if this research is about analyzing or mining subgraphs within a knowledge graph, it might fit under KG. However, the title doesn't explicitly mention knowledge graphs. It's more about a general graph mining problem. RAG is about retrieval in NLP, which doesn't seem related. Time-series and multimodal are unrelated here. \n\nSo, the closest might be KG if the context is about knowledge graphs, but the title itself doesn't specify that. The problem is general graph mining. Since the options are only these four, and the paper's title doesn't mention any of the other three topics, maybe it doesn't fit any. But wait, the user is asking if it belongs to one of these four. If the paper is about mining subgraphs in a knowledge graph, then it's KG. But without explicit mention, it's hard to say. However, the term \"densest k-subgraph\" is a standard graph problem, not necessarily tied to knowledge graphs. So perhaps it doesn't belong to any of the four topics listed. Therefore, the answer would be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33339@AAAI"},
{"title": "One for Dozens: Adaptive REcommendation for All Domains with Counterfactual Augmentation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"One for Dozens: Adaptive REcommendation for All Domains with Counterfactual Augmentation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Adaptive REcommendation\" suggests it's about recommendation systems. The mention of \"All Domains\" might imply that it's trying to work across different types of data or contexts. \"Counterfactual Augmentation\" is a term I'm not super familiar with, but I think it relates to generating synthetic data by considering what would happen under different scenarios, which is used in machine learning to improve model robustness.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather. Multimodal deals with combining different data types, like text and images. RAG stands for Retrieval-Augmented Generation, which is about using retrieval methods to enhance generative models. KG is Knowledge Graphs, which are structured representations of information.\n\nThe paper's focus seems to be on recommendation systems using counterfactual methods. None of the four topics directly relate to recommendation systems. RAG is about retrieval and generation, which is different. KG could be related if they're using knowledge graphs for recommendations, but the title doesn't mention that. The key terms here are \"adaptive recommendation\" and \"counterfactual augmentation,\" which don't align with the listed topics. So, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33340@AAAI"},
{"title": "Enhancing Sequential Recommendation with Global Diffusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Sequential Recommendation with Global Diffusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Sequential Recommendation\" usually refers to recommendation systems that take into account the sequence of user interactions over time. That's a common area in time-series analysis because the data is ordered in time. So maybe time-series is a candidate.\n\n\"Global Diffusion\" – diffusion here might relate to how information spreads through a network. In the context of recommendation systems, this could involve graph structures or knowledge graphs (KG), where nodes represent items or users and edges represent relationships. If they're using a graph-based approach to model the diffusion process, that would point towards Knowledge Graphs (KG).\n\nBut wait, could it be multimodal? Multimodal typically involves combining different types of data, like text, images, and audio. The title doesn't mention different data modalities, so probably not multimodal.\n\nRAG (Retrieval-Augmented Generation) is about using retrieval methods to augment generative models, often in NLP tasks. The title doesn't mention anything about retrieval or generation, so RAG is probably not it.\n\nSo the main contenders are time-series and KG. The sequential aspect points to time-series, but the \"global diffusion\" part might be using a graph-based method, which is part of KG. However, in recommendation systems, sequential models often use time-series data, but if they're enhancing it with a diffusion process on a graph, that's more about the structure of the data, which is a Knowledge Graph. So maybe KG is the right answer here. But I'm a bit torn because sequential recommendation is a time-series problem. However, the enhancement with global diffusion might be using a graph-based approach, which is part of KG. I think the key is the \"global diffusion\" part. If they're using a graph to model the diffusion, then it's KG. If they're just using time-series methods, then it's time-series. The title says \"enhancing\" sequential recommendation with global diffusion, which suggests adding a graph-based component. So the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33341@AAAI"},
{"title": "FairGP: A Scalable and Fair Graph Transformer Using Graph Partitioning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"FairGP: A Scalable and Fair Graph Transformer Using Graph Partitioning.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Graph Transformer\" suggests it's related to graph structures. The term \"Graph\" here is key. Then \"Graph Partitioning\" is mentioned, which is a technique used in graph theory to divide a graph into parts. Now, the options given are time-series, multimodal, RAG, and KG. \n\nTime-series usually deals with data points indexed in time order. Multimodal involves combining different data types like text, images, etc. RAG stands for Retrieval-Augmented Generation, which is about enhancing models with external information retrieval. KG is Knowledge Graph, which is a structured representation of knowledge, often using graphs.\n\nThe paper's focus is on a graph transformer with fairness and scalability, using graph partitioning. Since it's about graphs and their processing, the closest match would be Knowledge Graphs (KG). But wait, RAG is about retrieval and generation, which doesn't seem to fit here. The paper isn't about combining different modalities, so multimodal is out. Time-series is unrelated. So, the answer should be KG. But I need to make sure. The term \"Graph Transformer\" is more about graph neural networks, which are used in various applications, including knowledge graphs. So yes, KG is the right category here.\n</think>\n\nKG", "url": "https://papers.cool/venue/33342@AAAI"},
{"title": "Dynamic Multi-Interest Graph Neural Network for Session-Based Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Dynamic Multi-Interest Graph Neural Network for Session-Based Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Dynamic\" might suggest something related to time, but not sure yet. \"Multi-Interest\" could imply handling multiple aspects or modalities, but again, not certain. \"Graph Neural Network\" definitely makes me think of Knowledge Graphs (KG), since GNNs are often used with graph-structured data. Session-based recommendation usually involves user interactions over time, which might be time-series, but the mention of a graph neural network points more towards a knowledge graph approach. \n\nWait, RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models, so probably not that. Multimodal would involve multiple data types like text and images, which isn't mentioned here. Time-series could be a possibility if the model processes sequential data over time, but the key term here is \"Graph Neural Network,\" which is more aligned with Knowledge Graphs. So I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33343@AAAI"},
{"title": "AD4CD: Causal-Guided Anomaly Detection for Enhancing Cognitive Diagnosis", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AD4CD: Causal-Guided Anomaly Detection for Enhancing Cognitive Diagnosis.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. AD4CD probably stands for Anomaly Detection for Cognitive Diagnosis. The key terms here are \"anomaly detection\" and \"cognitive diagnosis.\" The method mentioned is \"causal-guided,\" which suggests using causal relationships in the detection process.\n\nNow, looking at the possible topics. Time-series analysis usually involves data points indexed in time order, like stock prices over time. Multimodal refers to combining multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graph, which structures information as entities and relationships.\n\nThe paper's focus is on anomaly detection in cognitive diagnosis, using causal guidance. Anomaly detection can be part of various fields, but the mention of \"causal\" might relate to how data is structured or analyzed. However, none of the four topics directly relate to causal methods unless it's part of a knowledge graph, but KG typically involves structured data representation. Since the title doesn't mention time-based data, multiple modalities, retrieval-augmented generation, or knowledge graphs specifically, it doesn't fit into any of the four categories. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33344@AAAI"},
{"title": "Sub-Interest-Aware Representation Uniformity for Recommender System", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Sub-Interest-Aware Representation Uniformity for Recommender System.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Sub-Interest-Aware\" suggests that the model is considering different aspects or sub-interests of users. \"Representation Uniformity\" might refer to how the representations (like embeddings) are distributed, possibly aiming for diversity or coverage. The application is in a Recommender System.\n\nNow, the options. Time-series would involve data over time, like sequences or temporal patterns. The title doesn't mention time or sequences, so maybe not time-series. Multimodal usually involves combining different data types, like text and images. The title doesn't mention multiple modalities, so probably not that either.\n\nRAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP tasks. The title is about a recommender system's representation, not retrieval or generation. KG is Knowledge Graphs, which involve structured data and relationships. The title doesn't mention graphs or structured knowledge.\n\nSo, the paper is about improving representations in a recommender system by considering sub-interests and uniformity. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The focus is on representation learning in recommenders, which is a different area. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33345@AAAI"},
{"title": "S²DN: Learning to Denoise Unconvincing Knowledge for Inductive Knowledge Graph Completion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"S²DN: Learning to Denoise Unconvincing Knowledge for Inductive Knowledge Graph Completion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Inductive Knowledge Graph Completion\" immediately makes me think of Knowledge Graphs (KG). The term \"Knowledge Graph\" is right there. The paper is about completing a knowledge graph, which involves predicting missing links or entities. The method mentioned is about denoising unconvincing knowledge, which sounds like improving the quality of the knowledge in the graph by removing noise or incorrect information. \n\nNow, checking the other options. Time-series would involve data over time, like stock prices or weather data. The title doesn't mention anything about time or sequences. Multimodal usually refers to combining different data types like text, images, and audio. There's no indication of multiple modalities here. RAG stands for Retrieval-Augmented Generation, which is a method combining retrieval of information with generation models, often used in question-answering. The title doesn't mention retrieval or generation. \n\nSo, the key term here is \"Knowledge Graph,\" which directly points to the KG topic. The rest of the title supports that it's about improving knowledge graphs through denoising. Therefore, the correct category is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33346@AAAI"},
{"title": "On Designing the Optimal Integrated Ad Auction in E-commerce Platforms", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"On Designing the Optimal Integrated Ad Auction in E-commerce Platforms.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually involves data over time, like stock prices or weather data. The title doesn't mention anything about time-based data analysis, so probably not time-series.\n\nMultimodal refers to combining different types of data, like text and images. The paper is about ad auctions in e-commerce, which might involve different data types, but the title doesn't specify that. It's more about the auction design itself.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information and then generates a response. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on auction design, not on building or using a knowledge graph.\n\nSo, the paper is about designing an optimal ad auction system. None of the given topics (time-series, multimodal, RAG, KG) directly relate to auction design or e-commerce platforms in this context. The topics listed are more about data types or specific AI techniques, while the paper seems to be in the area of economics, game theory, or operations research. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33347@AAAI"},
{"title": "Unveiling Multi-View Anomaly Detection: Intra-view Decoupling and Inter-view Fusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unveiling Multi-View Anomaly Detection: Intra-view Decoupling and Inter-view Fusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-View\" suggests that the research involves multiple perspectives or data sources. Anomaly detection is the main task here. The methods mentioned are intra-view decoupling and inter-view fusion. \n\nIntra-view decoupling probably refers to handling each individual view (or data source) separately, maybe to extract features or detect anomalies within each view. Inter-view fusion would then combine information from different views to improve the anomaly detection. \n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem to be directly mentioned here. RAG (Retrieval-Augmented Generation) is related to models that use retrieval to augment generation, which doesn't fit. KG (Knowledge Graph) involves structured data and relationships, which also isn't obvious here. \n\nMultimodal, on the other hand, deals with multiple types of data or modalities. Since \"multi-view\" can be analogous to multimodal (each view being a different modality), this seems like the best fit. The paper is about combining different views (modalities) for anomaly detection, which aligns with multimodal research. \n\nI don't see any mention of time-series data, RAG, or knowledge graphs in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33349@AAAI"}
{"title": "Unveiling Multi-View Anomaly Detection: Intra-view Decoupling and Inter-view Fusion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unveiling Multi-View Anomaly Detection: Intra-view Decoupling and Inter-view Fusion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Multi-View\" suggests that the research involves multiple perspectives or data sources. Anomaly detection is the main task here. The methods mentioned are intra-view decoupling and inter-view fusion. \n\nIntra-view decoupling probably refers to handling each individual view (or data source) separately, maybe to extract features or detect anomalies within each view. Inter-view fusion would then combine information from different views to improve the anomaly detection. \n\nNow, looking at the possible topics. Time-series is about data over time, which doesn't seem to be directly mentioned here. RAG (Retrieval-Augmented Generation) is related to models that use retrieval to augment generation, which doesn't fit. KG (Knowledge Graph) involves structured data and relationships, which also isn't obvious here. \n\nMultimodal, on the other hand, deals with multiple types of data or modalities. Since \"multi-view\" can be analogous to multimodal (each view being a different modality), this seems like the best fit. The paper is about combining different views (modalities) for anomaly detection, which aligns with multimodal research. \n\nI don't see any mention of time-series data, RAG, or knowledge graphs in the title. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33349@AAAI"},
{"title": "DutyTTE: Deciphering Uncertainty in Origin-Destination Travel Time Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DutyTTE: Deciphering Uncertainty in Origin-Destination Travel Time Estimation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Origin-Destination Travel Time Estimation\" sounds like it's about predicting how long it takes to travel between two points. That's probably related to time-series data because travel times can vary over time. Time-series analysis often deals with data points indexed in time order, which could be relevant here for predicting travel times based on historical data.\n\nNow, the other parts: \"Deciphering Uncertainty\" suggests they're looking at the variability or unpredictability in these estimates. Maybe they're using statistical models or machine learning techniques that handle uncertainty, but that doesn't directly point to one of the four categories unless it's time-series.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about combining different data types, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate responses. The title doesn't seem to involve generating text or using retrieval methods, so RAG is unlikely.\n\nKG is Knowledge Graph, which involves structured data and relationships between entities. The paper's focus on travel time estimation doesn't immediately suggest building or using a knowledge graph. Unless they're modeling the transportation network as a graph, but the title doesn't specify that.\n\nSo, the main clue is \"Travel Time Estimation,\" which is a classic problem in time-series analysis. They might be using time-series models to predict travel times, considering factors that change over time. The uncertainty aspect could be part of the time-series forecasting, like predicting confidence intervals or handling variable traffic patterns.\n\nTherefore, the most likely topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33350@AAAI"},
{"title": "DOGE: LLMs-Enhanced Hyper-Knowledge Graph Recommender for Multimodal Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DOGE: LLMs-Enhanced Hyper-Knowledge Graph Recommender for Multimodal Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"LLMs-Enhanced\" suggests they're using large language models. \"Hyper-Knowledge Graph\" – that's definitely a Knowledge Graph (KG) reference. Then \"Recommender for Multimodal Recommendation\" – multimodal is one of the options. So the paper is about a recommender system that uses a knowledge graph enhanced by LLMs and is for multimodal data.\n\nThe options are time-series, multimodal, RAG, KG. The title mentions both \"Hyper-Knowledge Graph\" and \"Multimodal Recommendation.\" But the question is to pick one of the four. The user might be looking for the primary topic. Since the title includes \"Hyper-Knowledge Graph,\" which directly points to KG. However, \"Multimodal\" is also in there. But the options are separate. The task is to choose which of the four it belongs to. The paper is using a knowledge graph (KG) enhanced by LLMs for multimodal recommendations. So the main focus here is the use of a knowledge graph in the recommender system. The multimodal aspect is the application area, but the core method is the knowledge graph. So the answer should be KG. Alternatively, if the primary focus is on multimodal, but the title says \"for Multimodal Recommendation,\" which is the application. The main technique is the Hyper-Knowledge Graph. So the correct topic here is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33351@AAAI"},
{"title": "Trust-GRS: A Trustworthy Training Framework for Graph Neural Network Based Recommender Systems Against Shilling Attacks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Trust-GRS: A Trustworthy Training Framework for Graph Neural Network Based Recommender Systems Against Shilling Attacks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Graph Neural Network,\" \"Recommender Systems,\" and \"Shilling Attacks.\" The framework is called Trust-GRS, which probably stands for Trust Graph Recommender System or something similar. \n\nGraph Neural Networks (GNNs) are a type of neural network designed to work with graph-structured data. Recommender systems using GNNs might involve modeling user-item interactions as a graph. Now, the four options given are time-series, multimodal, RAG, and KG. \n\nTime-series would involve data that's sequential over time, like stock prices or sensor data. The title doesn't mention anything about time or sequences, so probably not time-series. \n\nMultimodal refers to combining multiple types of data, like text and images. The title doesn't mention different data modalities, so that's probably not it either. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database and uses it to generate responses. The title doesn't mention retrieval or generation, so RAG seems unlikely. \n\nKG stands for Knowledge Graph, which is a structured representation of knowledge, often in the form of a graph. Since the paper uses Graph Neural Networks and mentions a framework for recommender systems, which often use knowledge graphs to model relationships between entities, this seems plausible. The mention of \"Graph Neural Network\" directly relates to graph structures, which are central to Knowledge Graphs. \n\nAdditionally, the focus on shilling attacks might involve ensuring the integrity of the graph data, which is part of making the system trustworthy. Knowledge Graphs are often used in recommender systems to capture complex relationships, so this aligns with KG. \n\nTherefore, the correct topic is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33352@AAAI"},
{"title": "Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Knowledge Graph Reasoning\" immediately makes me think of Knowledge Graphs (KG). The main focus here is on reasoning within a knowledge graph. The other part mentions \"Uncertainty Aware Perspective,\" which might relate to how the reasoning handles uncertainty, but the core topic is still about knowledge graphs. \n\nTime-series would involve data over time, like stock prices or weather data. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. None of these seem to fit the title. The key term here is \"Knowledge Graph,\" so the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33353@AAAI"},
{"title": "LS-TGNN: Long and Short-Term Temporal Graph Neural Network for Session-Based Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LS-TGNN: Long and Short-Term Temporal Graph Neural Network for Session-Based Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Temporal Graph Neural Network\" suggests that it's dealing with graphs over time. The \"Long and Short-Term\" part probably refers to modeling both long-term and short-term temporal patterns. Session-based recommendation usually involves predicting the next item a user might interact with based on their current session, which is a sequence of actions over time. \n\nTime-series analysis involves data points indexed in time order. Since the model is handling temporal aspects (long and short-term), this seems related to time-series. The graph neural network part might be using a graph structure to model relationships between items or users, but the key here is the temporal aspect. \n\nMultimodal would involve combining different types of data, like text and images, which isn't mentioned here. RAG (Retrieval-Augmented Generation) is about using retrieval methods to enhance generation models, which doesn't seem to fit. KG (Knowledge Graph) involves structured data and relationships, but the title doesn't mention knowledge graphs specifically. \n\nSo the main focus is on temporal modeling for recommendations, which aligns with time-series. Even though there's a graph component, the temporal aspect is emphasized, so time-series is the best fit here.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33354@AAAI"},
{"title": "Tab-Shapley: Identifying Top-k Tabular Data Quality Insights", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Tab-Shapley: Identifying Top-k Tabular Data Quality Insights.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Tab-Shapley\" probably refers to a method or algorithm. \"Tabular\" data is structured data in rows and columns, like spreadsheets. \"Shapley\" might be related to Shapley values from game theory, used in machine learning for feature attribution. The goal is to identify the top-k data quality insights. So, the paper is about analyzing tabular data to find the most important quality issues.\n\nNow, the possible topics. Time-series is about data over time, like stock prices or weather. Multimodal involves multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which combines retrieval with generation models. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus is on tabular data quality, using Shapley values. None of the topics directly relate to time-series, multimodal, RAG, or KG. It's about data quality analysis in tabular datasets, which doesn't fit into any of the four categories listed. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33355@AAAI"},
{"title": "A Label-free Heterophily-guided Approach for Unsupervised Graph Fraud Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"A Label-free Heterophily-guided Approach for Unsupervised Graph Fraud Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Label-free\" suggests it's unsupervised, which is common in many machine learning areas. \"Heterophily-guided\" might relate to graph properties. Heterophily in graphs refers to the tendency of nodes to connect to dissimilar nodes, which is a concept in graph theory. \"Unsupervised Graph Fraud Detection\" clearly mentions graphs, so that's a hint. \n\nNow, the options are time-series, multimodal, RAG, or KG. Time-series deals with data over time, which doesn't seem to fit here. Multimodal involves combining different data types like text and images, which isn't mentioned. RAG stands for Retrieval-Augmented Generation, which is more about enhancing models with external information retrieval, typically in NLP. KG is Knowledge Graphs, which are structured representations of knowledge, often using graph structures. \n\nThe paper is about graph fraud detection using a heterophily-guided approach. Since it's focused on graphs and fraud detection in that context, the most relevant topic here would be Knowledge Graphs (KG). RAG is more about retrieval in models, not graph structure. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33356@AAAI"},
{"title": "Guaranteeing Out-Of-Distribution Detection in Deep RL via Transition Estimation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Guaranteeing Out-Of-Distribution Detection in Deep RL via Transition Estimation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The main focus is on Out-Of-Distribution (OOD) detection in Deep Reinforcement Learning (Deep RL). The method mentioned is Transition Estimation. \n\nTime-series usually involves data over time, like sequences or temporal data. This paper is about reinforcement learning, which does involve sequences of actions and states, but the key here is OOD detection. Not sure if that's time-series specific.\n\nMultimodal refers to combining multiple data types, like text and images. The title doesn't mention anything about multiple modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, common in NLP. This paper is about RL and OOD detection, so RAG doesn't seem relevant here.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper doesn't mention anything about knowledge graphs or structured data, so that's probably not it either.\n\nSo, the remaining options are time-series, multimodal, RAG, or KG. Since none of the other three seem to fit, maybe it's none? But wait, the paper is about Deep RL. Transition Estimation in RL might involve modeling state transitions, which could be time-dependent. However, the primary focus here is on OOD detection, which is more about uncertainty or anomaly detection in the model's predictions. \n\nI don't think this falls under any of the four specified topics. The paper is about reinforcement learning and OOD detection, which are separate areas. So the answer should be \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33357@AAAI"},
{"title": "Seeing Beyond Noise: Joint Graph Structure Evaluation and Denoising for Multimodal Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Seeing Beyond Noise: Joint Graph Structure Evaluation and Denoising for Multimodal Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multimodal Recommendation\" immediately stands out. Multimodal usually refers to using multiple types of data or modalities, like text, images, audio, etc. So that's a hint towards the \"multimodal\" topic. \n\nThen there's \"Graph Structure Evaluation and Denoising.\" Graphs are related to Knowledge Graphs (KG), which are structured representations of information. But the paper is about evaluating and denoising the graph structure in the context of multimodal recommendations. However, the primary focus here seems to be on handling multiple modalities in the recommendation system, using graph structures as part of the method. \n\nRAG (Retrieval-Augmented Generation) is more about combining retrieval from a knowledge base with generation models, which doesn't seem to be the case here. Time-series would involve data over time, which isn't mentioned. \n\nSo even though there's a mention of graph structures, the main topic here is multimodal because the title explicitly states \"Multimodal Recommendation.\" The graph part is a method used within that context. Therefore, the correct topic should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33358@AAAI"}
{"title": "Online Fraud Detection via Test-Time Retrieval-Based Representation Enrichment", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Online Fraud Detection via Test-Time Retrieval-Based Representation Enrichment.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Online Fraud Detection\" suggests it's about detecting fraudulent activities in real-time or online data. The method mentioned is \"Test-Time Retrieval-Based Representation Enrichment.\" The key terms here are \"retrieval-based\" and \"representation enrichment.\" \n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves relevant information from a database during inference to enhance its responses. Since the title mentions \"retrieval-based\" at test time, this seems like it could be related to RAG. The idea is that during testing (when making predictions), the model enriches its representations by retrieving relevant data, which aligns with how RAG works by incorporating retrieved information into the model's processing.\n\nTime-series would involve data points indexed in time order, like stock prices over time. The title doesn't mention anything about time series data specifically. Multimodal refers to using multiple types of data (e.g., text and images), but the title doesn't indicate multiple modalities. KG stands for Knowledge Graphs, which are structured representations of knowledge, but there's no mention of graphs or structured data here.\n\nSo, the most likely topic is RAG because the method described involves retrieval during test time to enhance representations, which is a core aspect of Retrieval-Augmented Generation.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33359@AAAI"},
{"title": "GeoMamba: Towards Multi-granular POI Recommendation with Geographical State Space Model", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GeoMamba: Towards Multi-granular POI Recommendation with Geographical State Space Model.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"POI\" stands for Points of Interest, so this is about recommending places. \"Multi-granular\" suggests different levels of detail or scales. \"Geographical State Space Model\" – state space models are often used in time-series analysis, like in Kalman filters or sequence modeling. But the term \"geographical\" here might imply spatial aspects. \n\nNow, the four options. Time-series usually involves data over time. Multimodal would involve combining different data types like text and images. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper's focus seems to be on a model (GeoMamba) for POI recommendation using a geographical state space model. State space models are typically used in time-series, but here it's combined with geographical aspects. However, the key here is whether it's about time-series data. If the model is handling sequential data over time, then it's time-series. But if it's more about spatial data without a temporal component, maybe not. However, POI recommendations often involve user check-ins over time, so maybe there's a time aspect. But the title doesn't explicitly mention time. The term \"state space model\" is a strong indicator for time-series, as those models are commonly used there. So maybe it's time-series. \n\nAlternatively, if the model is combining different modalities (like text, images, location), it would be multimodal. But the title doesn't mention multiple data types. RAG and KG are less likely here. The paper is about a model for recommendation, which could be a type of system, but the specific mention of state space model points more towards time-series. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33360@AAAI"},
{"title": "Domain-Level Disentanglement Framework Based on Information Enhancement for Cross-Domain Cold-Start Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Domain-Level Disentanglement Framework Based on Information Enhancement for Cross-Domain Cold-Start Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Domain-Level Disentanglement\" suggests they're working with different domains, maybe separating features or information specific to each domain. \"Information Enhancement\" implies improving the data or features used. The goal is \"Cross-Domain Cold-Start Recommendation,\" which is about recommending items when there's little data in a new domain by leveraging another domain.\n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. The title doesn't mention time or sequences, so probably not that. Multimodal usually deals with multiple data types, like text and images. The title doesn't mention different modalities, so maybe not. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, often in NLP. The title doesn't mention retrieval or generation. KG (Knowledge Graph) involves structured data and relationships. The paper is about cross-domain recommendations, which might use knowledge graphs to transfer information between domains. But the title doesn't explicitly mention a knowledge graph. Alternatively, cross-domain cold-start could involve using a knowledge graph to link domains. However, the key terms here are \"disentanglement\" and \"information enhancement,\" which might relate to RAG if they're retrieving information from another domain. Wait, RAG is more about using retrieved documents to generate answers. The cold-start problem in recommendations is often addressed with transfer learning or using auxiliary information. If they're using a knowledge graph to connect domains, that would be KG. But the title doesn't mention a knowledge graph. Alternatively, maybe it's a framework that uses information from another domain, which could be part of RAG if they're retrieving relevant data. But I'm not sure. The term \"disentanglement\" is more common in representation learning, where you separate factors of variation. In cross-domain settings, this could help in transferring knowledge. However, none of the four topics directly mention disentanglement. Since the options are time-series, multimodal, RAG, or KG, and the paper is about cross-domain recommendations with information enhancement, maybe it's related to RAG if they're retrieving information from another domain to enhance the cold-start scenario. But I'm not certain. Alternatively, if they're using a knowledge graph to link domains, it would be KG. But the title doesn't specify. Since the answer has to be one of the four or none, and the title doesn't clearly mention any of the four, maybe it's none. Wait, but cross-domain cold-start is a common problem in recommendation systems. RAG is a method that could be used here if they're retrieving information from another domain. But the title doesn't mention retrieval or generation. Hmm. Maybe the answer is none because it doesn't fit any of the four categories. Alternatively, maybe it's RAG if they're using retrieval from another domain. But I'm not sure. The key terms don't align with the four topics. So the answer is none.\n</think>\n\nnone", "url": "https://papers.cool/venue/33361@AAAI"},
{"title": "Hyperparametric Robust and Dynamic Influence Maximization", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hyperparametric Robust and Dynamic Influence Maximization.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Influence Maximization\" sounds like a problem in social networks or graph theory, where you want to maximize the spread of influence. The terms \"Robust\" and \"Dynamic\" suggest that the method handles changing conditions or uncertainties. \"Hyperparametric\" might refer to using hyperparameters in the model, which is common in machine learning.\n\nNow, looking at the possible topics. Time-series deals with data over time, like stock prices or weather. Multimodal involves combining different data types, like text and images. RAG (Retrieval-Augmented Generation) is about using retrieval systems to enhance generative models. KG (Knowledge Graph) involves structured data representations, often using graphs.\n\nInfluence Maximization is typically studied in the context of graphs, especially social networks. Knowledge Graphs are a type of graph structure used to represent entities and their relationships. So, if the paper is about optimizing influence spread in a graph structure, it might relate to Knowledge Graphs. However, the title doesn't explicitly mention knowledge graphs. It just says \"Influence Maximization,\" which is a broader concept. The terms \"Dynamic\" and \"Robust\" could relate to how the influence spreads over time or under varying conditions, but that's more about the algorithm's properties rather than the data type.\n\nRAG and multimodal don't seem relevant here. The title doesn't mention anything about combining different data modalities or using retrieval for generation. Time-series is about sequential data, which isn't directly indicated here. So, the closest might be Knowledge Graphs if the influence is modeled on a graph structure. But the title doesn't specify that. It could be a general graph problem. Since the options are limited to the four given, and the paper's topic isn't clearly one of them, maybe the answer is \"none.\" But I'm not entirely sure. Wait, maybe \"Dynamic\" in the title could imply time-series? But dynamic influence maximization is more about how the influence changes over time in a network, which is a graph problem. So perhaps it's related to Knowledge Graphs if the network is a KG. But without explicit mention, it's a stretch. The safest answer might be \"none\" because the title doesn't clearly align with any of the four specified topics.\n</think>\n\nnone", "url": "https://papers.cool/venue/33362@AAAI"},
{"title": "Towards Loss-Resilient Image Coding for Unstable Satellite Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards Loss-Resilient Image Coding for Unstable Satellite Networks.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Loss-Resilient Image Coding\" suggests that the research is about encoding images in a way that can handle data loss. \"Unstable Satellite Networks\" implies the application is in environments where network conditions are unreliable, like satellite communications. \n\nNow, looking at the possible topics. Time-series usually involves data over time, like stock prices or sensor data. This doesn't seem to fit here. Multimodal refers to combining multiple data types, like text and images. The paper is about image coding, but there's no mention of combining different modalities. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to aid in generating responses. That doesn't seem related to image coding for satellite networks. \n\nKG is Knowledge Graphs, which are structured representations of knowledge. Again, not directly related to image coding techniques. \n\nSo, the paper is about improving image coding to be resilient against data loss in unstable networks. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. The focus is on image processing and network resilience, which doesn't fall under the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33363@AAAI"},
{"title": "Adversarial Contrastive Graph Masked AutoEncoder Against Graph Structure and Feature Dual Attacks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Adversarial Contrastive Graph Masked AutoEncoder Against Graph Structure and Feature Dual Attacks.\" Hmm, I need to figure out which of the four topics this belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The key terms here are \"Graph Masked AutoEncoder,\" \"Graph Structure,\" and \"Feature Dual Attacks.\" The mention of \"Graph\" makes me think of Knowledge Graphs (KG), since KGs are structured representations of information. But wait, there's also the term \"AutoEncoder,\" which is a type of neural network used in unsupervised learning. The adversarial aspect and contrastive learning might relate to making the model robust against attacks on both the structure and features of the graph.\n\nNow, the options are time-series, multimodal, RAG, or KG. Time-series would involve data over time, like stock prices or weather data. Multimodal would involve combining different data types, like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured data representations.\n\nThe paper's focus is on graph structures and features, using an autoencoder to handle adversarial attacks. Since it's specifically about graphs and their structures, this seems to align with Knowledge Graphs (KG). The other topics don't fit here. There's no mention of time-series data, multimodal inputs, or retrieval-augmented generation. So the answer should be KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33364@AAAI"},
{"title": "AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha Factors", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"AlphaForge: A Framework to Mine and Dynamically Combine Formulaic Alpha Factors.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"AlphaForge\" sounds like a framework, maybe in finance since \"alpha factors\" are related to stock returns. \"Mine and Dynamically Combine Formulaic Alpha Factors\" suggests they're extracting and combining factors that predict stock performance. \n\nNow, the possible topics. Time-series analysis deals with data over time, which is common in finance. Multimodal usually involves combining different data types like text and images. RAG is Retrieval-Augmented Generation, which uses external data for generating responses. KG is Knowledge Graphs, which structure information in a graph format.\n\nThe paper's focus is on mining and combining alpha factors. Alpha factors in finance are typically derived from historical time-series data of stock prices, volumes, etc. So, the process of mining these factors would involve analyzing time-series data. Dynamically combining them might involve models that process sequences or time-based patterns. \n\nMultimodal doesn't seem right here because there's no mention of different data modalities. RAG and KG are more about information retrieval and structured knowledge, which doesn't align with the formulaic factors in finance. \n\nTherefore, the most likely topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33365@AAAI"},
{"title": "Ready for You When You Are Back: Content-Driven Session-Based Recommendation for Continuity of Experience", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Ready for You When You Are Back: Content-Driven Session-Based Recommendation for Continuity of Experience.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Session-Based Recommendation\" makes me think of recommendations that are based on user sessions, which are sequences of interactions over time. That might relate to time-series data because each session is a sequence of events. But I'm not sure yet. \n\n\"Content-Driven\" suggests that the recommendations are based on the content of the items, maybe using item features or metadata. But how does that tie into the four topics? RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, often in NLP. KG (Knowledge Graph) involves structured data and relationships between entities. Multimodal would involve multiple data types like text, images, etc. Time-series is about sequential data over time.\n\nThe key part here is \"Session-Based Recommendation.\" Session-based recommendations typically model user interactions within a session, which is a sequence of actions. So that's sequential data, which is time-series. But wait, sometimes session-based recommendations can use other methods too. However, the mention of \"Continuity of Experience\" might imply that the model is looking at the temporal aspect of user sessions to maintain a smooth experience when the user returns. \n\nSo, if the paper is about modeling user sessions as sequences to provide recommendations, that's time-series. The content-driven part might refer to using item content features, but the core of the recommendation is session-based, which is a time-series problem. \n\nI don't see any mention of knowledge graphs or multimodal data here. RAG is about retrieval and generation, which doesn't seem to fit. So the most likely topic is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33366@AAAI"},
{"title": "Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality Constraints", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality Constraints.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the word \"Multi-Modal\" is right there in the title. That immediately makes me think of the multimodal category. But I should check the rest of the title to be sure. The paper is about recommendation unlearning, which involves removing or forgetting certain data from a model. The context given is legal, licensing, and modality constraints. \n\nNow, the key terms here are \"Multi-Modal,\" which refers to using multiple types of data (like text, images, audio) together. The other part is \"unlearning,\" which is about removing data from a model's training. But the question is about the research topic the paper belongs to. The options are time-series, multimodal, RAG, or KG. \n\nSince the title explicitly mentions \"Multi-Modal,\" that's a strong indicator. The other parts of the title don't seem to relate to time-series data, which is about sequences over time. RAG (Retrieval-Augmented Generation) is a method that combines retrieval with generation, often used in NLP. KG (Knowledge Graph) involves structured data representations. The title doesn't mention anything about retrieval, generation, or knowledge graphs. \n\nTherefore, the most fitting category here is multimodal. The paper is about handling multiple modalities in a recommendation system, specifically addressing unlearning under certain constraints. So the answer should be multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33367@AAAI"},
{"title": "Integrating Personalized Spatio-Temporal Clustering for Next POI Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Integrating Personalized Spatio-Temporal Clustering for Next POI Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Spatio-Temporal\" refers to both space and time. So that's a clue. \"Clustering\" suggests grouping data points, maybe based on location and time. \"Next POI Recommendation\" means predicting the next point of interest someone will visit. \n\nTime-series analysis deals with data over time. Since the method uses spatio-temporal clustering, which involves time, this might be related to time-series. But wait, POI recommendations often involve location data, which is spatial. So maybe it's a combination of spatial and temporal data. But the question is whether it fits into one of the four categories. \n\nMultimodal would involve multiple types of data, like text and images. The title doesn't mention different data types, so probably not multimodal. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which doesn't seem to fit here. KG (Knowledge Graph) involves structured data and relationships, which also isn't mentioned. \n\nSo the key here is \"spatio-temporal,\" which is about time and space. Since time-series is one of the options and it's a component of spatio-temporal, maybe the answer is time-series. But wait, spatio-temporal could be a subset of time-series, but sometimes it's considered a separate area. However, the given options don't have a spatio-temporal category. The closest is time-series. So I think the answer is time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33368@AAAI"}
{"title": "UniFORM: Towards Unified Framework for Anomaly Detection on Graphs", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UniFORM: Towards Unified Framework for Anomaly Detection on Graphs.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. The key parts here are \"Anomaly Detection on Graphs.\" Anomaly detection is a common task in various domains. Now, graphs are structures that represent relationships between entities, so this is likely related to graph data. \n\nLooking at the options, RAG stands for Retrieval-Augmented Generation, which is more about combining retrieval with generative models, often in NLP. KG is Knowledge Graphs, which are structured representations of knowledge, typically using graphs. But the title specifically mentions anomaly detection on graphs, which sounds more like analyzing graph structures for anomalies rather than building or using a knowledge graph. \n\nMultimodal refers to combining multiple data types like text, images, audio, etc. The title doesn't mention anything about multiple modalities, so probably not that. Time-series is about data over time, which again, the title doesn't mention. \n\nSo the closest fit here is KG (Knowledge Graphs) because graphs are involved. However, wait—KG usually refers to knowledge graphs, which are a type of graph used to represent entities and their relationships. But the paper is about anomaly detection on graphs in general. However, the options given are RAG, KG, multimodal, time-series. Since the paper is about graphs and anomaly detection, and KG is one of the options, maybe it's considered under KG. But sometimes graph-based anomaly detection could be a separate area. However, given the choices, the best fit is KG. Alternatively, maybe it's none? But the title does mention graphs, so perhaps it's related to KG. Let me double-check. If the paper is about graphs in general, not specifically knowledge graphs, then maybe it's none. But the options don't have a \"graph\" category. The available options are time-series, multimodal, RAG, KG. So if the paper is about graphs, then KG (Knowledge Graphs) is the closest. But I'm a bit uncertain because not all graph-based research is about knowledge graphs. However, given the choices, I think the answer is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33369@AAAI"},
{"title": "Enhancing Diffusion Model with Auxiliary Information Mining-Exploration and Efficient Sampling Mechanism for Sequential Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Enhancing Diffusion Model with Auxiliary Information Mining-Exploration and Efficient Sampling Mechanism for Sequential Recommendation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on improving a diffusion model for sequential recommendation. Diffusion models are typically used in generative tasks, but here it's applied to sequential data. Sequential recommendation usually involves predicting the next item in a sequence, which is a time-series problem because the data is ordered over time. \n\nThe mention of \"auxiliary information mining\" might imply using additional data sources, but that's not necessarily multimodal unless it's combining different types of data (like text and images). The title doesn't specify different modalities, so maybe that's not it. RAG (Retrieval-Augmented Generation) involves using retrieval mechanisms to augment generation, but the title talks about a sampling mechanism, which might be different. KG (Knowledge Graphs) involve structured data, but there's no mention of graphs here. \n\nSo, the key part is \"sequential recommendation,\" which is a time-series task. The model is being enhanced for sequences, so time-series makes sense. The other components like auxiliary information and sampling are methods to improve the model but don't point to the other topics. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33370@AAAI"},
{"title": "Genomics Data Lossless Compression with (S, K)-Mer Encoding and Deep Neural Networks", "topic": "none", "raw_response": "<think>\nOkay, let's see. The user wants me to analyze the research paper title and determine which of the four topics it belongs to: time-series, multimodal, RAG, or KG. The title is \"Genomics Data Lossless Compression with (S, K)-Mer Encoding and Deep Neural Networks.\"\n\nFirst, I need to break down the title. The main subject here is genomics data compression. The methods mentioned are (S, K)-Mer encoding and deep neural networks. Let's recall what each of the four topics entails.\n\nTime-series research deals with data points indexed in time order. Genomics data might have a sequence aspect, but compression isn't inherently time-series unless the data is analyzed over time. However, the title doesn't mention time or temporal aspects, so maybe not time-series.\n\nMultimodal refers to combining multiple data types, like text and images. The title only mentions genomics data, which is a single modality, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to enhance its responses. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The paper's focus is on compression techniques using encoding and neural networks, not on building or utilizing knowledge graphs. \n\nSo, none of the four topics (time-series, multimodal, RAG, KG) seem to fit. The paper is about data compression in genomics using specific encoding and deep learning, which doesn't align with any of the listed categories. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33371@AAAI"},
{"title": "Pioneer: Physics-informed Riemannian Graph ODE for Entropy-increasing Dynamics", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Pioneer: Physics-informed Riemannian Graph ODE for Entropy-increasing Dynamics.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Physics-informed\" suggests that the model incorporates physical laws or principles. \"Riemannian Graph ODE\" – Riemannian refers to Riemannian geometry, which is a type of non-Euclidean geometry. Graph ODE might be an ordinary differential equation applied to a graph structure. \"Entropy-increasing Dynamics\" implies that the system's entropy is increasing over time, which relates to thermodynamics or information theory.\n\nNow, looking at the possible topics. Time-series analysis deals with data over time, often using models like RNNs or LSTMs. Multimodal refers to combining multiple data types (like text and images). RAG stands for Retrieval-Augmented Generation, which is a method in NLP that uses external knowledge sources. KG is Knowledge Graph, which is a structured representation of entities and their relationships.\n\nThe paper's title mentions a \"Riemannian Graph ODE.\" The term \"Graph\" here might be related to graph structures, which are used in Knowledge Graphs (KG). Knowledge Graphs often involve modeling relationships between entities using graph structures. However, the paper is about a physics-informed ODE on a Riemannian manifold, which might be more about the mathematical structure rather than the knowledge representation aspect. \n\nWait, but RAG is Retrieval-Augmented Generation, which is different. KG is Knowledge Graph. The paper's focus on a graph structure in the context of ODEs and physics might not directly relate to knowledge graphs. Knowledge Graphs are more about storing and querying structured data, whereas here the graph is part of the model's architecture. \n\nTime-series is about sequential data over time, but the title doesn't explicitly mention time-series data. The ODE part could be used for modeling time-dependent processes, but the key here is the graph structure. \n\nMultimodal is about combining different data types, which isn't mentioned here. \n\nSo, the most likely candidate is KG, but I'm not entirely sure. Alternatively, maybe none of them. Wait, the paper is about a Riemannian Graph ODE. If \"Graph\" here refers to a graph neural network or a graph structure, maybe it's related to Knowledge Graphs. But Knowledge Graphs are more about the data structure rather than the model's architecture. \n\nAlternatively, the term \"Riemannian Graph\" might be a specific type of model. However, none of the four topics (time-series, multimodal, RAG, KG) directly match this. The paper seems to be about a novel model using Riemannian geometry and graphs, which might not fit into any of the given categories. \n\nWait, RAG is Retrieval-Augmented Generation, which is a different area. KG is Knowledge Graph. The paper's title doesn't mention anything about retrieval or generation, so RAG is out. It's not about combining multiple modalities, so multimodal is out. Time-series is about temporal data, but the title doesn't specify that. The graph part might be related to Knowledge Graphs, but the paper's focus is on the ODE and physics-informed aspects. \n\nHmm. Maybe the answer is KG because of the \"Graph\" in the title. But I'm not certain. Alternatively, maybe it's none. Let me think again. The four options are time-series, multimodal, RAG, KG. The paper's title doesn't clearly align with any of these. The \"Graph\" in the title might be a red herring. Knowledge Graphs are a specific type of graph structure for knowledge representation. If the paper is about a graph-based model for dynamics, it might not be a Knowledge Graph. Therefore, the correct answer might be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33372@AAAI"},
{"title": "GDiffRetro: Retrosynthesis Prediction with Dual Graph Enhanced Molecular Representation and Diffusion Generation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"GDiffRetro: Retrosynthesis Prediction with Dual Graph Enhanced Molecular Representation and Diffusion Generation.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, let's break down the title. Retrosynthesis prediction is about predicting how to break down a molecule into simpler precursors, which is a common task in chemistry. The methods mentioned are dual graph enhanced molecular representation and diffusion generation. \n\nDual graph enhanced molecular representation probably refers to using graph structures to model molecules. Graphs are common in representing molecular structures where nodes are atoms and edges are bonds. So, this might relate to Knowledge Graphs (KG), which are structured representations of information. But wait, KG usually refers to more general knowledge bases, not just molecular structures. However, in this context, the graph is part of the molecular representation, so maybe it's more about graph-based models rather than a knowledge graph. \n\nThen there's diffusion generation. Diffusion models are a type of generative model used in machine learning, often for image or data generation. But the question is about the four topics listed. RAG stands for Retrieval-Augmented Generation, which combines retrieval of information with generation. Multimodal refers to combining different types of data like text, images, etc. Time-series is about data over time.\n\nThe paper is about retrosynthesis, which is a specific domain in chemistry. The use of graphs (dual graph) suggests that the model is using graph structures to represent molecules. Knowledge Graphs (KG) are a type of graph that encodes entities and their relationships. However, in this case, the graph is part of the molecular representation, which is more about the structure of the molecule itself rather than a knowledge base. So maybe it's not KG. \n\nRAG involves retrieval and generation, but the title mentions diffusion generation, which is a different approach. Multimodal would require combining different data types, but the title doesn't mention that. Time-series is about sequential data over time, which doesn't seem relevant here. \n\nSo, the key elements are the dual graph for molecular representation and diffusion generation. Since the graph is part of the molecular model, perhaps it's related to Knowledge Graphs (KG), but I'm not sure. Alternatively, if the graph is just a data structure for the molecule, maybe it's not one of the four topics. The options are time-series, multimodal, RAG, or KG. If it's using graph structures, maybe it's KG. But I'm a bit confused. Let me think again. \n\nKG typically refers to a structured repository of knowledge, like Wikipedia or a database of entities and relations. In this case, the graph is part of the molecular representation, which is more about the structure of the molecule. So maybe it's not KG. The other options don't fit. The paper is about a specific application in chemistry using graph-based models and diffusion. Since none of the four topics (time-series, multimodal, RAG, KG) directly match, maybe the answer is \"none\". But wait, the user might consider graph-based methods as part of KG. Hmm. Alternatively, maybe the dual graph is part of a knowledge graph. But I'm not certain. The title doesn't mention knowledge bases or external knowledge, just molecular graphs. So perhaps it's none of the listed topics. Therefore, the answer is \"none\".\n</think>\n\nnone", "url": "https://papers.cool/venue/33373@AAAI"},
{"title": "LLM4RSR: Large Language Models as Data Correctors for Robust Sequential Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"LLM4RSR: Large Language Models as Data Correctors for Robust Sequential Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"LLM4RSR\" probably stands for Large Language Models for Robust Sequential Recommendation. The key parts here are \"Large Language Models\" and \"Sequential Recommendation.\" \n\nSequential recommendation is a type of recommendation system that deals with sequences of user interactions over time. So, that's about time-series data, right? Because the user's actions are ordered in time, and the model needs to predict the next item based on the sequence. So time-series might be a candidate here.\n\nBut wait, the paper is using Large Language Models (LLMs) as data correctors. Data correction could involve handling noisy or incorrect data in the sequences. But does that relate to any of the other topics? Let's check the options again.\n\nMultimodal usually refers to combining different types of data, like text and images. The title doesn't mention anything about multiple modalities, so probably not that.\n\nRAG stands for Retrieval-Augmented Generation, which is a method where a model retrieves information from a database and then generates a response. The title doesn't mention retrieval or generation in that context, so maybe not RAG.\n\nKG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention knowledge graphs either.\n\nSo the main focus here is on sequential data for recommendations, which is a time-series problem. Even though LLMs are used, the core of the research is about handling sequential data robustly. Therefore, the topic should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33374@AAAI"},
{"title": "EDGE: Unknown-aware Multi-label Learning by Energy Distribution Gap Expansion", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"EDGE: Unknown-aware Multi-label Learning by Energy Distribution Gap Expansion.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Unknown-aware\" suggests the model is handling unknown classes or data, which is a common issue in machine learning. \"Multi-label learning\" means the model can assign multiple labels to a single input. The method is called \"Energy Distribution Gap Expansion,\" which sounds like it's using some energy-based model or distribution analysis to expand the gap between known and unknown classes.\n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or sensor data. The title doesn't mention anything about time, so probably not time-series. Multimodal would involve combining different data types, like text and images. The title doesn't mention multiple modalities, so maybe not that either. RAG (Retrieval-Augmented Generation) is about using retrieval to enhance generation, often in NLP. The title doesn't mention retrieval or generation. KG (Knowledge Graph) involves structured data and relationships. Again, the title doesn't mention graphs or knowledge bases.\n\nThe paper seems focused on a learning method for multi-label classification with an emphasis on handling unknown classes. The techniques mentioned (energy distribution, gap expansion) don't directly align with the four topics listed. So, the answer is probably \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33375@AAAI"},
{"title": "Hubness Change Point Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Hubness Change Point Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. \"Hubness\" refers to the tendency of certain data points to be frequently connected to others in a network or graph. \"Change Point Detection\" is about identifying points in a sequence where the underlying process changes. So, the paper is likely about detecting when the hubness in a dataset changes over time or in some sequence.\n\nNow, looking at the possible topics. Time-series analysis deals with data points indexed in time order. If the hubness is being analyzed over time, then it's a time-series topic. Multimodal refers to data from multiple sources or types (like text and images), which doesn't seem to fit here. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which is more related to NLP. KG (Knowledge Graph) involves structured data and relationships, but the title doesn't mention knowledge graphs specifically.\n\nSo, the key here is whether hubness is being analyzed in a time-ordered sequence. Since change point detection is a common task in time-series analysis, and hubness could be a property changing over time, this seems to fit under time-series. There's no mention of multiple modalities, RAG, or knowledge graphs. Therefore, the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33376@AAAI"},
{"title": "Language Pre-training Guided Masking Representation Learning for Time Series Classification", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Language Pre-training Guided Masking Representation Learning for Time Series Classification.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Time Series Classification\" right at the end. That seems like a strong indicator for the time-series topic. But I should check the other parts to be sure. The method described is \"Language Pre-training Guided Masking Representation Learning.\" So they're using language pre-training techniques, maybe similar to how BERT works, but applied to time series data. \n\nNow, the options are time-series, multimodal, RAG, or KG. Multimodal would involve combining different data types like text and images. RAG is Retrieval-Augmented Generation, which is about using retrieved information during generation. KG is Knowledge Graphs, which are structured data representations. The title doesn't mention anything about combining modalities, retrieval, or knowledge graphs. The focus is on time series classification using a method inspired by language pre-training. So the main topic here is definitely time-series. The mention of language pre-training might be a method, but the application is on time series data. So the answer should be time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33377@AAAI"},
{"title": "Unlocking the Power of Patch: Patch-Based MLP for Long-Term Time Series Forecasting", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Unlocking the Power of Patch: Patch-Based MLP for Long-Term Time Series Forecasting.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, the title mentions \"Long-Term Time Series Forecasting.\" That immediately makes me think of time-series analysis. Time-series forecasting is a common research area, so that's a strong indicator. The term \"patch-based\" might refer to a method where data is divided into patches or segments, which is a technique sometimes used in processing sequences, like in image processing or time-series. The MLP here is a Multilayer Perceptron, a type of neural network. So combining patch-based MLP for time series forecasting seems to fit under time-series.\n\nNow, checking the other options. Multimodal would involve combining different types of data, like text and images. The title doesn't mention anything about multiple modalities. RAG is Retrieval-Augmented Generation, which is more about using retrieval to enhance generative models, often in NLP. KG is Knowledge Graphs, which involve structured data and relationships. The title doesn't mention anything related to knowledge graphs or retrieval. \n\nSo the most likely answer is time-series. The key words in the title point directly to time series forecasting, and the other topics don't seem relevant here.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33378@AAAI"}
{"title": "CoDeR: Counterfactual Demand Reasoning for Sequential Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"CoDeR: Counterfactual Demand Reasoning for Sequential Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Counterfactual Demand Reasoning\" suggests they're looking at hypothetical scenarios, maybe in the context of user demand. \"Sequential Recommendation\" implies that the recommendations are based on sequences, like user interactions over time. So sequential here might relate to time-series data, where the order of events matters.\n\nTime-series analysis deals with data points indexed in time order. Sequential recommendation systems often use time-series data to predict the next item a user might want. For example, in e-commerce, recommending products based on past purchases in a sequence. So that points towards time-series.\n\nMultimodal would involve combining different types of data, like text and images. RAG is Retrieval-Augmented Generation, which uses retrieved information to enhance model outputs. KG is Knowledge Graphs, which are structured representations of knowledge. The title doesn't mention anything about combining different data types, retrieval, or knowledge graphs. The focus is on sequential data and counterfactual reasoning for recommendations. \n\nCounterfactual reasoning here is about considering what would happen if different actions were taken, which is a method used in causal inference. But the main aspect for categorization is the sequential aspect of the recommendation. So the topic is likely time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33379@AAAI"},
{"title": "Adapting to Non-Stationary Environments: Multi-Armed Bandit Enhanced Retrieval-Augmented Generation on Knowledge Graphs", "topic": "none", "raw_response": "<think>\nOkay, let's break down the title. The main components are \"Adapting to Non-Stationary Environments,\" \"Multi-Armed Bandit,\" \"Enhanced Retrieval-Augmented Generation,\" and \"on Knowledge Graphs.\" \n\nFirst, \"Retrieval-Augmented Generation\" (RAG) is a specific technique that combines retrieval from a database with generation, so that's a key term here. Then there's mention of \"Knowledge Graphs\" (KG), which are structured representations of information. The paper is using RAG in the context of knowledge graphs.\n\nThe other parts like \"Multi-Armed Bandit\" and \"Non-Stationary Environments\" suggest the paper is addressing dynamic environments where the system needs to adapt over time, possibly using reinforcement learning concepts. However, the core technologies being discussed are RAG and KG. \n\nSince the title explicitly mentions \"Retrieval-Augmented Generation\" and \"Knowledge Graphs,\" the primary topics here are RAG and KG. The question asks to choose one if it belongs to any of the listed topics. The title includes both RAG and KG, but the options are separate. The user might expect the most specific or primary one. However, the instructions say to respond with the topic name if it belongs to any. Since RAG is one of the options and the title mentions it directly, the answer should be RAG. Alternatively, if the focus is on the knowledge graph aspect, then KG. But the title says \"Enhanced Retrieval-Augmented Generation on Knowledge Graphs,\" which implies that RAG is the main method being enhanced, and it's applied on KGs. So the primary topic here is RAG, with KG as the application context. Therefore, the correct answer is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33380@AAAI"},
{"title": "ScoreNet: Consistency-driven Framework with Multi-side Information Fusion for Session-based Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"ScoreNet: Consistency-driven Framework with Multi-side Information Fusion for Session-based Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Session-based Recommendation\" suggests that the paper is about recommending items based on user sessions, which are sequences of interactions over time. That might relate to time-series since sessions are temporal. But wait, session-based recommendations often use sequential data, so maybe time-series is a possibility.\n\nThen there's \"Multi-side Information Fusion.\" \"Multi-side\" could imply combining different types of data or modalities. Multimodal research involves integrating multiple data types, like text, images, etc. But in recommendation systems, \"multi-side\" might refer to different aspects of the data, such as user, item, and session context. However, multimodal typically refers to different sensory inputs, so maybe not exactly that. But the term \"fusion\" does make me think of combining different sources, which could be multimodal.\n\n\"Consistency-driven Framework\" – not sure how that ties in. Maybe ensuring consistency across different parts of the model? Not directly pointing to any of the four topics.\n\nLooking at the four options again: time-series, multimodal, RAG, KG. RAG is Retrieval-Augmented Generation, which is more about combining retrieval with generation models, often in NLP. KG is Knowledge Graphs, which involve structured data and relationships. The title doesn't mention anything about knowledge graphs or retrieval-augmented generation. \n\nSo, between time-series and multimodal. Session-based recommendations often use sequential data (time-series), but the \"multi-side information fusion\" part might lean towards multimodal if they're combining different data types. However, in recommendation systems, \"multi-side\" could refer to user, item, and session features rather than different modalities. So maybe it's more about integrating different aspects within the same domain rather than different modalities. \n\nAlternatively, if \"multi-side\" refers to multiple modalities (like text and images), then it's multimodal. But the title doesn't specify different data types. The key term here is \"multi-side information fusion.\" If \"multi-side\" here means combining different types of information (e.g., user, item, session), it's more about integrating different features rather than different modalities. So maybe it's not multimodal. \n\nSession-based recommendations are typically time-series because they model sequences of user interactions. So the primary topic might be time-series. However, the paper's focus on fusion of multi-side information could be a method within time-series analysis. So the main topic would be time-series. \n\nWait, but the question is to choose between the four options. If the paper is about session-based recommendations using sequential data, then time-series. If it's about combining different data sources (modalities), then multimodal. The title mentions \"multi-side information fusion,\" which sounds like combining different aspects (user, item, session) but not necessarily different modalities. So maybe it's not multimodal. \n\nTherefore, the most likely answer is time-series. But I'm a bit uncertain because \"multi-side\" could imply multimodal. However, without explicit mention of different data types (like text, image, audio), it's safer to go with time-series.\n</think>\n\ntime-series", "url": "https://papers.cool/venue/33381@AAAI"},
{"title": "POI Recommendation via Multi-Objective Adversarial Imitation Learning", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"POI Recommendation via Multi-Objective Adversarial Imitation Learning.\" I need to figure out which of the given topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, POI stands for Points of Interest, so this is about recommending places like restaurants, parks, etc. The method mentioned is Multi-Objective Adversarial Imitation Learning. Let's break that down. Multi-objective suggests optimizing for multiple goals, which is common in recommendation systems. Adversarial Imitation Learning is a type of machine learning where a model learns by imitating expert behavior, using adversarial training. \n\nNow, looking at the possible topics. Time-series would involve data over time, like stock prices or weather. The title doesn't mention time or temporal data, so maybe not. Multimodal usually refers to using multiple data types, like text and images. The title doesn't mention different modalities. RAG is Retrieval-Augmented Generation, which combines retrieval and generation models, often in NLP. KG is Knowledge Graphs, which are structured data representations. \n\nThe paper's focus is on a specific learning method for recommendation, but none of the keywords in the title directly relate to time-series, multimodal, RAG, or KG. The method is about adversarial imitation learning, which is a machine learning technique but not one of the listed topics. So the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33382@AAAI"},
{"title": "Explicit and Implicit Examinee-Question Relation Exploiting for Efficient Computerized Adaptive Testing", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Explicit and Implicit Examinee-Question Relation Exploiting for Efficient Computerized Adaptive Testing.\" I need to figure out which of the four topics—time-series, multimodal, RAG, or KG—it belongs to.\n\nFirst, breaking down the title. The main focus seems to be on examinee-question relations in computerized adaptive testing. Adaptive testing usually involves adjusting questions based on the test-taker's responses, which is a form of personalized assessment. The terms \"explicit\" and \"implicit\" relations might refer to how the system models the interactions between the examinee and the questions. \n\nNow, looking at the possible topics. Time-series analysis deals with data over time, like stock prices or weather. This paper doesn't mention anything about time-based data, so probably not time-series. \n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The title doesn't mention different data modalities, so maybe not multimodal. \n\nRAG stands for Retrieval-Augmented Generation, which is a method in NLP where a model retrieves information from a database to generate answers. The paper's focus is on adaptive testing, which is more about item selection and user modeling rather than generating text based on retrieved data. So RAG might not fit here.\n\nKG is Knowledge Graphs, which are structured representations of information. If the paper is building a graph of examinee-question relationships, that could be a knowledge graph. However, the title mentions \"exploiting\" these relations for efficiency, which might involve modeling the relationships but not necessarily constructing a knowledge graph. \n\nAlternatively, the \"relations\" could be part of a knowledge graph structure, where examinees and questions are nodes with edges representing interactions. If they're explicitly modeling these relationships in a graph, then it's a KG. But if it's just using some form of relational data without a structured graph, maybe not. \n\nComputerized adaptive testing often uses item response theory or machine learning models to select questions. The mention of \"explicit and implicit\" relations might refer to different ways of modeling the interactions, perhaps using a graph structure to represent these relations. So, if they're using a knowledge graph to model examinee-question interactions, then the topic is KG. Otherwise, if it's just a relational model without a graph structure, it might not fit. \n\nGiven the title's emphasis on \"relations\" and \"exploiting\" them, it's possible they're using a knowledge graph approach to represent and utilize these relationships for efficient testing. Therefore, the topic might be KG. But I'm not entirely sure. Let me double-check. The other options don't seem to fit. Time-series is out. Multimodal is out. RAG is about retrieval and generation, which isn't the case here. So the most plausible is KG.\n</think>\n\nKG", "url": "https://papers.cool/venue/33383@AAAI"},
{"title": "DR-VAE: Debiased and Representation-enhanced Variational Autoencoder for Collaborative Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"DR-VAE: Debiased and Representation-enhanced Variational Autoencoder for Collaborative Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, let's break down the title. DR-VAE is a type of Variational Autoencoder (VAE), which is a generative model. The key parts here are \"Debiased\" and \"Representation-enhanced,\" and the application is \"Collaborative Recommendation.\" Collaborative recommendation is a common area in recommendation systems, where the model uses user-item interactions to make recommendations.\n\nNow, looking at the four options. Time-series would involve data that's sequential over time, like stock prices or weather data. The title doesn't mention anything about time or sequences, so maybe not time-series.\n\nMultimodal refers to using multiple types of data, like combining text, images, and audio. The title doesn't mention multiple data modalities, so probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's typically used in models that combine retrieval of information with generation, like in some NLP tasks. The title doesn't mention retrieval or generation, so RAG might not be it.\n\nKG is Knowledge Graph, which involves structured data representing entities and their relationships. The paper's focus is on collaborative recommendation, which is more about user-item interactions rather than structured knowledge graphs. Unless the VAE is being used to model a knowledge graph, but the title doesn't indicate that.\n\nSo, the paper is about a VAE model for collaborative filtering. None of the four topics (time-series, multimodal, RAG, KG) directly relate to this. Collaborative recommendation is a different area, perhaps under recommendation systems or machine learning, but not the specified topics. Therefore, the answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33385@AAAI"},
{"title": "M^3EL: A Multi-task Multi-topic Dataset for Multi-modal Entity Linking", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"M^3EL: A Multi-task Multi-topic Dataset for Multi-modal Entity Linking.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. The dataset is called M^3EL, which probably stands for something related to multi-task, multi-topic, and multi-modal. The key part here is \"Multi-modal Entity Linking.\" Entity Linking is a task where you link mentions of entities in text to their corresponding entries in a knowledge base. Now, \"multi-modal\" suggests that the dataset uses multiple types of data, like text and images or other modalities. \n\nLooking at the options: time-series deals with data over time, which doesn't seem relevant here. RAG (Retrieval-Augmented Generation) is about combining retrieval with generation models, which isn't directly mentioned. KG (Knowledge Graph) is related to structured data and entity linking, but the title specifically mentions \"multi-modal,\" which points more towards handling different data types. \n\nSo, the term \"multi-modal\" in the title directly corresponds to the multimodal topic. The dataset is designed for multi-modal entity linking, which involves integrating different modalities (like text and images) for the linking task. Therefore, the correct category here is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33386@AAAI"},
{"title": "UniPCGC: Towards Practical Point Cloud Geometry Compression via an Efficient Unified Approach", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"UniPCGC: Towards Practical Point Cloud Geometry Compression via an Efficient Unified Approach.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, time-series usually deals with data that's ordered in time, like stock prices over days or sensor data over time. The title mentions point cloud geometry compression. Point clouds are 3D data points, often used in things like 3D modeling or LiDAR data. Compression here is about reducing the size of that data. Time-series doesn't seem to fit because it's not about temporal data.\n\nNext, multimodal. That refers to combining multiple types of data, like text and images, or audio and video. The paper's title is about point cloud compression, which is a single data type. Unless the compression method uses multiple modalities, but the title doesn't mention that. So probably not multimodal.\n\nRAG stands for Retrieval-Augmented Generation. That's a technique where a model uses a retrieval system to get information and then generates a response. The title doesn't mention anything about retrieval or generation, so RAG seems unlikely.\n\nKG is Knowledge Graphs, which are structured representations of knowledge, often used for semantic reasoning. The paper is about compressing point cloud geometry, which is more about data compression algorithms rather than knowledge representation. So KG doesn't fit here either.\n\nSo none of the four topics seem to match. The paper is about point cloud compression, which is a different area. The answer should be \"none.\"\n</think>\n\nnone", "url": "https://papers.cool/venue/33387@AAAI"},
{"title": "MDFG: Multi-Dimensional Fine-Grained Modeling for Fatigue Detection", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"MDFG: Multi-Dimensional Fine-Grained Modeling for Fatigue Detection.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"Multi-Dimensional\" suggests that the model uses multiple dimensions or types of data. \"Fine-Grained Modeling\" implies detailed analysis. The application is \"Fatigue Detection,\" which could involve various data sources like physiological signals, maybe video for eye tracking, or other sensors.\n\nNow, looking at the possible topics. Time-series would involve data over time, like heart rate or EEG. Multimodal would mean combining different data types, like combining video and audio. RAG is Retrieval-Augmented Generation, which is more about using retrieved information to enhance model outputs, often in NLP. KG is Knowledge Graphs, which structure information in a graph format.\n\nThe title mentions \"Multi-Dimensional,\" which could point to multimodal if those dimensions are different data types. Fatigue detection might use multiple modalities, such as facial expressions, voice, and physiological signals. So \"Multi-Dimensional\" here might refer to combining different data sources, making it multimodal. The other terms like \"Fine-Grained Modeling\" don't directly relate to the other topics. Since there's no mention of time-series data specifically, or knowledge graphs, or retrieval-augmented generation, the most likely category is multimodal.\n</think>\n\nmultimodal", "url": "https://papers.cool/venue/33388@AAAI"},
{"title": "Towards S²-Challenges Underlying LLM-Based Augmentation for Personalized News Recommendation", "topic": "none", "raw_response": "<think>\nOkay, let's see. The title is \"Towards S²-Challenges Underlying LLM-Based Augmentation for Personalized News Recommendation.\" I need to figure out which of the four topics it belongs to: time-series, multimodal, RAG, or KG.\n\nFirst, breaking down the title. \"LLM-Based Augmentation\" suggests they're using Large Language Models for some kind of augmentation. \"Personalized News Recommendation\" is the application area. The \"S²-Challenges\" part might refer to specific challenges, maybe scalability or something else, but not sure. \n\nNow, looking at the options. Time-series would involve data over time, like stock prices or weather. Multimodal would involve multiple data types, like text and images. RAG is Retrieval-Augmented Generation, which combines retrieval of information with generation. KG is Knowledge Graphs, which are structured representations of knowledge.\n\nThe paper is about using LLMs for augmentation in news recommendation. If they're using retrieval to get information and then generating recommendations, that might be RAG. But the title doesn't explicitly mention retrieval. Alternatively, if they're combining different data sources (like text and user behavior), it could be multimodal. However, personalized news recommendation often uses user data over time, which could be time-series. But the key term here is \"LLM-Based Augmentation.\" \n\nRAG specifically involves using a retriever to get relevant documents and then a generator to create the output. If the augmentation here is about retrieving additional information to enhance the recommendation, then RAG makes sense. The title doesn't mention knowledge graphs, so KG is less likely. Time-series would require temporal data analysis, which isn't the focus here. Multimodal would need multiple modalities, which isn't specified. So the most likely is RAG.\n</think>\n\nRAG", "url": "https://papers.cool/venue/33389@AAAI"}
